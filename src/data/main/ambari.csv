issue_id,component,reporter,summary,description,affected_version,fixed_version,description_words,Surprising,Dormant,Blocker,Security,Performance,Breakage,file_count,files
12,,Eric Yang,Add additional transition states,For running a server (daemon)  the current states are: START and STARTED. It would be nice to have transition state: STARTING  and STOPPING.,0.1.0,0.1.0,23,0,0,0,0,0,0,0,
46,ambari-agent,Eric Yang,Preserve cluster id  blueprint name  and blueprint revision in agent local disk,After agent execute commands on behave of the controller  agent should store cluster id  blueprint name and blueprint revision in the local disk to keep track of the current deployment state on the agent.,0.1.0,0.1.0,34,0,0,0,0,0,0,0,
92,ambari-agent,Eric Yang,Agent should retry heartbeat message  if controller did not receive the heartbeat,If the heartbeat was not received correctly by the controller  then it should retry.,0.1.0,0.1.0,14,0,0,0,0,0,0,0,
103,ambari-server; ambari-web,Eric Yang,Remove agent entities beans from public schema xsd,Agent entities beans are located ambari-client: org.apache.ambari.common.rest.entities.agent. Hence  schema xsd generation for public rest api will include agent entities beans. We should move it to org.apache.ambari.common.rest.agent to exclude agent entities to expose to public.,0.1.0,0.1.0,34,0,0,0,0,0,0,0,
192,,Ramya Sunil,Check for NN safemode during restarts,There is no checks for safemode when we reconfigure the cluster.,0.9.0,0.9.0,11,1,0,0,0,0,0,2,CHANGES.txt;hmc/puppet/modules/hdp-hadoop/manifests/hdfs/service_check.pp;
198,ambari-server,Jitendra Nath Pandey,Dependency of templeton on hcat client,hcat client should be installed at the templeton server node.,0.9.0,0.9.0,10,1,0,0,0,0,0,2,CHANGES.txt;hmc/php/puppet/genmanifest/PuppetClassDependencies.php;
199,ambari-server,Jitendra Nath Pandey,Remove import of mysql puppet module from manifest.,Remove import of mysql puppet module from manifest because this module is deprecated.,0.9.0,0.9.0,13,1,0,0,0,0,0,2,CHANGES.txt;hmc/php/puppet/genmanifest/generateManifest.php;
202,,Ramya Sunil,Add check to verify jdk path after install,After the jdk install  we do not validate the path. This causes problems during service start in later stages.,0.9.0,0.9.0,19,1,0,0,0,0,0,2,CHANGES.txt;hmc/puppet/modules/hdp/manifests/java/package.pp;
207,ambari-server,Jitendra Nath Pandey,PHP Notice: Undefined variable: manifest in /usr/share/hmc/php/puppet/genmanifest/hostsConfig.php,Undefined variable used.,0.9.0,0.9.0,4,1,0,0,0,0,0,0,
208,,Hitesh Shah,Support filtering hosts based on discovery status,Api to get hosts should allow filtering out bad hosts,0.9.0,0.9.0,10,0,0,0,0,0,0,0,
217,,vitthal (Suhas) Gogate,Alert table on the right needs to be tied visually/verbally to the context/content it is displaying,Currently in Dashboard when service entry is clicked  right side alerts table caption does not indicate that it is showing alerts related to that service. So Cpation of the table should change indicating the corresponding service name.,0.9.0,0.9.0,37,1,0,0,0,0,0,0,
222,,vitthal (Suhas) Gogate,Remove the word alert from all the Nagios alerts descriptions.,IT is sort of redundant..,0.9.0,0.9.0,6,1,0,0,0,0,0,0,
226,,Suresh Srinivas,Make the daemon names and other field names consistent,Following names need to be consistent: Hdfs -&gt; HDFS Mapreduce -&gt; MapReduce Zookeeper -&gt; ZooKeeper HADOOP -&gt; Hadoop,0.9.0,0.9.0,20,1,0,0,0,0,0,0,
232,,Vikram Dixit K,Enable LZO should show checkbox instead of text,Currently the enable lzo option shows a text box that needs to be filled with true/false. Changing the UI element to checkbox.,0.9.0,0.9.0,22,1,0,0,0,0,0,0,
236,ambari-server,Jitendra Nath Pandey,Increase puppet agent timeout.,Puppet agent timeout should be increases as sometimes (possibly due to a bug in ruby) puppet master takes long time to compile and send back the catalog.,0.9.0,0.9.0,27,0,0,0,0,0,0,0,
237,ambari-server,Jitendra Nath Pandey,Refactor puppet kick loop to easily change retries and timeouts.,Refactor puppet kick loop to easily change retries and timeouts.,0.9.0,0.9.0,10,0,0,0,0,1,0,0,
245,ambari-server,Jitendra Nath Pandey,Support data cleanup if installation fails.,We need to support data cleanup so that a cluster can be re-installed in case of failures.,0.9.0,0.9.0,17,0,0,0,0,0,0,0,
247,,Varun Kapoor,Replace index.php with clusters.php,Like the title says: overwrite index.php with the contents of clusters.php  making sure to add a link to the AddNodesWizard as well.,0.9.0,0.9.0,22,0,0,0,0,0,0,0,
249,,Vikram Dixit K,Uninstall support from UI,Uninstall/wipeout support from UI.,0.9.0,0.9.0,4,0,0,0,0,0,0,0,
252,,Varun Kapoor,Remove 'Playground' files from HMC,There's a bunch of (temporary playground) files that got wrongly committed to the HMC codebase  so this is to remove all of them and get things into a cleaner state (at least on the face of things).,0.9.0,0.9.0,37,0,0,0,0,0,0,0,
253,,Ramya Sunil,Support uninstall state in mysql modules,Currently  there is no support for uninstall of mysql package.,0.9.0,0.9.0,10,0,0,0,0,0,0,0,
255,,Varun Kapoor,Rename/Relocate files as appropriate,There's some images in the html/ directory (that should be in images/)  there's .html files whose extension should be changed to .htmli  and such  that would be nice to clean up.,0.9.0,0.9.0,31,0,0,0,0,0,0,0,
256,,Ramya Sunil,Update hive config to enable authorization,In /etc/hive/conf/hive-site.xml&lt;property&gt; &lt;name&gt;hive.security.authorization.enabled&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;description&gt;enable or disable the hive client authorization&lt;/description&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;hive.security.authorization.manager&lt;/name&gt; &lt;value&gt;org.apache.hcatalog.security.HdfsAuthorizationProvider&lt;/value&gt; &lt;description&gt;the hive client authorization manager class name. The user defined authorization class should implement interface org.apache.hadoop.hive.ql.security.authorization.HiveAuthorizationProvider. &lt;/description&gt;&lt;/property&gt;In /etc/hive/conf/hive-env.sh  add -export HIVE_AUX_JARS_PATH=/usr/lib/hcatalog/share/hcatalog/hcatalog-0.4.0.jar,0.9.0,0.9.0,46,0,0,0,0,0,0,0,
257,site,Arpit Gupta,Manage services section will have any empty section when no client only components installed,On the manage services page we have a section for client only services that have no long running processes.If the user has no such component there is a heading but no content. Maybe we can hide the heading when no such service is present.,0.9.0,0.9.0,44,0,0,0,0,0,0,0,
262,site,Arpit Gupta,Init Wizard: Advanced Config validation errors can be bypassed,Make the Naigos password (and re-type password) different so as you cause a validation error.This will let the user move on to the next screen by ignoring all other validation errors on this page.,0.9.0,0.9.0,34,0,0,0,0,0,0,0,
264,site,Arpit Gupta,Nagios Admin Contact should be checked to ensure it is always an email address,,0.9.0,0.9.0,1,0,0,0,0,0,0,0,
274,,Ramya Sunil,Templeton data on hdfs needs to be readable by all users,Content of /user/templeton dir-bash-3.2$ hadoop dfs -ls /user/templetonFound 4 items-rw-r--r-- 3 templeton hdfs 107373 2012-05-14 19:53 /user/templeton/hadoop-streaming.jar-rw------- 3 templeton hdfs 35352096 2012-05-14 19:53 /user/templeton/hive.tar.gz-rw------- 3 templeton hdfs 47909478 2012-05-14 19:53 /user/templeton/pig.tar.gz-rw------- 3 templeton hdfs 127652 2012-05-14 19:53 /user/templeton/ugi.jarOnly templeton user can use the jars,0.9.0,0.9.0,50,0,0,0,0,0,0,0,
276,site,Suresh Srinivas,Update HDFS parameter configuration description,Updating the short description and tooltip long description as follows:Changing the text that affects WebUI as follows: filesystem -&gt; file system HDFS Append Enabled -&gt; Append enabled HDFS WebHDFS Enabled -&gt; WebHDFS enabled Hadoop maximum Java heap size -&gt; Hadoop maximum Java heap size (MB)  Java Heap Size for slave daemons -&gt; Maximum Java heap size for daemons such as Balancer in MB (-Xmx)   NameNode maximum Java heap size -&gt; NameNode initial Java heap size (MB)  Java Heap Size for NameNode -&gt; Initial and minimum Java heap size for NameNode in MB (-Xms)   Hadoop Young Generation heap size -&gt; NameNode new generation size (MB)  Maximum size for New Generation for java heap size -&gt; Default size of Java new generation in MB for NameNode (-XX:NewSize)   DataNode Java heap size -&gt; DataNode maximum Java heap size (MB)  Java Heap Size for DataNode -&gt; Maximum Java heap size for DataNode in MB (-Xmx),0.1.0; ambari-186,0.9.0,163,0,0,0,0,0,0,0,
280,,Vikram Dixit K,Cleanup of utilities,We need an api for the UI to figure out the status of the cluster.,0.9.0,0.9.0,15,0,0,0,0,0,0,0,
283,,Vikram Dixit K,Fixup review and deploy rendering,Currently render of the review and deploy page is messy.,0.9.0,0.9.0,10,0,0,0,0,0,0,0,
287,ambari-server; ambari-web,Vikram Dixit K,Add link to uninstall on index page,Uninstall link is now hooked into the index page.,0.9.0,0.9.0,9,0,0,0,0,0,0,0,
290,ambari-server,Jitendra Nath Pandey,Comment in addNodesWizardInit.js.,Comment in addNodesWizardInit.js.,0.9.0,0.9.0,3,0,0,0,0,0,0,0,
292,ambari-web,Jitendra Nath Pandey,HTML being spewed in the Review+Deploy page.,HTML being spewed in the Review+Deploy page.,0.9.0,0.9.0,7,0,0,0,0,0,0,0,
300,,Yusaku Sako,Change the status message (success/error) location so that it shows below the page summary box  rather than above  more better visibility,,0.9.0,0.9.0,1,0,0,0,0,0,0,0,
302,,Ramya Sunil,regionservers config in the hbase only has localhost in it,/etc/hbase/conf/regionserver should correctly populate the slaves list,0.9.0,0.9.0,7,0,0,0,0,0,0,0,
304,,Vinod Kumar Vavilapalli,Upgrade to yui-3.5.1,,0.9.0,0.9.0,1,0,0,0,0,0,0,0,
310,,Yusaku Sako,Externalize message resources for the welcome page.  Update styles on various pages.,,0.9.0,0.9.0,1,0,0,0,0,0,0,0,
312,,Hitesh Shah,Uninstall's wipe flag should be correctly passed to puppet,,0.9.0,0.9.0,1,0,0,0,0,0,0,0,
316,,Vinod Kumar Vavilapalli,Grid mount points page doesn't let one pass with only a custom mount point,,0.9.0,0.9.0,1,0,0,0,0,0,0,0,
319,ambari-server,Jitendra Nath Pandey,Scale puppet master to large number of nodes.,Scale puppet master to large number of nodes.,0.9.0,0.9.0,8,0,0,0,0,0,0,0,
323,ambari-server,Vikram Dixit K,During any process in the cluster initialization wizard  if the user goes back to the '1 Create Cluster' tab  the user is stuck.,,0.9.0,0.9.0,1,0,0,0,0,0,0,0,
326,ambari-server,Jitendra Nath Pandey,Dependencies should be added only during install phase,Host level dependencies are being set in running stage as well  which is redundant. It can be assumed that dependencies were installed at install stage.,0.9.0,0.9.0,25,0,0,0,0,0,0,0,
330,,Vinod Kumar Vavilapalli,Provide a way to resume if browser crashes/is closed during the deploy-in-progress,Currently when the browser is closed one cannot view the install in progress. They will have to look at the logs on the hmc machine to figure out whats going on. It would be nice if we can provide a way to get back to the install progress.,0.9.0,0.9.0,48,0,0,0,0,0,0,0,
335,,Ramya Sunil,Redundant downloads even though the artifacts are already installed,Artifacts (such as mysql-connector.zip  hive.tar.gz  pig.tar.gz  ext.zip) are being downloaded even though they are previously installed leading to additional execution time.,0.9.0,0.9.0,21,0,0,0,0,0,0,0,
338,ambari-server,Vikram Dixit K,Cluster status update needs to happen for all stages of installation wizard.,Cluster status should be updated in db for each stage of the installation wizard. This is used to enable restart of browser and also showing status of the cluster on the index page.,0.9.0,0.9.0,33,0,0,0,0,0,0,0,
339,ambari-web,Vikram Dixit K,Making transitionToNextStage more robust,If the currentStage is null  we should not proceed with a transition.,0.9.0,0.9.0,12,0,0,0,0,0,0,0,
349,ambari-server; ambari-web,Vikram Dixit K,Logging in case of error during uninstall needs to be fixed.,Logs disappear post uninstall because the transaction is also cleaned from the db.,0.9.0,0.9.0,13,0,0,0,0,0,0,0,
352,,Yusaku Sako,Add flow control - force redirects to appropriate pages based on cluster configuration status for better usability,If no cluster has been set up yet  redirect to the welcome page.If a cluster is being configured (but has not gone thru deployment)  redirect to Step 1 of the cluster init wizard.If a cluster is being deployed  redirect to the deployment progress page.If a cluster has gone thru deployment but failed  redirect to the re-install page.If a cluster has gone thru deployment and succeed  do not perform any forced redirect.,0.9.0,0.9.0,71,0,0,0,0,0,0,0,
357,,Yusaku Sako,Redesign master service assignment page so that it takes up less vertical space,,0.9.0,0.9.0,1,0,0,0,0,0,0,0,
362,ambari-server,Vikram Dixit K,Create lock file as part of rpm install,Lock file is being created as part of create cluster. This is brittle and needs to be done as part of the rpm install.,0.9.0,0.9.0,24,0,0,0,0,0,0,0,
366,,Varun Kapoor,Package up the fonts/ subdirectory in the HMC RPM,The new fonts/ subdirectory used for the buttons on the ManageServices page isn't packaged up.,0.9.0,0.9.0,15,0,0,0,0,0,0,0,
369,,Yusaku Sako,Improve Service Management page and general popup styling,,0.9.0,0.9.0,1,0,0,0,0,0,0,0,
371,ambari-server,Jitendra Nath Pandey,Mysql packages not being sent during install and uninstall,Mysql packages not being sent during install and uninstall.,0.9.0,0.9.0,9,0,0,0,0,0,0,0,
377,ambari-server,Jitendra Nath Pandey,Uninstall does not handle component dependencies.,Uninstall does not handle component dependencies.,0.9.0,0.9.0,6,0,0,0,0,0,0,0,
386,,Hitesh Shah,On Single Node install when install all the components the recommended num for Map/Reduce Tasks is too high,Use lower count of maps/reduce slots for a single node install.,0.9.0,0.9.0,11,0,0,0,0,0,0,0,
393,,Mahadev konar,ZooKeeper myid files not existent on ZK install.,ZooKeeper myid files not existent on ZK install.,0.9.0,0.9.0,8,0,0,0,0,0,0,0,
394,ambari-server,Vikram Dixit K,Add nodes fails to find node in db,Host not found in db error on assign nodes page,0.9.0,0.9.0,11,0,0,0,0,0,0,0,
399,,Yusaku Sako,Cannot uninstall - the page hangs with the spinning icon,,0.9.0,0.9.0,1,0,0,0,0,0,0,0,
401,ambari-server,Jitendra Nath Pandey,Manual config changes for nn get reset on stop/start from hmc,Manual config changes for nn get reset on stop/start from hmc,0.9.0,0.9.0,11,0,0,0,0,0,0,0,
402,ambari-server,Vikram Dixit K,Completing successful add node takes one to initialize cluster page starting from scratch,,0.9.0,0.9.0,1,0,0,0,0,0,0,0,
404,,Yusaku Sako,Unify the top nav for both Monitoring and Cluster Management,,0.9.0,0.9.0,1,0,0,0,0,0,0,0,
414,,Mahadev konar,Add rpm spec for hmc agent.,Add rpm spec for hmc agent.,0.9.0,0.9.0,6,0,0,0,0,0,0,0,
415,,Hitesh Shah,Reset service back to original state after reconfiguration,,0.9.0,0.9.0,1,0,0,0,0,0,0,0,
420,,Yusaku Sako,Improve style on error log popups,,0.9.0,0.9.0,1,0,0,0,0,0,0,0,
426,,Ramya Sunil,Reinstall of cluster after failure to install results in failure,According to Bikas:I tried to install a single node cluster. That failed for some random issue.I was presented an option to reinstall.I clicked on that option and it asked me to uninstall.I chose uninstall and wipe data option.Uninstall failed.This happened because the install did not complete in the first place.Thu May 24 17:45:28 -0400 2012 /Stage17/Hdp-oozie::Service/Hdp-oozie::Service::Createsymlinks/usr/lib/oozie/oozie-server/lib/mapred-site.xml/File/usr/lib/oozie/oozie-server/lib/mapred-site.xml/ensure (err): change from absent to present failed: Could not set 'present on ensure: No such file or directory - /usr/lib/oozie/oozie-server/lib/mapred-site.xml at /etc/puppet/agent/modules/hdp-oozie/manifests/service.pp:61,0.9.0,0.9.0,78,0,0,0,0,0,0,0,
429,,Mahadev konar,Fix bug with jmx parsing on HBase.,Fix bug with jmx parsing on HBase.,0.9.0,0.9.0,7,0,0,0,0,0,0,0,
433,ambari-server,Vikram Dixit K,Using service stop instead of killall for uninstall,,0.9.0,0.9.0,1,0,0,0,0,0,0,0,
435,ambari-server,Vikram Dixit K,Uninstall needs to update status for failure.,This is to enable the routing layer to redirect appropriately.,0.9.0,0.9.0,10,0,0,0,0,0,0,0,
442,,Ramya Sunil,Duplicate definition: Class[Hdp-hbase::Regionserver::Enable-ganglia],Duplicate definition: Class&#91;Hdp-hbase::Regionserver::Enable-ganglia&#93; is already defined; cannot redefine at /etc/puppet/agent/modules/hdp-ganglia/manifests/monitor.pp:37 on node ip-10-64-19-248.ec2.internal,0.9.0,0.9.0,14,0,0,0,0,0,0,0,
449,,Yusaku Sako,Post cluster install/deploy the URL hmc/html/initializeCluster.php should be disabled,Install a cluster. Then go to http://&lt;host&gt;/hmc/html/initializeCluster.php URL. You get a page enter cluster name. If you enter a cluster name  existing install is wiped out. We need to disable this URL on an installed cluster.Only way to enable this should be uninstall.,0.9.0,0.9.0,43,0,0,0,0,0,0,0,
450,,Yusaku Sako,Boldify/Redify restart HMC message when nagios/ganglia is on the hmc host,,0.9.0,0.9.0,1,0,0,0,0,0,0,0,
455,,vitthal (Suhas) Gogate,nagios shows service status critical if hbase is not installed,,0.9.0,0.9.0,1,0,0,0,0,0,0,0,
466,ambari-server; ambari-web,Vikram Dixit K,Add nodes page alerts removed in case of adding duplicate nodes,Alerts that are being shown needs to be changed to be compatible with current implementation of showing errors. A link now appears to 'Show the duplicate nodes' which shows the duplicate nodes.,0.9.0,0.9.0,32,0,0,0,0,0,0,0,
467,,Mahadev konar,Fix hive stop to escape $.,,0.9.0,0.9.0,1,0,0,0,0,0,0,0,
468,,Yusaku Sako,Post-Install Add Nodes - update progress title and success/error messages to reflect what it's actually doing/has done,,0.9.0,0.9.0,1,0,0,0,0,0,0,0,
475,,Yusaku Sako,Add missing JS file for making post cluster install Add Nodes work,,0.9.0,0.9.0,1,0,0,0,0,0,0,0,
482,,Yusaku Sako,Show the same welcome page to the user if the user starts configuring a cluster but has not started deploy yet,,0.9.0,0.9.0,1,0,0,0,0,0,0,0,
486,,Yusaku Sako,Add Node installs MySQL Server for Hive,Adding slave nodes post cluster install will install MySQL Server if Hive was selected as a service at the time of cluster installation.,0.9.0,0.9.0,24,0,0,0,0,0,0,0,
488,,Yusaku Sako,Manage service needs a way to recover from terminated browser sessions,We need to block users from being able to start/stop services when we have a batch of start/stop activities are already in progress.Do something similar to deployment progress display and bring the user back to that modal status display which will end when we detect success/failure.,0.9.0,0.9.0,46,0,0,0,0,0,0,0,
491,,Yusaku Sako,Service Reconfiguration screens should respect the 'reconfigurable' attributes set in ConfigProperties table,Some service config parameters are editable (can be customized on initial install)  but cannot be reconfigured post cluster install.This info is stored in ConfigProperties table  but the Service Reconfiguration screens are allowing these non-reconfigurable parameters to be changed.,0.9.0,0.9.0,38,0,0,0,0,0,0,0,
492,,Hitesh Shah,make support for os check a bit more robust,,0.9.0,0.9.0,1,0,0,0,0,0,0,0,
493,,Hitesh Shah,Add rack_info as column in Hosts table,,0.9.0,0.9.0,1,0,0,0,0,0,0,0,
494,,Mahadev konar,Fix node assignments not not allow slaves on master.,,0.9.0,0.9.0,1,0,0,0,1,0,0,0,
501,,Yusaku Sako,Speed up page load/reload times,,0.9.0,0.9.0,1,0,0,0,0,0,0,0,
508,,Varun Kapoor,Support Resume For Add Nodes,Just like for Manage Services + Deploy + Uninstall.,0.9.0,0.9.0,9,0,0,0,0,0,0,0,
510,,Yusaku Sako,Modify the router to force redirection to 'Add Nodes Progress' popup,,0.9.0,0.9.0,1,0,0,0,0,0,0,0,
512,,Mahadev konar,Fix puppet manifests for tarball downloads via rpms.,,0.9.0,0.9.0,1,0,0,0,0,0,0,0,
519,ambari-server,Vikram Dixit K,update to fix the ganglia monitor_and_server anchor problem,update to fix the ganglia monitor_and_server anchor problem,0.9.0,0.9.0,8,0,0,0,0,0,0,0,
528,,Ramya Sunil,Fix oozie smoke test failure,Oozie smoke test failing with 'Error: E0301 : E0301: Invalid resource &#91;usr/lib/oozie/conf&#93;',0.9.0,0.9.0,13,0,0,0,0,0,0,0,
529,,Hitesh Shah,Fix Advanced Config: HDFS reserved space is in bytes. Too many bytes to count.,Simplify user input.,0.9.0,0.9.0,3,0,0,0,0,0,0,0,
539,,Hitesh Shah,Create a spec file with less dependencies for HMC,Simplify process for users that want to use different dependencies for PHP and Ruby.e.g PHP-5.3  ruby-1.8.7,0.9.0,0.9.0,16,0,0,0,0,0,0,0,
543,infra,Vikram Dixit K,Rpm naming needs to be corrected.,Rpm naming needs to be corrected.,0.9.0,0.9.0,6,0,0,0,0,0,0,0,
544,,Ramya Sunil,Templeton configs for pig archive not correct in HMC,From Arpit:The configs for pig in templeton are wrong.The deployed configs are&lt;property&gt; &lt;name&gt;templeton.pig.archive&lt;/name&gt; &lt;value&gt;hdfs:///apps/templeton/&lt;/value&gt; &lt;description&gt;The path to the Pig archive.&lt;/description&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;templeton.pig.path&lt;/name&gt; &lt;value&gt;/pig-0.9.2/bin/pig&lt;/value&gt; &lt;description&gt;The path to the Pig executable.&lt;/description&gt; &lt;/property&gt;They are missing the pig tar ball. For example they should be&lt;property&gt; &lt;name&gt;templeton.pig.archive&lt;/name&gt; &lt;value&gt;hdfs:///apps/templeton/pig.tar.gz&lt;/value&gt; &lt;description&gt;The path to the Pig archive.&lt;/description&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;templeton.pig.path&lt;/name&gt; &lt;value&gt;pig.tar.gz/pig-0.9.2/bin/pig&lt;/value&gt; &lt;description&gt;The path to the Pig executable.&lt;/description&gt; &lt;/property&gt;So both the properties are missing 'pig-0.9.2.tar.gz',0.9.0,0.9.0,79,0,0,0,0,0,0,0,
546,,Hitesh Shah,Puppet fails to install 32-bit JDK properly on RHEL6,mkdir -p /usr/jdk32 ; chmod +x /tmp/HDP-artifacts//jdk-6u31-linux-i586.bin; cd /usr/jdk32 ; echo A | /tmp/HDP-artifacts//jdk-6u31-linux-i586.bin -noregister 2&gt;&amp;1Unpacking...Checksumming...Extracting.../var/www/html/downloads/jdk-6u31-linux-i586.bin: ./install.sfx.1794: /lib/ld-linux.so.2: bad ELF interpreter: No such file or directoryFailed to extract the files. Please refer to the Troubleshooting section ofthe Installation Instructions on the download page for more information.Puppet should ensure glibc.i686 is installed before trying to install jdk.,0.9.0,0.9.0,56,0,0,0,0,0,0,0,
547,,Hitesh Shah,Change os type check during node bootstrap to allow RHEL6 or CentOS6 nodes,hmc/php/frontend/addNodes/verifyAndUpdateNodesInfo.php hardcodes checks to only allow rhel5 or centos5 nodes.,0.9.0,0.9.0,10,0,0,1,0,0,0,0,
548,,Hitesh Shah,Puppet agent install script should use correct epel repo,hmc/ShellScripts/puppet_agent_install.sh hardcodes to epel-release rpm for CentOS-5.4. Should be more intelligent to handle different OS types.,0.9.0,0.9.0,16,0,0,1,0,0,0,0,
550,,Yusaku Sako,Add support to jump to a specified state in the wizard for development purposes,,0.9.0,0.9.0,1,0,0,0,0,0,0,0,
552,,Vinod Kumar Vavilapalli,Update README to point to trunk,We need to fix the README to point to trunk after the merge of ambari-186 branch.,0.9.0,0.9.0,16,0,0,0,0,0,0,0,
565,,Yusaku Sako,Remove YUI source files from SVN,Currently YUI 3.5.1 source files are in SVN.We don't really need to have them checked into SVN as we don't track changes. We are pre-concatenating and minifying the YUI js files  so we don't need the files to run Ambari anyhow.We should just remove them from SVN and instead just checkin the tarball.,0.9.0,0.9.0,53,0,0,0,0,0,0,0,
566,,Yusaku Sako,Update documentation,Modify pom.xml to create output files under ../site  rather than ./target.Make minor wording modifications.,0.9.0,0.9.0,14,0,0,0,0,0,0,0,
569,,Hitesh Shah,Nagios install fails on RHEL6,Puppet layer  when trying to install nagios  tries to install php-pecl-json when it is not needed and fails when trying to do so. On RHEL6  php-5.3 is default which has the json module built into it.,0.9.0,0.9.0,36,0,0,1,0,0,0,0,
570,,Yusaku Sako,Consolidate head tags for organization and combine CSS files for faster load,,0.9.0,0.9.0,1,0,0,0,0,1,0,0,
573,,Hitesh Shah,Puppet error: Cannot reassign variable zookeeper_hosts at modules/hdp/manifests/params.pp:47,Seems like a typo: $zookeeper_hosts = hdp_default('zookeeper_hosts')Should be $public_zookeeper_hosts,0.9.0,0.9.0,9,0,0,0,0,0,0,0,
576,,Jaimin D Jetly,In Custom config for Nagios: emails with multiple periods before the '@' fails validation,,0.9.0,0.9.0,1,0,0,0,0,0,0,0,
578,,Yusaku Sako,Custom Config page: don't allow form submission if there are client-side validation errors,Currently the button looks disabled when there are client-side validation errors  but it is clickable. This is a problem because there is no server-side validation to make sure that the passwords match.,0.9.0,0.9.0,32,0,0,0,1,0,0,0,
581,,Jaimin D Jetly,special characters in hosts files created on some common windows editors causes issues,,0.9.0,0.9.0,1,0,0,0,0,0,0,0,
587,ambari-agent; ambari-server; ambari-web; documentation; infra; site; test,Vikram Dixit K,Rat compliance patch,Adding apache license to all the files within Ambari for rat tool compliance.,0.9.0,0.9.0,13,0,0,0,0,0,0,0,
588,,Yusaku Sako,Externalize the manager service name and point the Help link to a valid URL,The master role assignment page (Step 5 of install) and the cluster topology summary page are referencing the manager service name as 'HMC Server'. This needs to be changed to 'Ambari' server.The post-install success message on a single-node install has the same issue.Currently  the Help link in the top nav launches a new tab and loads the page that the user is on. Instead  load the Help page on Ambari project website (for now  we'll point it to the Install Guide as a placeholder).,0.9.0,0.9.0,84,0,0,0,0,0,0,0,
591,,Yusaku Sako,License header for PHP files should use PHP comments  not HTML comments,Some PHP files have the HTML-style comments. This is problematic sincethe license headers are becoming part of the HTML response. Worse yet  the headers are repeated multiple times in the response. This can also cause unexpected behavior.,0.9.0,0.9.0,37,0,0,0,0,0,0,0,
592,,Vinod Kumar Vavilapalli,Add a link to NOTICE file on every page,This is so that stuff with different compatible licenses can be attributed appropriately.,0.9.0,0.9.0,13,0,0,0,0,0,0,0,
597,,Mahadev konar,Remove /usr/bin/php dependency from the rpm's,,0.9.0,1,1,0,0,0,0,0,0,0,
600,,Hitesh Shah,Fix lzo installs to work correctly on RHEL6,,0.9.0,1,1,0,0,1,0,0,0,0,
607,,Hitesh Shah,Increase puppet timeouts to handle single-node installs timing out,,0.9.0,1,1,0,0,0,0,1,0,0,
614,,Yusaku Sako,The database set up script has a duplicate definition of AmbariConfig so install fails,,1,1,1,0,0,0,0,0,0,0,
615,,Yusaku Sako,Eliminate redundant and unused definition for the columns in the table ConfigProperties,ConfigProperties table has a column named 'display_type'.There's also a JSON-encoded 'display_attributes' column.The 'display_attributes' column has the attributes 'isPassword'  'displayType'  and 'noDisplay'. This is duplicate information is already stored by the 'display_type' column so these attributes are not needed.Upon inspecting the code  these attributes are not used so changing them have no effect. We should simply get rid of these attributes.,0.9.0,1,60,0,0,0,0,0,0,0,
628,,Ashish Singh,hdp-nagios and hdp-monitoring has wrong configuration file location  also owner:group permissions are wrong.,Suse environment has wrong configuration location for hdp-dashboard and hdp-nagios. Also  owner:group permissions were wrongly set to root:root instead of 'wwwrun' and group is 'www,0.9.0,1,25,0,0,0,1,0,0,0,
633,,Yusaku Sako,Fix invalid HTML markup on Monitoring Dashboard,,0.9.0,1,1,0,0,0,0,0,0,0,
635,,Yusaku Sako,Add Nodes Progress: for partial failure that lets the user continue  display an orange bar rather than a red bar in the progress popup,,0.9.0,1,1,0,0,0,0,0,0,0,
636,,Yusaku Sako,Support for Hadoop Security (front-end changes),,0.9.0,1,1,0,0,0,0,0,0,0,
638,,Yusaku Sako,Weirdness with Custom Config page when the user goes back to previous stages,Issue 1. Going back and forth between different stages in the Cluster Install Wizard  it is possible to get into a state where Custom Config form has the submit button disabled but no field errors are shown.Steps to replicate: Go up to Stage 6  but do not submit the form Go back to Stage 3 Go up to Stage 6 again. No field errors are shown when they should be.Issue 2. Custom Config stage is skipped once you get to 'Review and Deploy' and go back to a stage preceding Custom Config.Steps to replicate: Go thru the Cluster Install Wizard up to Stage 7 ('Review and Deploy')  but do not submit the form. Go back to Stage 4 or 5. Once you submit the form on Stage 5  Stage 6 is skipped and goes directly to Stage 7. If you go back to Stage 3 or earlier  then Stage 6 will not be skipped.,0.9.0,0.9.0; 1.0,154,0,0,0,0,0,0,0,
668,,Hitesh Shah,Ambari should install yum priorities on all nodes to ensure main repo is picked first,Depending on which main hadoop repo is used to setup the cluster  sometimes  wrong packages may be pulled from add-on repos even if the main repo has a higher priority and has the same package. This can create problems by incompatible dependencies getting installed at times.,0.9.0,0.9.0; 1.0,47,0,0,0,0,0,0,0,
675,,Hitesh Shah,Make puppet generate more logs on command failures,,0.9.0,0.9.0; 1.0,1,0,0,0,0,0,0,0,
689,,Mahadev konar,Fix ambari agent init.d scripts and the bootstrapping.,,0.9.0,0.9.0,1,0,0,0,0,0,0,0,
701,,Hitesh Shah,Ambari does not handle a pre-setup user-supplied Hive Metastore,Ambari treats a Hive Metastore as something that it still needs to install and setup even though it may not have the necessary permissions to do so.,0.9.0,1.0; 0.9.1,28,0,0,0,0,0,0,0,
1072,ambari-web,Srimanth Gunturi,Change text on alerts 'about XX hours ago',Alerts should have text like :OK for about 17 hoursWARN for about 17 hoursCRIT for about 17 hours,1.2.0,1.2.0,18,1,0,0,0,0,0,0,
1081,ambari-web,Srimanth Gunturi,HDFS disk capacity on dashboard is seen as negative number,Sometimes disk capacity calculations end up in negative numbers.,1.2.0,1.2.0,9,1,0,0,0,0,0,0,
1085,ambari-web,Yusaku Sako,Remove files from ambari-web that were not meant to be checked in,ambari-web/node_modules  ambari-web/public  ambari-web/ambari.iml were not meant to be checked in. Must remove.,1.2.0,1.2.0,12,0,0,0,0,0,0,0,
1092,ambari-web,Srimanth Gunturi,dashboard > Summary > capacity pie chart keeps changing colors,,1.2.0,1.2.0,1,0,0,0,0,0,0,0,
1096,ambari-web,Srimanth Gunturi,Create heatmap legend entries for missing data/invalid hosts,Currently we dont fill anything which is ambiguous.,1.2.0,1.2.0,8,1,0,0,0,0,0,0,
1098,ambari-web,Srimanth Gunturi,Switching services does not update various UI elements,When you switch services in the UI  sometimes alerts are mismatched compared to selected service. Also the highlights in left-bar are not working.,1.2.0,1.2.0,23,1,0,0,0,0,0,0,
1102,ambari-web,ARUN KUMAR KANDREGULA,Error handling when errors are encountered during preparation for deploy,Currently  if any errors are encountered during preparation for deploy  the user is taken to the deploy page and the hosts will be shown as 'Waiting' but nothing happens. This is bad UX.At a minimum  we should prevent the user from proceeding and display an appropriate error message if any error is encountered after 'Deploy' is clicked  but before we transition to Step 9.We should also think about how a user can recover from this situation.At this point  the deploy has not initiated  but certain API calls may have succeeded  so we may have incomplete info in the database. Currently there's no convenient way to 'rollback'.We can either ask the user to clean the slate by reinitializing the database and try again (should succeed if the original problem was temporary).We can also build more logic in the UI to retry  check if records already exist  etc...,1.2.0,1.2.0,146,1,0,0,0,0,0,0,
1103,ambari-web,ARUN KUMAR KANDREGULA,Need to be able to reliably recover from the case when the browser is closed during deploy (Step 8 post submission  Step 9) of the wizard,Need to be able to reliably recover from the case when the browser is closed during deploy (Step 8 post submission  Step 9) of the wizard.Even after submitting  Step 10  its taking to Step 9 after browser restart. Ideally it should take to monitoring page.,1.2.0,1.2.0,45,1,0,0,0,0,0,0,
1106,ambari-web,Jaimin D Jetly,User-specified custom configs (such as hdfs-site.xml overrides) should be persisted to maintain what the user specified,,1.2.0,1.2.0,1,0,0,0,0,0,0,0,
1113,ambari-web,ARUN KUMAR KANDREGULA,Install Wizard: Confirm host stuck at Preparing stage,With the install wizard went to assign slaves page successfully  returned back to Welcome page  reentered data and then the UI got stuck at Confirm hosts page.,1.2.0,1.2.0,27,0,0,0,0,0,0,0,
1115,ambari-web,Srimanth Gunturi,Host component live status is broken,When datanode is stopped on a host  its status keeps jumping.,1.2.0,1.2.0,11,0,0,0,0,0,0,0,
1123,ambari-web,Srimanth Gunturi,Ambari heatmaps and host information shows infinity for disk space used,When cluster is started after install  it has disk_total of null which results in Infinity.,1.2.0,1.2.0,16,1,0,0,0,0,0,0,
1125,ambari-web,Srimanth Gunturi,Graphs 'degrade' over time,Leave a page with graphs open for several minutes.The graphs become really coarse.It probably has something to do with the fact that Ganglia only provides 6-minute averages beyond the first 61 minutes (first 61 minutes  Ganglia keeps 15-second samples) and we may not be exactly querying for the last 60 minutes.,1.2.0,1.2.0,51,0,0,0,0,0,0,0,
1142,ambari-web,ARUN KUMAR KANDREGULA,On Notification Popup  clicking 'go to nagios UI' doesn't load nagios UI,1) Cause notification to occur (for example  stop oozie)2) On dashboard  click notification icon3) On the notification popup  click 'go to nagios web UI'4) nothing happens.This issue is on IE9  Safari and Chrome. Works fine on Firefox.,1.2.0,1.2.0,37,0,0,0,0,0,0,0,
1143,ambari-web,ARUN KUMAR KANDREGULA,tmpfs filesystem being added to the list in the dir used by Ambari,I saw this on a sles cluster. On EC2 they have a tmpfs mounted and Ambari picked it up.Not sure what the ideal solution is but i feel tmpfs should not be included in the available mount points.Also the tmpfs is being used in various directories that will have to change during the install.Attached screenshots.,1.2.0,1.2.0,55,0,0,0,0,0,0,0,
1150,ambari-web,Yusaku Sako,Installer Wizard - Retry feature in Deploy step (Step 9) is broken,,1.2.0,1.2.0,1,0,0,0,0,0,0,0,
1151,ambari-web,Yusaku Sako,Reconfigure fails silently; it's not firing any API calls due to a JS error,,1.2.0,1.2.0,1,0,0,0,0,0,0,0,
1153,ambari-web,Yusaku Sako,Host jams in status 'Preparing' if host name is wrong,,1.2.0,1.2.1,1,0,0,0,0,0,0,0,
1154,ambari-web,Yusaku Sako,The check boxes to check/uncheck one of the members in a multi artifact graphs is not very readable. It should be more apparent on which one the user clicked on,,1.2.0,1.2.0,1,0,0,0,0,0,0,0,
1159,ambari-web,Yusaku Sako,Check the log/run dir locations to make sure its an abs path,,1.2.0,1.2.0,1,0,0,0,0,0,0,0,
1164,,Mahadev konar,Disk Info Metrics and memory usage sometimes do not show up for an hour or so.,Disk Info Metrics and memory usage sometimes do not show up for an hour or so.,1.2.0,1.2.2,16,0,0,0,0,0,0,0,
1181,ambari-web,Yusaku Sako,Clean up table header UI for sorting and filter clear 'x' for Hosts table,,1.2.0,1.2.3,1,0,0,0,0,0,0,0,
1182,ambari-web,Yusaku Sako,Clean up table header UI for sorting and filter clear 'x' for Jobs table,,1.2.0,1.2.1,1,0,0,0,0,0,0,0,
1184,ambari-web,Yusaku Sako,After adding hosts  the host count shown in the Dashboard is incorrect,,1.2.0,1.2.1,1,0,0,0,0,0,0,0,
1190,ambari-web,Yusaku Sako,Detailed log view dialogs are not center-aligned,,1.2.0,1.2.1,1,0,0,0,0,0,0,0,
1196,ambari-web,Yusaku Sako,Automatically update host-level popup info/logs,For host-level popup info/logs that appear during the deploy step (Step 9) of the Install and Add Hosts Wizards  the information shown is not automatically updated based on the latest values in the models when the background poller updates the models.Currently  the user needs to close the popup and then re-open to see the updated info.,1.2.0,1.2.1,56,0,0,0,0,0,0,0,
1207,,Mahadev konar,Remove /hdp as the httpd conf for any of the nagios urls - should replace it with ambarinagios or something else.,Remove /hdp as the httpd conf for any of the nagios urls - should replace it with ambarinagios or something else.,1.2.0,1.2.1,21,0,0,0,0,0,0,0,
1210,,Mahadev konar,Allow capacity scheduler to be attached to host role configs for CS configurability in the API's.,Allow capacity scheduler to be attached to host role configs for CS configurability in the API's.,1.2.0,1.2.1,16,0,0,0,0,0,0,0,
1214,ambari-web,Yusaku Sako,In any starts fails  'warn' the host and the overall install,If any service start fails  'warn' the host and 'warn' the overall install.Allow the other start tasks to complete.Allow the user to click next.,1.2.0,1.2.1,24,0,0,0,0,0,0,0,
1216,ambari-web,Yusaku Sako,Add filters module,,1.2.0,1.2.1,1,0,0,0,0,0,0,0,
1218,ambari-web,Yusaku Sako,Refactor Job Browser User filter,,1.2.0,1.2.1,1,0,0,0,0,0,0,0,
1223,ambari-web,Yusaku Sako,Confirm Hosts page: It looks like hosts disappear if you are on 'Fail' filter and click on 'Retry Failed' button,,1.2.0,1.2.1,1,0,0,0,0,0,0,0,
1224,ambari-web,Yusaku Sako,Drop the 'all' option from Hosts > Component Filter and Jobs > Users Filter,,1.2.0,1.2.1,1,0,0,0,0,0,0,0,
1229,ambari-web,Yusaku Sako,Dashboard - make disk usage pie chart in HDFS summary easier to understand,,1.2.0,1.2.1,1,0,0,0,0,0,0,0,
1231,,Mahadev konar,Replace sudo with su in the ambari setup script since ambari server setup is already run as root.,Replace sudo with su in the ambari setup script since ambari server setup is already run as root.,1.2.0,1.2.1; 1.2.3,18,0,0,0,0,0,0,0,
1233,,Mahadev konar,Directory permissions on httpd /var/www/cgi-bin should not be touched by Ambari.,Directory permissions on httpd /var/www/cgi-bin should not be touched by Ambari.,1.2.0,1.2.1; 1.2.3,11,0,0,0,1,0,0,0,
1235,ambari-web,Yusaku Sako,Host health indicator should have a tooltip showing details,,1.2.0,1.2.1,1,0,0,0,0,0,0,0,
1244,ambari-web,Yusaku Sako,Install Options - line up the Target Hosts section with the rest of the page,,1.2.0,1.2.1,1,0,0,0,0,0,0,0,
1253,ambari-web,Yusaku Sako,Use ember-precompiler-brunch npm plugin,Use the Ember Handlebars precompiler plugin (ember-precompiler-brunch) that's in the NPM registry so that we can specify a specific plugin version to use in package.json  rather than the current plugin that Ambari Web uses (which is not in the NPM registry - it is retrieved from a git repo and Ambari Web can break if the plugin gets updated).,1.2.0,1.2.1,59,0,0,0,0,0,0,0,
1259,,Mahadev konar,Fix the host roles live status not go back to INSTALLED if it was in START_FAILED state.,Fix the host roles live status not go back to INSTALLED if it was in START_FAILED state.,1.2.0,1.2.1,17,0,0,0,0,0,0,0,
1260,ambari-server,Siddharth Wagle,Remove hard coded JMX port mappings,The JMXPropertyProvider contains a map of component names to ports ... JMX_PORTS.put('NAMENODE'  '50070'); JMX_PORTS.put('DATANODE'  '50075'); JMX_PORTS.put('JOBTRACKER'  '50030'); JMX_PORTS.put('TASKTRACKER'  '50060'); JMX_PORTS.put('HBASE_MASTER'  '60010');These ports can change in configuration. Need to create the mapping dynamically.This is required for secure HDP cluster to work.,1.2.1,1.2.2,57,0,0,0,0,0,0,0,
1264,ambari-web,Yusaku Sako,Service graphs refresh with spinners,Service graphs are refreshing with spinners  rather than simply shifting to the left.See the attached movie clip.,1.2.0,1.2.1,17,0,0,0,0,0,0,0,
1265,ambari-web,Yusaku Sako,Job Browser - Filter by Input  output and duration,&lt;expression&gt; ::= [&lt;operator&gt;] [&lt;whitespace&gt;]* &lt;value&gt; [&lt;duration-unit&gt; | &lt;io-unit&gt;]&lt;operator&gt; ::= '&gt;' | '&lt;' | '='&lt;whitespace&gt; ::= ' '&lt;value&gt; :== int | float&lt;duration-unit&gt; ::= 's' | 'm' | 'h'&lt;io-unit&gt; ::= 'k' | 'kb' | 'm' | 'mb' | 'g' | 'gb'If &lt;operator&gt; is ommitted  '=' is assumed.If &lt;duration-unit&gt; is omitted  's' is assumed.If &lt;io-unit&gt; is omitted  'k' is assumed.&lt;duration-unit&gt; and &lt;io-unit&gt; are case-insensitive.,1.2.0,1.2.1,67,0,0,0,0,0,0,0,
1266,,Mahadev konar,Agent checks packages as part of host check but doesn't tell which ones are needed or conflicting,Agent checks packages as part of host check but doesn't tell which ones are needed or conflicting,1.2.0,1.2.1,17,0,0,0,0,0,0,0,
1267,,Mahadev konar,Store example Hive Queries somewhere in Ambari that's easily accessible for demo/test purposes,Store example Hive Queries somewhere in Ambari that's easily accessible for demo/test purposes,1.2.0,1.2.1,13,0,0,0,0,0,0,0,
1271,ambari-web,Yusaku Sako,On Confirm Hosts page  add a link to show the Host Checks popup in the success message,,1.2.0,1.2.1,1,0,0,0,0,0,0,0,
1273,ambari-web,Srimanth Gunturi,Edit User: No error message is shown when the user does not enter the correct 'old password',No error message is shown when the user does not enter the correct 'old password' when editing an user.,1.2.0,1.2.1,19,0,0,0,0,0,0,0,
1274,ambari-web,Srimanth Gunturi,Shrink top nav height,Navbar's height should be shrunk to ~40px.,1.2.0,1.2.2,7,0,0,0,0,0,0,0,
1275,ambari-web,Srimanth Gunturi,Incorrect displaying 'Background operations' window after changing state of component,Steps:1. Change state (start/stop operations are preferable) for lot of components so that the number of background operations was approximately 20-30;2. Change size of browser (800-900 px);3. Go to down of page;4. Change state for next component;5. Confirm changing;Result:'Background operations' window was opened  but it 'OK' button is not visible.Expected result:'Background operations' window contains scroll bar for all background operations. 'OK' button is available for using.,1.2.0,1.2.2,66,0,0,0,0,0,0,0,
1277,,Mahadev konar,Failing build due to url moved on Suse.,Failing build due to url moved on Suse. Looks like centos5 and 6 handle redirection all fine but doesnt look like the maven plugin handles that on SUSE.,1.2.0,1.2.1,28,0,0,0,0,0,0,0,
1279,ambari-web,Srimanth Gunturi,Make sure that Ambari Web renders all elements correctly when the browser width is 1024px or narrower,Current behavior is to dynamically layout elements as the browser viewport size changes. This causes elements to overlap  go outside the bounding box  positioned in a weird way  etc.Let's set minimum width to be 1024px (or maybe 980px to account for the scrollbar) and make sure that all elements are laid out correctly.Bigger than 1024px should still utilize more screen space as it does today.,1.2.0,1.2.1,65,0,0,0,0,0,0,0,
1299,ambari-agent,Yusaku Sako,Bootstrap can hang indefinitely,I was bootstrapping 4 nodes. One of them got stuck in 'Installing' phase and won't time out even after ~30 minutes.It seems like starting of ambari-agent was hanging.,1.2.0,1.2.3,28,0,0,0,0,0,0,0,
1300,ambari-web,Srimanth Gunturi,Service status / host component status can get stuck in the green blinking state if stop fails - no further operation can be performed,This happens when a service/host component is running  but stop fails. This leaves the desired_state in the INSTALLED (i.e.  STOPPED) state  while the live state is STARTED.Currently  UI assumes when desired_state==INSTALLED and state==STARTED  it is STARTING. This was a trick to get around the problem of backend live state update lagging and to make UI more responsive.,1.2.0,1.2.1,57,0,0,0,0,0,0,0,
1305,ambari-web,ARUN KUMAR KANDREGULA,Make sure that Ambari Web renders all elements correctly when the browser width is 1024px or narrower (refactor),Current behavior is to dynamically layout elements as the browser viewport size changes. This causes elements to overlap  go outside the bounding box  positioned in a weird way  etc.Let's set minimum width to be 1024px (or maybe 980px to account for the scrollbar) and make sure that all elements are laid out correctly.Bigger than 1024px should still utilize more screen space as it does today.,1.2.0,1.2.1,65,0,0,1,0,0,0,0,
1308,ambari-web,ARUN KUMAR KANDREGULA,Properly display Apps page aggregate summary and data table when there are no data to be shown,,1.2.0,1.2.1,1,0,0,0,0,0,0,0,
1309,ambari-web,ARUN KUMAR KANDREGULA,Remove all text from Apps views  controllers  templates to messages.js,,1.2.0,1.2.2,1,0,0,0,0,0,0,0,
1311,ambari-web,ARUN KUMAR KANDREGULA,Host health indicator should have a tooltip showing few details (refactoring),,1.2.0,1.2.1,1,0,0,0,0,0,0,0,
1321,ambari-web,Srimanth Gunturi,Switching out of Jobs page does not launch popup anymore,On the jobs page click on Job-X and see the popup with all the job information. Now switch to Services page and come back to the jobs page. Now clicking on Job-X will not launch popup.,1.2.0,1.2.1,36,0,0,0,0,0,0,0,
1330,,Mahadev konar,Cluster missing hosts after successful install and restart.,Cluster missing hosts after successful install and restart. This bug got introduced due to my patch in AMBARI-1301.,1.2.1,1.2.1,31,0,0,0,0,0,0,0,
1333,ambari-web,Yusaku Sako,Add username validation for Ambari local users,,1.2.0,1.2.3,1,0,0,0,0,0,0,0,
1335,ambari-web,Yusaku Sako,Show validation error when the user specifies target hosts that are already part of the cluster,,1.2.0,1.2.2,1,0,0,0,0,0,0,0,
1337,ambari-web,Yusaku Sako,Refactor Job Browser filter,,1.2.0,1.2.3,1,0,0,0,0,0,0,0,
1340,ambari-web,Yusaku Sako,Enhance Install/Start/Test progress display,When we are showing progress for cluster install  it takes a while for any of the host-level or overall progress to show any progress completion percentage (they can get stuck at 0% for several minutes). This is because host-level completion is not displayed until the first install task for the task is complete. Instead  we should advance percentage complete when the tasks changes the status (from PENDING-&gt;QUEUED-&gt;IN_PROGRESS) to better reflect the install progress to the end user.,1.2.1,1.2.2,77,0,0,0,0,0,0,0,
1343,ambari-agent,Siddharth Wagle,Service Check fails after secure install due to wrong kinit path,For manually installed kdc  the kinit path in the puppet script is /usr/kerberos/bin/kinitActual location:root@ip-10-38-13-250 data]# whereis kinitkinit: /usr/bin/kiniterr: /Stage&#91;2&#93;/Hdp-hbase::Hbase::Service_check/Hdp-hadoop::Exec-hadoop&#91;hbase::service_check::test&#93;/Hdp::Exec&#91;/usr/kerberos/bin/kinit -kt /etc/security/keytabs/hdfs.headless.keytab hdfs; hadoop --config /etc/hadoop/conf fs -test -e /apps/hbase/data/usertable&#93;/Exec&#91;/usr/kerberos/bin/kinit -kt /etc/security/keytabs/hdfs.headless.keytab hdfs; hadoop --config /etc/hadoop/conf fs -test -e /apps/hbase/data/usertable&#93;: Failed to call refresh: Could not find command '/usr/kerberos/bin/kinit',1.2.1,1.2.3,52,1,0,0,0,0,0,0,
1348,ambari-web,Yusaku Sako,Externalize strings to messages.js,Externalize string resources to messages.js.,1.2.1,1.2.2,5,1,0,0,0,0,0,0,
1351,ambari-web,Jaimin D Jetly,Provide consistent ordering of hosts in heatmap,,1.2.1,1.2.2,1,0,0,0,0,0,0,0,
1354,ambari-web,Jaimin D Jetly,'No alerts' badge on the Host Detail page should be green  not red,,1.2.1,1.2.2,1,0,0,0,0,0,0,0,
1359,ambari-web,Jaimin D Jetly,App Browser rows colours should alternate from dark grey to light grey and back,,1.2.1,1.2.3,1,0,0,0,0,0,0,0,
1360,ambari-web,Jaimin D Jetly,Mouse cursor hover behavior is strange on Job Browser,When hovering the mouse cursor around Show All  Filtered  the mouse cursor changes to the 'hand' icon as expected. To the right  the cursor turns into a hand even when hovering over areas where there's no link. Hovering over 'Clear filters'  the cursor does not turn into the 'hand'.,1.2.1,1.2.2,49,0,0,0,0,0,0,0,
1373,ambari-web,Jaimin D Jetly,Since there is the ability to log in to Ambari Web as different users the current user should be indicated,,1.2.1,1.2.2,1,0,0,0,0,0,0,0,
1376,ambari-web,Jaimin D Jetly,Wrong calculation of duration filter on apps page,Wrong calculation for the duration filter if we enter just number  without h  m or s to specify the unit. By default we should take seconds as the default unit.,1.2.1,1.2.2,30,0,0,0,0,0,0,0,
1432,,Mahadev konar,Ambari Agent registration hangs due to Acceptor bug in Jetty for not reading through accepted connections.,Ambari Agent registration hangs due to Acceptor bug in Jetty for not reading through accepted connections.,1.2.0,1.2.2,16,0,0,0,0,0,0,0,
1441,ambari-web,Yusaku Sako,Validation for username used in service configs is broken,,1.2.2,1.2.2,1,0,0,0,1,0,0,0,
1449,ambari-web,Jaimin D Jetly,Failure popup shown for reconfiguring HDFS when MapReduce is not installed,,1.2.1,1.2.2,1,0,0,0,0,0,0,3,CHANGES.txt;ambari-web/app/controllers/main/service/info/configs.js;ambari-web/app/messages.js;
1450,ambari-web,Yusaku Sako,Remove hard-coded stack version,,1.2.2,1.2.3,1,0,0,0,0,0,0,0,
1456,ambari-web,Yusaku Sako,Cannot proceed after bootstrapping in some cases due to a run-time error while running host checks,,1.2.2,1.2.2,1,0,0,0,0,0,0,0,
1460,ambari-web,Yusaku Sako,Optimize query call for retrieving host information,Every 15 seconds  Ambari Web makes a call to retrieve information about all hosts in the cluster. With 400+ nodes  this call retrieves about 10MB of info  since the API returns last_agent_env  which is host check results used during bootstrap and makes the payload huge.By optimizing the query string for this API call  we can cut down on the payload by more than 90%.,1.2.0,1.2.2,64,0,0,0,0,1,0,0,
1461,ambari-web,Yusaku Sako,Optimize query for getting service and host component status back from the server,The API response for getting service/host component status back from the server is unnecessarily big due to nagios_alerts being included as part of the response. This optimization can cut the payload in half or more  and also eases load on the server since it does not have to get Nagios alerts as part of fulfilling the API call.,1.2.0,1.2.2,58,0,0,0,0,1,0,0,
1465,ambari-server,Siddharth Wagle,Minimize Read and Write locks for createHosts,Invocation count and exec time for ClustersImpl.mapHostToCluser very highorg.apache.ambari.server.state.cluster.ClustersImpl.mapHostToCluster(String  String) Time(ms): 252 925 Avg Time(ms): 5 269 Own Time(ms): 211Invocation Count: 48Each time host is mapped to cluster we refresh the entity manager. This results in the createHosts call taking excess of 10 minutes,1.2.2,1.2.3,42,1,0,0,0,1,0,0,
1466,,Mahadev konar,Optimize ganglia rrd script to be able to respond within reasonable time to queries made by the UI.,Optimize ganglia rrd script to be able to respond within reasonable time to queries made by the UI.,1.2.2,1.2.2,18,0,0,0,0,1,0,0,
1473,ambari-web,Yusaku Sako,Further optimization of querying host information from the server,Further work on optimizing query for getting host information on top of BUG-1460.,1.2.2,1.2.2,13,0,0,0,0,0,0,0,
1486,,Mahadev konar,Fix TestHostName to take care of issues when gethostname and getfqdn do not match.,Fix TestHostName to take care of issues when gethostname and getfqdn do not match.,1.2.1,1.2.2,14,0,0,0,0,0,0,0,
1487,,Mahadev konar,Fix alerts at host level if MapReduce is not selected not to alert for tasktrackers not running.,Fix alerts at host level if MapReduce is not selected not to alert for tasktrackers not running.,1.2.0,1.2.2,17,1,0,0,0,0,0,0,
1488,,Mahadev konar,Nagios script causes unwanted  Datanode logs.,Nagios script causes unwanted Datanode logs.,1.2.0,1.2.2,6,1,0,0,0,0,0,0,
1489,,Mahadev konar,Add hadoop-lzo to be one of the rpms to check for before installation.,Add hadoop-lzo to be one of the rpms to check for before installation.,1.2.0,1.2.2,13,0,0,0,0,0,0,0,
1496,ambari-web,Jaimin D Jetly,Make all service properties reconfigurable.,,1.2.1,1.2.2,1,0,0,0,0,0,0,0,
1497,,Mahadev konar,Fix start up option for ambari-server where there is a missing space.,Fix start up option for ambari-server where there is a missing space.,1.2.2,1.2.2,12,0,0,0,0,0,0,0,
1499,ambari-web,Yusaku Sako,Add hosts is broken,This is due to performance enhancements for querying hosts.Hosts/disk_info for the hosts being added is expected in the Add Hosts wizard  but it is now missing.,1.2.2,1.2.2,26,0,0,0,0,1,0,0,
1505,ambari-web,Xi Wang,Hosts page: add filtering by host status,Show the host status filter at the top of the Hosts table  showing the status and the number of hosts in that status.,1.2.3,1.2.3,23,0,0,0,0,0,0,0,
1519,ambari-web,Yusaku Sako,Ambari Web goes back and forth between frozen and usable state peridocially on a large cluster,The background polling to update the live status of services and host components runs every 6 seconds. When this happens  the whole UI freezes for several seconds periodically.,1.2.0,1.2.2,28,0,0,0,0,1,0,0,
1520,ambari-web,Srimanth Gunturi,Alerts take around 20-30 seconds to show up everytime you refresh the dashboard.,Alerts take around 20-30 seconds to show up everytime you refresh the dashboard.,1.2.2,1.2.2,13,0,0,0,0,1,0,0,
1536,ambari-web,Xi Wang,Hosts page layout fixes,1.Use Bootstrap-style tooltip for the hover tooltip on the host status dots as well as the disk usage bars. The current tooltip does not show up unless you rest your mouse cursor for more than a second - users will simply assume there's no tooltip hover when quickly moving the mouse cursor over them.2.We can kill some space between the status dots and the hostnames in the table as well.3.Also  there is too much margin at the top compared to the rest of the pages.,1.2.3,1.2.3,85,0,0,0,0,0,0,2,CHANGES.txt;ambari-web/app/styles/application.less;
1537,ambari-web,Xi Wang,Constrain the width of all wizard popups,Currently  the popup for any wizard resizes to fill up the width of the browser width with some horizontal margin. Vertically  it resizes to fit the height of the content; in some cases  it looks really silly on a wide screen.We should specify the max width of the wizard popup. Ambari Web supports two width configurations (wide and narrow)  so the wizard popup should look good in these two configurations.,1.2.3,1.2.3,70,0,0,0,0,0,0,0,
1559,ambari-server,Steve Ratay,Jobs failed count always returns 0 in the jobtracker API metrics,See the attachments  but after running both successful and failed MapReduce jobs  the jobs submitted count includes all jobs  the jobs successful appears correct  but the jobs failed count is still 0.,1.2.2,1.2.2,32,0,0,0,0,0,0,0,
1580,ambari-web,Yusaku Sako,Stack Upgrade Wizard - resume upon page refresh / login,,1.2.3,1.2.3,1,0,0,0,0,0,0,0,
1581,ambari-web,Yusaku Sako,Host progress popup - generic component for showing progress on async operations,This is for the popup that shows up upon clicking already-performed or currently-in-progress async operations.We should take what we already have for host-level popup in Step 9 as a base and make it reusable  with a new higher level showing all hosts.,1.2.3,1.2.3,42,0,0,0,0,0,0,0,
1582,ambari-server,Siddharth Wagle,Cannot start hadoop services after hdfs re-configuration and amabri server restart.,Cannot start hadoop services after several restarts since the agents.,1.2.2,1.2.2,10,0,0,0,0,0,0,0,
1597,ambari-agent,Siddharth Wagle,Templeton smoke test fails for secure cluster,Templeton start fails due to multiple errors.[0;36mnotice: /Stage&#91;2&#93;/Hdp-templeton::Copy-hdfs-directories/Hdp-hadoop::Hdfs::Copyfromlocal&#91;/usr/lib/hadoop/contrib/streaming/hadoop-streaming*.jar&#93;/Hdp-hadoop::Exec-hadoop&#91;fs -copyFromLocal /usr/lib/hadoop/contrib/streaming/hadoop-streaming*.jar /apps/webhcat/hadoop-streaming.jar&#93;/Hdp::Exec&#91;/usr/bin/kinit -kt /etc/security/keytabs/hcat.headless.keytab hcat; hadoop --config /etc/hadoop/conf fs -copyFromLocal /usr/lib/hadoop/contrib/streaming/hadoop-streaming*.jar /apps/webhcat/hadoop-streaming.jar&#93;/Exec&#91;/usr/bin/kinit -kt /etc/security/keytabs/hcat.headless.keytab hcat; hadoop --config /etc/hadoop/conf fs -copyFromLocal /usr/lib/hadoop/contrib/streaming/hadoop-streaming*.jar /apps/webhcat/hadoop-streaming.jar&#93;/returns: kinit: Client not found in Kerberos database while getting initial credentials^[[0m,1.2.3,1.2.3,47,0,0,0,0,0,0,0,
1621,ambari-web,Yusaku Sako,Config/Reconfig UI should not allow certain configs to have host-level overrides,,1.2.3,1.2.3,1,0,0,0,0,0,0,0,
1631,ambari-web,Yusaku Sako,Security Wizard - integrate host progress popup,,1.2.3,1.2.3,1,0,0,0,0,0,0,0,
1641,ambari-server,Steve Ratay,Some map and reduce task metrics are missing for the tasktrackers in the API,With Ambari 1.2.2  I can get the metrics.mapred object to show up for the tasktracker component. Our code is hitting the URL: http://sdll4474.labs.teradata.com:8080/api/v1/clusters/sdll4474.labs.teradata.com/services/MAPREDUCE/components/TASKTRACKER?fields=host_components/*. Here one of the objects in the host_components array. Note that the data in metrics.mapred.tasktracker is providing some data Ie never seen before. In previous versions we say properties such as reduces_running  reduceTaskSlots  maps_running  etc. in this object. { 'href' : 'http://aster39h1.td.teradata.com:8080/api/v1/clusters/aster39h1.td.teradata.com/hosts/byn001-17/host_components/TASKTRACKER'  'HostRoles' : { 'cluster_name' : 'aster39h1.td.teradata.com'  'desired_state' : 'STARTED'  'state' : 'STARTED'  'component_name' : 'TASKTRACKER'  'service_name' : 'MAPREDUCE'  'host_name' : 'byn001-17' }  'metrics' : { 'boottime' : 1.360089758E9  'process' : { 'proc_total' : 845.211111111  'proc_run' : 0.0 }  'rpc' : { 'rpcAuthorizationSuccesses' : 9  'SentBytes' : 6842  'rpcAuthorizationFailures' : 0  'ReceivedBytes' : 26187  'NumOpenConnections' : 0  'callQueueLen' : 0  'RpcQueueTime_num_ops' : 59  'rpcAuthenticationSuccesses' : 0  'RpcProcessingTime_num_ops' : 59  'rpcAuthenticationFailures' : 0  'RpcProcessingTime_avg_time' : 0.6666666666666666  'RpcQueueTime_avg_time' : 0.0 }  'mapred' : { 'shuffleOutput' : { 'shuffle_success_outputs' : 1  'shuffle_handler_busy_percent' : 0.0  'shuffle_output_bytes' : 1400  'shuffle_failed_outputs' : 0  'shuffle_exceptions_caught' : 0 }  'tasktracker' : { 'ConfigVersion' : 'default'  'HttpPort' : 50060  'TasksInfoJson' : '{/'running/':0 /'failed/':0 /'commit_pending/':0}'  'JobTrackerUrl' : 'aster39h1.td.teradata.com:50300'  'Healthy' : true  'Version' : '1.1.2.22  r'  'Hostname' : 'byn001-17'  'RpcPort' : 48526 } }  'ugi' : { 'loginFailure_num_ops' : 0  'loginSuccess_num_ops' : 0  'loginSuccess_avg_time' : 0.0  'loginFailure_avg_time' : 0.0 }  'disk' : { 'disk_total' : 36841.767  'disk_free' : 36776.9775333  'part_max_used' : 70.7 }  'cpu' : { 'cpu_speed' : 1999.0  'cpu_wio' : 0.0  'cpu_num' : 24.0  'cpu_idle' : 99.8886111111  'cpu_nice' : 0.0  'cpu_aidle' : 0.0  'cpu_system' : 0.1  'cpu_user' : 0.0227777777778 }  'rpcdetailed' : { 'getTask_avg_time' : 1.0  'ping_avg_time' : 0.0  'done_avg_time' : 1.0  'getProtocolVersion_avg_time' : 0.0  'getMapCompletionEvents_avg_time' : 0.0  'done_num_ops' : 9  'getMapCompletionEvents_num_ops' : 6  'canCommit_num_ops' : 6  'ping_num_ops' : 2  'commitPending_avg_time' : 1.0  'statusUpdate_num_ops' : 15  'statusUpdate_avg_time' : 1.0  'getTask_num_ops' : 9  'getProtocolVersion_num_ops' : 9  'commitPending_num_ops' : 3  'canCommit_avg_time' : 0.0 }  'load' : { 'load_fifteen' : 0.0  'load_one' : 0.0  'load_five' : 0.0 }  'jvm' : { 'memHeapCommittedM' : 100.4375  'NonHeapMemoryUsed' : 25214472  'logFatal' : 0  'threadsWaiting' : 17  'gcCount' : 122400  'threadsBlocked' : 0  'HeapMemoryUsed' : 77617416  'logWarn' : 0  'logError' : 0  'HeapMemoryMax' : 954466304  'memNonHeapCommittedM' : 26.125  'memNonHeapUsedM' : 24.046394  'gcTimeMillis' : 81352  'NonHeapMemoryMax' : 136314880  'logInfo' : 3  'memHeapUsedM' : 73.81818  'threadsNew' : 0  'threadsTerminated' : 0  'maxMemoryM' : 758.4375  'threadsTimedWaiting' : 10  'threadsRunnable' : 6 }  'network' : { 'pkts_out' : 111.684472222  'bytes_in' : 1428.83666667  'bytes_out' : 23201.8668056  'pkts_in' : 13.9853333333 }  'memory' : { 'mem_total' : 1.31854096E8  'swap_free' : 6291448.0  'mem_buffers' : 574794.711111  'mem_shared' : 0.0  'swap_total' : 6291448.0  'mem_cached' : 6061952.85556  'mem_free' : 1.23072573378E8 } }  'component' : [ { 'href' : 'http://aster39h1.td.teradata.com:8080/api/v1/clusters/aster39h1.td.teradata.com/services/MAPREDUCE/components/TASKTRACKER'  'ServiceComponentInfo' : { 'cluster_name' : 'aster39h1.td.teradata.com'  'component_name' : 'TASKTRACKER'  'service_name' : 'MAPREDUCE' } } ] },1.2.2,1.2.3,452,0,0,0,0,0,0,4,CHANGES.txt;ambari-server/src/main/resources/jmx_properties.json;ambari-server/src/test/java/org/apache/ambari/server/controller/jmx/JMXPropertyProviderTest.java;ambari-server/src/test/resources/mapreduce_tasktracker_jmx.json;
1645,ambari-web,Yusaku Sako,Undo should not be allowed on component hosts,,1.2.3,1.2.3,1,0,0,0,0,0,0,0,
1666,ambari-agent,Siddharth Wagle,Oozie properties for principal and keytab not read from oozie-site,Oozie principal is create by the UI as oozie/${hostname}@realm.comPuppet script has a bug that does not read this property and uses default 'oozie' as the principal,1.2.3,1.2.3,26,0,0,0,0,0,0,0,
1667,ambari-agent,Siddharth Wagle,Starting all services fails on secure cluster (excluding HBase and ZooKeeper),HDFS service check failure leads to this.After the failure of the 'HDFS service check' task  stage fails. But HDFS comes up.The Ambari server hostname for secure cluster: ec2-54-234-164-5.compute-1.amazonaws.com,1.2.3,1.2.3,29,0,0,0,0,0,0,0,
1702,ambari-server,Siddharth Wagle,Ambari/GSInstallers need to set the value of mapred.jobtracker.completeuserjobs.maximum,mapred.jobtracker.completeuserjobs.maximum is currently set to 0. This causes issues with failed(/successful) jobs from pig and other job submitters because the references to the failed job is cleared up asap in jobtracker preventing one from accessing the failure reason. This value should be bumped up to about 100 according to the MapReduce team.,1.2.3,1.2.3,52,0,0,0,0,0,0,0,
1724,,Sumit Mohanty,Agent has it hard-coded that HDP repo file can only be downloaded once,Upgrade requires agents to download the repo file anytime.,1.2.3,1.2.3,9,0,0,0,0,0,0,0,
1726,,Sumit Mohanty,It seems upgrades available at the FE is hard-coded to 1.3.0,In order to test upgrade  I modified the available stack definitions to allow upgrade from 1.2.0 to 1.2.2 and removed upgrade to 1.3.0. However  the FE still says '(Upgrade available: HDP-1.3.0)'. However  http://server:8080/api/v1/stacks2/HDP/versions/1.3.0/ has min_upgrade_version as null.{ 'href' : 'http://server:8080/api/v1/stacks2/HDP/versions/1.3.0/'  'Versions' : { 'stack_version' : '1.3.0'  'stack_name' : 'HDP'  'min_upgrade_version' : null } ...,1.2.3,1.2.3,62,0,0,0,0,0,0,0,
1739,ambari-agent,Siddharth Wagle,HBase and Zk failed to start on secure install,Error during starting hbase and zookeeper during secure install.Incorrectly parsed Files:hbase-env.shzookeeper-env.sh,1.2.3,1.2.3,11,0,0,0,0,0,0,0,
1752,ambari-server,Siddharth Wagle,Backend support for MySQL and Oracle for Oozie and Hive,Add ability to use Oracle DB for Hive and Oozie in Ambari,1.2.3,1.2.3,12,0,0,0,0,0,0,0,
1757,,Sumit Mohanty,Add support for Stack 1.2.2 to Ambari,Add support for Stack 1.2.2 to Ambari.,1.2.2,1.2.2,7,1,0,0,0,0,0,0,
1764,,Tom Beerbower,Unable to get all tasks from more than one request_id by one request,When trying to get tasks from more than one request_id returns tasks only for one.request 'api/v1/clusters/mycluster/requests?Requests/id=1|Requests/id=2'returns:{'href' : 'http://ec2-23-20-223-127.compute-1.amazonaws.com:8080/api/v1/clusters/mycluster/requests?Requests/id=1|Requests/id=2' 'items' : [{'href' : 'http://ec2-23-20-223-127.compute-1.amazonaws.com:8080/api/v1/clusters/mycluster/requests/2' 'Requests' :{ 'id' : 2  'cluster_name' : 'mycluster' }}]},1.2.2,1.2.3,48,0,0,0,0,0,0,3,CHANGES.txt;ambari-server/src/main/java/org/apache/ambari/server/controller/internal/RequestResourceProvider.java;ambari-server/src/test/java/org/apache/ambari/server/controller/internal/RequestResourceProviderTest.java;
1770,ambari-agent,Siddharth Wagle,Hue installation fails due to manifest errors,Hue installation fails due to following errors:1. Change in the name of rpm bundle2. Empty values in the hue.ini sections,1.2.3,1.2.3,20,1,0,0,0,0,0,0,
1775,ambari-web,Jaimin D Jetly,Security wizard - Javascript error is thrown when zooKeeper is included as a secure service.,,1.2.3,1.2.3,1,0,0,0,0,0,0,0,
1789,,Sumit Mohanty,Stopping and then Starting all services doesn't start NameNode,Security wizard stops all services  applies configuration and then starts all services.Sometimes it has been noticed that the action to stop all service completes successfully but the action to start all services never sends the task to start NameNode.,1.2.3,1.2.3,39,1,0,0,0,0,0,0,
1791,ambari-agent,Siddharth Wagle,Can not specify request context for smoke test request,Regarding BUG-3509 when we send request to server likeapi/v1/clusters/cl1/services/HDFS/actions/HDFS_SERVICE_CHECKRequest Method:POST Form Data:{'RequestInfo':{'context':'Smoke Test'}}This request is not setting request_context.,1.2.3,1.2.3,18,0,0,0,0,0,0,0,
1816,ambari-web,Jaimin D Jetly,Security wizard: Add missing secure configs to Hbase service and make 'zookeeper' as default primary name for zookeeper principal.,,1.2.3,1.2.3,1,1,0,0,1,0,0,0,
1818,ambari-agent,Siddharth Wagle,HBase master shuts down immediately after start in a secure cluster.,HBase master shuts down immediately after start in a secure cluster.Wrong settings in the hbase_master_jaas. Need to replace the 'HOST with actual fqdn,1.2.3,1.2.3,23,0,0,0,0,0,0,0,
1837,ambari-web,Jaimin D Jetly,Few core-site properties vanished after seemingly benign reconfiguration.,UI metadata properties are not being reconfigured and retained on saving services.,1.2.3,1.2.3,12,1,0,0,0,0,0,0,
1838,ambari-web,Jaimin D Jetly,Cluster Management > Services > MapReduce > Config throws JS error and the page comes up blank,,1.2.3,1.2.3,1,1,0,0,0,0,0,0,
1840,ambari-web,Srimanth Gunturi,For global properties show restart for appropriate services only,Currently when one service changes a property which doesnt effect all other services  the rest of the services are marked for restart. This is because the global tags are changed. Using work done in AMBARI-1797  only appropriate services should be marked as needing restart.,1.2.3,1.2.3,57,1,0,0,0,0,0,0,
1847,ambari-web,Srimanth Gunturi,Make single PUT call for multiple host overrides,Currently when we save host-overrides configuration  we have to do PUT of the delta on each host.This is problematic if admin provides an exception to 100 hosts. This will require 100 PUT calls which is expensive. There is a bulk update mechanism  but that requires the same content for all 100 hosts. This will not be the case if any hosts have other properties that are overridden.To save on network calls  we have to make one PUT call via the new API provided by AMBARI-1844.,1.2.3,1.2.3,98,1,0,0,0,0,0,0,
1849,ambari-web,Yusaku Sako,Cosmetic problems on HBase Dashboard,,1.2.3,1.2.3,1,0,0,0,0,0,0,0,
1855,ambari-web,Yusaku Sako,Capacity Scheduler: when adding a new queue  populate fields,When creating a new queue  populate all fields with default values except for:Queue NameCapacityMax CapacityUsersGroupsAdmin UsersAdmin Groups,1.2.3,1.2.3,17,1,0,0,0,0,0,0,
1859,,Sumit Mohanty,Cannot load Nagios Alerts due to 400 Bad Request,Given the API call: http://dev.hortonworks.com:8080/api/v1/clusters/test403_2/host_components?HostRoles/component_name=NAGIOS_SERVER&amp;fields=HostRoles/nagios_alertsThe feedback is:{ 'status' : 400  'message' : 'The properties [HostRoles/nagios_alerts] specified in the request or predicate are not supported for the resource type HostComponent.' },1.2.3,1.2.3,33,1,0,0,1,0,0,0,
1860,,Sumit Mohanty,Master broken - Cannot deploy services,Datanode install fails on multi-node clusters because the following configuration property:$ambari_db_rca_url= 'jdbc:postgresql://localhost/ambarirca'Ensure all of these variables are wired up:'ambari_db_rca_url''ambari_db_rca_driver''ambari_db_rca_username''ambari_db_rca_password',1.2.3,1.2.3,19,0,0,0,0,0,0,0,
1870,ambari-agent,Matthew Farrellee,ambari-agent RPM claims ownership of /usr/sbin,This may impact other versions  only branch-1.2 was changed.The ambari-agent.spec (generated from rpm-maven-plugin) claims ownership of /usr/sbin $ grep sbin target/rpm/ambari-agent/SPECS/ambari-agent.spec | grep attr%attr(755 root root) /usr/sbinThis is a problem because the filesystem RPM owns /usr/sbin.According to rpm-maven-plugin documentation&#91;0&#93;  this is because the only file under /usr/sbin is ambari-agent and'directoryIncludedIf the value is true then the attribute string will be written for the directory if the sources identify all of the files in the directory (that is  no other mapping contributed files to the directory). This is the default behavior.'The 'no other mapping contributed files to the directory' bit is important.The solution is to add directoryInclude=false to the mapping.&#91;0&#93; http://mojo.codehaus.org/rpm-maven-plugin/map-params.html,1.2.2,1.2.3,112,0,0,0,0,0,0,0,
1872,ambari-web,Jaimin D Jetly,Ambari FE is not setting proper value for fs.checkpoint.edits.dir,,1.2.3,1.2.3,1,1,0,0,0,0,0,0,
1873,ambari-web,Yusaku Sako,HUE pid and log dir labels are flip flopped,,1.2.3,1.2.3,1,0,0,0,0,0,0,0,
1876,ambari-web,Yusaku Sako,Capacity Scheduler: implement user/group and admin user/group validation rules,,1.2.3,1.2.3,1,1,0,0,0,0,0,0,
1877,ambari-web,Yusaku Sako,Reassign Master Wizard  Step 2: prevent proceed next without changing target host,,1.2.3,1.2.3,1,1,0,0,0,0,0,0,
1880,ambari-web,Srimanth Gunturi,stacks2 API uses 'type' to refer to config tags and no longer exposes 'filename' as a property,FE needs to be modified to not to use 'filename' in stacks API to get the config tags. The new property is 'type'.,1.2.3,1.2.3,23,1,0,0,0,0,0,0,
1881,,Mahadev konar,API to map global properties to services is partially complete.,API to map global properties to services is partially complete. The API gives 'global.xml' to approximately 47 properties. However the 'global' site has many more properties - so I dont know if some are fully missed.,1.2.3,1.2.3,36,1,0,0,0,1,0,0,
1891,ambari-web,Srimanth Gunturi,Impossibility to scroll metric window after browser width changing,Open detailed view of any metric diagram on Services page  for example 'Total Space Utilization'. After that change width of browser less than width of detailed view of metric diagram. Right arrow for graph time paging is invisible and we can't to resolve this problem using horizontal scrollbar.,1.2.3,1.2.3,48,0,0,0,0,0,0,0,
1896,ambari-web,Srimanth Gunturi,Disable editing Capacity Scheduler on host configs,Go to Configs tab of Host.Result: Queues in Capacity Scheduler category are editable.Expected: Queues in Capacity Scheduler category shouldn't be editable.,1.2.3,1.2.3,21,1,0,0,0,0,0,0,
1904,ambari-web,Yusaku Sako,Update default stack version to 1.3.0,,1.2.3,1.2.3,1,1,0,0,0,0,0,0,
1912,ambari-web,Jaimin D Jetly,HBase master doesn't come up after disabling security.,,1.2.3,1.2.3,1,1,0,0,0,0,0,0,
1915,ambari-server,Siddharth Wagle,Client install tasks are shown twice in install progress popup,Client is re-configured by re-installing all client only hosts. This results in multiple tasks for client install in the UI.API response:{ 'href' : 'http://ec2-50-17-99-21.compute-1.amazonaws.com:8080/api/v1/clusters/yusaku/requests/2'  'Requests' : { 'id' : 2  'cluster_name' : 'yusaku' }  'tasks' : [ { 'href' : 'http://ec2-50-17-99-21.compute-1.amazonaws.com:8080/api/v1/clusters/yusaku/requests/2/tasks/43'  'Tasks' : { 'exit_code' : 0  'stdout' : 'notice: /Stage[2]/Hdp-oozie/Configgenerator::Configfile[oozie-site]/File[/etc/oozie/conf/oozie-site.xml]/content: content changed '{md5}eaf59cc452c92e64b559071586150a08' to '{md5}cb15303aab1c384d19c102a6ce650ed2'/nnotice: Finished catalog run in 2.04 seconds'  'status' : 'COMPLETED'  'stderr' : 'none'  'host_name' : 'ip-10-40-19-235.ec2.internal'  'id' : 43  'cluster_name' : 'yusaku'  'attempt_cnt' : 1  'request_id' : 2  'command' : 'INSTALL'  'role' : 'OOZIE_CLIENT'  'start_time' : 1365743356709  'stage_id' : 1 } }  { 'href' : 'http://ec2-50-17-99-21.compute-1.amazonaws.com:8080/api/v1/clusters/yusaku/requests/2/tasks/51'  'Tasks' : { 'exit_code' : 999  'stdout' : ''  'status' : 'QUEUED'  'stderr' : ''  'host_name' : 'ip-10-40-19-235.ec2.internal'  'id' : 51  'cluster_name' : 'yusaku'  'attempt_cnt' : 1  'request_id' : 2  'command' : 'START'  'role' : 'GANGLIA_MONITOR'  'start_time' : 1365743407043  'stage_id' : 2 } }  { 'href' : 'http://ec2-50-17-99-21.compute-1.amazonaws.com:8080/api/v1/clusters/yusaku/requests/2/tasks/41'  'Tasks' : { 'exit_code' : 0  'stdout' : 'notice: Finished catalog run in 2.22 seconds'  'status' : 'COMPLETED'  'stderr' : 'none'  'host_name' : 'ip-10-40-19-235.ec2.internal'  'id' : 41  'cluster_name' : 'yusaku'  'attempt_cnt' : 1  'request_id' : 2  'command' : 'INSTALL'  'role' : 'HCAT'  'start_time' : 1365743356684  'stage_id' : 1 } }  { 'href' : 'http://ec2-50-17-99-21.compute-1.amazonaws.com:8080/api/v1/clusters/yusaku/requests/2/tasks/54'  'Tasks' : { 'exit_code' : 999  'stdout' : ''  'status' : 'QUEUED'  'stderr' : ''  'host_name' : 'ip-10-80-81-236.ec2.internal'  'id' : 54  'cluster_name' : 'yusaku'  'attempt_cnt' : 1  'request_id' : 2  'command' : 'START'  'role' : 'GANGLIA_SERVER'  'start_time' : 1365743407078  'stage_id' : 2 } }  { 'href' : 'http://ec2-50-17-99-21.compute-1.amazonaws.com:8080/api/v1/clusters/yusaku/requests/2/tasks/55'  'Tasks' : { 'exit_code' : 999  'stdout' : ''  'status' : 'QUEUED'  'stderr' : ''  'host_name' : 'ip-10-80-81-236.ec2.internal'  'id' : 55  'cluster_name' : 'yusaku'  'attempt_cnt' : 1  'request_id' : 2  'command' : 'START'  'role' : 'NAGIOS_SERVER'  'start_time' : 1365743407100  'stage_id' : 2 } }  { 'href' : 'http://ec2-50-17-99-21.compute-1.amazonaws.com:8080/api/v1/clusters/yusaku/requests/2/tasks/50'  'Tasks' : { 'exit_code' : 999  'stdout' : ''  'status' : 'QUEUED'  'stderr' : ''  'host_name' : 'ip-10-40-19-235.ec2.internal'  'id' : 50  'cluster_name' : 'yusaku'  'attempt_cnt' : 1  'request_id' : 2  'command' : 'START'  'role' : 'DATANODE'  'start_time' : 1365743407032  'stage_id' : 2 } }  { 'href' : 'http://ec2-50-17-99-21.compute-1.amazonaws.com:8080/api/v1/clusters/yusaku/requests/2/tasks/67'  'Tasks' : { 'exit_code' : 999  'stdout' : ''  'status' : 'PENDING'  'stderr' : ''  'host_name' : 'ip-10-40-19-235.ec2.internal'  'id' : 67  'cluster_name' : 'yusaku'  'attempt_cnt' : 0  'request_id' : 2  'command' : 'START'  'role' : 'HBASE_REGIONSERVER'  'start_time' : -1  'stage_id' : 4 } }  { 'href' : 'http://ec2-50-17-99-21.compute-1.amazonaws.com:8080/api/v1/clusters/yusaku/requests/2/tasks/47'  'Tasks' : { 'exit_code' : 0  'stdout' : 'warning: Dynamic lookup of $hadoop_heapsize is deprecated. Support will be removed in Puppet 2.8. Use a fully-qualified variable name (e.g.  $classname::variable) or parameterized classes./nnotice: /Stage[2]/Hdp-hive/Configgenerator::Configfile[hive-site]/File[/etc/hive/conf/hive-site.xml]/content: content changed '{md5}29d1def766d4aadfddbf38db13a2712e' to '{md5}2d26829fd012bf5f195e760fc8eeb7f9'/nnotice: Finished catalog run in 2.84 seconds'  'status' : 'COMPLETED'  'stderr' : 'none'  'host_name' : 'ip-10-80-81-236.ec2.internal'  'id' : 47  'cluster_name' : 'yusaku'  'attempt_cnt' : 1  'request_id' : 2  'command' : 'INSTALL'  'role' : 'HIVE_CLIENT'  'start_time' : 1365743356758  'stage_id' : 1 } }  { 'href' : 'http://ec2-50-17-99-21.compute-1.amazonaws.com:8080/api/v1/clusters/yusaku/requests/2/tasks/45'  'Tasks' : { 'exit_code' : 0  'stdout' : 'notice: Finished catalog run in 2.24 seconds'  'status' : 'COMPLETED'  'stderr' : 'none'  'host_name' : 'ip-10-40-19-235.ec2.internal'  'id' : 45  'cluster_name' : 'yusaku'  'attempt_cnt' : 1  'request_id' : 2  'command' : 'INSTALL'  'role' : 'SQOOP'  'start_time' : 1365743356733  'stage_id' : 1 } }  { 'href' : 'http://ec2-50-17-99-21.compute-1.amazonaws.com:8080/api/v1/clusters/yusaku/requests/2/tasks/44'  'Tasks' : { 'exit_code' : 0  'stdout' : 'notice: Finished catalog run in 2.13 seconds'  'status' : 'COMPLETED'  'stderr' : 'none'  'host_name' : 'ip-10-40-19-235.ec2.internal'  'id' : 44  'cluster_name' : 'yusaku'  'attempt_cnt' : 1  'request_id' : 2  'command' : 'INSTALL'  'role' : 'PIG'  'start_time' : 1365743356721  'stage_id' : 1 } }  { 'href' : 'http://ec2-50-17-99-21.compute-1.amazonaws.com:8080/api/v1/clusters/yusaku/requests/2/tasks/56'  'Tasks' : { 'exit_code' : 999  'stdout' : ''  'status' : 'QUEUED'  'stderr' : ''  'host_name' : 'ip-10-80-81-236.ec2.internal'  'id' : 56  'cluster_name' : 'yusaku'  'attempt_cnt' : 1  'request_id' : 2  'command' : 'START'  'role' : 'NAMENODE'  'start_time' : 1365743407109  'stage_id' : 2 } }  { 'href' : 'http://ec2-50-17-99-21.compute-1.amazonaws.com:8080/api/v1/clusters/yusaku/requests/2/tasks/52'  'Tasks' : { 'exit_code' : 999  'stdout' : ''  'status' : 'QUEUED'  'stderr' : ''  'host_name' : 'ip-10-40-19-235.ec2.internal'  'id' : 52  'cluster_name' : 'yusaku'  'attempt_cnt' : 1  'request_id' : 2  'command' : 'START'  'role' : 'ZOOKEEPER_SERVER'  'start_time' : 1365743407062  'stage_id' : 2 } }  { 'href' : 'http://ec2-50-17-99-21.compute-1.amazonaws.com:8080/api/v1/clusters/yusaku/requests/2/tasks/42'  'Tasks' : { 'exit_code' : 0  'stdout' : 'warning: Dynamic lookup of $hadoop_heapsize is deprecated. Support will be removed in Puppet 2.8. Use a fully-qualified variable name (e.g.  $classname::variable) or parameterized classes./nnotice: /Stage[2]/Hdp-hive/Configgenerator::Configfile[hive-site]/File[/etc/hive/conf/hive-site.xml]/content: content changed '{md5}27e517fec40f6157f75eb3116d5387bf' to '{md5}54ff14d0a6d9968e900f28853125b294'/nnotice: Finished catalog run in 2.28 seconds'  'status' : 'COMPLETED'  'stderr' : 'none'  'host_name' : 'ip-10-40-19-235.ec2.internal'  'id' : 42  'cluster_name' : 'yusaku'  'attempt_cnt' : 1  'request_id' : 2  'command' : 'INSTALL'  'role' : 'HIVE_CLIENT'  'start_time' : 1365743356697  'stage_id' : 1 } }  { 'href' : 'http://ec2-50-17-99-21.compute-1.amazonaws.com:8080/api/v1/clusters/yusaku/requests/2/tasks/63'  'Tasks' : { 'exit_code' : 999  'stdout' : ''  'status' : 'PENDING'  'stderr' : ''  'host_name' : 'ip-10-80-81-236.ec2.internal'  'id' : 63  'cluster_name' : 'yusaku'  'attempt_cnt' : 0  'request_id' : 2  'command' : 'START'  'role' : 'HBASE_MASTER'  'start_time' : -1  'stage_id' : 3 } }  { 'href' : 'http://ec2-50-17-99-21.compute-1.amazonaws.com:8080/api/v1/clusters/yusaku/requests/2/tasks/62'  'Tasks' : { 'exit_code' : 999  'stdout' : ''  'status' : 'PENDING'  'stderr' : ''  'host_name' : 'ip-10-40-19-235.ec2.internal'  'id' : 62  'cluster_name' : 'yusaku'  'attempt_cnt' : 0  'request_id' : 2  'command' : 'START'  'role' : 'TASKTRACKER'  'start_time' : -1  'stage_id' : 3 } }  { 'href' : 'http://ec2-50-17-99-21.compute-1.amazonaws.com:8080/api/v1/clusters/yusaku/requests/2/tasks/46'  'Tasks' : { 'exit_code' : 0  'stdout' : 'notice: Finished catalog run in 2.77 seconds'  'status' : 'COMPLETED'  'stderr' : 'none'  'host_name' : 'ip-10-80-81-236.ec2.internal'  'id' : 46  'cluster_name' : 'yusaku'  'attempt_cnt' : 1  'request_id' : 2  'command' : 'INSTALL'  'role' : 'HCAT'  'start_time' : 1365743356744  'stage_id' : 1 } }  { 'href' : 'http://ec2-50-17-99-21.compute-1.amazonaws.com:8080/api/v1/clusters/yusaku/requests/2/tasks/58'  'Tasks' : { 'exit_code' : 999  'stdout' : ''  'status' : 'QUEUED'  'stderr' : ''  'host_name' : 'ip-10-85-70-140.ec2.internal'  'id' : 58  'cluster_name' : 'yusaku'  'attempt_cnt' : 1  'request_id' : 2  'command' : 'START'  'role' : 'GANGLIA_MONITOR'  'start_time' : 1365743407125  'stage_id' : 2 } }  { 'href' : 'http://ec2-50-17-99-21.compute-1.amazonaws.com:8080/api/v1/clusters/yusaku/requests/2/tasks/60'  'Tasks' : { 'exit_code' : 999  'stdout' : ''  'status' : 'QUEUED'  'stderr' : ''  'host_name' : 'ip-10-85-70-140.ec2.internal'  'id' : 60  'cluster_name' : 'yusaku'  'attempt_cnt' : 1  'request_id' : 2  'command' : 'START'  'role' : 'ZOOKEEPER_SERVER'  'start_time' : 1365743407164  'stage_id' : 2 } }  { 'href' : 'http://ec2-50-17-99-21.compute-1.amazonaws.com:8080/api/v1/clusters/yusaku/requests/2/tasks/69'  'Tasks' : { 'exit_code' : 999  'stdout' : ''  'status' : 'PENDING'  'stderr' : ''  'host_name' : 'ip-10-85-70-140.ec2.internal'  'id' : 69  'cluster_name' : 'yusaku'  'attempt_cnt' : 0  'request_id' : 2  'command' : 'START'  'role' : 'OOZIE_SERVER'  'start_time' : -1  'stage_id' : 4 } }  { 'href' : 'http://ec2-50-17-99-21.compute-1.amazonaws.com:8080/api/v1/clusters/yusaku/requests/2/tasks/64'  'Tasks' : { 'exit_code' : 999  'stdout' : ''  'status' : 'PENDING'  'stderr' : ''  'host_name' : 'ip-10-85-70-140.ec2.internal'  'id' : 64  'cluster_name' : 'yusaku'  'attempt_cnt' : 0  'request_id' : 2  'command' : 'START'  'role' : 'HIVE_METASTORE'  'start_time' : -1  'stage_id' : 3 } }  { 'href' : 'http://ec2-50-17-99-21.compute-1.amazonaws.com:8080/api/v1/clusters/yusaku/requests/2/tasks/48'  'Tasks' : { 'exit_code' : 0  'stdout' : 'warning: Dynamic lookup of $service_state at /var/lib/ambari-agent/puppet/modules/hdp-hadoop/manifests/init.pp:213 is deprecated. Support will be removed in Puppet 2.8. Use a fully-qualified variable name (e.g.  $classname::variable) or parameterized classes./nwarning: Dynamic lookup of $tasktracker_port is deprecated. Support will be removed in Puppet 2.8. Use a fully-qualified variable name (e.g.  $classname::variable) or parameterized classes./nwarning: Dynamic lookup of $ambari_db_rca_url is deprecated. Support will be removed in Puppet 2.8. Use a fully-qualified variable name (e.g.  $classname::variable) or parameterized classes./nwarning: Dynamic lookup of $ambari_db_rca_driver is deprecated. Support will be removed in Puppet 2.8. Use a fully-qualified variable name (e.g.  $classname::variable) or parameterized classes./nwarning: Dynamic lookup of $ambari_db_rca_username is deprecated. Support will be removed in Puppet 2.8. Use a fully-qualified variable name (e.g.  $classname::variable) or parameterized classes./nwarning: Dynamic lookup of $ambari_db_rca_password is deprecated. Support will be removed in Puppet 2.8. Use a fully-qualified variable name (e.g.  $classname::variable) or parameterized classes./nnotice: /Stage[2]/Hdp-hadoop::Initialize/Configgenerator::Configfile[core-site]/File[/etc/hadoop/conf/core-site.xml]/content: content changed '{md5}95bdcddd064261ac3a00d8c0a7f79fee' to '{md5}d6f5b9646bf280e915e3b0d42ed622a9'/nnotice: /Stage[2]/Hdp-hadoop::Initialize/Configgenerator::Configfile[hdfs-site]/File[/etc/hadoop/conf/hdfs-site.xml]/content: content changed '{md5}5f83b57cbac46a0b7007ed94720a8c3b' to '{md5}e0e38c4dc10fc81b12637e34796ced70'/nnotice: /Stage[2]/Hdp-hadoop::Initialize/Configgenerator::Configfile[mapred-site]/File[/etc/hadoop/conf/mapred-site.xml]/content: content changed '{md5}42b54b8e096eafa7ba53c8f5b53bda3e' to '{md5}409f4680bc7871db2864afecbcefdb36'/nnotice: Finished catalog run in 3.67 seconds'  'status' : 'COMPLETED'  'stderr' : 'none'  'host_name' : 'ip-10-80-81-236.ec2.internal'  'id' : 48  'cluster_name' : 'yusaku'  'attempt_cnt' : 1  'request_id' : 2  'command' : 'INSTALL'  'role' : 'MAPREDUCE_CLIENT'  'start_time' : 1365743356769  'stage_id' : 1 } }  { 'href' : 'http://ec2-50-17-99-21.compute-1.amazonaws.com:8080/api/v1/clusters/yusaku/requests/2/tasks/70'  'Tasks' : { 'exit_code' : 999  'stdout' : ''  'status' : 'PENDING'  'stderr' : ''  'host_name' : 'ip-10-85-70-140.ec2.internal'  'id' : 70  'cluster_name' : 'yusaku'  'attempt_cnt' : 0  'request_id' : 2  'command' : 'START'  'role' : 'WEBHCAT_SERVER'  'start_time' : -1  'stage_id' : 5 } }  { 'href' : 'http://ec2-50-17-99-21.compute-1.amazonaws.com:8080/api/v1/clusters/yusaku/requests/2/tasks/61'  'Tasks' : { 'exit_code' : 999  'stdout' : ''  'status' : 'PENDING'  'stderr' : ''  'host_name' : 'ip-10-40-19-235.ec2.internal'  'id' : 61  'cluster_name' : 'yusaku'  'attempt_cnt' : 0  'request_id' : 2  'command' : 'START'  'role' : 'HBASE_MASTER'  'start_time' : -1  'stage_id' : 3 } }  { 'href' : 'http://ec2-50-17-99-21.compute-1.amazonaws.com:8080/api/v1/clusters/yusaku/requests/2/tasks/66'  'Tasks' : { 'exit_code' : 999  'stdout' : ''  'status' : 'PENDING'  'stderr' : ''  'host_name' : 'ip-10-85-70-140.ec2.internal'  'id' : 66  'cluster_name' : 'yusaku'  'attempt_cnt' : 0  'request_id' : 2  'command' : 'START'  'role' : 'SECONDARY_NAMENODE'  'start_time' : -1  'stage_id' : 3 } }  { 'href' : 'http://ec2-50-17-99-21.compute-1.amazonaws.com:8080/api/v1/clusters/yusaku/requests/2/tasks/49'  'Tasks' : { 'exit_code' : 0  'stdout' : 'notice: /Stage[2]/Hdp-oozie/Configgenerator::Configfile[oozie-site]/File[/etc/oozie/conf/oozie-site.xml]/content: content changed '{md5}001c4940080d2ea315a9720676f1bcad' to '{md5}282f1e354fe7f9da0f6de43425a40d40'/nnotice: Finished catalog run in 2.24 seconds'  'status' : 'COMPLETED'  'stderr' : 'none'  'host_name' : 'ip-10-80-81-236.ec2.internal'  'id' : 49  'cluster_name' : 'yusaku'  'attempt_cnt' : 1  'request_id' : 2  'command' : 'INSTALL'  'role' : 'OOZIE_CLIENT'  'start_time' : 1365743356796  'stage_id' : 1 } }  { 'href' : 'http://ec2-50-17-99-21.compute-1.amazonaws.com:8080/api/v1/clusters/yusaku/requests/2/tasks/53'  'Tasks' : { 'exit_code' : 999  'stdout' : ''  'status' : 'QUEUED'  'stderr' : ''  'host_name' : 'ip-10-80-81-236.ec2.internal'  'id' : 53  'cluster_name' : 'yusaku'  'attempt_cnt' : 1  'request_id' : 2  'command' : 'START'  'role' : 'GANGLIA_MONITOR'  'start_time' : 1365743407070  'stage_id' : 2 } }  { 'href' : 'http://ec2-50-17-99-21.compute-1.amazonaws.com:8080/api/v1/clusters/yusaku/requests/2/tasks/68'  'Tasks' : { 'exit_code' : 999  'stdout' : ''  'status' : 'PENDING'  'stderr' : ''  'host_name' : 'ip-10-85-70-140.ec2.internal'  'id' : 68  'cluster_name' : 'yusaku'  'attempt_cnt' : 0  'request_id' : 2  'command' : 'START'  'role' : 'HIVE_SERVER'  'start_time' : -1  'stage_id' : 4 } }  { 'href' : 'http://ec2-50-17-99-21.compute-1.amazonaws.com:8080/api/v1/clusters/yusaku/requests/2/tasks/65'  'Tasks' : { 'exit_code' : 999  'stdout' : ''  'status' : 'PENDING'  'stderr' : ''  'host_name' : 'ip-10-85-70-140.ec2.internal'  'id' : 65  'cluster_name' : 'yusaku'  'attempt_cnt' : 0  'request_id' : 2  'command' : 'START'  'role' : 'JOBTRACKER'  'start_time' : -1  'stage_id' : 3 } }  { 'href' : 'http://ec2-50-17-99-21.compute-1.amazonaws.com:8080/api/v1/clusters/yusaku/requests/2/tasks/57'  'Tasks' : { 'exit_code' : 999  'stdout' : ''  'status' : 'QUEUED'  'stderr' : ''  'host_name' : 'ip-10-80-81-236.ec2.internal'  'id' : 57  'cluster_name' : 'yusaku'  'attempt_cnt' : 1  'request_id' : 2  'command' : 'START'  'role' : 'ZOOKEEPER_SERVER'  'start_time' : 1365743407117  'stage_id' : 2 } }  { 'href' : 'http://ec2-50-17-99-21.compute-1.amazonaws.com:8080/api/v1/clusters/yusaku/requests/2/tasks/59'  'Tasks' : { 'exit_code' : 999  'stdout' : ''  'status' : 'QUEUED'  'stderr' : ''  'host_name' : 'ip-10-85-70-140.ec2.internal'  'id' : 59  'cluster_name' : 'yusaku'  'attempt_cnt' : 1  'request_id' : 2  'command' : 'START'  'role' : 'MYSQL_SERVER'  'start_time' : 1365743407156  'stage_id' : 2 } } ]},1.2.3,1.2.3,1766,1,0,0,0,0,0,0,
1917,,Jaimin D Jetly,Ambari Core-Site.xml Missing Property for LZO (enabled) - io.compression.codecs,,1.2.3,1.2.3,1,1,0,0,0,0,0,0,
1919,,Sumit Mohanty,JobTracker History Server failed to come up on 1.3.0 stack and the request for service stall is stalled,Attempted to install a cluster with 1.3.0 stack.Service install was all green  but JobTracker History Server failed to come up.The request for the service start is stalled  with no tasks in QUEUED or IN_PROGRESS state  but with some tasks in PENDING state.,1.2.3,1.2.3,42,0,0,0,0,0,0,0,
1923,,Sumit Mohanty,Allow for users to customize Nagios user accounts,Allow for customers to install the users used for Nagios.,1.2.3,1.2.4,10,1,0,0,0,0,0,0,
1924,,Sumit Mohanty,Allow for users to customize Ganglia gmetad + gmond user accounts,Allow customization of ganglia gmetad and gmond users.For reference: looks like this is available in gsInstaller so the pattern exists to follow for Ambari impl. Defaults to nobody/nobody,1.2.3,1.2.3,28,1,0,0,0,0,0,0,
1933,,Sumit Mohanty,Test failure : testCascadeDeleteStages,mvn clean install produces the following failure ...testCascadeDeleteStages(org.apache.ambari.server.actionmanager.TestActionManager):Exception [EclipseLink-4002] (Eclipse Persistence Services -2.4.0.v20120608-r11652):org.eclipse.persistence.exceptions.DatabaseException(..),1.2.3,1.2.3,20,0,0,0,0,0,0,0,
1934,,Sumit Mohanty,Security vulnerability with Ganglia and Nagios,Ganglia Issue : Unspecified vulnerability in Ganglia Web before 3.5.1 allows remote attackers to execute arbitrary PHP code via unknown attack vectors. http://ganglia.info/?p=549 Ganglia Web 3.5.1 Release Security Advisory There is a security issue in Ganglia Web going back to at least 3.1.7 which can lead to arbitrary script being executed with web user privileges possibly leading to a machine compromise. Issue has been fixed in the latest version of Ganglia Web which can be downloaded from https://sourceforge.net/projects/ganglia/files/ganglia-web/3.5.1/ Solution: Need to get upgraded rpms with the Ganglia Web version 3.5.7 which has the fix for this vulnerability.Nagios: Multiple stack-based buffer overflows in the get_history function in history.cgi in Nagios Core before 3.4.4  and Icinga 1.6.x before 1.6.2  1.7.x before 1.7.4  and 1.8.x before 1.8.4  might allow remote attackers to execute arbitrary code via a long (1) host_name variable (host parameter) or (2) svc_description variable. http://www.nagios.org/projects/nagioscore/history/core-3x http://lists.grok.org.uk/pipermail/full-disclosure/2012-December/089125.html Vulnerable software and versions - nagios:nagios:3.4.3 and previous versions,1.2.3,1.2.3,169,1,0,0,1,0,0,0,
1944,ambari-server,Siddharth Wagle,All Service Smoke tests fail when run with service start,has_key(): expects the first argument to be a hash  got '' which is of type String at /var/lib/ambari-agent/puppet/modules/hdp/manifests/init.pp:38 on node ip-10-38-25-227.ec2.internalsite-pp#12.04.2013 03:16:38import '/var/lib/ambari-agent/puppet/modules/hdp/manifests/*.pp'import '/var/lib/ambari-agent/puppet/modules/hdp-hadoop/manifests/*.pp'import '/var/lib/ambari-agent/puppet/modules/hdp-hbase/manifests/*.pp'import '/var/lib/ambari-agent/puppet/modules/hdp-zookeeper/manifests/*.pp'import '/var/lib/ambari-agent/puppet/modules/hdp-oozie/manifests/*.pp'import '/var/lib/ambari-agent/puppet/modules/hdp-pig/manifests/*.pp'import '/var/lib/ambari-agent/puppet/modules/hdp-sqoop/manifests/*.pp'import '/var/lib/ambari-agent/puppet/modules/hdp-templeton/manifests/*.pp'import '/var/lib/ambari-agent/puppet/modules/hdp-hive/manifests/*.pp'import '/var/lib/ambari-agent/puppet/modules/hdp-hcat/manifests/*.pp'import '/var/lib/ambari-agent/puppet/modules/hdp-mysql/manifests/*.pp'import '/var/lib/ambari-agent/puppet/modules/hdp-monitor-webserver/manifests/*.pp'import '/var/lib/ambari-agent/puppet/modules/hdp-repos/manifests/*.pp'$ambari_db_rca_password= ['mapred']$nagios_server_host= ['ip-10-38-25-227.ec2.internal']$ambari_db_rca_url= ['jdbc:postgresql://ip-10-38-25-227.ec2.internal/ambarirca']$webhcat_server_host= ['ip-10-38-25-227.ec2.internal']$hbase_rs_hosts= ['ip-10-38-25-227.ec2.internal']$slave_hosts= ['ip-10-38-25-227.ec2.internal']$namenode_host= ['ip-10-38-25-227.ec2.internal']$ganglia_server_host= ['ip-10-38-25-227.ec2.internal']$hbase_master_hosts= ['ip-10-38-25-227.ec2.internal']$hive_mysql_host= ['ip-10-38-25-227.ec2.internal']$oozie_server= ['ip-10-38-25-227.ec2.internal']$ambari_db_rca_driver= ['org.postgresql.Driver']$zookeeper_hosts= ['ip-10-38-25-227.ec2.internal']$jtnode_host= ['ip-10-38-25-227.ec2.internal']$ambari_db_rca_username= ['mapred']$hive_server_host= ['ip-10-38-25-227.ec2.internal']node /default/ { stage{1 :} -&gt; stage{2 :}class {'hdp': stage =&gt; 1}class {'hdp-zookeeper::quorum::service_check': stage =&gt; 2}},1.2.3,1.2.3,72,0,0,0,0,0,0,0,
1947,ambari-agent,Siddharth Wagle,Oozie Smoke test fails with errors on the start services/install page.,Ozzie smoke tests fail,1.2.3,1.2.3,4,0,0,0,0,0,0,0,
1948,ambari-agent,Siddharth Wagle,System logs are not present on tasktracker,Run a mapreduce job.Find the attempt id and look for system logs on tasktracker.http://ec2-54-224-138-78.compute-1.amazonaws.com:50060/tasklog?attemptid=attempt_201304121816_0003_m_000000_0Actual result:The syslogs are not present here.Only stdout and stderr logs are present.,1.2.3,1.2.3,29,1,0,0,0,0,0,0,
1952,infra,Ashish Singh,hadoop dependency version for ambari-log4j is hardcoded  making it regular expression based to pick latest from the repository.,Ambari-log4j has hardcoded hadoop-core and hadoop-tools dependency. Make it version as regular expression to pick from the range from 1.0 &lt;= x &lt; 2.0.Also  updating the repository url.,1.2.3,1.2.3,28,1,0,0,0,0,0,0,
1956,ambari-web,Yusaku Sako,Wrong install status shown in Add Service Wizard,Upon master component install failure  the host status becomes 'warning' instead of 'failed' for Add Service Wizard.,1.2.3,1.2.3,17,1,0,0,0,0,0,0,
1957,ambari-web,Yusaku Sako,Hosts table: whether the alert filter is in effect or not is not clear,Currently  when the red badge inside the Hosts tab is clicked  it shows hosts that have at least one alert and no other hosts are displayed.The fact that the alert filter is in effect is not clear to the user and causes confusion.,1.2.3,1.2.3,43,0,0,0,0,0,0,0,
1966,ambari-web,Yusaku Sako,Client install tasks are shown twice in progress popup during start phase of install wizard (update API call to include params/reconfigure_client),,1.2.3,1.2.3,1,1,0,0,0,0,0,0,
1978,ambari-agent,Siddharth Wagle,Deploying HDP-1.3.0 results in several alerts - is it related to hard-coded port,TaskTracker  RegionServer  HBase master process down because check_tcp failure.Looks like the hadoop-services.cfg.erb has:check_command check_tcp!&lt;%=scope.function_hdp_template_var('jtnode_port')%&gt;!-w 1 -c 1and looks like the ports are not getting replaced and end up being empty.,1.2.3,1.2.3,30,0,0,0,0,0,0,0,
1980,,Nate Cole,When nagios is unavailable  return null instead of throwing an Exception,NAGIOS_SERVER alerts are retrieved from the nagios server when requesting the host_component. There is a SystemException thrown in the case of an IOException  which propagates as a 500 error for the entire request.In this case  set the nagios_alerts element to null instead of the 500 error.,1.2.3,1.2.3,46,0,0,0,0,0,0,0,
1988,ambari-web,Yusaku Sako,Hostname pattern expression is broken,dev[01-03].domain.com expanded to:dev1.domain.comdev2.domain.comdev3.domain.comShould be:dev01.domain.comdev02.domain.comdev03.domain.com,1.2.3,1.2.3,4,0,0,0,0,0,0,0,
1997,ambari-web,Yusaku Sako,Filtered hosts get out of sync with the filter selection,1. Browse to Hosts2. Click one of the filters3. Browse to Services and back to Hosts4. The filter links show All as the current filter but the filter didn't reset and still shows a sub-set of hosts,1.2.3,1.2.3,37,0,0,0,0,0,0,0,
1998,ambari-web,Yusaku Sako,Action buttons on host details page not formatted properly on Firefox,,1.2.3,1.2.3,1,0,0,0,0,0,0,0,
1999,ambari-web,Yusaku Sako,Clicking on Cancel on the Service Config page should not reload the entire app,When Cancel is clicked on the Service Config page  simply reload the config (not the entire app).,1.2.3,1.2.3,17,1,0,0,0,0,0,0,
2001,ambari-web,Yusaku Sako,Filtering on Jobs table does not work under certain situations,,1.2.3,1.2.3,1,1,0,0,0,0,0,0,
2003,ambari-web,Yusaku Sako,Hosts tab: clicking on red badge should not toggle 'Alerts' filter,Clicking on the red badge in the Hosts tab should not toggle the 'Alerts' filter on the Hosts page (clicking anywhere in Hosts tab should go to Hosts page with 'All' selected).,1.2.3,1.2.3,32,1,0,0,0,0,0,0,
2008,,Sumit Mohanty,Using mixed OS overwrites ambari.repo during install,Performed install on mixed OS environment with 8 hosts.Ambari Server = RHEL6Three Hosts = RHEL6Four Hosts = RHEL5Performed manual ambari-agent bootstrap of the Four RHEL5 hosts. I was able to successfully register all hosts. When install started  the four RHEL5 hosts failed on installing their first component. Looking at the servers  looks like the right HDP.repo and HDP-epel.repo files are put in place.But looks like the ambari.repo file had been overwritten at some point during the install process  and now is point to the RHEL6 repos  causing failures.,1.2.3,1.2.3,88,1,0,0,0,0,0,0,
2013,,Nate Cole,Cannot delete cluster with components in UNKNOWN state,When components are marked in an UNKNOWN state  it is not possible to delete the cluster - this should be possible.,1.2.3,1.2.3,21,0,0,0,0,0,0,0,
2019,ambari-server,Siddharth Wagle,Cannot decommission data node (ensure recommission also works),stderr: $configuration&#91;hdfs-site&#93; is not an hash or array when accessing it with dfs.hosts.exclude at /var/lib/ambari-agent/puppet/modules/hdp-hadoop/manifests/hdfs/decommission.pp:24 on node ip-10-82-213-66.ec2.internal stdout:None,1.2.3,1.2.3,20,0,0,0,0,1,0,0,
2024,ambari-server,Siddharth Wagle,Ambari Server becomes unresponsive after crashing on http reads on jersey.,The api's are being handled by a queuedthreadpool. The queuedthread pool size is 25.Somehow the http connections are being torn down from the UI side but the server still is hanging onto that socket and reading (most likely UI will also need to close http connections if its not using them - which might be an issue as well but doesnt have to addressed as urgent). The server has a read timeout of 0 which means it will just hang on to that socket for read. This causes all the threads to block at one time or the other. Simple solution is add read timeouts to all the SelectChannelConnector and SslSelectChannelConnector we use.Exception trace: SEVERE: The exception contained within MappableContainerException could not be mapped to a response  re-throwing to the HTTP containerorg.eclipse.jetty.io.EofException: early EOF at org.eclipse.jetty.server.HttpInput.read(HttpInput.java:65) at org.codehaus.jackson.impl.ByteSourceBootstrapper.ensureLoaded(ByteSourceBootstrapper.java:507) at org.codehaus.jackson.impl.ByteSourceBootstrapper.detectEncoding(ByteSourceBootstrapper.java:129) at org.codehaus.jackson.impl.ByteSourceBootstrapper.constructParser(ByteSourceBootstrapper.java:224) at org.codehaus.jackson.JsonFactory._createJsonParser(JsonFactory.java:785) at org.codehaus.jackson.JsonFactory.createJsonParser(JsonFactory.java:561) at org.codehaus.jackson.jaxrs.JacksonJsonProvider.readFrom(JacksonJsonProvider.java:414) at com.sun.jersey.json.impl.provider.entity.JacksonProviderProxy.readFrom(JacksonProviderProxy.java:139) at com.sun.jersey.spi.container.ContainerRequest.getEntity(ContainerRequest.java:474)Notice the API's is being called all the time - meaning they probalby had a browser up and running for a long time.There might be a possibilility that the browser might have some issues after running for a long time. Something to keep in mind when this happens again. Easy way to check that is to call Ambari server API's and also bring up a new browser window (new instance) and try hitting the browser UI.,1.2.3,1.2.3,227,0,0,0,0,1,0,0,
2027,ambari-web,Yusaku Sako,Add validation checks for Add Property on custom site configs,,1.2.3,1.2.3,1,1,0,0,0,0,0,0,
2029,ambari-web,Yusaku Sako,Error when loading /main/services directly,,1.2.3,1.2.3,1,0,0,0,0,0,0,0,
2030,ambari-web,Yusaku Sako,Make frontend changes to account for the host component status UNKNOWN,Service status: if any of the master components are in UNKNOWN state  show the unknown icon. The action buttons for the service are disabled. Host status: if the host status is UNKNOWN or the heartbeat has not been received in more than 180 seconds  show the unknown icon. Host component status: if the host component status is UNKNOWN  show the unknown icon. The action button for the host component is disabled.,1.2.3,1.2.3,72,1,0,0,0,0,0,0,
2031,infra,Giridharan Kesavan,Add clover code coverage profile,mvn test -Pclover -Dclover.license=&lt;clover.coverage.license&gt; should run the unit tests and return html/xml code coverage reports,1.3.0,,16,0,0,0,0,0,0,0,
2034,ambari-web,Yusaku Sako,Disable 'Add Component' button in the Host Details page if the host is in UNKNOWN state or !isHeartbeating,,1.2.3,1.2.3,1,0,0,0,0,0,0,0,
2035,ambari-web,Yusaku Sako,'Add local user' button is enabled but nothing happens upon clicking it under certain conditions,Steps to reproduce1. Go to Admin tab2. Click on 'Add Local User' button3. Click on Admin tab again4. Clicking on 'Add Local User' button does nothing,1.2.3,1.2.3,26,0,0,0,0,0,0,0,
2038,ambari-web,Yusaku Sako,Services links on Dashboard connected to incorrect pages,Click on any of the service links shown on the Dashboard page.It transitions to the service page and the content displayed is correct for the service chosen  but the URL indicates that it is another service and the side-menu shows a different service highlighted.,1.2.3,1.2.3,44,0,0,0,0,0,0,0,
2045,ambari-server,Siddharth Wagle,Add Unit test to verify  client re-install for install failed client,Add Unit test to verify  When INSTALL is schedules on client components it should also be scheduled on components that are in INSTALL_FAILED state,1.2.3,1.2.3,24,0,0,0,0,0,0,0,
2054,ambari-web,Yusaku Sako,If 'Install from Local Repository' selected in install wizard  Add Host wizard not working,,1.2.3,1.2.3,1,0,0,0,0,0,1,0,
2058,ambari-web,Yusaku Sako,Host Detail page: if the host component is in INSTALL_FAILED state  we should let the user reinstall it,,1.2.3,1.2.3,1,0,0,0,0,0,0,0,
2061,ambari-web,Yusaku Sako,HBase Heatmaps: clean up labels and units,,1.2.3,1.2.3,1,0,0,0,0,0,0,0,
2065,,Sumit Mohanty,Hadoop group customization does not take affect,To customize the hadoop group  when it was changed from 'hadoop' to 'hadoopgroup'  it didn't look like it worked.root@ip-10-85-135-237 hdfsuser# id hdfsuid=495(hdfs) gid=494(hdfs) groups=494(hdfs) 495(hadoop)And looking at the /etc/group filepuppet:x:497:hadoopgroup:x:500:rrdcached:x:496:apache:x:48:hadoop:x:495:mapred hdfs,1.2.3,1.2.3,29,0,0,0,0,0,0,0,
2068,ambari-web,Yusaku Sako,'Preparing to install ' message needs spacing,,1.2.3,1.2.3,1,0,0,0,0,0,0,0,
2070,ambari-web,Yusaku Sako,Changing service directories should popup a confirmation/warning dialog upon save,Post-install  if the user tries to reconfigure NN  SNN  MapReduce local/system directories  we should popup a confirmation/warning upon Save as this is potentially a dangerous operation.,1.2.3,1.2.3,26,0,0,0,0,0,0,0,
2075,ambari-web,Yusaku Sako,Admin role can't be assigned to LDAP user,,1.2.3,1.2.3,1,0,0,0,0,0,0,0,
2081,ambari-agent,Siddharth Wagle,changeUid.sh failing during installation,On SUSE  I received a puppet error on each agent that /tmp/changeUid.sh failed during installation. (Sorry I no longer have the error  I made puppet change and restarted to get by it). But in a nutshell  running the command manually gave:ip-10-82-233-26:/tmp # /tmp/changeUid.sh ambari-qa 1012 /tmp/ambari-qa /home/ambari-qa /var/spool/mail/ambari-qaChanging uid of ambari-qa from 1012 to 1012Changing directory permisions for /tmp/ambari-qa /home/ambari-qa /var/spool/mail/ambari-qausermod: UID 1012 is not unique.Note that the usermod is trying to change to an existing UID  so the command is failing everywhere,1.2.3,1.2.4,87,0,0,0,0,0,0,0,
2087,,Sumit Mohanty,Tasks are not filtered by parent request id,STEPS:1) Get tasks for first request  /api/v1/clusters/&lt;cluster&gt;/requests/&lt;firstRequest&gt;  i.e. task1 ... taskN12) Get tasks for second request by task from first requst  like /api/v1/clusters/&lt;cluster&gt;/requests/&lt;secondRequest&gt;/tasks/task1 (note task1 belongs to first request  not second)3) Notice that task from first request are present in second request.,1.2.3,1.2.3,40,0,0,0,0,0,0,0,
2089,,Xi Wang,Post Ambari upgrade  Hive and Oozie fail to start after reconfigure,,1.2.3,1.2.3,1,0,0,0,0,0,0,0,
2095,ambari-web,Jaimin D Jetly,It's possible to get into a state where install retry is not possible if the agent stops heartbeating,This affects both Install and Add Host Wizards.Steps to reproduce:While installing components  stop the agent on one of the hosts.Waiting for a while puts the components on the host into the UNKNOWN state.Click Retry from the UI. This causes a server-side error and the UI gets confused (the hosts are shown with 'Waiting' message and no 'Retry' button is available).The user is not able to get out of this state.,1.2.3,1.2.3,70,0,0,0,0,0,0,0,
2101,ambari-agent,Siddharth Wagle,Hive service check (still) failing with file permissions,Stack upgrade testing is still showing this to be an issue.warning: Unrecognised escape sequence '/;' in file /var/lib/ambari-agent/puppet/modules/hdp-hive/manifests/hive/service_check.pp at line 32warning: Dynamic lookup of $configuration is deprecated. Support will be removed in Puppet 2.8. Use a fully-qualified variable name (e.g.  $classname::variable) or parameterized classes.notice: /Stage[1]/Hdp::Snappy::Package/Hdp::Snappy::Package::Ln[32]/Hdp::Exec[hdp::snappy::package::ln 32]/Exec[hdp::snappy::package::ln 32]/returns: executed successfullynotice: /Stage[2]/Hdp-hcat::Hcat::Service_check/Exec[hcatSmoke.sh prepare]/returns: ls: cannot access /usr/share/java/*oracle*: No such file or directorynotice: /Stage[2]/Hdp-hcat::Hcat::Service_check/Exec[hcatSmoke.sh prepare]/returns: 13/05/09 15:01:52 WARN conf.HiveConf: DEPRECATED: Configuration property hive.metastore.local no longer has any effect. Make sure to provide a valid value for hive.metastore.uris if you are connecting to a remote metastore.notice: /Stage[2]/Hdp-hcat::Hcat::Service_check/Exec[hcatSmoke.sh prepare]/returns: log4j:ERROR setFile(null true) call failed.notice: /Stage[2]/Hdp-hcat::Hcat::Service_check/Exec[hcatSmoke.sh prepare]/returns: java.io.FileNotFoundException: /tmp/ambari_qa/hive.log (Permission denied)notice: /Stage[2]/Hdp-hcat::Hcat::Service_check/Exec[hcatSmoke.sh prepare]/returns: at java.io.FileOutputStream.openAppend(Native Method)notice: /Stage[2]/Hdp-hcat::Hcat::Service_check/Exec[hcatSmoke.sh prepare]/returns: at java.io.FileOutputStream.&lt;init&gt;(FileOutputStream.java:192)notice: /Stage[2]/Hdp-hcat::Hcat::Service_check/Exec[hcatSmoke.sh prepare]/returns: at java.io.FileOutputStream.&lt;init&gt;(FileOutputStream.java:116)notice: /Stage[2]/Hdp-hcat::Hcat::Service_check/Exec[hcatSmoke.sh prepare]/returns: at org.apache.log4j.FileAppender.setFile(FileAppender.java:290)notice: /Stage[2]/Hdp-hcat::Hcat::Service_check/Exec[hcatSmoke.sh prepare]/returns: at org.apache.log4j.FileAppender.activateOptions(FileAppender.java:164)notice: /Stage[2]/Hdp-hcat::Hcat::Service_check/Exec[hcatSmoke.sh prepare]/returns: at org.apache.log4j.DailyRollingFileAppender.activateOptions(DailyRollingFileAppender.java:216)notice: /Stage[2]/Hdp-hcat::Hcat::Service_check/Exec[hcatSmoke.sh prepare]/returns: at org.apache.log4j.config.PropertySetter.activate(PropertySetter.java:257)notice: /Stage[2]/Hdp-hcat::Hcat::Service_check/Exec[hcatSmoke.sh prepare]/returns: at org.apache.log4j.config.PropertySetter.setProperties(PropertySetter.java:133)notice: /Stage[2]/Hdp-hcat::Hcat::Service_check/Exec[hcatSmoke.sh prepare]/returns: at org.apache.log4j.config.PropertySetter.setProperties(PropertySetter.java:97)notice: /Stage[2]/Hdp-hcat::Hcat::Service_check/Exec[hcatSmoke.sh prepare]/returns: at org.apache.log4j.PropertyConfigurator.parseAppender(PropertyConfigurator.java:689)notice: /Stage[2]/Hdp-hcat::Hcat::Service_check/Exec[hcatSmoke.sh prepare]/returns: at org.apache.log4j.PropertyConfigurator.parseCategory(PropertyConfigurator.java:647)notice: /Stage[2]/Hdp-hcat::Hcat::Service_check/Exec[hcatSmoke.sh prepare]/returns: at org.apache.log4j.PropertyConfigurator.configureRootCategory(PropertyConfigurator.java:544)notice: /Stage[2]/Hdp-hcat::Hcat::Service_check/Exec[hcatSmoke.sh prepare]/returns: at org.apache.log4j.PropertyConfigurator.doConfigure(PropertyConfigurator.java:440)notice: /Stage[2]/Hdp-hcat::Hcat::Service_check/Exec[hcatSmoke.sh prepare]/returns: at org.apache.log4j.PropertyConfigurator.doConfigure(PropertyConfigurator.java:476)notice: /Stage[2]/Hdp-hcat::Hcat::Service_check/Exec[hcatSmoke.sh prepare]/returns: at org.apache.log4j.PropertyConfigurator.configure(PropertyConfigurator.java:354)notice: /Stage[2]/Hdp-hcat::Hcat::Service_check/Exec[hcatSmoke.sh prepare]/returns: at org.apache.hadoop.hive.common.LogUtils.initHiveLog4jDefault(LogUtils.java:124)notice: /Stage[2]/Hdp-hcat::Hcat::Service_check/Exec[hcatSmoke.sh prepare]/returns: at org.apache.hadoop.hive.common.LogUtils.initHiveLog4jCommon(LogUtils.java:77)notice: /Stage[2]/Hdp-hcat::Hcat::Service_check/Exec[hcatSmoke.sh prepare]/returns: at org.apache.hadoop.hive.common.LogUtils.initHiveLog4j(LogUtils.java:58)notice: /Stage[2]/Hdp-hcat::Hcat::Service_check/Exec[hcatSmoke.sh prepare]/returns: at org.apache.hcatalog.cli.HCatCli.main(HCatCli.java:61)notice: /Stage[2]/Hdp-hcat::Hcat::Service_check/Exec[hcatSmoke.sh prepare]/returns: at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)notice: /Stage[2]/Hdp-hcat::Hcat::Service_check/Exec[hcatSmoke.sh prepare]/returns: at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)notice: /Stage[2]/Hdp-hcat::Hcat::Service_check/Exec[hcatSmoke.sh prepare]/returns: at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)notice: /Stage[2]/Hdp-hcat::Hcat::Service_check/Exec[hcatSmoke.sh prepare]/returns: at java.lang.reflect.Method.invoke(Method.java:597)notice: /Stage[2]/Hdp-hcat::Hcat::Service_check/Exec[hcatSmoke.sh prepare]/returns: at org.apache.hadoop.util.RunJar.main(RunJar.java:160)notice: /Stage[2]/Hdp-hcat::Hcat::Service_check/Exec[hcatSmoke.sh prepare]/returns: log4j:ERROR Either File or DatePattern options are not set for appender [DRFA].notice: /Stage[2]/Hdp-hcat::Hcat::Service_check/Exec[hcatSmoke.sh prepare]/returns: Exception in thread 'main' java.lang.RuntimeException: java.io.IOException: Permission deniednotice: /Stage[2]/Hdp-hcat::Hcat::Service_check/Exec[hcatSmoke.sh prepare]/returns: at org.apache.hadoop.hive.ql.session.SessionState.start(SessionState.java:272)notice: /Stage[2]/Hdp-hcat::Hcat::Service_check/Exec[hcatSmoke.sh prepare]/returns: at org.apache.hcatalog.cli.HCatCli.main(HCatCli.java:79)notice: /Stage[2]/Hdp-hcat::Hcat::Service_check/Exec[hcatSmoke.sh prepare]/returns: at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method),1.2.3,1.2.3,245,0,0,0,1,0,0,0,
2103,ambari-web,Jeff Sposetti,Support for configuring and running Ambari Web Server https,Need to be able to run Ambari Web (and access Ambari REST APIs) over HTTPS. Should document assuming the user comes with their own certificate. User should also be able to configure which port to expose HTTPS.,1.2.0; 1.2.1; 1.2.2; 1.2.3,1.2.5,39,0,1,0,0,0,0,0,
2111,ambari-web,Yusaku Sako,Enable customization of smoke test user,,1.2.3,1.2.4,1,0,0,0,0,0,0,0,
2118,ambari-server,Chad Roberts,ambari-web modifications to allow for Hadoop Compatible Filesystems (HCFS),Make modifications to ambari-web that will allow for the selection of a Hadoop Compatible Filesystem. These changes include allowing HDFS to be unselected (either HDFS or HCFS must be selected). If HCFS is chosen  push appropriate configuration (site-conf.xml) files during the install so that systems will work with HCFS as the underlying filesystem rather than HDFS.,1.2.5,1.2.5,56,0,0,1,0,0,0,0,
2130,ambari-server,Trevor McKay,Use modified dependencies if a stack contains an HCFS service (Hadoop Compatible File System),Use stack metadata to determine if a stack contains an HCFS service and generate modified RoleCommandOrder dependencies if it does.,1.2.2,1.2.5,20,0,0,1,0,0,0,0,
2134,ambari-server,Jaimin D Jetly,Set default value of oozie property 'oozie.service.AuthorizationService.authorization.enabled' to true.,,1.2.4,1.2.4,1,0,0,0,0,0,0,0,
2136,,Mahadev konar,Home paths are not set correctly in /etc/sqoop/conf/sqoop-env.sh,Ambari sets the followings:#Set path to where bin/hadoop is availableexport HADOOP_HOME=${HADOOP_HOME:-/usr}#set the path to where bin/hbase is availableexport HBASE_HOME=${HBASE_HOME:-/usr}#Set the path to where bin/hive is availableexport HIVE_HOME=${HIVE_HOME:-/usr}# add libthrift in hive to sqoop class path first so hive imports workexport SQOOP_USER_CLASSPATH=''ls ${HIVE_HOME}/lib/libthrift-*.jar 2&gt; /dev/null':${SQOOP_USER_CLASSPATH}'#Set the path for where zookeper config dir isexport ZOOCFGDIR=${ZOOCFGDIR:-/etc/zookeeper/conf}It should be the followings (also screenshot is available):#Set path to where bin/hadoop is availableexport HADOOP_HOME=${HADOOP_HOME:-/usr/lib/hadoop}#set the path to where bin/hbase is availableexport HBASE_HOME=${HBASE_HOME:-/usr/lib/hbase}#Set the path to where bin/hive is availableexport HIVE_HOME=${HIVE_HOME:-/usr/lib/hive}#Set the path for where zookeper config dir isexport ZOOCFGDIR=${ZOOCFGDIR:-/etc/zookeeper/conf}# add libthrift in hive to sqoop class path first so hive imports workexport SQOOP_USER_CLASSPATH=''ls ${HIVE_HOME}/lib/libthrift-*.jar 2&gt; /dev/null':${SQOOP_USER_CLASSPATH},1.2.2,1.2.4,110,0,0,0,0,0,0,0,
2143,,Sumit Mohanty,HBASE fails to start on master,HBASE master fails to start on master. From log:2013-05-14 21:06:43 487 FATAL org.apache.hadoop.hbase.master.HMaster: Unhandled exception. Starting shutdown.org.apache.hadoop.security.AccessControlException: org.apache.hadoop.security.AccessControlException: Permission denied: user=hbase  access=EXECUTE  inode='/apps/hbase/data':hdfs:hdfs:drwx------ at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:39) at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:27) at java.lang.reflect.Constructor.newInstance(Constructor.java:513) at org.apache.hadoop.ipc.RemoteException.instantiateException(RemoteException.java:95) at org.apache.hadoop.ipc.RemoteException.unwrapRemoteException(RemoteException.java:57) at org.apache.hadoop.hdfs.DFSClient.getFileInfo(DFSClient.java:1134) at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:556) at org.apache.hadoop.fs.FileSystem.exists(FileSystem.java:779) at org.apache.hadoop.hbase.util.FSUtils.getVersion(FSUtils.java:287) at org.apache.hadoop.hbase.util.FSUtils.checkVersion(FSUtils.java:329) at org.apache.hadoop.hbase.master.MasterFileSystem.checkRootDir(MasterFileSystem.java:434) at org.apache.hadoop.hbase.master.MasterFileSystem.createInitialFileSystemLayout(MasterFileSystem.java:146) at org.apache.hadoop.hbase.master.MasterFileSystem.&lt;init&gt;(MasterFileSystem.java:131) at org.apache.hadoop.hbase.master.HMaster.finishInitialization(HMaster.java:532) at org.apache.hadoop.hbase.master.HMaster.run(HMaster.java:391) at java.lang.Thread.run(Thread.java:662),1.2.4,1.2.4,63,0,0,0,0,0,0,0,
2144,ambari-agent,Siddharth Wagle,Installation with existing Oracle DB fails,On Step8 'Customize Services' for HIVE and OOZIE we can use option 'Existing Oracle DB'.But after Cluster install HIVE and OOZIE didn't start (with option 'Existing Oracle DB').In the logs I found such:/var/log/hive/hive.logCaused by: org.datanucleus.exceptions.NucleusException: Attempt to invoke the 'DBCP' plugin to create a ConnectionPool gave an error : The specified datastore driver ('oracle.jdbc.driver.OracleDriver') was not found in the CLASSPATH. Please check your CLASSPATH specification  and the name of the driver./var/log/oozie/oozie.log013-05-14 11:25:59 618 FATAL Services:533 - USER[-] GROUP[-] TOKEN[-] APP[-] JOB[-] ACTION[-] E0103: Could not load service classes  Cannot load JDBC driver class 'oracle.jdbc.driver.OracleDriver'org.apache.oozie.service.ServiceException: E0103: Could not load service classes  Cannot load JDBC driver class 'oracle.jdbc.driver.OracleDriver',1.2.4,1.2.4,121,0,0,0,0,0,0,0,
2146,,Sumit Mohanty,When hive and oozie users have been changed after upgrade hive metastore and oozie cannot start properly,Oozie start failure:^[[0;36mnotice: /Stage[2]/Hdp-oozie::Service/Hdp::Exec[exec su - ooziexx -c 'cd /var/tmp/oozie &amp;&amp; /usr/lib/oozie/bin/oozie-start.sh']/Exec[exec su - ooziexx -c 'cd /var/tmp/oozie &amp;&amp; /usr/lib/oozie/bin/oozie-start.sh']/returns: Setting OOZIE_BASE_URL: http://ip-10-212-166-111.ec2.internal:11000/oozie^[[0m^[[0;36mnotice: /Stage[2]/Hdp-oozie::Service/Hdp::Exec[exec su - ooziexx -c 'cd /var/tmp/oozie &amp;&amp; /usr/lib/oozie/bin/oozie-start.sh']/Exec[exec su - ooziexx -c 'cd /var/tmp/oozie &amp;&amp; /usr/lib/oozie/bin/oozie-start.sh']/returns: Using CATALINA_BASE: /var/lib/oozie/oozie-server^[[0m^[[0;36mnotice: /Stage[2]/Hdp-oozie::Service/Hdp::Exec[exec su - ooziexx -c 'cd /var/tmp/oozie &amp;&amp; /usr/lib/oozie/bin/oozie-start.sh']/Exec[exec su - ooziexx -c 'cd /var/tmp/oozie &amp;&amp; /usr/lib/oozie/bin/oozie-start.sh']/returns: Setting OOZIE_HTTPS_KEYSTORE_FILE: /home/ooziexx/.keystore^[[0m^[[0;36mnotice: /Stage[2]/Hdp-oozie::Service/Hdp::Exec[exec su - ooziexx -c 'cd /var/tmp/oozie &amp;&amp; /usr/lib/oozie/bin/oozie-start.sh']/Exec[exec su - ooziexx -c 'cd /var/tmp/oozie &amp;&amp; /usr/lib/oozie/bin/oozie-start.sh']/returns: Setting OOZIE_HTTPS_KEYSTORE_PASS: password^[[0m^[[0;36mnotice: /Stage[2]/Hdp-oozie::Service/Hdp::Exec[exec su - ooziexx -c 'cd /var/tmp/oozie &amp;&amp; /usr/lib/oozie/bin/oozie-start.sh']/Exec[exec su - ooziexx -c 'cd /var/tmp/oozie &amp;&amp; /usr/lib/oozie/bin/oozie-start.sh']/returns: Setting CATALINA_OUT: /var/log/oozie//catalina.out^[[0m^[[0;36mnotice: /Stage[2]/Hdp-oozie::Service/Hdp::Exec[exec su - ooziexx -c 'cd /var/tmp/oozie &amp;&amp; /usr/lib/oozie/bin/oozie-start.sh']/Exec[exec su - ooziexx -c 'cd /var/tmp/oozie &amp;&amp; /usr/lib/oozie/bin/oozie-start.sh']/returns: Using CATALINA_PID: /var/run/oozie/oozie.pid^[[0m^[[0;36mnotice: /Stage[2]/Hdp-oozie::Service/Hdp::Exec[exec su - ooziexx -c 'cd /var/tmp/oozie &amp;&amp; /usr/lib/oozie/bin/oozie-start.sh']/Exec[exec su - ooziexx -c 'cd /var/tmp/oozie &amp;&amp; /usr/lib/oozie/bin/oozie-start.sh']/returns: ^[[0m^[[0;36mnotice: /Stage[2]/Hdp-oozie::Service/Hdp::Exec[exec su - ooziexx -c 'cd /var/tmp/oozie &amp;&amp; /usr/lib/oozie/bin/oozie-start.sh']/Exec[exec su - ooziexx -c 'cd /var/tmp/oozie &amp;&amp; /usr/lib/oozie/bin/oozie-start.sh']/returns: Using CATALINA_OPTS: -Dderby.stream.error.file=/var/log/oozie//derby.log^[[0m^[[0;36mnotice: /Stage[2]/Hdp-oozie::Service/Hdp::Exec[exec su - ooziexx -c 'cd /var/tmp/oozie &amp;&amp; /usr/lib/oozie/bin/oozie-start.sh']/Exec[exec su - ooziexx -c 'cd /var/tmp/oozie &amp;&amp; /usr/lib/oozie/bin/oozie-start.sh']/returns: Adding to CATALINA_OPTS: -Doozie.home.dir=/usr/lib/oozie -Doozie.config.dir=/etc/oozie/conf -Doozie.log.dir=/var/log/oozie/ -Doozie.data.dir=/grid/0/hadoop/oozie/data/ -Doozie.config.file=oozie-site.xml -Doozie.log4j.file=oozie-log4j.properties -Doozie.log4j.reload=10 -Doozie.http.hostname=ip-10-212-166-111.ec2.internal -Doozie.admin.port=11001 -Doozie.http.port=11000 -Doozie.https.port=11443 -Doozie.base.url=http://ip-10-212-166-111.ec2.internal:11000/oozie -Doozie.https.keystore.file=/home/ooziexx/.keystore -Doozie.https.keystore.pass=password -Djava.library.path=/usr/lib/hadoop/lib/native/Linux-amd64-64^[[0m^[[0;36mnotice: /Stage[2]/Hdp-oozie::Service/Hdp::Exec[exec su - ooziexx -c 'cd /var/tmp/oozie &amp;&amp; /usr/lib/oozie/bin/oozie-start.sh']/Exec[exec su - ooziexx -c 'cd /var/tmp/oozie &amp;&amp; /usr/lib/oozie/bin/oozie-start.sh']/returns: ^[[0m^[[0;36mnotice: /Stage[2]/Hdp-oozie::Service/Hdp::Exec[exec su - ooziexx -c 'cd /var/tmp/oozie &amp;&amp; /usr/lib/oozie/bin/oozie-start.sh']/Exec[exec su - ooziexx -c 'cd /var/tmp/oozie &amp;&amp; /usr/lib/oozie/bin/oozie-start.sh']/returns: /usr/lib/oozie/oozie-server/bin/catalina.sh: line 386: /var/run/oozie/oozie.pid: Permission denied^[[0m^[[1;35merr: /Stage[2]/Hdp-oozie::Service/Hdp::Exec[exec su - ooziexx -c 'cd /var/tmp/oozie &amp;&amp; /usr/lib/oozie/bin/oozie-start.sh']/Exec[exec su - ooziexx -c 'cd /var/tmp/oozie &amp;&amp; /usr/lib/oozie/bin/oozie-start.sh']/returns: change from notrun to 0 failed: su - ooziexx -c 'cd /var/tmp/oozie &amp;&amp; /usr/lib/oozie/bin/oozie-start.sh' returned 1 instead of one of [0] at /var/lib/ambari-agent/puppet/modules/hdp/manifests/init.pp:340^[[0m^[[0;36mnotice: /Stage[2]/Hdp-oozie::Service/Hdp::Exec[exec su - ooziexx -c 'cd /var/tmp/oozie &amp;&amp; /usr/lib/oozie/bin/oozie-start.sh']/Anchor[hdp::exec::exec su - ooziexx -c 'cd /var/tmp/oozie &amp;&amp; /usr/lib/oozie/bin/oozie-start.sh'::end]: Dependency Exec[exec su - ooziexx -c 'cd /var/tmp/oozie &amp;&amp; /usr/lib/oozie/bin/oozie-start.sh'] has failures: true^[[0m^[[0;33mwarning: /Stage[2]/Hdp-oozie::Service/Hdp::Exec[exec su - ooziexx -c 'cd /var/tmp/oozie &amp;&amp; /usr/lib/oozie/bin/oozie-start.sh']/Anchor[hdp::exec::exec su - ooziexx -c 'cd /var/tmp/oozie &amp;&amp; /usr/lib/oozie/bin/oozie-start.sh'::end]: Skipping because of failed dependencies^[[0m^[[0;36mnotice: /Stage[2]/Hdp-oozie::Service/Hdp-oozie::Service::Directory[/var/log/oozie]/Hdp::Directory_recursive_create[/var/log/oozie]/Hdp::Directory[/var/log/oozie]/File[/var/log/oozie]/owner: owner changed 'oozie' to 'ooziexx'^[[0m^[[0;36mnotice: /Stage[2]/Hdp-oozie::Service/Hdp-oozie::Service::Directory[/var/log/oozie]/Hdp::Directory_recursive_create[/var/log/oozie]/Hdp::Directory[/var/log/oozie]/File[/var/log/oozie]/group: group changed 'oozie' to 'hadoopxx'^[[0m^[[0;36mnotice: /Stage[2]/Hdp-oozie::Service/Hdp-oozie::Service::Directory[/var/run/oozie]/Hdp::Directory_recursive_create[/var/run/oozie]/Hdp::Directory[/var/run/oozie]/File[/var/run/oozie]/owner: owner changed 'oozie' to 'ooziexx'^[[0m^[[0;36mnotice: /Stage[2]/Hdp-oozie::Service/Hdp-oozie::Service::Directory[/var/run/oozie]/Hdp::Directory_recursive_create[/var/run/oozie]/Hdp::Directory[/var/run/oozie]/File[/var/run/oozie]/group: group changed 'oozie' to 'hadoopxx'^[[0m^[[0;36mnotice: Finished catalog run in 9.36 seconds^[[0m,1.2.4,1.2.4,365,0,0,0,0,0,0,0,
2147,,Nate Cole,Capture user for auditing config changes,Add the ability to capture username and save in the table for config mappings. This applies to cluster and host level,1.2.3,1.2.5,21,0,0,0,0,0,0,0,
2149,,Mahadev konar,Ambari needs to set right path for GC log directory of Hbase process.,Ambari needs to set right path for GC log directory of Hbase process.,1.2.2,1.2.4,13,0,0,0,0,0,0,0,
2152,ambari-web,Yusaku Sako,Sometimes stale host / host component indicators are shown,,1.2.3,1.2.4,1,0,0,0,0,0,0,0,
2159,,Mahadev konar,After upgrading ambari from 1.2.2.5 to 1.2.3.6 the server throws 500 error when starting/stopping any service,After upgrading ambari from 1.2.2.5 to 1.2.3.6 the server throws 500 error when starting/stopping any service,1.2.3,1.2.4,16,0,0,0,0,0,0,0,
2161,ambari-agent,Jaimin D Jetly,Datanode Start fails in secure cluster.,,1.2.3,1.2.5,1,0,0,0,1,0,0,0,
2171,ambari-web,Yusaku Sako,Host status filter not restored on Hosts page when navigating back,,1.2.3,1.2.4,1,0,0,0,0,0,0,0,
2172,ambari-web,Yusaku Sako,Fix unit tests for Ambari Web,Fix currently failing unit tests.,1.2.3,1.2.4,5,0,0,0,0,0,0,0,
2173,,Sumit Mohanty,TEST BROKEN : FAIL: test_upgradeCommand_executeCommand (TestActionQueue.TestActionQueue),TEST BROKEN : FAIL: test_upgradeCommand_executeCommand (TestActionQueue.TestActionQueue),1.2.4,1.2.4,6,0,0,0,0,0,0,0,
2180,,Mahadev konar,Remove '0.1' stack definition since its never been used and is redundant.,Remove '0.1' stack definition since its never been used and is redundant.,1.2.4,1.2.4,12,0,0,0,0,0,0,0,
2187,ambari-web,Srimanth Gunturi,Hadoop2 Monitoring: Jobs page should be hidden when HDP 2.0.x stack is installed,When a HDP 2.0.x stack is installed  the Jobs page should be hidden.,1.2.4,1.4.0,13,0,0,0,0,0,0,0,
2188,ambari-web,Srimanth Gunturi,Update mock json data for Test mode,,1.2.4,1.4.0,1,0,0,0,0,0,0,0,
2192,ambari-agent,Nate Cole,Agent heartbeat lost during install,Agent heartbeat can become lost during install. The underlying issue is that during install  various yum commands are executed for component installation. However  the heartbeat ALSO performs a 'yum -C repolist'. If that command is taking a long time  the yum process can become deadlocked. The results of the repolist'ing are not used at this time  so remove it until needed.,1.2.3,1.2.4,61,0,0,0,0,0,0,0,
2195,,Vikram Dixit K,Ambari has a deadlock when re-installing after reboot of cluster nodes,Java stack information for the threads listed above:==================================================='Thread-2': at org.apache.ambari.server.state.ServiceImpl.getDesiredConfigs(ServiceImpl.java:240) waiting to lock &lt;0x000000077b356dd0&gt; (a org.apache.ambari.server.state.ServiceImpl$$EnhancerByGuice$$9e2acafa) at org.apache.ambari.server.state.ServiceComponentImpl.getDesiredConfigs(ServiceComponentImpl.java:292) locked &lt;0x000000077b39bce8&gt; (a org.apache.ambari.server.state.ServiceComponentImpl$$EnhancerByGuice$$af7a745c) at org.apache.ambari.server.state.svccomphost.ServiceComponentHostImpl.getDesiredConfigs(ServiceComponentHostImpl.java:1057) at org.apache.ambari.server.agent.HeartbeatMonitor.generateStatusCommands(HeartbeatMonitor.java:166) at org.apache.ambari.server.agent.HeartbeatMonitor.doWork(HeartbeatMonitor.java:137) at org.apache.ambari.server.agent.HeartbeatMonitor.run(HeartbeatMonitor.java:85) at java.lang.Thread.run(Thread.java:662)'main': at org.apache.ambari.server.state.ServiceComponentImpl.debugDump(ServiceComponentImpl.java:376) waiting to lock &lt;0x000000077b39bce8&gt; (a org.apache.ambari.server.state.ServiceComponentImpl$$EnhancerByGuice$$af7a745c) at org.apache.ambari.server.state.ServiceImpl.debugDump(ServiceImpl.java:354) locked &lt;0x000000077b356dd0&gt; (a org.apache.ambari.server.state.ServiceImpl$$EnhancerByGuice$$9e2acafa) at org.apache.ambari.server.state.cluster.ClusterImpl.debugDump(ClusterImpl.java:693) at org.apache.ambari.server.state.cluster.ClustersImpl.debugDump(ClustersImpl.java:517) at org.apache.ambari.server.controller.AmbariServer.run(AmbariServer.java:320) at org.apache.ambari.server.controller.AmbariServer.main(AmbariServer.java:432)Found 1 deadlock.,1.2.4,1.2.4,58,0,0,0,0,1,0,0,
2200,ambari-server,Chad Roberts,ambari-server start script (ambari-server.py) will never use SERVER_START_CMD_DEBUG,The ambari-server.py start script has a command defined for starting the ambari-server in debug mode (SERVER_START_CMD_DEBUG  which turns on remote debugging)  but there is currently no option supported that will force the script to use the debug start commaand. I propose adding a --debug option so that you can run 'ambari-server start --debug' to activate remote debugging.,1.2.5,1.2.5,57,0,0,0,0,0,0,0,
2203,ambari-web,Yusaku Sako,Background operations popup does not automatically refresh the task log,,1.2.3,1.2.4,1,0,0,0,0,0,0,0,
2207,ambari-web,Yusaku Sako,Add unit tests for Utils,,1.2.5,1.2.5,1,0,0,0,0,0,0,0,
2208,ambari-web,Yusaku Sako,Reassign Master Wizard: refreshing page on step 2  3 or 4 breaks wizard,,1.3.0,1.3.0,1,0,0,0,0,0,0,0,
2212,ambari-web,Yusaku Sako,Change config loading mechanism to allow for different stack versions,,1.4.0,1.4.0,1,0,0,0,0,0,0,0,
2217,,Sumit Mohanty,Increase ambari-agent test coverage,ActionQueue.py missing 'Unrecognized command' testcase (L. 173) /src/test/python/TestActionQueue.py:42 unused test_RetryAction stub (retry is implemented in another way) /src/main/python/ambari_agent/ActionQueue.py:221 not covered case if commandresult&#91;&#39;exitcode&#39;&#93; != 0: /src/main/python/ambari_agent/ActionQueue.py:247 not covered case if command.has_key('roleCommand') and command&#91;&#39;roleCommand&#39;&#93; == 'START':PuppetExecutor.py configureEnviron/generate_repo_manifests/run_manifest/runCommand are not covered.PythonExecutor.py isSuccessfull is not testedRepoInstaller.py prepareReposInfo/generateFiles are not coveredshell.py is not covered,1.2.4,1.2.4,62,0,0,0,0,0,0,0,
2223,ambari-agent,Siddharth Wagle,Using an external MySQL / Oracle database for Oozie does not work,When setting up Oozie with an external database  the following commands are run:cd /var/tmp/oozie &amp;&amp; /usr/lib/oozie/bin/oozie-setup.sh -hadoop 0.20.200 /usr/lib/hadoop/ -extjs /usr/share/HDP-oozie/ext.zip -jars /usr/lib/hadoop/lib/hadoop-lzo-0.5.0.jar:/usr/share/java/mysql-connector-java.jarThe above command succeeds.However  the next command fails:cd /var/tmp/oozie &amp;&amp; /usr/lib/oozie/bin/ooziedb.sh create -sqlfile oozie.sql -run setting OOZIE_CONFIG=${OOZIE_CONFIG:-/etc/oozie/conf} setting OOZIE_DATA=${OOZIE_DATA:-/var/lib/oozie} setting OOZIE_LOG=${OOZIE_LOG:-/var/log/oozie} setting CATALINA_BASE=${CATALINA_BASE:-/var/lib/oozie/oozie-server} setting CATALINA_TMPDIR=${CATALINA_TMPDIR:-/var/tmp/oozie} setting CATALINA_PID=${CATALINA_PID:-/var/run/oozie/oozie.pid} setting JAVA_HOME=/usr/jdk/jdk1.6.0_31 setting OOZIE_LOG=/var/log/oozie/ setting CATALINA_PID=/var/run/oozie/oozie.pid setting OOZIE_DATA=/grid/0/hadoop/oozie/data/ setting JAVA_LIBRARY_PATH=/usr/lib/hadoop/lib/native/Linux-amd64-64Validate DB ConnectionError: Could not connect to the database: java.lang.ClassNotFoundException: com.mysql.jdbc.DriverStack trace for the error was (for debug purposes):--------------------------------------java.lang.Exception: Could not connect to the database: java.lang.ClassNotFoundException: com.mysql.jdbc.Driver at org.apache.oozie.tools.OozieDBCLI.validateConnection(OozieDBCLI.java:358) at org.apache.oozie.tools.OozieDBCLI.createDB(OozieDBCLI.java:168) at org.apache.oozie.tools.OozieDBCLI.run(OozieDBCLI.java:112) at org.apache.oozie.tools.OozieDBCLI.main(OozieDBCLI.java:63)Caused by: java.lang.ClassNotFoundException: com.mysql.jdbc.Driver at java.net.URLClassLoader$1.run(URLClassLoader.java:202) at java.security.AccessController.doPrivileged(Native Method) at java.net.URLClassLoader.findClass(URLClassLoader.java:190) at java.lang.ClassLoader.loadClass(ClassLoader.java:306) at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:301) at java.lang.ClassLoader.loadClass(ClassLoader.java:247) at java.lang.Class.forName0(Native Method) at java.lang.Class.forName(Class.java:169) at org.apache.oozie.tools.OozieDBCLI.createConnection(OozieDBCLI.java:347) at org.apache.oozie.tools.OozieDBCLI.validateConnection(OozieDBCLI.java:354) ... 3 more--------------------------------------,1.2.4,1.2.4,154,0,0,0,0,1,0,0,
2228,,Sumit Mohanty,Fix MySQL and Oracle DDL scripts according to last DB changes,user_name column was added to clusterconfigmapping and hostconfigmapping tables. This changes should be made to DDL scripts for Oracle and MySQL also.,1.2.4,1.2.4,22,0,0,0,0,0,0,0,
2233,,Sumit Mohanty,Ensure version values are used appropriately throughout Ambari,The current version of Ambari build is being used in several scenarios: Ensure Ambari Server installs the correct version of Ambari Agent Ensure that Ambari Server only accepts registration from correct version of Ambari Agent Ensure that DB version is compatible with Ambari Server  The DB version itself will be used to control DB upgrades  Towards this end the following open issues remain: Get the build version be automatically embedded in the version file Use the above for deploying agent as well as allowing agents to register Regarding DB version there are two possible paths:  Separate out DB version and have it be modified manually as needed Have the build version be used as DB version - this may make writing upgrade scripts little complicated as build version may change due to some proj mgmt decision,1.2.4,1.2.4,141,1,0,0,0,0,0,0,
2240,ambari-web,Jaimin D Jetly,Allow Security related configs to be modified via custom settings,,1.2.5,1.2.5,1,0,0,0,0,0,0,4,ambari-web/app/data/HDP2/config_mapping.js;ambari-web/app/data/HDP2/config_properties.js;ambari-web/app/data/config_mapping.js;ambari-web/app/data/config_properties.js;
2259,,Oleg Nechiporenko,Start/Stop button may stay enabled for 30-40 seconds after it has been clicked,Start/Stop button stays enabled for atleast 30-40 seconds after its been clicked already.,1.2.4,1.2.5; 1.4.0,13,1,0,0,0,0,0,0,
2260,,Tom Beerbower,Bad hosts query example in API docs,The example ...'hosts' : [ { 'href' : 'http://your.ambari.server/api/v1/clusters/c1/hosts/host1'  'Hosts' : { 'cluster_name' : 'c1'  'host_name' : 'some.cluster.host' } }  { 'href' : 'http://your.ambari.server/api/v1/clusters/c1/hosts/host2'  'Hosts' : { 'cluster_name' : 'c1'  'host_name' : 'another.cluster.host' } ]... should read ... 'hosts' : [ { 'href' : 'http://your.ambari.server/api/v1/clusters/c1/hosts/some.host'  'Hosts' : { 'cluster_name' : 'c1'  'host_name' : 'some.host' } }  { 'href' : 'http://your.ambari.server/api/v1/clusters/c1/hosts/another.host'  'Hosts' : { 'cluster_name' : 'c1'  'host_name' : 'another.host' } } ],1.2.4,1.2.5,120,0,0,0,0,0,0,3,ambari-server/docs/api/v1/clusters-cluster.md;ambari-server/docs/api/v1/index.md;ambari-server/docs/api/v1/index.md;
2262,ambari-web,Andrii Tkach,On 'install Options' page  when selecting 'Perform manual registration on hosts and do not use SSH' is setting 'Path to 64-bit JDK' disabled,On 'install Options' page  when selecting 'Perform manual registration on hosts and do not use SSH' is setting 'Path to 64-bit JDK' disabled(Screen Shot 2013-06-03 at 10.54.49 AM.png).Also path to 64-bit JDK JAVA_HOME' input field is enabled with unchecked check box(unchecked.png).Steps:1. Go to 'Install Options' page.Result:'Path to 64-bit JDK JAVA_HOME' input field is available for editing when check box is unchecked.,1.2.4,1.2.4,61,0,0,0,1,0,0,0,
2270,ambari-agent; ambari-server,Dmytro Sen,Provide way to optionally enable two-way SSL for Server-Agent communication,The two-way SSL mechanism used during server-agent registration exists to protect communication. This is useful in production environments but in typical 'first use' or POC scenarios  having this level of security is not necessary. As well  certificate generation can be problematic causing failures.We need to provide a way to make this mechanism optional:1) By default  ship with Server-Agent Two-Way SSL off.2) At any time post install  a user should be able to turn on Two-Way SSL and turn it back off  etc.,1.2.3,1.2.5,82,0,0,0,1,0,0,0,
2279,ambari-web,Jaimin D Jetly,Configuration mapping metadata on ambari-web should be computed as per the stack selection.,,1.2.4,1.2.5,1,0,0,0,0,0,0,2,ambari-web/app/controllers/main/service/info/configs.js;ambari-web/app/controllers/wizard/step8_controller.js;
2290,ambari-server,Dmytro Sen,Ambari Upgrade prcoess should preserve the old configs and add the new config options to the old config files.,The Ambari Upgrade process should preserve the old configs and add the new config options to the old config files.Currently we have it the other way around  that we copy the needed 3 properties from the old config files - this is wrong. We need to use the older config file and add the new options to the old config file. This is because the older config file can have all kinds of config option that the user might have used. We have to really really keep in mind usability of the product when fixing issues.,1.2.5,1.2.5,96,1,0,0,0,0,0,0,
2300,ambari-server,Dmitry Lysnichenko,500 Exception creating service component during install,I was installing a new cluster in my VM when the progress blocked on step 12. Looking on browser log  the PUTs for clusters desired_configs succeeded  but the very next call to create service component failed.&#91;POST&#93; http://dev.hortonworks.com:8080/api/v1/clusters/vmc/services?ServiceInfo/service_name=HDFSStatus Code:500 Invalid arguments  clustername and componentname should be non-null and non-empty when trying to create a componentData uploaded:{'components':[{'ServiceComponentInfo':{'component_name':'NAMENODE'}} {'ServiceComponentInfo':{'component_name':'SECONDARY_NAMENODE'}} {'ServiceComponentInfo':{'component_name':'DATANODE'}} {'ServiceComponentInfo':{'component_name':'HDFS_CLIENT'}}]}:Exception on server console:Mar 21  2013 11:25:09 AM com.sun.jersey.spi.container.ContainerResponse mapMappableContainerExceptionSEVERE: The RuntimeException could not be mapped to a response  re-throwing to the HTTP containerjava.lang.IllegalArgumentException: Invalid arguments  clustername and componentname should be non-null and non-empty when trying to create a component at org.apache.ambari.server.controller.AmbariManagementControllerImpl.createComponents(AmbariManagementControllerImpl.java:387) at org.apache.ambari.server.controller.internal.ComponentResourceProvider$1.invoke(ComponentResourceProvider.java:88) at org.apache.ambari.server.controller.internal.ComponentResourceProvider$1.invoke(ComponentResourceProvider.java:85) at org.apache.ambari.server.controller.internal.AbstractResourceProvider.createResources(AbstractResourceProvider.java:229) at org.apache.ambari.server.controller.internal.ComponentResourceProvider.createResources(ComponentResourceProvider.java:85) at org.apache.ambari.server.controller.internal.ClusterControllerImpl.createResources(ClusterControllerImpl.java:131) at org.apache.ambari.server.api.services.persistence.PersistenceManagerImpl.create(PersistenceManagerImpl.java:75) at org.apache.ambari.server.api.handlers.QueryCreateHandler.persist(QueryCreateHandler.java:163) at org.apache.ambari.server.api.handlers.QueryCreateHandler.handleRequest(QueryCreateHandler.java:68) at org.apache.ambari.server.api.services.BaseRequest.process(BaseRequest.java:98) at org.apache.ambari.server.api.services.BaseService.handleRequest(BaseService.java:73) at org.apache.ambari.server.api.services.ServiceService.createServices(ServiceService.java:114) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25) at java.lang.reflect.Method.invoke(Method.java:597),1.2.3,1.2.5,143,1,0,0,0,0,0,0,
2313,,Oleg Nechiporenko,UI allows adding already existing properties to custom core-site.xml /hdfs-site.xml settings and creates confusion,Steps:1. Go to 'Services' page.2. Select 'HDFS' service.3. Select 'Configs' tab.4. Open 'Custom core-site.xml' panel.5. Add property with name 'ipc.client.idlethreshold' to this panel.Result:Property with name 'ipc.client.idlethreshold' was added to 'Custom core-site.xml' panel. But there is already presented property with same name in 'core-site.xml' file. After saving added property was disappeared from UI  and after service starting value of the old was changed to new (on UI and in 'core-site.xml' file).Expected result:UI should not allow to add property with existing name in specified file.,1.2.4,1.2.5,83,0,0,0,0,0,0,0,
2337,ambari-web,Jaimin D Jetly,Security Wizard: navigation not locked down  causes artifacts  and other unwanted side effects,,1.2.5,1.2.5,1,1,0,0,1,0,0,0,
2346,ambari-web,Yusaku Sako,API call to get 'metrics/cpu' does not work for NameNode and JobTracker host components,1. http://ambari:8080/api/v1/clusters/cluster/services?fields=components/host_components/metricsincludes all metrics for NameNode and JobTracker  including cpu metrics.2. http://ambari:8080/api/v1/clusters/cluster/services?fields=components/host_components/metrics/cpudoes not return cpu metrics for NameNode and JobTracker,1.2.5,1.2.5,26,1,0,0,0,0,0,1,ambari-agent/src/main/puppet/modules/hdp-ganglia/files/rrd.py;
2349,ambari-server,Oleksandr Diachenko,Enhance processing of ojdbc.jar before starting ambari server,Enhancements: Read RESOURCE_DIR from the ambari.properties Ask user twice to place drivers to /usr/share/java,1.2.4,1.2.4,14,1,0,0,0,0,0,0,
2362,ambari-web,Andrii Tkach,Unit Tests: Added tests to install wizard for step 3  5  10,,1.2.5,1.2.5,1,1,0,0,0,0,0,0,
2363,ambari-server,Dmitry Lysnichenko,Intermittent test failure with HBase port Scanner test.,This test fails sometimes and is not very reliable.,1.2.5,1.2.5,10,1,0,0,0,0,0,0,
2371,ambari-web,Jaimin D Jetly,Security Wizard: webhcat Server start fails on enabling security,This happens when templeton.kerberos.principal property is set to HTTP/_HOST@&lt;realm name&gt; instead of HTTP/&lt;internal host name&gt;@&lt;realm name&gt;,1.2.5,1.2.5,16,1,0,0,1,0,0,2,ambari-web/app/controllers/main/admin/security/add/step3.js;ambari-web/app/controllers/main/admin/security/disable.js;
2372,ambari-web,Yusaku Sako,Show installed stack and its services,List the installed stack and its services in Admin &gt; Cluster page.,1.2.5,1.2.5,12,1,0,0,0,0,0,0,
2375,ambari-web,Andrii Tkach,Unit Tests: Added tests to models,Added unit tests to models: Rack  Host  HostComponent.,1.2.5,1.2.5,8,1,0,0,0,0,0,0,
2377,ambari-web,Oleg Nechiporenko,Add Host Wizard: show info about manual steps required on a secure cluster,When a cluster is in secure mode  there are additional manual steps that need to be performed when adding new hosts to the cluster.In the Review page  add a prominent box with a red background and display the following text:You are running your cluster in secure mode. You must set up the keytabs for all the hosts you are adding before you proceed.'Upon clicking 'Deploy'  show a confirmation popup with the text:Before you proceed  please make sure that the keytabs have been set up on the hosts you are adding per the instructions on the Review page. Otherwise  the assigned components will not be able to start properly on the hosts being added. OK CancelNote that the extra message and confirmation popup should show only when security is enabled on the cluster.,1.2.5,1.2.5,132,1,0,0,0,0,0,0,
2383,ambari-server,Siddharth Wagle,Add unit tests for ambari-server python changes,AMBARI-2174 - Add missing unit tests for the code changes,1.2.5,1.2.5,21,1,0,0,0,0,0,1,ambari-web/app/utils/host_progress_popup.js;
2391,ambari-server,Oleksandr Diachenko,Bootstrap is broken for ambari web with RHEL-5.8,Steps:1. Install ambari-server.2. Go to 'Install Options' page.3. Set the hosts list and ssh-key  click 'Next' button.Result:Ambari Web is blocked in 'Confirm Hosts'. Confirming was not ended after not less than 40 minutes.,1.2.4,1.2.4,33,1,0,0,0,0,0,0,
2394,ambari-server,Siddharth Wagle,ambari-server setup borken in trunk,install_jce_manually() in the download_jdk() result in fatal exception.Checking JDK...INFO: Loading properties from /etc/ambari-server/conf/ambari.propertiesERROR: Error getting ambari propertiesERROR: Exiting with exit code -1. Reason: Downloading or installing JDK failed: 'Fatal exception: Error getting ambari properties  exit code -1'. Exiting.,1.2.5,1.2.5,38,1,0,0,0,0,0,0,
2402,ambari-web,Xi Wang,Add support for 'classic' dashboard,,1.2.5,1.2.5,1,1,0,0,0,0,0,0,
2403,ambari-server,Dmitry Lysnichenko,ambari-server setup should allow user to change database password,If we run setup second time. Amabri should allow user to change the DB password for the ambari-user.Currently  the executed script should allow for this.command: &#91;&#39;su&#39;  &#39;-&#39;  &#39;postgres&#39;  &#39;--command=psql -f /var/lib/ambari-server/resources/Ambari-DDL-Postgres-CREATE.sql -v username=/&#39;&quot;ambari-server&quot;/&#39; -v password=&quot;/&#39;/&#39;&quot;&#39;&#93;,1.2.5,1.2.5,36,0,0,0,1,0,0,0,
2408,ambari-web,Jaimin D Jetly,Kerberos globals are shown in HDFS config page during install,,1.2.5,1.2.5,1,1,0,0,0,0,0,0,
2413,ambari-web,Andrii Tkach,Installer Wizard step-6: NameNode and SNameNode should not be co-hosted by default on multinode cluster.,,1.2.5,1.2.5,1,0,0,0,0,0,0,0,
2414,ambari-web,Oleg Nechiporenko,HDFS Config page is broken in testMode on trunk,HDFS Config page (post-install) does not load when App.testMode = true,1.2.5,1.2.5,11,0,0,0,0,0,0,0,
2426,ambari-web,Xi Wang,Set default widgets to show for the Dashboard,,1.2.5,1.2.5,1,1,0,0,0,0,0,0,
2433,ambari-server,Dmitry Lysnichenko,Bootstrap failed on rhel 5.6,STDOUTTraceback (most recent call last):File '/tmp/setupAgent.py'  line 192  in ?main(sys.argv)File '/tmp/setupAgent.py'  line 188  in mainsys.exit(runAgent(passPhrase  expected_hostname))File '/tmp/setupAgent.py'  line 80  in runAgentagent_retcode = subprocess.call('/usr/sbin/ambari-agent start --expected-hostname={0}'.format(expected_hostname)  shell=True)AttributeError: 'str' object has no attribute 'format'Error seems to be caused by python 2.4 version.,1.2.5,1.2.5,40,1,0,0,0,0,0,0,
2441,ambari-server,Dmitry Lysnichenko,Ambari server start fails with reconfigured user,STR:1) Run ambari-server setup.2) Choose custom user  user1.3) Delete ambari.user from ambari.properties.4) Run ambari-server setup.5) Choose custom user  different from choosen in step 2  user2.6) Run ambari-server start.Got error:ambari-server startUsing python /usr/bin/python2.6Starting ambari-serverHave root privileges.Checking iptables...iptables is disabled nowRunning server: &#91;&#39;/bin/su&#39;  &#39;user2&#39;  &#39;-s&#39;  &#39;/bin/sh&#39;  &#39;-c&#39;  &#39;/usr/jdk64/jdk1.6.0_31/bin/java -server -XX:NewRatio=3 -XX:+UseConcMarkSweepGC -XX:-UseGCOverheadLimit -XX:CMSInitiatingOccupancyFraction=60 -Xms512m -Xmx2048m -cp /etc/ambari-server/conf:/usr/lib/ambari-server/*:/usr/lib64/qt-3.3/bin:/usr/local/sbin:/usr/local/bin:/sbin:/bin:/usr/sbin:/usr/bin:/root/bin:/usr/lib/ambari-server/* org.apache.ambari.server.controller.AmbariServer &gt;/var/log/ambari-server/ambari-server.out 2&gt;&amp;1 &amp; echo $! &gt; /var/run/ambari-server/ambari-server.pid&#39;&#93;done.sh: /var/run/ambari-server/ambari-server.pid: Permission deniedsh: /var/log/ambari-server/ambari-server.out: Permission denied,1.2.5,1.2.5,70,1,0,0,0,0,0,0,
2443,ambari-agent; ambari-web,Jaimin D Jetly,Security wizard: smoke test for services fails with customized service user names.,,1.2.5,1.2.5,1,1,0,0,1,0,0,0,
2447,ambari-server,Dmitry Lysnichenko,Upgrade from 1.2.2/1.2.3.7 to 1.2.5 fails because the ddl script does not work - metainfo version change is broken.,Upgrade from 1.2.2/1.2.3.7 to 1.2.5 fails because the ddl script does not work - metainfo version change is broken.Again we need thorugh testing around this. Please make sure we have tested 1.2.2 and 1.2.3  1.2.4 upgrade to 1.2.5.,1.2.5,1.2.5,38,0,0,0,0,0,0,0,
2461,ambari-server,Dmitry Lysnichenko,Add unit tests for bootstrap and setupAgent python scripts for the server.,Add unit tests for bootstrap and setupAgent python scripts for the server.We need to find gaps on the bootstrap and setupagent script and add unit tests for them.,1.2.5,1.2.5,29,1,0,0,0,0,0,0,
2465,ambari-web,Srimanth Gunturi,Create command line script to manipulate Ambari configurations (get  set  add  delete),We need a script which can manually set the configs when UI is not able to  or does not support.,1.2.5,1.2.5,20,1,0,0,0,0,0,0,
2466,ambari-web,Yusaku Sako,Hive/Oozie database settings should accept custom JDBC URLs,Ran into issues setting up Hive and Oozie with an Oracle database.1. We are hard-coding port 1521 for the JDBC URL. 2. There are two types of JDBC URLs for Oracle: jdbc:oracle:thin:@&#91;HOST&#93;&#91;:PORT&#93;:SID jdbc:oracle:thin:@//&#91;HOST&#93;&#91;:PORT&#93;/SERVICEWe are making the assumption that it is the latter  but this may not work depending on how Oracle is set up.3. We prompt for the 'Database Name'. In Oracle context  this could be the SID or SERVICE NAME  but it's not clear what this is.As a solution to all of the above  we will construct the JDBC URL based on the database type  host  and name for Hive/Oozie and present it to the user as an editable text field during install.Post-install  the JDBC URL remains editable  but does not change automatically as changes other database-related parameters.,1.2.4,1.2.4,133,1,0,0,0,0,0,0,
2471,,Mahadev konar,Remove unnecessary check for hostnames/ service name which is wrong.,Remove unnecessary check for hostnames/ service name which is wrong.,1.2.4,1.2.4,10,1,0,0,0,0,0,0,
2475,,Ximo Guanter,Ambari bootstrap actions report success even if a failure happened,Sometimes  bootstrap actions reports success even if it has failed host tasks:&lt;bootStrapRequest&gt; &lt;status&gt;SUCCESS&lt;/status&gt; &lt;hostsStatus&gt; &lt;hostName&gt;andromeda54.hi.inet&lt;/hostName&gt; &lt;status&gt;FAILED&lt;/status&gt; &lt;statusCode&gt;1&lt;/statusCode&gt; &lt;log&gt; [...] &lt;/log&gt; &lt;/hostsStatus&gt; &lt;hostsStatus&gt; &lt;hostName&gt;andromeda55.hi.inet&lt;/hostName&gt; &lt;status&gt;FAILED&lt;/status&gt; &lt;statusCode&gt;1&lt;/statusCode&gt; &lt;log&gt; [...] &lt;/log&gt; &lt;/hostsStatus&gt; &lt;log&gt; [...] &lt;/log&gt;&lt;/bootStrapRequest&gt;,1.3.0,1.5.0,65,1,0,0,0,0,0,0,
2480,ambari-web,Xi Wang,Dashboard page has a lot of footer padding,This ticket solved:1. Dashboard page has padding space under footer.2. When a widget got deleted  the page scroll to top.(page should stay in place),1.2.5,1.2.5,24,1,0,0,0,0,0,0,
2486,ambari-agent,Dmitry Lysnichenko,shell.killprocessgrp is not working in a reliable way,We have noticed an issue where shell.killprocessgrp is not working correctly. We have seen a scenario where namenode start takes a long time when on a secure cluster the jce policy is unavailable. After 10 minutes when the agent tries to kill the puppet process it invariably fails.We need to run some experiment (perhaps using long running puppet processes) to ensure that shell.killprocessgrp works as expected.Also  we need to verify that the behavior is as expected on both RHEL and Suse.,1.2.5,1.2.5,81,1,0,0,0,0,0,0,
2490,ambari-server,Siddharth Wagle,Issues with setup ldap,I got this blow-up (when bind anon was either false or I just pressed returnBind anonymously true/false (false):====================Review Settings====================authentication.ldap.primaryUrl: my.ldap:389authentication.ldap.secondaryUrl: asdauthentication.ldap.useSSL: falseauthentication.ldap.usernameAttribute: uidauthentication.ldap.baseDn: basednauthorization.userRoleName: userauthorization.adminRoleName: adminauthentication.ldap.bindAnonymously: falseTraceback (most recent call last):File '/usr/sbin/ambari-server.py'  line 3047  in &lt;module&gt;main()File '/usr/sbin/ambari-server.py'  line 2891  in mainsetup_ldap()File '/usr/sbin/ambari-server.py'  line 2353  in setup_ldapprint('%s: %s' % (property  ldap_property_value_mapproperty))KeyError: 'authentication.ldap.managerDn',1.2.5,1.2.5,51,1,0,0,0,0,0,0,
2491,ambari-web,Andrii Tkach,Security Wizard: show which principals and keytabs need to be created on which hosts,Currently it is very difficult to know what principals and keytabs need to be created on which hosts.We should present this information to the end user in a format that is easy to consume.The user running the wizard may not be the one who will be creating keytabs and principals. We can expose the capability to download a csv file and send it to the appropriate person who may parse the data to create a script to generate principals/keytabs (or do so manually).Display the attached as a popup after Configure Services step is done.Let's show it as a popup so that we don't affect any existing navigation/flow.For generating the content:Keytab paths are based on the user inputPrincipal names are based on the user inputNameNode host: show the nn and HTTP principals and keytab pathsJobTracker host: show the jt principal and keytab pathOozie Server host: show the oozie and HTTP principals and keytab pathsNagios Server host: show the nagios principal and keytab pathHBase Master host: show the hbase principal and keytab pathHive Server host: show the hive principal and keytab pathWebHCat Server host: show the HTTP principal and keytab pathZooKeeper Server host: show the zookeeper principal and keytab pathDataNode host: show the dn principal and keytab pathTaskTracker host: show the tt principal and keytab pathRegionServer host: show the hbase principal and keytab pathIf there are duplicated principals on the same host  display it only once.Clickng on 'Download CSV' downloads the CSV file ('host-principal-keytab-list.csv'). The same content  except each row is a comma-delimited list with a /n at the end.,1.2.5,1.2.5,258,1,0,0,0,0,0,0,
2497,ambari-agent,Vitaly Brodetskyi,Remove dependence on dfs_datanode_http_address global for Nagios checks,ambari-agent/src/main/puppet/modules/hdp-nagios/templates/hadoop-services.cfg.erb shows the following:# HDFS::DATANODE Checksdefine service { hostgroup_name slaves use hadoop-service service_description DATANODE::DataNode process down servicegroups HDFS check_command check_tcp!&lt;%=scope.function_hdp_template_var('dfs_datanode_http_address')%&gt;!-w 1 -c 1 normal_check_interval 1 retry_check_interval 0.5 max_check_attempts 3}define service { hostgroup_name slaves use hadoop-service service_description DATANODE::DataNode storage full servicegroups HDFS check_command check_datanode_storage!&lt;%=scope.function_hdp_template_var('dfs_datanode_http_address')%&gt;!90%!90% normal_check_interval 5 retry_check_interval 1 max_check_attempts 2}We need to remove dependence on dfs_datanode_http_address and use the actual config property like:hdp_get_port_from_url($hdfs-site['dfs.datanode.http.address']),1.2.5,1.2.5,79,0,0,0,0,0,0,0,
2498,ambari-server,Oleksandr Diachenko,Cleanup setup https flow,Expected flow:[root@localhost ~]# ambari-server setup-httpsUsing python /usr/bin/python2.6Setting up HTTPS properties...Do you want to configure HTTPS [y/n] (y)?SSL port (8443) ? Please enter path to Certificate: /some/path/on/my/host/server.crtPlease enter path to Private Key: /some/path/on/my/host/server.keyPlease enter password for Private Key:Importing and saving certificate...done.NOTE: Reset Ambari Server to apply changes ('ambari-server restart|stop|start')Ambari Server 'HTTPS setup' completed successfully. Exiting.,1.2.5,1.2.5,63,1,0,0,0,0,0,0,
2515,ambari-web,Jaimin D Jetly,Cannot add property mapred.task.tracker.task-controller,,1.2.5,1.2.5,1,0,0,0,1,0,0,0,
2517,ambari-agent,Siddharth Wagle,Decommission data node not working in secure mode,Decommission datanode does not do kinit before refresh.,1.2.5,1.2.5,8,1,0,0,0,0,0,0,
2519,ambari-web,Srimanth Gunturi,Add download CSV action for security wizard,We need CSV content which shows which principals  keytabs etc. end up on the various hosts. This will be useful in scripts or other tools which can create appropriate environment.,1.2.5,1.2.5,30,1,0,0,0,0,0,0,
2522,ambari-agent,Siddharth Wagle,Zookeeper smoke test failing in secure cluster,Zookeeper smoke test failing in secure cluster,1.2.5,1.2.5,7,1,0,0,0,0,0,0,
2525,ambari-server,Dmitry Lysnichenko,Add helpful message when not able to download jdk with setup options for the user to be able to specify the jdk.,Add helpful message when not able to download jdk with setup options for the user to be able to specify the jdk.,1.2.5,1.2.5,22,0,0,0,0,0,0,0,
2532,ambari-agent,Siddharth Wagle,Incorrect permission on taskcontroller.cfg,/etc/conf/hadoop/taskcontroller.cfgIn secure mode permissions are set to '400'.,1.2.5,1.2.5,8,0,0,0,1,0,0,0,
2534,ambari-server,Sumit Mohanty,Some memory configs are set to -1 in Ambari,Some memory configs are set to -1 in ambari-mapred.cluster.reduce.memory.mb-mapred.jobtracker.maxtasks.per.job-mapred.cluster.max.reduce.memory.mb-mapred.cluster.map.memory.mb-mapred.job.map.memory.mb-mapred.job.reduce.memory.mb-mapred.cluster.max.map.memory.mbModify the stack definition to put default values as appropriate.,1.2.4,1.2.5,18,0,0,0,0,0,0,0,
2542,ambari-server,Nate Cole,Custom Repo URL cannot be set when non-root,The first iteration for creating custom repo URL persisted the new URL to disk. This poses a problem when running Ambari as non-root because the file system is owned by root. Change the implementation to save the override in the metainfo table.,1.2.5,1.2.5,42,0,0,0,0,0,0,0,
2545,ambari-agent,Dmitry Lysnichenko,Regression: Agent external hostname is not verified during bootstrap with no warnings,When confirming hosts using external addresses bootstrapping should be failed immediately and a warning should be logged. Right now this functionality is broken  neither warning in log nor failing immediately present,1.2.5,1.2.5,31,0,0,0,0,0,0,0,
2546,ambari-web,Srimanth Gunturi,Simplify Local Repo setup in installer UI,Enhance the UI to use stacks API to give user a choice of stacks and be able to customize repository locations.,1.2.5,1.4.0,21,0,0,0,0,0,0,0,
2555,ambari-web,Andrii Tkach,Security Wizard: Create separate page for principal/keytab,Add step 'Create Principals and Keytabs' to Security wizard.,1.2.5,1.2.5,9,0,0,0,0,0,0,7,ambari-web/app/controllers/main/admin/security/add/step4.js;ambari-web/app/messages.js;ambari-web/app/routes/add_security.js;ambari-web/app/routes/main.js;ambari-web/app/templates/main/admin/security/add/step1.hbs;ambari-web/app/templates/main/admin/security/add/step2.hbs;ambari-web/app/templates/main/admin/security/add/step3.hbs;
2556,ambari-server,Dmitry Lysnichenko,Ctrl+C during ambari-server setup prints out a python stack trace,We should be able to catch KeyBoardInterrupt in ambari-server main and print a useful message like:'Aborting ... Keyboard Interrupt.' and avoid the stack trace for the user.,1.2.5,1.2.5,27,0,0,0,0,0,0,0,
2568,ambari-agent,Dmitry Lysnichenko,Setup LDAP does not validate true/false response,Garbage responses to true/false questions just pass thru. Notice below  just put in garbage for Use SSL and that's what it would have written.Need validation to confirm they enter either 1) return to accept default or 2) the word true or 3) the word false. Else  inform the user'Property must be 'true' or 'false'.' and ask again.Secondary URL :Use SS &#91;true/false&#93; (false): asdUser name attribute* (uid):Base DN* :Property cannot be blank.Base DN* : asdBind anonymously* true/false (false):Manager DN* :asdEnter Manager Password*:Re-enter password:Passwords do not matchEnter Manager Password*:Re-enter password:====================Review Settings====================authentication.ldap.primaryUrl: my.url:849authentication.ldap.useSSL: asdauthentication.ldap.usernameAttribute: uid,1.2.5,1.2.5,93,0,0,0,1,0,0,0,
2578,ambari-server,Dmitry Lysnichenko,Using another user for ambari server user create a local group for the ambari server user with same name.,Using an ambari-qa user (that is a ldap user and he has hadoop set up as a primary ldap group) [root@va21 ldap]# id ambari-qauid=524(ambari-qa) gid=522(hadoop) groups=522(hadoop)causes ambari-server setup to create an ambari-qa local group (at /etc/group). ambari-qa:x:601:ambari-qa[root@va21 ldap]# id ambari-qauid=524(ambari-qa) gid=522(hadoop) groups=522(hadoop) 601(ambari-qa)Ldap users and groups are transparent for ambari-server  it starts well.The problem is that additional group is created.,1.2.5,1.2.5,73,0,0,0,0,0,0,0,
2585,ambari-web,Aleksandr Kovalenko,Host Check report show hosts without issues,Report contains hosts  which don't have issues  but should show 'A space delimited list of hosts which have issues'.,1.2.5,1.2.5,19,0,0,0,0,0,0,0,
2590,,Xi Wang,JS Error when deleting a widget after sorting it on remove/edit sign,,1.2.5,1.2.5,1,0,0,0,0,0,0,0,
2594,ambari-agent,Siddharth Wagle,HDP installation fails due to puppet syntax error,namenode_host is not an hash or array when accessing it with 0 at /var/lib/ambari-agent/puppet/modules/hdp/manifests/params.pp:70 on node host1.,1.2.5,1.2.5,17,0,0,0,0,0,0,0,
2595,ambari-web,Andrii Tkach,Properties of the same name cannot be added to different custom site.xml's,Steps (Installer Wizard):Go to 'Customize Services' page.Select 'HDFS' tab.Add custom property 'xxx' to 'Custom core-site.xml' panel.Try add custom property 'xxx' to 'Custom hdfs-site.xml' panel.Result:Custom property can not be added to 'Custom hdfs-site.xml' panel (see attachment).Steps (Ambari monitoring UI):Go to 'Customize Services' page.Select 'HDFS' tab.Add custom property to 'Custom core-site.xml' panel (for example  'install-test-core-site').Continue and end hadoop installation.Go to 'Services' page.Select 'MapReduce' tab.Try add custom property 'install-test-core-site' to 'Custom mapred-site.xml' panel.Result:Custom property can not be added to 'Custom mapred-site.xml' panel (see attachment).,1.2.5,1.2.5,81,0,0,0,0,0,0,1,ambari-web/app/views/common/configs/services_config.js;
2600,ambari-web,Antonenko Alexander,Add Quick Links (Web UI) for Oozie  Hue  Nagios  Ganglia,There are no quick links for Oozie. Similarly  some other services also are missing the quick links.,1.2.5,1.2.5,17,0,0,0,0,0,0,0,
2605,ambari-agent,Siddharth Wagle,'kdestroy' not required for zookeeper smoke test,zookeeper smoke test passes without having to 'kdestroy' on the user running the smoke test.,1.2.5,1.2.5,15,0,0,0,0,0,0,0,
2608,ambari-server,Sumit Mohanty,WebHCat and Oozie services does not start on RHEL5 with enabled security because of 'CRITICAL: Error doing kinit for nagios',FE only has support to provide single path for kinit. As Ambari supports mixed OS deployment it cannot be guaranteed that kinit exists at the same path on all nodes. FE should allow providing a set of look-up paths for kinit as well as the BE should support a set of default lookup paths.,1.2.5,1.2.5,54,1,0,0,0,0,0,0,
2612,ambari-agent; ambari-server,Dmytro Shkvyra,Rename agent.fqdn property in ambari.props to server.fqdn,lets just rename agent -&gt; server,1.2.5,1.2.5,6,0,0,0,0,0,0,0,
2613,ambari-web,Aleksandr Kovalenko,Host Checks: truncation on checked processes makes it difficult to know the actual processes in conflict,Processes are truncated too short and can't really tell what's in conflict. Since there is a lot of space on the right (in fact  the hostname column is too far to the left compared to other sections)  we should display more characters (with hover tooltip showing full text).,1.2.5,1.2.5,48,0,0,0,0,0,0,0,
2614,ambari-web,Andrii Tkach,Popover with config name goes beyond the container,See attachecd screenshot.,1.2.5,1.2.5,3,0,0,0,0,0,0,0,
2619,ambari-web,Antonenko Alexander,Wrong info on Services > Summary tab for DataNodes Live  TaskTrackers Live  RegionServers live,1. Install cluster2. On the host with SNameNode  we also have a region server3. Stop snamenode component on that host4. Services &gt; hbase &gt; summary shows region server is not liveAlso after stopping DataNode or TaskTracker  component status changes are not reflected on Services &gt; summary tab,1.2.5,1.2.5,47,1,0,0,0,0,0,0,
2631,ambari-server,Oleksandr Diachenko,Host cleanup left two packages(ambari-log4j  libconfuse),,1.2.5,1.2.5,1,1,0,0,0,0,0,0,
2632,,Xi Wang,Dashboard Widgets: 'hover to show details' experience is jarring,,1.2.5,1.2.5,1,1,0,0,0,0,0,0,
2633,,Sumit Mohanty,Reset the latest stack version for 1.2.5,Reset the latest stack version for 1.2.5,1.2.5,1.2.5,7,1,0,0,0,0,0,0,
2635,ambari-web,Srimanth Gunturi,Perf: Service summary view inefficiently binds to host components,In ambari-web/app/views/main/service/info/summary.js#hostComponentsUpd()  is called per each hostComponent's host and master property change. On a 150 node cluster  we get like 300 calls just for this method.Due to this  service_mapper  which usually maps in 600ms  takes now 5.8s.,1.2.5,1.2.5,38,1,0,0,0,1,0,0,
2636,,Xi Wang,Dashboard Metrics legend size increased unexpectedly on mouseover from line space,This happened in a very specific situation.1. Put mouse on the line space around a metric widget.2. hover on the widget with mouse down.Result:The legend show up as a strange bigger size.,1.2.5,1.2.5,32,0,0,0,0,0,0,0,
2637,ambari-web,Jaimin D Jetly,Security CSV cleanup,Should say 'Hive Metastore and HiveServer2'  not just HiveServer2. Even though they are co-located master components  let's make it clear this principal is for both include keytab file column. In addition to the keytab full path column (/etc/security/keytabs/jt.service.keytab)  include a column with just the filename (jt.service.keytab). Easier to copy/paste/parse if you want to use the CSV file.,1.2.5,1.2.5,58,1,0,0,0,0,0,2,ambari-web/app/controllers/main/admin/security/add/step3.js;ambari-web/app/utils/string_utils.js;
2640,ambari-web,Aleksandr Kovalenko,Going back to Customize Services page from the Install page resets certain directory values,Steps to reproduce: Install using non-default directories Upon install failure  go back to Customize Services page from the left nav. Certain directories (NN dirs  SNN dir  DN dirs  Oozie Data Dir  ZK Dir  etc) are reverted back to the default. Other parameters are not reverted back.,1.2.4,1.2.5,46,1,0,0,0,0,0,0,
2642,ambari-web,Oleg Nechiporenko,Update Ember-I18n,,1.4.0,1.4.0,1,1,0,0,0,0,0,0,
2643,,Nate Cole,Read timeout issues in Oracle JDBC connections where read has a long timeout,Read timeout issues in Oracle JDBC connections where read has a long timeout. This happens when the read timeout is too long. In order to set appropriate timeout  add specially prefixed values in ambari.properties,1.2.5,1.2.5,34,1,0,0,0,1,0,0,
2644,ambari-server,Siddharth Wagle,Ambari-server can not find password for remote database with password encryption enabled,Performed cluster setup as proposed at E2E test scenario. ambari-server setupambari-server setup-ldapambari-server encrypt-passwordsambari-server setup-httpsambari-server startServer does not start. It complains about missing password file / db password alias19:03:36 249 INFO Configuration:300 - Generation of file with password19:03:37 320 INFO CredentialProvider:146 - action =&gt; PUT  alias =&gt; ambari.db.password19:03:37 885 INFO Configuration:313 - Reading password from existing file19:03:38 838 INFO CredentialProvider:146 - action =&gt; PUT  alias =&gt; ambari.ldap.manager.password19:12:02 925 INFO Configuration:313 - Reading password from existing file19:12:02 946 INFO Configuration:324 - API SSL Authentication is turned on.19:12:02 946 INFO Configuration:329 - Reading password from existing file19:12:02 948 INFO Configuration:481 - Hosts Mapping File null19:12:02 951 INFO HostsMap:60 - Using hostsmap file null19:12:04 467 INFO MasterKeyServiceImpl:209 - Loading from persistent master: #1.0# Fri  Jul 12 2013 19:03:34.71719:12:06 016 INFO AmbariServer:446 - Getting the controller19:12:11 146 INFO CertificateManager:68 - Initialization of root certificate19:12:11 147 INFO CertificateManager:70 - Certificate exists:false19:12:11 147 INFO CertificateManager:137 - Generation of server certificate19:12:16 383 INFO ShellCommandUtil:43 - Command openssl genrsa -des3 -passout pass:n15KV1q6aWRZIP86XAjpTdbTaKo0HHWIsTuaOPZQdxycChECKG -out /var/lib/ambari-server/keys/ca.key 4096 was finished with exit code: 0 - the operation was completely successfully.19:12:16 431 INFO ShellCommandUtil:43 - Command openssl req -passin pass:n15KV1q6aWRZIP86XAjpTdbTaKo0HHWIsTuaOPZQdxycChECKG -new -key /var/lib/ambari-server/keys/ca.key -out /var/lib/ambari-server/keys/ca.crt -batch was finished with exit code: 0 - the operation was completely successfully.19:12:16 483 INFO ShellCommandUtil:43 - Command openssl x509 -passin pass:n15KV1q6aWRZIP86XAjpTdbTaKo0HHWIsTuaOPZQdxycChECKG -req -days 365 -in /var/lib/ambari-server/keys/ca.crt -signkey /var/lib/ambari-server/keys/ca.key -out /var/lib/ambari-server/keys/ca.crt was finished with exit code: 0 - the operation was completely successfully.19:12:16 496 INFO ShellCommandUtil:43 - Command openssl pkcs12 -export -in /var/lib/ambari-server/keys/ca.crt -inkey /var/lib/ambari-server/keys/ca.key -certfile /var/lib/ambari-server/keys/ca.crt -out /var/lib/ambari-server/keys/keystore.p12 -password pass:n15KV1q6aWRZIP86XAjpTdbTaKo0HHWIsTuaOPZQdxycChECKG -passin pass:n15KV1q6aWRZIP86XAjpTdbTaKo0HHWIsTuaOPZQdxycChECKG was finished with exit code: 0 - the operation was completely successfully.19:12:16 883 INFO AmbariServer:123 - ********* Meta Info initialized **********19:12:16 896 INFO ClustersImpl:88 - Initializing the ClustersImpl19:12:17 115 ERROR Configuration:610 - Error reading from credential store.19:12:17 116 ERROR Configuration:616 - Cannot read password for alias = /etc/ambari-server/conf/password.dat19:12:17 117 ERROR AmbariServer:455 - Failed to run the Ambari Serverjava.lang.RuntimeException: Unable to read database password at org.apache.ambari.server.configuration.Configuration.readPasswordFromFile(Configuration.java:596) at org.apache.ambari.server.configuration.Configuration.getRcaDatabasePassword(Configuration.java:583) at org.apache.ambari.eventdb.webservice.WorkflowJsonService.setDBProperties(WorkflowJsonService.java:95) at org.apache.ambari.server.controller.AmbariServer.performStaticInjection(AmbariServer.java:437) at org.apache.ambari.server.controller.AmbariServer.run(AmbariServer.java:125) at org.apache.ambari.server.controller.AmbariServer.main(AmbariServer.java:452)Caused by: java.io.FileNotFoundException: File '/etc/ambari-server/conf/password.dat' does not exist at org.apache.commons.io.FileUtils.openInputStream(FileUtils.java:265) at org.apache.commons.io.FileUtils.readFileToString(FileUtils.java:1457) at org.apache.commons.io.FileUtils.readFileToString(FileUtils.java:1475) at org.apache.ambari.server.configuration.Configuration.readPasswordFromFile(Configuration.java:594) ... 5 more19:12:17 118 ERROR AmbariServer:420 - Error stopping the serverjava.lang.NullPointerException at org.apache.ambari.server.controller.AmbariServer.stop(AmbariServer.java:418) at org.apache.ambari.server.controller.AmbariServer.main(AmbariServer.java:457)Content of ambari.properties:server.jdbc.rca.driver=oracle.jdbc.driver.OracleDriverauthentication.ldap.managerDn=uid=hdfs ou=people ou=dev dc=apache dc=orgauthentication.ldap.primaryUrl=localhost:389server.jdbc.rca.url=jdbc:oracle:thin:@ip-10-34-79-165.ec2.internal:1521/XEserver.connection.max.idle.millis=900000server.jdbc.port=1521server.version.file=/var/lib/ambari-server/resources/versionserver.jdbc.rca.user.passwd=/etc/ambari-server/conf/password.datapi.authenticate=truejce_policy.url=http://public-repo-1.hortonworks.com/ARTIFACTS/jce_policy-6.zipserver.persistence.type=remoteclient.api.ssl.key_name=https.keyauthentication.ldap.useSSL=falseambari-server.user=ambar-serverclient.api.ssl.port=8443authentication.ldap.usernameAttribute=uidserver.jdbc.user.name=ambariserver.jdbc.schema=XEjava.home=/usr/jdk64/jdk1.6.0_31server.os_type=redhat6api.ssl=truebootstrap.script=/usr/lib/python2.6/site-packages/ambari_server/bootstrap.pyclient.api.ssl.cert_name=https.crtauthentication.ldap.bindAnonymously=falseclient.security=ldapserver.jdbc.hostname=ip-10-34-79-165.ec2.internalresources.dir=/var/lib/ambari-server/resourcessecurity.passwords.encryption.enabled=truebootstrap.setup_agent.script=/usr/lib/python2.6/site-packages/ambari_server/setupAgent.pyserver.jdbc.driver=oracle.jdbc.driver.OracleDriverjdk.url=http://public-repo-1.hortonworks.com/ARTIFACTS/jdk-6u31-linux-x64.binsecurity.server.keys_dir=/var/lib/ambari-server/keysserver.jdbc.rca.user.name=ambariwebapp.dir=/usr/lib/ambari-server/webmetadata.path=/var/lib/ambari-server/resources/stacksserver.jdbc.url=jdbc:oracle:thin:@ip-10-34-79-165.ec2.internal:1521/XEserver.fqdn.service.url=http://169.254.169.254/latest/meta-data/public-hostnamebootstrap.dir=/var/run/ambari-server/bootstrapauthentication.ldap.baseDn=dc=apache dc=orgserver.jdbc.user.passwd=${alias=ambari.db.password}authentication.ldap.managerPassword=${alias=ambari.ldap.manager.password}server.jdbc.database=oraclesecurity.server.two_way_ssl=trueFile /etc/ambari-server/conf/password.dat is missingSetup flow:[root@ip-10-116-65-200 kerb]# ambari-server setupUsing python /usr/bin/python2.6Initializing...Setup ambari-serverChecking SELinux...SELinux status is 'enabled'SELinux mode is 'enforcing'Temporarily disabling SELinuxWARNING: SELinux is set to 'permissive' mode and temporarily disabled.OK to continue [y/n] (y)? yCustomize user account for ambari-server daemon [y/n] (n)? yEnter user account for ambari-server daemon (root):ambar-serverAdjusting ambari-server permissions and ownership...Checking iptables...iptables is disabled now. please reenable later.Checking JDK...Downloading JDK from http://public-repo-1.hortonworks.com/ARTIFACTS/jdk-6u31-linux-x64.bin to /var/lib/ambari-server/resources/jdk-6u31-linux-x64.binJDK distribution size is 85581913 bytesjdk-6u31-linux-x64.bin... 100% (81.6 MB of 81.6 MB)Successfully downloaded JDK distribution to /var/lib/ambari-server/resources/jdk-6u31-linux-x64.binTo install the Oracle JDK you must accept the license terms found at http://www.oracle.com/technetwork/java/javase/downloads/jdk-6u21-license-159167.txt. Not accepting will cancel the Ambari Server setup.Do you accept the Oracle Binary Code License Agreement [y/n] (y)? Installing JDK to /usr/jdk64Successfully installed JDK to /usr/jdk64/jdk1.6.0_31Downloading JCE Policy archive from http://public-repo-1.hortonworks.com/ARTIFACTS/jce_policy-6.zip to /var/lib/ambari-server/resources/jce_policy-6.zipSuccessfully downloaded JCE Policy archive to /var/lib/ambari-server/resources/jce_policy-6.zipCompleting setup...Configuring database...Enter advanced database configuration [y/n] (n)? ySelect database:1 - PostgreSQL (Embedded)2 - Oracle[1]:2Hostname [localhost]:ip-10-34-79-165.ec2.internalPort [1521]:Select Oracle identifier type:1 - Service Name2 - SID[1]:XEInvalid number.Select Oracle identifier type:1 - Service Name2 - SID[1]:1Service Name [ambari]:XEUsername [ambari]: Enter Database Password [bigdata]: WARNING: Before starting Ambari Server  you must copy the Oracle JDBC driver JAR file to /usr/share/java.Press &lt;enter&gt; to continue.Copying JDBC drivers to server resources...Configuring remote database connection properties...WARNING: Cannot find oracle sqlplus client in the path to load the Ambari Server schema. Before starting Ambari Server  you must run the following DDL against the database to create the schema sqlplus ambari/bigdata &lt; /var/lib/ambari-server/resources/Ambari-DDL-Oracle-CREATE.sql Press &lt;enter&gt; to continue.WARNING: The cli was not foundAmbari Server 'setup' completed with warnings.[root@ip-10-116-65-200 kerb]# less /etc/passwd,1.2.5,1.2.5,665,0,0,0,0,0,0,0,
2646,ambari-web,Jeff Sposetti,Improve styles for HostCleanup code area,,1.2.5,1.2.5,1,0,0,0,0,0,0,0,
2653,ambari-agent; ambari-server,Dmytro Shkvyra,Add umask checks for host checks - we should alert if umask is not 022.,Add umask checks for host checks - we should alert if umask is not 022.,1.2.5,1.2.5,15,1,0,0,0,0,0,0,
2657,ambari-web,Andrii Tkach,Add a re-type new password field when changing passwords for ambari users,We should add a third text box to re-type the new password while changing the password for an ambari user.,1.2.5,1.4.0,20,1,0,0,0,0,0,0,
2660,ambari-web,Srimanth Gunturi,Host checks say pass when all hosts failed to register,When all hosts fail to register  there are no warnings  and hence we show OK for host checks.,1.2.5,1.2.5,18,1,0,0,0,0,0,0,
2661,ambari-web,Jaimin D Jetly,Security wizard: Relogin while on step3 without quitting the wizard throws JS error.,Steps to reproduce: Go to step-3 (Generate principals and keytabs) of Enable security wizard. Restart Amabri server. Refresh on step-3. ui will take you to login page. Entering correct credentials  user will be navigated again to step-3 of security wizard. At this point JS error is encountered.,1.2.5,1.2.5,48,1,0,0,0,0,0,1,ambari-web/app/routes/main.js;
2670,ambari-web,Antonenko Alexander,Start button not available for various components within 10 sec after stop operation finishes,Steps to reproduce: 1. Stop a component. 2. Wait for the corresponding BG operation to finish. Result: 'Start' button isn't available for the component within 10 seconds since stop operation finished in UI. It appears later.This happens cuz of update interval  it is set to 15 seconds (App.contentUpdateInterval)  that's why in some moments it can take up to 15 sec to update components status  after request is done.Solution: Create a seperate update interval specialy for updating host components. In config.js we even have App.componentsUpdateInterval = 6000; But this value was not used anywhere in code till now.,1.2.5,1.2.5,97,1,0,0,0,1,0,0,
2681,ambari-server,Sumit Mohanty,setup ldap does not validate secondary url,setup ldap does not validate secondary url. It should validate the input (when entered) the same way as the primary.,1.2.5,1.2.5,20,0,0,0,0,0,0,0,
2688,ambari-server,Artem Baranchuk,Error messages printed to log,Notice in the ambari-server snippet below a lot of these messages:ERROR Configuration:616 - Cannot read password for alias = nullSteps to reproduce:Setup serverSetup encrypt passwords  don't persist the keySetup httpsStart the server  provided master keyDo cluster install,1.2.5,1.4.0,46,0,0,0,0,0,0,0,
2689,ambari-web,Jaimin D Jetly,Enable Security Wizard stops on step '2. Save Configurations' and doesn't let the user leave the wizard,,1.2.5,1.2.5,1,0,0,0,0,0,0,4,ambari-web/app/controllers/main/admin/security/add/step4.js;ambari-web/app/controllers/main/admin/security/disable.js;ambari-web/app/messages.js;ambari-web/app/models/cluster_states.js;
2690,ambari-web,Xi Wang,Datanode Live widget displays 0 dead when no datanode is live on a cluster.,,1.2.5,1.4.0,1,1,0,0,0,0,0,0,
2692,ambari-web,Aleksandr Kovalenko,Disable Show report for 0 issues,Report on Host Checks for 0 isses looks like:####################################### Host Checks Report## Generated: Tue Jul 09 2013 13:11:14 GMT+0300 (FLE Daylight Time)############################################################################# Hosts## A space delimited list of hosts which have issues.# Provided so that administrators can easily copy hostnames into scripts  email etc.######################################HOSTSShow Report button should be disabled for 0 issues or at least do not show HOSTS section in report.,1.2.5,1.4.0,68,0,0,0,0,0,0,0,
2697,ambari-web,Jaimin D Jetly,Disable security not working in web-ui testMode.,,1.2.5,1.2.5,1,0,0,0,1,0,0,1,ambari-web/app/controllers/main/admin/security/disable.js;
2698,ambari-web,Aleksandr Kovalenko,Host specific progress bar for a task has some inconsistencies,See the attached images. The third image added is a summary of what was going on.,1.2.5,1.4.0,16,1,0,0,0,0,0,0,
2701,,Dmytro Sen,Implement a cleanup thread that removes files in ambari-agent data directory that are older than a configurable amount of time,Implement a cleanup thread that removes files in ambari-agent data directory that are older than a month or so(must be configurable).It's required  because the directory will grow unbounded if it's not cleaned up.,1.2.3,1.4.0,33,1,0,0,0,0,0,0,
2707,ambari-web,Oleg Nechiporenko,Fix JS Unit tests after merge 1.4.0 to trunk,,1.4.0,1.4.0,1,1,0,0,0,0,0,0,
2708,ambari-web,Antonenko Alexander,Make ambari web testMode work for installer wizard with HDP stack-2 selection.,Installer wizard with HDP stack-2 selection in test mode,1.4.0,1.4.0,9,0,0,0,0,0,0,0,
2716,ambari-web,Jaimin D Jetly,Disable autocomplete on form tag for Ambari UI.,,1.2.5,1.2.5,1,1,0,0,0,0,0,16,ambari-web/app/models/form.js;ambari-web/app/templates/common/configs/addPropertyWindow.hbs;ambari-web/app/templates/common/configs/capacity_scheduler.hbs;ambari-web/app/templates/common/configs/overrideWindow.hbs;ambari-web/app/templates/common/configs/service_config.hbs;ambari-web/app/templates/main/admin/user/create.hbs;ambari-web/app/templates/main/admin/user/edit.hbs;ambari-web/app/templates/main/dashboard/edit_widget_popup.hbs;ambari-web/app/templates/main/mirroring/dataset.hbs;ambari-web/app/templates/main/mirroring/testConnection.hbs;ambari-web/app/templates/main/mirroring/testConnectionResults.hbs;ambari-web/app/templates/wizard/step1.hbs;ambari-web/app/templates/wizard/step1_addLocalRepository.hbs;ambari-web/app/templates/wizard/step5.hbs;ambari-web/app/views/common/configs/services_config.js;ambari-web/app/views/wizard/step0_view.js;
2723,ambari-agent,Artem Baranchuk,hbase super user cannot submit jobs since Ambari creates hbase super user with uid<1000,Copytable jobs need to be submitted as the hbase super user however the uid for hbase super user created by Ambari has uid &lt; 1000,1.2.5,1.4.0,25,1,0,0,0,0,0,0,
2727,ambari-web,Oleg Nechiporenko,Disallow actions upon host components on hosts that stopped heartbeating,On a host that stopped heartbeating  the UI shows actions to perform on host components. However  upon executing an action  the backend does not create any tasks and returns 200. The UI doesn't do anything in this case. Instead  the UI should disable action buttons in this case.,1.4.0,1.4.0,48,1,0,0,0,0,0,0,
2729,ambari-web,Andrii Babiichuk,While a host component is being installed (INSTALLING state)  it does not show up in the Host Detail page,Say Add Hosts wizard fails to add a host and the host components are in INSTALL_FAILED state. In this case  the UI displays the host component with a red gear and shows the action menu with the current state 'Install Failed' and the action 'Re-Install'. Once you invoke 'Re-Install'  the host component disappears from the UI. Once the host component finishes installing  it magically appears again.,1.2.5,1.4.0,66,1,0,0,0,0,0,0,
2733,ambari-web,Oleg Nechiporenko,Hosts and Host Details page UI tweaks,1. Hosts &gt; Design around full hostname being displayed. Consider being able to show 40 characters and then truncate &gt; 40 chars 2. Hosts &gt; Show # control should persist when navigating around app  and after logout/login3. Hosts &gt; Make Components list an expand/collapse control instead of a list with abbreviations4. Host Details &gt; Move Components area above Summary area since the Component Controls are used very often (much more often than viewing the Summary area info).,1.4.0,1.4.0,77,1,0,0,0,0,0,0,
2748,ambari-server,Sumit Mohanty,Misc logging changes,Additional logs:  When a task is timed-out/failed API requests to update component and component hosts   Remove logs  Do not log ganglia population time when its less than 5 second,1.4.0,1.4.0,36,1,0,0,0,0,0,0,
2753,ambari-web,Antonenko Alexander,Security Wizard step 4: no hosts shown when clicking on the 'Start Services'/'Stop Services' link,Proceed to step 4 of security wizard  click on 'Start Services' or 'Stop Services' link.Result: popup window is shown with empty contentThis bug was happening due to js error 'Uncaught TypeError: Cannot call method 'filterProperty' of null' in setBackgroundOperationHeader: functionAfter background operation (host popup) popup was optimized for better peformace on large cluster this error showed up. New function on setting popup header  did not account that this popup (HostPopup) is used not only in BG operations  but also in security wizard.,1.2.5,1.2.5,82,1,0,0,0,0,0,0,
2758,ambari-web,Andrii Babiichuk,Jobs page: table is not striped and pagination is not disabled,To reproduce go to the Jobs page from top menu (do not open .../main/apps directly). Table is not striped and pagination buttons are enabled even if there is only one page.,1.4.0,1.4.0,31,1,0,0,0,0,0,0,
2760,ambari-web,Srimanth Gunturi,Stack 2.0.3  Hive Check execute fail,When installing Hadoop 2 stack  Hive service check fails to run.,1.4.0,1.4.0,11,1,0,0,0,0,0,0,
2761,ambari-web,Antonenko Alexander,Customize Services page - Misc tab: incorrect behavior of popup window for changing user names,In firefoxSteps:Go to 'Customize Services' page.Select 'Misc' tab.Change username for HDFS  HBase or Group (do not move focus to other elements).Click 'Next' button.Result:Browser was switched to 'Review' page.Was opened popup window for changing properties depended with user names. User must to refresh the page for popup menu disappearing.,1.2.5,1.2.5,48,1,0,0,0,0,0,0,
2763,ambari-server,Siddharth Wagle,Ozzie does not work with local FS user,Running jobs as a local FS user does not work work 2.0.* stack because of permissions on /tmp/hadoop-yarn/staging  which is the default staging dir.,1.4.0,1.4.0,24,1,0,0,0,1,0,0,
2768,ambari-web,Oleg Nechiporenko,Host Checks > Show Report is showing bogus information for FILES AND FOLDERS,Host Checks popup is showing that /usr/lib/hadoop already exists.When I clicked on 'Show Reports'  it is showing '/usr/lib/hadoop/ /folder'. This doesn't make much sense. FILES AND FOLDERS/usr/lib/hadoop/ /folderThe API is showing: 'stackFoldersAndFiles' : [ { 'name' : '/usr/lib/hadoop'  'type' : 'directory' },1.4.0,1.4.0,54,0,0,0,0,0,0,0,
2769,ambari-web,Andrii Babiichuk,FE should show the error-details when it encounters error while persisting web client state,Error which occurred while requesting cluster status is not informative.Change url in request for cluster state  go to admin page and try to enable security.,1.2.5,1.4.0,25,1,0,0,1,0,0,0,
2777,ambari-web,Yusaku Sako,Cannot save HDFS configs with SNN in MAINTENANCE mode,,1.4.0,1.4.0,1,1,0,0,0,0,0,0,
2782,ambari-web,Oleg Nechiporenko,Hadoop2 stack install should merge YARN MR2 options,YARN in current Hadoop 2 stack has only MR2 as application. Since it does not make sense to install YARN without a default application  and MR2 cannot be installed by itself  we should combine both into a single install option (see screenshot).,1.4.0,1.4.0,42,1,0,0,0,0,0,0,
2786,ambari-server,Andrew Onischuk,YARN time series data needed for NodeManager statuses,We need API call for a graph which will show NodeManager status counts. NodeManagers can be in the following states: active  lost  unhealthy  rebooted  and decommissioned.,1.4.0,1.4.0,26,1,0,0,0,0,0,0,
2799,ambari-web,Oleg Nechiporenko,YARN service summary additional information,We need to show below 2 additional information Across cluster memory - used/reserved/total Queues information if available,1.4.0,1.4.0,17,1,0,0,0,0,0,0,
2808,ambari-web,Dmytro Shkvyra,Can't add from UI some queues in capacity-scheduler.xml,Properties of capacity-scheduler.xml are truncated by ' '. It make impossible to create multiple queues  please see http://hadoop.apache.org/docs/current/hadoop-yarn/hadoop-yarn-site/CapacityScheduler.html,1.4.0,1.4.0,20,1,0,0,0,0,0,0,
2816,ambari-web,Oleg Nechiporenko,Customize Services: directories are shown in comma-delimited format when revisiting,In the Install Wizard  Customize Services page shows multiple directories delimited by newlines.However  when revisiting the page (go back to Customize Services from the Review page  for example)  the directories are shown in comma-delimited format. We should always show the directories in newline-delimited format. Note that when we actually store the value  the directories are comma-delimited (which is correct).,1.4.0,1.4.0,59,1,0,0,0,0,0,0,
2829,ambari-web,Oleg Nechiporenko,Dashboard refactor and Unit tests,,1.4.0,1.4.0,1,1,0,0,0,0,0,0,
2834,ambari-server,Jaimin D Jetly,Utility script to generate keytabs is broken,keytab Tar for each host is packaged including hostname. Untaring it on a host creates path starting with &lt;hostanme&gt;/&lt;actual path&gt;. Fix is to package the content inside the hostname directory excluding the hostname directory itself.,1.4.0,1.4.0,35,0,0,0,0,0,0,0,
2836,ambari-web,Andrew Onischuk,HBase 0.95.2 - Logger doesn't work,Installing 0.95.2 from internal repo 2.0.5. hbase-daemon.sh defines a default logger of INFO RFA{{  when log4j.properties uses {{INFO DRFA. They should match  as startup generates an error and does not continue.We should stop over writing the log4j properties for hbase. This will allow for hbase log4j properties to be in sync with those that come with the rpms.,1.4.0,1.4.0,56,1,0,0,0,0,0,0,
2838,ambari-server,Sumit Mohanty,Running Requests are not visibile on the UI since the API is not returning the running requests.,The issue is the following:getRequestsByTaskStatus behaves correctly and returns the latest N requests. Note that the N requests have M (M &gt;&gt; N) tasks.Then the call to findByRequestIds gets oldest N tasks where the requestId for tasks belong to the list returned by the first call. So instead of getting M tasks we only get N tasks that too N oldest tasks which are returned. As a result the call never returns that latest request/tasks. The fix is to drop the filter done by the calls findByRequestIds and findByRequestAndTaskIds. Filter should only be applied on the number of requests to be returned.,1.2.5,1.2.5,102,0,0,0,0,0,0,0,
2840,ambari-web,Andrii Tkach,YARN and ZK data directory names have ' ' at end,Installed the Hadoop2 stack and upon finishing the zk_data_dir in global  and yarn.nodemanager.local-dirs in yarn-site have the folder names suffixed with ' ' in API. Consequently  the folder names on system end up with a ' ' at end. Ex: /hadoop/yarn  and /hadoop/zookeeper .,1.4.0,1.4.0,41,1,0,0,0,0,0,3,ambari-web/app/controllers/wizard.js;ambari-web/app/controllers/wizard/step7_controller.js;ambari-web/app/controllers/wizard/step8_controller.js;
2847,ambari-agent,Siddharth Wagle,Restart service component fails if pid is reallocated,1. Stop secondary namenode.2. Edit the pid file  default location = /var/run/hadoop/hdfs/hadoop-hdfs-secondarynamenode.pid3. Change the pid to any other process pid that is currently running.4. Start secondary namenode.Outcome:Secondary namenode start command succeeds but secondary namenode does not start. (indicated by live status of the component).,1.3.0,1.4.0,44,1,0,0,0,0,0,0,
2858,ambari-server,Dmytro Sen,YARN time series data needed for AllocatedContainers,API call for a graph which will show time series for YARN Allocated containers.,1.4.0,1.4.0,14,1,0,0,0,0,0,0,
2864,ambari-agent,Siddharth Wagle,Host registration fails,Host registration fails with:INFO 2013-08-10 01:50:49 923 Controller.py:99 - Unable to connect to: https://c6401.ambari.apache.org:8441/agent/v1/register/c6403.ambari.apache.orgTraceback (most recent call last): File '/usr/lib/python2.6/site-packages/ambari_agent/Controller.py'  line 80  in registerWithServer ret = json.loads(response) File '/usr/lib64/python2.6/json/__init__.py'  line 307  in loads return _default_decoder.decode(s) File '/usr/lib64/python2.6/json/decoder.py'  line 319  in decode obj  end = self.raw_decode(s  idx=_w(s  0).end()) File '/usr/lib64/python2.6/json/decoder.py'  line 338  in raw_decode raise ValueError('No JSON object could be decoded')ValueError: No JSON object could be decodedambari-server.log is showing:01:55:22 732 WARN [qtp967966535-50] ServletHandler:514 - /agent/v1/register/c6401.ambari.apache.orgcom.google.gson.JsonSyntaxException: java.lang.IllegalStateException: Expected a string but was BEGIN_OBJECT at line 1 column 3680 at com.google.gson.internal.bind.ReflectiveTypeAdapterFactory$Adapter.read(ReflectiveTypeAdapterFactory.java:176) at com.google.gson.internal.bind.TypeAdapterRuntimeTypeWrapper.read(TypeAdapterRuntimeTypeWrapper.java:40) at com.google.gson.internal.bind.ArrayTypeAdapter.read(ArrayTypeAdapter.java:72) at com.google.gson.internal.bind.ReflectiveTypeAdapterFactory$1.read(ReflectiveTypeAdapterFactory.java:93) at com.google.gson.internal.bind.ReflectiveTypeAdapterFactory$Adapter.read(ReflectiveTypeAdapterFactory.java:172) at com.google.gson.internal.bind.ReflectiveTypeAdapterFactory$1.read(ReflectiveTypeAdapterFactory.java:93) at com.google.gson.internal.bind.ReflectiveTypeAdapterFactory$Adapter.read(ReflectiveTypeAdapterFactory.java:172) at com.google.gson.internal.bind.ReflectiveTypeAdapterFactory$1.read(ReflectiveTypeAdapterFactory.java:93) at com.google.gson.internal.bind.ReflectiveTypeAdapterFactory$Adapter.read(ReflectiveTypeAdapterFactory.java:172) at com.google.gson.Gson.fromJson(Gson.java:795) at com.google.gson.Gson.fromJson(Gson.java:761) at org.apache.ambari.server.api.GsonJsonProvider.readFrom(GsonJsonProvider.java:60) at com.sun.jersey.spi.container.ContainerRequest.getEntity(ContainerRequest.java:474) at com.sun.jersey.server.impl.model.method.dispatch.EntityParamDispatchProvider$EntityInjectable.getValue(EntityParamDispatchProvider.java:123) at com.sun.jersey.server.impl.inject.InjectableValuesProvider.getInjectableValues(InjectableValuesProvider.java:46) at com.sun.jersey.server.impl.model.method.dispatch.AbstractResourceMethodDispatchProvider$EntityParamInInvoker.getParams(AbstractResourceMethodDispatchProvider.java:153) at com.sun.jersey.server.impl.model.method.dispatch.AbstractResourceMethodDispatchProvider$TypeOutInvoker._dispatch(AbstractResourceMethodDispatchProvider.java:183) at com.sun.jersey.server.impl.model.method.dispatch.ResourceJavaMethodDispatcher.dispatch(ResourceJavaMethodDispatcher.java:75) at com.sun.jersey.server.impl.uri.rules.HttpMethodRule.accept(HttpMethodRule.java:288) at com.sun.jersey.server.impl.uri.rules.RightHandPathRule.accept(RightHandPathRule.java:147) at com.sun.jersey.server.impl.uri.rules.ResourceClassRule.accept(ResourceClassRule.java:108) at com.sun.jersey.server.impl.uri.rules.RightHandPathRule.accept(RightHandPathRule.java:147) at com.sun.jersey.server.impl.uri.rules.RootResourceClassesRule.accept(RootResourceClassesRule.java:84) at com.sun.jersey.server.impl.application.WebApplicationImpl._handleRequest(WebApplicationImpl.java:1469),1.4.0,1.4.0,153,0,0,0,0,0,0,0,
2865,ambari-agent,Sumit Mohanty,Nagios server fails to start with invalid configuration error,Nagios fails to start with invalid configuration error. (This is likely intermittent).Error: Configuration validation failed - when Nagios is started./usr/sbin/nagios -v /etc/nagios/nagios.cfgCopyright (c) 1999-2009 Ethan GalstadLast Modified: 03-15-2013License: GPLWebsite: http://www.nagios.orgReading configuration data... Read main config file okay...Processing object config file '/etc/nagios/objects/commands.cfg'...Processing object config file '/etc/nagios/objects/contacts.cfg'...Processing object config file '/etc/nagios/objects/timeperiods.cfg'...Processing object config file '/etc/nagios/objects/templates.cfg'...Processing object config file '/etc/nagios/objects/hadoop-hosts.cfg'...Processing object config file '/etc/nagios/objects/hadoop-hostgroups.cfg'...Processing object config file '/etc/nagios/objects/hadoop-servicegroups.cfg'...Processing object config file '/etc/nagios/objects/hadoop-services.cfg'...Processing object config file '/etc/nagios/objects/hadoop-commands.cfg'...Error: Could not find any hostgroup matching 'resourcemanager' (config file '/etc/nagios/objects/hadoop-services.cfg'  starting on line 292) Error processing object config files!***&gt; One or more problems was encountered while processing the config files... Check your configuration file(s) to ensure that they contain valid directives and data defintions. If you are upgrading from a previous version of Nagios  you should be aware that some variables/definitions may have been removed or modified in this version. Make sure to read the HTML documentation regarding the config files  as well as the 'Whats New' section to find out what has changed.,1.4.0,1.4.0,173,0,0,0,0,0,0,0,
2866,ambari-server,Oleksandr Diachenko,API JMX mapping needs to be updated due to property name changes,In Ambari UI  we show properties like NameNode RPC Time.We used to get this metric by querying the NameNode component for 'RpcQueueTime_avg_time'.However  in Hadoop 2  it looks like this property name changed to 'RpcQueueTimeAvgTime'  so the Ambari API no longer contains these metrics. Other properties related to NameNode RPC may have changed. We need to update the mapping accordingly.,1.4.0,1.4.0,59,0,0,0,0,0,0,0,
2871,ambari-agent,Oleksandr Diachenko,Nagios start fails due to invalid configs,Steps to reproduce:1) Deploy HDP-2.0.5 cluster with Nagios.2) Start of Nagios failed  puppet log:notice: /Stage[1]/Hdp::Snappy::Package/Hdp::Snappy::Package::Ln[32]/Hdp::Exec[hdp::snappy::package::ln 32]/Exec[hdp::snappy::package::ln 32]/returns: executed successfullynotice: /Stage[2]/Hdp-nagios::Server::Enable_snmp/Exec[enable_snmp]/returns: executed successfullynotice: /Stage[2]/Hdp-nagios::Server::Config/Hdp-nagios::Server::Configfile[hadoop-hostgroups.cfg]/Hdp::Configfile[/etc/nagios/objects/hadoop-hostgroups.cfg]/File[/etc/nagios/objects/hadoop-hostgroups.cfg]/content: content changed '{md5}873d2be7b9f78137e0740223944d93af' to '{md5}780117e3c2407e9d02b37eab93159149'notice: /Stage[2]/Hdp-nagios::Server::Config/Hdp-nagios::Server::Configfile[nagios]/Hdp::Configfile[/etc/init.d//nagios]/File[/etc/init.d//nagios]/content: content changed '{md5}3990694abc37617c79e2ea5276d71089' to '{md5}c4c4454911c0c6c1ba29d9d0dc2aa28c'notice: /Stage[2]/Hdp-nagios::Server::Config/Hdp-nagios::Server::Configfile[hadoop-hosts.cfg]/Hdp::Configfile[/etc/nagios/objects/hadoop-hosts.cfg]/File[/etc/nagios/objects/hadoop-hosts.cfg]/content: content changed '{md5}7979396ff0b495e40901acdd2ecc457c' to '{md5}fa5ec3a93a4827cc6a691e0b8e22b4f6'notice: /Stage[2]/Hdp-nagios::Server::Config/Hdp-nagios::Server::Configfile[hadoop-services.cfg]/Hdp::Configfile[/etc/nagios/objects/hadoop-services.cfg]/File[/etc/nagios/objects/hadoop-services.cfg]/content: content changed '{md5}06c9d0bb0aa3b1e7b30b19fb1bb30b5a' to '{md5}934241156b5489483dab8018f9cecd22'notice: /Stage[2]/Hdp-nagios::Server::Web_permisssions/Hdp::Exec[htpasswd -c -b /etc/nagios/htpasswd.users nagiosadmin p]/Exec[htpasswd -c -b /etc/nagios/htpasswd.users nagiosadmin p]/returns: executed successfullynotice: /Stage[2]/Hdp-nagios::Server::Web_permisssions/Hdp::Exec[apache_permissions_htpasswd.users]/Exec[apache_permissions_htpasswd.users]/returns: executed successfullynotice: /Stage[2]/Hdp-nagios::Server::Services/Exec[nagios]/returns: nagios is stoppednotice: /Stage[2]/Hdp-nagios::Server::Services/Exec[nagios]/returns: Configuration validation failed[FAILED]err: /Stage[2]/Hdp-nagios::Server::Services/Exec[nagios]/returns: change from notrun to 0 failed: service nagios start returned 1 instead of one of [0] at /var/lib/ambari-agent/puppet/modules/hdp-nagios/manifests/server.pp:284notice: /Stage[2]/Hdp-nagios::Server::Services/Exec[nagios]/returns: nagios is stoppednotice: /Stage[2]/Hdp-nagios::Server::Services/Exec[nagios]/returns: Configuration validation failed[FAILED]err: /Stage[2]/Hdp-nagios::Server::Services/Exec[nagios]: Failed to call refresh: service nagios start returned 1 instead of one of [0] at /var/lib/ambari-agent/puppet/modules/hdp-nagios/manifests/server.pp:284notice: /Stage[2]/Hdp-nagios::Server::Services/Anchor[hdp-nagios::server::services::end]: Dependency Exec[nagios] has failures: truewarning: /Stage[2]/Hdp-nagios::Server::Services/Anchor[hdp-nagios::server::services::end]: Skipping because of failed dependenciesnotice: /Stage[2]/Hdp-monitor-webserver/Hdp::Package[httpd]/Hdp::Package::Process_pkg[httpd]/Anchor[hdp::package::httpd::begin]: Dependency Exec[nagios] has failures: truewarning: /Stage[2]/Hdp-monitor-webserver/Hdp::Package[httpd]/Hdp::Package::Process_pkg[httpd]/Anchor[hdp::package::httpd::begin]: Skipping because of failed dependenciesnotice: /Stage[2]/Hdp-monitor-webserver/Hdp::Package[httpd]/Hdp::Package::Process_pkg[httpd]/Package[httpd]: Dependency Exec[nagios] has failures: truewarning: /Stage[2]/Hdp-monitor-webserver/Hdp::Package[httpd]/Hdp::Package::Process_pkg[httpd]/Package[httpd]: Skipping because of failed dependenciesnotice: /Stage[2]/Hdp-monitor-webserver/Hdp::Package[httpd]/Hdp::Package::Process_pkg[httpd]/Hdp::Java::Package[httpd]/Anchor[hdp::java::package::httpd::begin]: Dependency Exec[nagios] has failures: truewarning: /Stage[2]/Hdp-monitor-webserver/Hdp::Package[httpd]/Hdp::Package::Process_pkg[httpd]/Hdp::Java::Package[httpd]/Anchor[hdp::java::package::httpd::begin]: Skipping because of failed dependenciesnotice: /Stage[2]/Hdp-monitor-webserver/Hdp::Package[httpd]/Hdp::Package::Process_pkg[httpd]/Hdp::Java::Package[httpd]/Exec[mkdir -p /tmp/HDP-artifacts/ ; curl -kf --retry 10 http://dev01.hortonworks.com:8080/resources//jdk-6u31-linux-x64.bin -o /tmp/HDP-artifacts//jdk-6u31-linux-x64.bin httpd]: Dependency Exec[nagios] has failures: truewarning: /Stage[2]/Hdp-monitor-webserver/Hdp::Package[httpd]/Hdp::Package::Process_pkg[httpd]/Hdp::Java::Package[httpd]/Exec[mkdir -p /tmp/HDP-artifacts/ ; curl -kf --retry 10 http://dev01.hortonworks.com:8080/resources//jdk-6u31-linux-x64.bin -o /tmp/HDP-artifacts//jdk-6u31-linux-x64.bin httpd]: Skipping because of failed dependenciesnotice: /Stage[2]/Hdp-monitor-webserver/Hdp::Package[httpd]/Hdp::Package::Process_pkg[httpd]/Hdp::Java::Package[httpd]/Exec[mkdir -p /usr/jdk ; chmod +x /tmp/HDP-artifacts//jdk-6u31-linux-x64.bin; cd /usr/jdk ; echo A | /tmp/HDP-artifacts//jdk-6u31-linux-x64.bin -noregister &gt; /dev/null 2&gt;&amp;1 httpd]: Dependency Exec[nagios] has failures: truewarning: /Stage[2]/Hdp-monitor-webserver/Hdp::Package[httpd]/Hdp::Package::Process_pkg[httpd]/Hdp::Java::Package[httpd]/Exec[mkdir -p /usr/jdk ; chmod +x /tmp/HDP-artifacts//jdk-6u31-linux-x64.bin; cd /usr/jdk ; echo A | /tmp/HDP-artifacts//jdk-6u31-linux-x64.bin -noregister &gt; /dev/null 2&gt;&amp;1 httpd]: Skipping because of failed dependenciesnotice: /Stage[2]/Hdp-monitor-webserver/Hdp::Package[httpd]/Hdp::Package::Process_pkg[httpd]/Hdp::Java::Package[httpd]/File[/usr/jdk/jdk1.6.0_31/bin/java httpd]: Dependency Exec[nagios] has failures: truewarning: /Stage[2]/Hdp-monitor-webserver/Hdp::Package[httpd]/Hdp::Package::Process_pkg[httpd]/Hdp::Java::Package[httpd]/File[/usr/jdk/jdk1.6.0_31/bin/java httpd]: Skipping because of failed dependenciesnotice: /Stage[2]/Hdp-monitor-webserver/Hdp::Package[httpd]/Hdp::Package::Process_pkg[httpd]/Hdp::Java::Package[httpd]/Anchor[hdp::java::package::httpd::end]: Dependency Exec[nagios] has failures: truewarning: /Stage[2]/Hdp-monitor-webserver/Hdp::Package[httpd]/Hdp::Package::Process_pkg[httpd]/Hdp::Java::Package[httpd]/Anchor[hdp::java::package::httpd::end]: Skipping because of failed dependenciesnotice: /Stage[2]/Hdp-monitor-webserver/Hdp::Package[httpd]/Hdp::Package::Process_pkg[httpd]/Anchor[hdp::package::httpd::end]: Dependency Exec[nagios] has failures: truewarning: /Stage[2]/Hdp-monitor-webserver/Hdp::Package[httpd]/Hdp::Package::Process_pkg[httpd]/Anchor[hdp::package::httpd::end]: Skipping because of failed dependenciesnotice: /Stage[2]/Hdp-monitor-webserver/Hdp::Exec[monitor webserver restart]/Anchor[hdp::exec::monitor webserver restart::begin]: Dependency Exec[nagios] has failures: truewarning: /Stage[2]/Hdp-monitor-webserver/Hdp::Exec[monitor webserver restart]/Anchor[hdp::exec::monitor webserver restart::begin]: Skipping because of failed dependenciesnotice: /Stage[2]/Hdp-monitor-webserver/Hdp::Exec[monitor webserver restart]/Exec[monitor webserver restart]: Dependency Exec[nagios] has failures: truewarning: /Stage[2]/Hdp-monitor-webserver/Hdp::Exec[monitor webserver restart]/Exec[monitor webserver restart]: Skipping because of failed dependenciesnotice: /Stage[2]/Hdp-monitor-webserver/Hdp::Exec[monitor webserver restart]/Anchor[hdp::exec::monitor webserver restart::end]: Dependency Exec[nagios] has failures: truewarning: /Stage[2]/Hdp-monitor-webserver/Hdp::Exec[monitor webserver restart]/Anchor[hdp::exec::monitor webserver restart::end]: Skipping because of failed dependencies3) Run checkconfig:[root@dev02 ~]# /usr/sbin/nagios -v /etc/nagios/nagios.cfg Nagios Core 3.5.0Copyright (c) 2009-2011 Nagios Core Development Team and Community ContributorsCopyright (c) 1999-2009 Ethan GalstadLast Modified: 03-15-2013License: GPLWebsite: http://www.nagios.orgReading configuration data... Read main config file okay...Processing object config file '/etc/nagios/objects/commands.cfg'...Processing object config file '/etc/nagios/objects/contacts.cfg'...Processing object config file '/etc/nagios/objects/timeperiods.cfg'...Processing object config file '/etc/nagios/objects/templates.cfg'...Processing object config file '/etc/nagios/objects/hadoop-hosts.cfg'...Processing object config file '/etc/nagios/objects/hadoop-hostgroups.cfg'...Processing object config file '/etc/nagios/objects/hadoop-servicegroups.cfg'...Processing object config file '/etc/nagios/objects/hadoop-services.cfg'...Processing object config file '/etc/nagios/objects/hadoop-commands.cfg'...Error: Could not find any servicegroup matching 'MAPREDUCE' (config file '/etc/nagios/objects/hadoop-services.cfg'  starting on line 67) Error processing object config files!***&gt; One or more problems was encountered while processing the config files... Check your configuration file(s) to ensure that they contain valid directives and data defintions. If you are upgrading from a previous version of Nagios  you should be aware that some variables/definitions may have been removed or modified in this version. Make sure to read the HTML documentation regarding the config files  as well as the 'Whats New' section to find out what has changed.[root@dev02 ~]# It seems we have invalid condition for generation of MAPREDUCE Nagios checks.,1.4.0,1.4.0,566,0,0,0,0,0,0,0,
2876,ambari-server,Sumit Mohanty,Puppet script syntax issues result in hive deployment with custom DB and oozie service check failures,Few puppet variables are missing in jdbc-connector and oozie service-check puppet scripts.,1.4.0,1.4.0,12,0,0,0,0,0,0,0,
2879,ambari-agent,Siddharth Wagle,Oozie failed at smoke test in secured cluster,stderr:None stdout:notice: /Stage[1]/Hdp::Snappy::Package/Hdp::Snappy::Package::Ln[32]/Hdp::Exec[hdp::snappy::package::ln 32]/Exec[hdp::snappy::package::ln 32]/returns: executed successfullynotice: /Stage[1]/Hdp::Snmp/Hdp::Package[snmp]/Hdp::Package::Process_pkg[snmp]/Hdp::Java::Package[snmp]/Hdp::Java::Jce::Package[snmp]/Exec[jce-install snmp]/returns: executed successfullynotice: /Stage[2]/Hdp-oozie::Oozie::Service_check/Hdp-oozie::Smoke_shell_file[oozieSmoke.sh]/Exec[/tmp/oozieSmoke.sh]/returns: Moved to trash: hdfs://domU-12-31-39-07-D5-91.compute-1.internal:8020/user/ambari-qa/examplesnotice: /Stage[2]/Hdp-oozie::Oozie::Service_check/Hdp-oozie::Smoke_shell_file[oozieSmoke.sh]/Exec[/tmp/oozieSmoke.sh]/returns: Moved to trash: hdfs://domU-12-31-39-07-D5-91.compute-1.internal:8020/user/ambari-qa/input-datanotice: /Stage[2]/Hdp-oozie::Oozie::Service_check/Hdp-oozie::Smoke_shell_file[oozieSmoke.sh]/Exec[/tmp/oozieSmoke.sh]/returns: Error: AUTHENTICATION : Could not authenticate  GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - UNKNOWN_SERVER)notice: /Stage[2]/Hdp-oozie::Oozie::Service_check/Hdp-oozie::Smoke_shell_file[oozieSmoke.sh]/Exec[/tmp/oozieSmoke.sh]/returns: Invalid sub-command: Missing argument for option: infonotice: /Stage[2]/Hdp-oozie::Oozie::Service_check/Hdp-oozie::Smoke_shell_file[oozieSmoke.sh]/Exec[/tmp/oozieSmoke.sh]/returns:notice: /Stage[2]/Hdp-oozie::Oozie::Service_check/Hdp-oozie::Smoke_shell_file[oozieSmoke.sh]/Exec[/tmp/oozieSmoke.sh]/returns: use 'help [sub-command]' for help detailsnotice: /Stage[2]/Hdp-oozie::Oozie::Service_check/Hdp-oozie::Smoke_shell_file[oozieSmoke.sh]/Exec[/tmp/oozieSmoke.sh]/returns: Invalid sub-command: Missing argument for option: infonotice: /Stage[2]/Hdp-oozie::Oozie::Service_check/Hdp-oozie::Smoke_shell_file[oozieSmoke.sh]/Exec[/tmp/oozieSmoke.sh]/returns:notice: /Stage[2]/Hdp-oozie::Oozie::Service_check/Hdp-oozie::Smoke_shell_file[oozieSmoke.sh]/Exec[/tmp/oozieSmoke.sh]/returns: use 'help [sub-command]' for help detailsnotice: /Stage[2]/Hdp-oozie::Oozie::Service_check/Hdp-oozie::Smoke_shell_file[oozieSmoke.sh]/Exec[/tmp/oozieSmoke.sh]/returns:notice: /Stage[2]/Hdp-oozie::Oozie::Service_check/Hdp-oozie::Smoke_shell_file[oozieSmoke.sh]/Exec[/tmp/oozieSmoke.sh]/returns: workflow_status=err: /Stage[2]/Hdp-oozie::Oozie::Service_check/Hdp-oozie::Smoke_shell_file[oozieSmoke.sh]/Exec[/tmp/oozieSmoke.sh]/returns: change from notrun to 0 failed: sh /tmp/oozieSmoke.sh /etc/oozie/conf /etc/hadoop/conf ambari-qa true /etc/security/keytabs/smokeuser.headless.keytab EXAMPLE.COM jt/domu-12-31-39-07-d5-91.compute-1.internal@EXAMPLE.COM nn/domu-12-31-39-07-d5-91.compute-1.internal@EXAMPLE.COM /usr/bin/kinit returned 1 instead of one of [0] at /var/lib/ambari-agent/puppet/modules/hdp-oozie/manifests/oozie/service_check.pp:63notice: Finished catalog run in 51.05 seconds,1.2.5,1.4.0,129,0,0,0,0,0,0,0,
2884,ambari-web,Andrii Tkach,Oozie start fails - likely due to 'failed install',Oozie start failed with following in the log: hadoop dfs -chmod -R 755 /user/oozie/share' returned 1 instead of one of 0On the node: chmod: '/user/oozie/share': No such file or directoryoozie@c6402 ~$ hadoop dfs -ls /user/ DEPRECATED: Use of this script to execute hdfs command is deprecated.Instead use the hdfs command for it.Found 3 itemsdrwxrwx--- - ambari-qa hdfs 0 2013-08-02 02:40 /user/ambari-qadrwx------ - hive hdfs 0 2013-08-02 02:41 /user/hivedrwxrwxr-x - hdfs hdfs 0 2013-08-02 02:42 /user/oozieoozie@c6402 ~$ hadoop dfs -ls /user/oozieDEPRECATED: Use of this script to execute hdfs command is deprecated.Instead use the hdfs command for it.oozie@c6402 ~$The reason  the oozie smoke is failing to run an oozie job with more than one node in the cluster  due to bad settings in /etc/hadoop/core-site.xml:&lt;property&gt; &lt;name&gt;hadoop.proxyuser.oozie.hosts&lt;/name&gt; &lt;value&gt;host1&lt;/value&gt;&lt;/property&gt;host1  in my case is host on which oozie is not installed. After changing this to host2 (where oozie server is installed)  oozie smoke succeeded.,1.4.0,1.4.0,148,0,0,0,0,0,0,1,ambari-web/app/controllers/wizard/step8_controller.js;
2886,ambari-agent,Siddharth Wagle,HDFS Service Check failed (as designed) but took 10 mins to fail,After I had a cluster up and running successfully  but manually turned HDFS Safe Mode ON by running:hdfs dfsadmin -safemode enter.HDFS Execute Check failed due to Puppet timeout after 10 minutes.It should have failed quicker since task timeout is 10 minutes on server.,1.4.0,1.4.0,43,0,0,0,0,1,0,0,
2891,ambari-server,Sumit Mohanty,hadoop-env.sh and core-site are missing on hosts that have only yarn components deployed,Yarn component need hadoop-env.sh and core-site.xml. These files should be deployed on hosts on which only yarn components are deployed.,1.4.0,1.4.0,20,0,0,0,0,0,0,0,
2903,,Mahadev konar,Add HBase 96 metrics changes to jmx in a backwards compatible way.,Add HBase 96 metrics changes to jmx in a backwards compatible way.,1.4.0,1.4.0,13,0,0,0,0,0,0,0,
2905,ambari-server,Siddharth Wagle,SNAMENODE should not start after transition to Maintenance mode,Currently  in HA NN cluster  starting HDFS service at services tab  tries to start SNAMENODE as well (through it is in Maintainance state because of executing curl -u admin:admin -i -X PUT -d '{'RequestInfo':{'context':'SNN maintenance'} 'Body':{'HostRoles':{'state':'MAINTENANCE'}}}' http://$SERVER:8080/api/v1/clusters/$CLUSTER/hosts/$SNN_HOST/host_components/SECONDARY_NAMENODE command ),1.4.0,1.4.0,53,0,0,0,0,0,0,0,
2920,ambari-web,Yusaku Sako,Rename alert titles and descriptions,Currently Nagios alerts are shown in Ambari UI like so: (green check) NameNode process down &lt;- means NameNode process is up (red X) NameNode process down &lt;- means NameNode process is down (green check) Percent DataNode down &lt;- means % of DataNodes that are up is above the threshold (red X) Percent DataNode down &lt;- means % of DataNodes that are up is below the threshold (green check) Nagios status log staleness &lt;- means Nagios status log is fresh (red X) Nagios status log staleness &lt;- means Nagios status log is staleWhen a user sees the word 'down' with a positive indication (green check) for it  it's confusing. It's like saying 'this is red' in green... is it green or red?The proposal here is to rename these alerts  like so: (green check) NameNode process &lt;- means NameNode process is up/healthy (red X) NameNode process &lt;- means NameNode process is down/unhealthy (green check) Percent DataNodes live &lt;- means % of DataNodes that are up/healthy is above the threshold (red X) Percent DataNodes live &lt;- means % of DataNodes that are up/healthy is below the threshold (green check) Nagios status log freshness &lt;- means Nagios status log is fresh (red X) Nagios status log freshness &lt;- means Nagios status log is staleAlso there are inconsistencies in the way we show component names in alert titles and descriptions (like 'templeton server status' to mean 'WebHCat Server status'  etc). These need to be fixed.,1.4.0,1.4.0,240,0,0,0,0,0,0,0,
2927,ambari-web,Srimanth Gunturi,ResourceManager's RPC and NodeManager counts missing from time-series,ResourceManager's rpc.rpc.RpcQueueTimeAvgTime and yarn.ClusterMetrics.NumActiveNMs are not being provided accurately due to changes introduced in AMBARI-2910 to YARN configuration to collect more metrics.We need to narrow down the scope of metric collection to keep getting these previous metrics.,1.4.0,1.4.0,49,0,0,0,0,0,0,0,
2931,ambari-web,Andrii Tkach,Popover stuck after routing to another page,Steps to reporduce:1. Go to Installer-&gt;Welcome step2. Focus on cluster name textfield3. Hover on 'learn more' label4. Press Enter to route to the next pageResult:Popover remains visible on other pages,1.4.0,1.4.0,30,0,0,0,0,0,0,0,
2938,ambari-server,Sumit Mohanty,Update stack definition for MAPREDUCE2,Update stack definition for MAPREDUCE2 and the default site xml files.,1.4.0,1.4.0,11,0,0,0,0,0,0,0,
2939,ambari-server,Sumit Mohanty,Update 1.3.2 stack definition for repo url,Update 1.3.2 stack definition for repo url,1.2.5,1.2.5,7,0,0,0,0,0,0,0,
2943,,Mahadev konar,Oozie smoke tests fail on Ambari with NPE in Oozie Server.,Oozie smoke tests fail on Ambari with NPE in Oozie Server.,1.4.0,1.4.0,11,0,0,0,0,0,0,0,
2947,,Mahadev konar,Use a specific build number for the stck builds.,Use a specific build number for the stck builds.,1.4.0,1.4.0,9,0,0,0,0,0,0,0,
2948,ambari-agent,Siddharth Wagle,Mapreduce pid directory cutomization fails,Changing mapreduce log directory prefix results in Live status showing history server not started.,1.4.0,1.4.0,14,0,0,0,0,0,0,0,
2972,ambari-web,Andrii Tkach,Provide read-only view of security wizard entries,After enabling security  when browsing back to Admin &gt; Security  it would be good to see the tabs with the values entered during wizard setup (read-only)  just so it's easy to see what the user specifically entered during the wizard setup.,1.2.5,1.4.1,41,0,0,0,0,0,0,6,ambari-web/app/controllers/main/admin/security.js;ambari-web/app/controllers/main/admin/security/add/step2.js;ambari-web/app/templates/common/configs/services_config.hbs;ambari-web/app/templates/main/admin/security.hbs;ambari-web/app/views/common/configs/services_config.js;ambari-web/app/views/main/admin/security.js;
2973,ambari-agent; ambari-server,Vladimir Tkhir,Ambari server and agent are not stopped during package uninstall,When ambari-agent and ambari-server packages are uninstalled  uninstall scriplets don't stop running services. That's why processes remain running even after package removal. That may cause issues during upgrade (if administrator misses the 'stop services' step)[root@host01 ~]$ ambari-server statusUsing python /usr/bin/python2.6Ambari-server statusAmbari Server runningFound Ambari Server PID: '7850 at: /var/run/ambari-server/ambari-server.pid[root@host01]# ambari-agent statusFound ambari-agent PID: 3521ambari-agent running.Agent PID at: /var/run/ambari-agent/ambari-agent.pidAgent out at: /var/log/ambari-agent/ambari-agent.outAgent log at: /var/log/ambari-agent/ambari-agent.log[root@host01]# rpm -e ambari-server[root@host01]# rpm -e ambari-agent[root@host01]# ps aux | grep ambari | grep -v grep | grep -v postgresroot 7850 2.1 13.2 3031480 254212 ? Sl 20:51 0:36 /usr/jdk64/jdk1.6.0_31/bin/java -server -XX:NewRatio=3 -XX:+UseConcMarkSweepGC -XX:-UseGCOverheadLimit -XX:CMSInitiatingOccupancyFraction=60 -Xms512m -Xmx2048m -cp /etc/ambari-server/conf:/usr/lib/ambari-server/*:/sbin:/bin:/usr/sbin:/usr/bin:/usr/lib/ambari-server/* org.apache.ambari.server.controller.AmbariServerroot 3521 0.7 1.1 499760 22544 ? Sl 20:53 0:12 /usr/bin/python2.6 /usr/lib/python2.6/site-packages/ambari_agent/main.py start restart --expected-hostname=host01,1.4.1,1.4.1,128,0,0,0,0,0,0,0,
2986,,Mahadev konar,Should turn on predicate pushdown by default.,Should turn on predicate pushdown by default.,1.4.0,1.4.0,7,0,0,0,0,0,0,0,
3009,ambari-web,Andrii Babiichuk,Trim and/or validate config parameter values to prevent failures due to extra spaces,Automatically trim whitespaces (both leading and trailing) for: Database Host in Oozie and Hive Database Name in Oozie and Hive Database URL in Oozie and Hive All directories  including log dir  pid dir data dir  etc (I believe we already trim  split  and join for the UI config type 'directories'. We should trim on the single-line directory values  if we are not doing so already).Automatically trim all trailing spaces (but not leading spaces) for all config values with the following exceptions: Password fields Values that consist of spaces only (such as ' '),1.4.0,1.4.1,92,1,0,0,0,0,0,0,
3019,ambari-server,Siddharth Wagle,Ambari should always point to latest repo,Ambari should always point to latest repo.,1.4.0,1.4.0,7,0,0,0,0,0,0,0,
3021,ambari-web,Jaimin D Jetly,Customize Services page->Misc tab: Popup with related properties does not opened after 'Group User' value changing,,1.4.0,1.4.0,1,0,0,0,0,0,0,2,ambari-server/src/main/resources/stacks/HDP/2.0.5/services/YARN/configuration/yarn-site.xml;ambari-server/src/main/resources/stacks/HDPLocal/2.0.5/services/YARN/configuration/yarn-site.xml;
3024,,Mahadev konar,Oozie oozie-site.xml misssing two xsd values causing shell and sla workflows to fail,Following two values need to be added to oozie-site.xml in order to get sla and shell workflows to run successfully.shell-action-0.2.xsdoozie-sla-0.1.xsd oozie-sla-0.2.xsdFollowing is the property name&lt;property&gt;&lt;name&gt;oozie.service.SchemaService.wf.ext.schemas&lt;/name&gt;&lt;value&gt;shell-action-0.1.xsd email-action-0.1.xsd hive-action-0.2.xsd sqoop-action-0.2.xsd ssh-action-0.1.xsd distcp-action-0.1.xsd&lt;/value&gt;&lt;/property&gt;,1.4.0,1.4.0,24,0,0,0,0,0,0,0,
3026,ambari-server,Siddharth Wagle,Ambari server setup with silent option prints error statement for the first time,command: ambari-server setup -sCompleting setup...Configuring database...Enter advanced database configuration [y/n] &#40;n&#41;? ERROR: Connection properties not set in config file.Default properties detected. Using built-in database.Checking PostgreSQL...Running initdb: This may take upto a minute.About to start PostgreSQLConfiguring local database...Configuring PostgreSQL...Restarting PostgreSQLAmbari Server 'setup' completed successfully.Running ambari-server setup command again doesn't reproduce the error statement.,1.4.0,1.4.0,53,1,0,0,0,0,0,0,
3047,ambari-server,Sumit Mohanty,Enhance host clean up to handle tmp files and folders,Host cleanup should: remove files and folders in tmp folder based on what users are being cleaned remove default hadoop group,1.4.1,1.4.1,21,1,0,0,0,0,0,0,
3056,ambari-web,Andrii Tkach,Advanced config orders should be consistent in Install Wizard > Customize Services and Monitoring > Services > Config,Compare the config parameter ordering in Install Wizard &gt; Customize Services service configs and Monitoring &gt; Services &gt; Config; they are different.We should use the same parameter ordering that we use in Install Wizard &gt; Customize Services for Monitoring &gt; Services &gt; Config.,1.2.3,1.4.1,43,1,0,0,0,0,0,3,ambari-web/app/controllers/main/service/info/configs.js;ambari-web/app/data/HDP2/global_properties.js;ambari-web/app/utils/config.js;
3061,ambari-agent,Dmytro Sen,Do not use regex to determine folder name by full path for dfs_domain_socket_path,The point is to use custom puppet function instead of regex for line$dfs_domain_socket_path_dir = regsubst($hdp-hadoop::params::dfs_domain_socket_path  '/[^//]+$'  '').It could be implemented with ruby:File.split('/path/to/file') # =&gt; ['/path/to'  'file'],1.4.1,1.4.1,42,1,0,0,0,0,0,0,
3068,ambari-agent,Artem Baranchuk,Warning messages not cleared when task fails,Installed a cluster  namenode start fails  install exits with warnings.If i go an look at the specific task that fails  the puppet warnings are still present. Seems like those puppet warnings didn't get cleared.In a task failure case  having the warnings clear is when it's most important.,1.4.0,1.4.1,47,1,0,0,0,0,0,0,
3069,ambari-web,Oleg Nechiporenko,Fix Unit tests,,1.4.1,1.4.1,1,1,0,0,0,0,0,0,
3073,ambari-web,subin,Amabri Client refactoring -2,1) The last patch had an issue with the testcase because of which it did not compile. I might have accidently added a line while I was saving some of the files.(this is fixed in the new patch)The trunk currently fails for ambari-client.https://cwiki.apache.org/confluence/display/AMBARI/Ambari+python+Client has all the exposed methods,1.3.0,1.4.1,51,1,0,0,0,0,0,0,
3074,ambari-agent,Siddharth Wagle,Ambari wont start NodeManager because one of multiple folders not created,yarn-site having:'yarn.nodemanager.local-dirs' : '/grid/0/hadoop/yarn /grid/1/hadoop/yarn /grid/2/hadoop/yarn /grid/3/hadoop/yarn /grid/4/hadoop/yarn /grid/5/hadoop/yarn' 'yarn.nodemanager.log-dirs' : '/grid/0/hadoop/yarn /grid/1/hadoop/yarn /grid/2/hadoop/yarn /grid/3/hadoop/yarn /grid/4/hadoop/yarn /grid/5/hadoop/yarn' Now /grid/3 was mounted as read-only due to some disk errors. Though other folders got successfully created  Ambari will not start the NodeManager process.notice: /Stage[1]/Hdp::Snappy::Package/Hdp::Snappy::Package::Ln[32]/Hdp::Exec[hdp::snappy::package::ln 32]/Exec[hdp::snappy::package::ln 32]/returns: executed successfullynotice: /Stage[2]/Hdp-yarn::Nodemanager/Hdp-yarn::Nodemanager::Create_nm_dirs[/grid/3/hadoop/yarn]/Hdp::Directory_recursive_create[/grid/3/hadoop/yarn]/Hdp::Exec[mkdir -p /grid/3/hadoop/yarn]/Exec[mkdir -p /grid/3/hadoop/yarn]/returns: mkdir: cannot create directory '/grid/3/hadoop': Read-only file systemerr: /Stage[2]/Hdp-yarn::Nodemanager/Hdp-yarn::Nodemanager::Create_nm_dirs[/grid/3/hadoop/yarn]/Hdp::Directory_recursive_create[/grid/3/hadoop/yarn]/Hdp::Exec[mkdir -p /grid/3/hadoop/yarn]/Exec[mkdir -p /grid/3/hadoop/yarn]/returns: change from notrun to 0 failed: mkdir -p /grid/3/hadoop/yarn returned 1 instead of one of [0] at /var/lib/ambari-agent/puppet/modules/hdp/manifests/init.pp:479notice: /Stage[2]/Hdp-yarn::Nodemanager/Hdp-yarn::Nodemanager::Create_nm_dirs[/grid/3/hadoop/yarn]/Hdp::Directory_recursive_create[/grid/3/hadoop/yarn]/Hdp::Exec[mkdir -p /grid/3/hadoop/yarn]/Anchor[hdp::exec::mkdir -p /grid/3/hadoop/yarn::end]: Dependency Exec[mkdir -p /grid/3/hadoop/yarn] has failures: truewarning: /Stage[2]/Hdp-yarn::Nodemanager/Hdp-yarn::Nodemanager::Create_nm_dirs[/grid/3/hadoop/yarn]/Hdp::Directory_recursive_create[/grid/3/hadoop/yarn]/Hdp::Exec[mkdir -p /grid/3/hadoop/yarn]/Anchor[hdp::exec::mkdir -p /grid/3/hadoop/yarn::end]: Skipping because of failed dependenciesnotice: /Stage[2]/Hdp-yarn::Nodemanager/Hdp-yarn::Nodemanager::Create_nm_dirs[/grid/3/hadoop/yarn]/Hdp::Directory_recursive_create[/grid/3/hadoop/yarn]/Hdp::Directory[/grid/3/hadoop/yarn]/File[/grid/3/hadoop/yarn]: Dependency Exec[mkdir -p /grid/3/hadoop/yarn] has failures: truewarning: /Stage[2]/Hdp-yarn::Nodemanager/Hdp-yarn::Nodemanager::Create_nm_dirs[/grid/3/hadoop/yarn]/Hdp::Directory_recursive_create[/grid/3/hadoop/yarn]/Hdp::Directory[/grid/3/hadoop/yarn]/File[/grid/3/hadoop/yarn]: Skipping because of failed dependenciesnotice: /Stage[2]/Hdp-yarn::Initialize/Hdp-yarn::Generate_common_configs[yarn-common-configs]/Configgenerator::Configfile[capacity-scheduler]/File[/etc/hadoop/conf/capacity-scheduler.xml]/content: content changed '{md5}e5d17c21c7a5e1db9f3af35cba71df0a' to '{md5}2ca1d267a46f1aecac726caabaa16774'notice: /Stage[2]/Hdp-yarn::Initialize/Hdp-yarn::Generate_common_configs[yarn-common-configs]/Configgenerator::Configfile[capacity-scheduler]/File[/etc/hadoop/conf/capacity-scheduler.xml]/owner: owner changed 'hdfs' to 'yarn'notice: /Stage[2]/Hdp-yarn::Initialize/Hdp-yarn::Generate_common_configs[yarn-common-configs]/Configgenerator::Configfile[core-site]/File[/etc/hadoop/conf/core-site.xml]/content: content changed '{md5}86d742a780d59a957ea0a283dec03784' to '{md5}8506e4402ba8140ea4f9fed97b6f94e2'notice: /Stage[2]/Hdp-yarn::Initialize/Hdp-yarn::Generate_common_configs[yarn-common-configs]/Configgenerator::Configfile[yarn-site]/File[/etc/hadoop/conf/yarn-site.xml]/content: content changed '{md5}d84a967ce47a6b77734ed8f53d817c6e' to '{md5}42940cca6e8f64ae5de50524fb131274'notice: /Stage[2]/Hdp-yarn::Nodemanager/Hdp-yarn::Service[nodemanager]/Anchor[hdp-yarn::service::nodemanager::begin]: Dependency Exec[mkdir -p /grid/3/hadoop/yarn] has failures: truewarning: /Stage[2]/Hdp-yarn::Nodemanager/Hdp-yarn::Service[nodemanager]/Anchor[hdp-yarn::service::nodemanager::begin]: Skipping because of failed dependenciesnotice: /Stage[2]/Hdp-yarn::Nodemanager/Hdp-yarn::Service[nodemanager]/Hdp::Directory_recursive_create[/var/log/hadoop-yarn]/Hdp::Exec[mkdir -p /var/log/hadoop-yarn]/Anchor[hdp::exec::mkdir -p /var/log/hadoop-yarn::begin]: Dependency Exec[mkdir -p /grid/3/hadoop/yarn] has failures: truewarning: /Stage[2]/Hdp-yarn::Nodemanager/Hdp-yarn::Service[nodemanager]/Hdp::Directory_recursive_create[/var/log/hadoop-yarn]/Hdp::Exec[mkdir -p /var/log/hadoop-yarn]/Anchor[hdp::exec::mkdir -p /var/log/hadoop-yarn::begin]: Skipping because of failed dependenciesnotice: /Stage[2]/Hdp-yarn::Nodemanager/Hdp-yarn::Service[nodemanager]/Hdp::Directory_recursive_create[/var/log/hadoop-yarn]/Hdp::Exec[mkdir -p /var/log/hadoop-yarn]/Exec[mkdir -p /var/log/hadoop-yarn]: Dependency Exec[mkdir -p /grid/3/hadoop/yarn] has failures: truewarning: /Stage[2]/Hdp-yarn::Nodemanager/Hdp-yarn::Service[nodemanager]/Hdp::Directory_recursive_create[/var/log/hadoop-yarn]/Hdp::Exec[mkdir -p /var/log/hadoop-yarn]/Exec[mkdir -p /var/log/hadoop-yarn]: Skipping because of failed dependenciesnotice: /Stage[2]/Hdp-yarn::Nodemanager/Hdp-yarn::Service[nodemanager]/Hdp::Directory_recursive_create[/var/log/hadoop-yarn]/Hdp::Exec[mkdir -p /var/log/hadoop-yarn]/Anchor[hdp::exec::mkdir -p /var/log/hadoop-yarn::end]: Dependency Exec[mkdir -p /grid/3/hadoop/yarn] has failures: truewarning: /Stage[2]/Hdp-yarn::Nodemanager/Hdp-yarn::Service[nodemanager]/Hdp::Directory_recursive_create[/var/log/hadoop-yarn]/Hdp::Exec[mkdir -p /var/log/hadoop-yarn]/Anchor[hdp::exec::mkdir -p /var/log/hadoop-yarn::end]: Skipping because of failed dependenciesnotice: /Stage[2]/Hdp-yarn::Nodemanager/Hdp-yarn::Service[nodemanager]/Hdp::Directory_recursive_create[/var/log/hadoop-yarn]/Hdp::Directory[/var/log/hadoop-yarn]/File[/var/log/hadoop-yarn]: Dependency Exec[mkdir -p /grid/3/hadoop/yarn] has failures: truewarning: /Stage[2]/Hdp-yarn::Nodemanager/Hdp-yarn::Service[nodemanager]/Hdp::Directory_recursive_create[/var/log/hadoop-yarn]/Hdp::Directory[/var/log/hadoop-yarn]/File[/var/log/hadoop-yarn]: Skipping because of failed dependenciesnotice: /Stage[2]/Hdp-yarn::Nodemanager/Hdp-yarn::Service[nodemanager]/Hdp::Directory_recursive_create[/var/run/hadoop-yarn/yarn]/Hdp::Exec[mkdir -p /var/run/hadoop-yarn/yarn]/Anchor[hdp::exec::mkdir -p /var/run/hadoop-yarn/yarn::begin]: Dependency Exec[mkdir -p /grid/3/hadoop/yarn] has failures: truewarning: /Stage[2]/Hdp-yarn::Nodemanager/Hdp-yarn::Service[nodemanager]/Hdp::Directory_recursive_create[/var/run/hadoop-yarn/yarn]/Hdp::Exec[mkdir -p /var/run/hadoop-yarn/yarn]/Anchor[hdp::exec::mkdir -p /var/run/hadoop-yarn/yarn::begin]: Skipping because of failed dependenciesnotice: /Stage[2]/Hdp-yarn::Nodemanager/Hdp-yarn::Service[nodemanager]/Hdp::Directory_recursive_create[/var/run/hadoop-yarn/yarn]/Hdp::Exec[mkdir -p /var/run/hadoop-yarn/yarn]/Exec[mkdir -p /var/run/hadoop-yarn/yarn]: Dependency Exec[mkdir -p /grid/3/hadoop/yarn] has failures: truewarning: /Stage[2]/Hdp-yarn::Nodemanager/Hdp-yarn::Service[nodemanager]/Hdp::Directory_recursive_create[/var/run/hadoop-yarn/yarn]/Hdp::Exec[mkdir -p /var/run/hadoop-yarn/yarn]/Exec[mkdir -p /var/run/hadoop-yarn/yarn]: Skipping because of failed dependenciesnotice: /Stage[2]/Hdp-yarn::Nodemanager/Hdp-yarn::Service[nodemanager]/Hdp::Directory_recursive_create[/var/run/hadoop-yarn/yarn]/Hdp::Exec[mkdir -p /var/run/hadoop-yarn/yarn]/Anchor[hdp::exec::mkdir -p /var/run/hadoop-yarn/yarn::end]: Dependency Exec[mkdir -p /grid/3/hadoop/yarn] has failures: truewarning: /Stage[2]/Hdp-yarn::Nodemanager/Hdp-yarn::Service[nodemanager]/Hdp::Directory_recursive_create[/var/run/hadoop-yarn/yarn]/Hdp::Exec[mkdir -p /var/run/hadoop-yarn/yarn]/Anchor[hdp::exec::mkdir -p /var/run/hadoop-yarn/yarn::end]: Skipping because of failed dependenciesnotice: /Stage[2]/Hdp-yarn::Nodemanager/Hdp-yarn::Service[nodemanager]/Hdp::Directory_recursive_create[/var/run/hadoop-yarn/yarn]/Hdp::Directory[/var/run/hadoop-yarn/yarn]/File[/var/run/hadoop-yarn/yarn]: Dependency Exec[mkdir -p /grid/3/hadoop/yarn] has failures: truewarning: /Stage[2]/Hdp-yarn::Nodemanager/Hdp-yarn::Service[nodemanager]/Hdp::Directory_recursive_create[/var/run/hadoop-yarn/yarn]/Hdp::Directory[/var/run/hadoop-yarn/yarn]/File[/var/run/hadoop-yarn/yarn]: Skipping because of failed dependenciesnotice: /Stage[2]/Hdp-yarn::Nodemanager/Hdp-yarn::Service[nodemanager]/Hdp::Exec[su - yarn -c 'export HADOOP_LIBEXEC_DIR=/usr/lib/hadoop/libexec &amp;&amp; /usr/lib/hadoop-yarn/sbin/yarn-daemon.sh --config /etc/hadoop/conf start nodemanager']/Anchor[hdp::exec::su - yarn -c 'export HADOOP_LIBEXEC_DIR=/usr/lib/hadoop/libexec &amp;&amp; /usr/lib/hadoop-yarn/sbin/yarn-daemon.sh --config /etc/hadoop/conf start nodemanager'::begin]: Dependency Exec[mkdir -p /grid/3/hadoop/yarn] has failures: truewarning: /Stage[2]/Hdp-yarn::Nodemanager/Hdp-yarn::Service[nodemanager]/Hdp::Exec[su - yarn -c 'export HADOOP_LIBEXEC_DIR=/usr/lib/hadoop/libexec &amp;&amp; /usr/lib/hadoop-yarn/sbin/yarn-daemon.sh --config /etc/hadoop/conf start nodemanager']/Anchor[hdp::exec::su - yarn -c 'export HADOOP_LIBEXEC_DIR=/usr/lib/hadoop/libexec &amp;&amp; /usr/lib/hadoop-yarn/sbin/yarn-daemon.sh --config /etc/hadoop/conf start nodemanager'::begin]: Skipping because of failed dependenciesnotice: /Stage[2]/Hdp-yarn::Nodemanager/Hdp-yarn::Service[nodemanager]/Hdp::Exec[su - yarn -c 'export HADOOP_LIBEXEC_DIR=/usr/lib/hadoop/libexec &amp;&amp; /usr/lib/hadoop-yarn/sbin/yarn-daemon.sh --config /etc/hadoop/conf start nodemanager']/Exec[su - yarn -c 'export HADOOP_LIBEXEC_DIR=/usr/lib/hadoop/libexec &amp;&amp; /usr/lib/hadoop-yarn/sbin/yarn-daemon.sh --config /etc/hadoop/conf start nodemanager']: Dependency Exec[mkdir -p /grid/3/hadoop/yarn] has failures: truewarning: /Stage[2]/Hdp-yarn::Nodemanager/Hdp-yarn::Service[nodemanager]/Hdp::Exec[su - yarn -c 'export HADOOP_LIBEXEC_DIR=/usr/lib/hadoop/libexec &amp;&amp; /usr/lib/hadoop-yarn/sbin/yarn-daemon.sh --config /etc/hadoop/conf start nodemanager']/Exec[su - yarn -c 'export HADOOP_LIBEXEC_DIR=/usr/lib/hadoop/libexec &amp;&amp; /usr/lib/hadoop-yarn/sbin/yarn-daemon.sh --config /etc/hadoop/conf start nodemanager']: Skipping because of failed dependenciesnotice: /Stage[2]/Hdp-yarn::Nodemanager/Hdp-yarn::Service[nodemanager]/Hdp::Exec[su - yarn -c 'export HADOOP_LIBEXEC_DIR=/usr/lib/hadoop/libexec &amp;&amp; /usr/lib/hadoop-yarn/sbin/yarn-daemon.sh --config /etc/hadoop/conf start nodemanager']/Anchor[hdp::exec::su - yarn -c 'export HADOOP_LIBEXEC_DIR=/usr/lib/hadoop/libexec &amp;&amp; /usr/lib/hadoop-yarn/sbin/yarn-daemon.sh --config /etc/hadoop/conf start nodemanager'::end]: Dependency Exec[mkdir -p /grid/3/hadoop/yarn] has failures: truewarning: /Stage[2]/Hdp-yarn::Nodemanager/Hdp-yarn::Service[nodemanager]/Hdp::Exec[su - yarn -c 'export HADOOP_LIBEXEC_DIR=/usr/lib/hadoop/libexec &amp;&amp; /usr/lib/hadoop-yarn/sbin/yarn-daemon.sh --config /etc/hadoop/conf start nodemanager']/Anchor[hdp::exec::su - yarn -c 'export HADOOP_LIBEXEC_DIR=/usr/lib/hadoop/libexec &amp;&amp; /usr/lib/hadoop-yarn/sbin/yarn-daemon.sh --config /etc/hadoop/conf start nodemanager'::end]: Skipping because of failed dependenciesnotice: /Stage[2]/Hdp-yarn::Nodemanager/Hdp-yarn::Service[nodemanager]/Hdp::Exec[sleep 5; ls /var/run/hadoop-yarn/yarn/yarn-yarn-nodemanager.pid &gt;/dev/null 2&gt;&amp;1 &amp;&amp; ps 'cat /var/run/hadoop-yarn/yarn/yarn-yarn-nodemanager.pid' &gt;/dev/null 2&gt;&amp;1]/Anchor[hdp::exec::sleep 5; ls /var/run/hadoop-yarn/yarn/yarn-yarn-nodemanager.pid &gt;/dev/null 2&gt;&amp;1 &amp;&amp; ps 'cat /var/run/hadoop-yarn/yarn/yarn-yarn-nodemanager.pid' &gt;/dev/null 2&gt;&amp;1::begin]: Dependency Exec[mkdir -p /grid/3/hadoop/yarn] has failures: truewarning: /Stage[2]/Hdp-yarn::Nodemanager/Hdp-yarn::Service[nodemanager]/Hdp::Exec[sleep 5; ls /var/run/hadoop-yarn/yarn/yarn-yarn-nodemanager.pid &gt;/dev/null 2&gt;&amp;1 &amp;&amp; ps 'cat /var/run/hadoop-yarn/yarn/yarn-yarn-nodemanager.pid' &gt;/dev/null 2&gt;&amp;1]/Anchor[hdp::exec::sleep 5; ls /var/run/hadoop-yarn/yarn/yarn-yarn-nodemanager.pid &gt;/dev/null 2&gt;&amp;1 &amp;&amp; ps 'cat /var/run/hadoop-yarn/yarn/yarn-yarn-nodemanager.pid' &gt;/dev/null 2&gt;&amp;1::begin]: Skipping because of failed dependenciesnotice: /Stage[2]/Hdp-yarn::Nodemanager/Hdp-yarn::Service[nodemanager]/Hdp::Exec[sleep 5; ls /var/run/hadoop-yarn/yarn/yarn-yarn-nodemanager.pid &gt;/dev/null 2&gt;&amp;1 &amp;&amp; ps 'cat /var/run/hadoop-yarn/yarn/yarn-yarn-nodemanager.pid' &gt;/dev/null 2&gt;&amp;1]/Exec[sleep 5; ls /var/run/hadoop-yarn/yarn/yarn-yarn-nodemanager.pid &gt;/dev/null 2&gt;&amp;1 &amp;&amp; ps 'cat /var/run/hadoop-yarn/yarn/yarn-yarn-nodemanager.pid' &gt;/dev/null 2&gt;&amp;1]: Dependency Exec[mkdir -p /grid/3/hadoop/yarn] has failures: truewarning: /Stage[2]/Hdp-yarn::Nodemanager/Hdp-yarn::Service[nodemanager]/Hdp::Exec[sleep 5; ls /var/run/hadoop-yarn/yarn/yarn-yarn-nodemanager.pid &gt;/dev/null 2&gt;&amp;1 &amp;&amp; ps 'cat /var/run/hadoop-yarn/yarn/yarn-yarn-nodemanager.pid' &gt;/dev/null 2&gt;&amp;1]/Exec[sleep 5; ls /var/run/hadoop-yarn/yarn/yarn-yarn-nodemanager.pid &gt;/dev/null 2&gt;&amp;1 &amp;&amp; ps 'cat /var/run/hadoop-yarn/yarn/yarn-yarn-nodemanager.pid' &gt;/dev/null 2&gt;&amp;1]: Skipping because of failed dependenciesnotice: /Stage[2]/Hdp-yarn::Nodemanager/Hdp-yarn::Service[nodemanager]/Hdp::Exec[sleep 5; ls /var/run/hadoop-yarn/yarn/yarn-yarn-nodemanager.pid &gt;/dev/null 2&gt;&amp;1 &amp;&amp; ps 'cat /var/run/hadoop-yarn/yarn/yarn-yarn-nodemanager.pid' &gt;/dev/null 2&gt;&amp;1]/Anchor[hdp::exec::sleep 5; ls /var/run/hadoop-yarn/yarn/yarn-yarn-nodemanager.pid &gt;/dev/null 2&gt;&amp;1 &amp;&amp; ps 'cat /var/run/hadoop-yarn/yarn/yarn-yarn-nodemanager.pid' &gt;/dev/null 2&gt;&amp;1::end]: Dependency Exec[mkdir -p /grid/3/hadoop/yarn] has failures: truewarning: /Stage[2]/Hdp-yarn::Nodemanager/Hdp-yarn::Service[nodemanager]/Hdp::Exec[sleep 5; ls /var/run/hadoop-yarn/yarn/yarn-yarn-nodemanager.pid &gt;/dev/null 2&gt;&amp;1 &amp;&amp; ps 'cat /var/run/hadoop-yarn/yarn/yarn-yarn-nodemanager.pid' &gt;/dev/null 2&gt;&amp;1]/Anchor[hdp::exec::sleep 5; ls /var/run/hadoop-yarn/yarn/yarn-yarn-nodemanager.pid &gt;/dev/null 2&gt;&amp;1 &amp;&amp; ps 'cat /var/run/hadoop-yarn/yarn/yarn-yarn-nodemanager.pid' &gt;/dev/null 2&gt;&amp;1::end]: Skipping because of failed dependenciesnotice: /Stage[2]/Hdp-yarn::Nodemanager/Hdp-yarn::Service[nodemanager]/Anchor[hdp-yarn::service::nodemanager::end]: Dependency Exec[mkdir -p /grid/3/hadoop/yarn] has failures: truewarning: /Stage[2]/Hdp-yarn::Nodemanager/Hdp-yarn::Service[nodemanager]/Anchor[hdp-yarn::service::nodemanager::end]: Skipping because of failed dependenciesnotice: /Stage[2]/Hdp-yarn::Nodemanager/Anchor[hdp-yarn::nodemanager::end]: Dependency Exec[mkdir -p /grid/3/hadoop/yarn] has failures: truewarning: /Stage[2]/Hdp-yarn::Nodemanager/Anchor[hdp-yarn::nodemanager::end]: Skipping because of failed dependenciesnotice: /Stage[2]/Hdp-yarn::Initialize/Hdp-yarn::Generate_common_configs[yarn-common-configs]/Configgenerator::Configfile[mapred-site]/File[/etc/hadoop/conf/mapred-site.xml]/content: content changed '{md5}093cb1899b3c3b9dc4a7c1c93729c18b' to '{md5}4c462999cc47e6f6ba0e6381d71d81ba'notice: /Stage[2]/Hdp-yarn::Initialize/Hdp-yarn::Generate_common_configs[yarn-common-configs]/Configgenerator::Configfile[mapred-site]/File[/etc/hadoop/conf/mapred-site.xml]/owner: owner changed 'mapred' to 'yarn'notice: Finished catalog run in 2.39 seconds,1.4.0,1.4.1,710,1,0,0,0,0,0,0,
3076,,Billie Rinaldi,Jobs run date and duration not sorting correctly,Input and output bytes columns have been removed from the UI  but the web service doesn't know about that yet so it doesn't map the column index to a sort field correctly.,1.4.0,1.4.1,32,1,0,0,0,0,0,0,
3077,,Billie Rinaldi,Jobs summary has 'oldest' and 'youngest' run dates swapped,The web service is labeling these incorrectly when they are retrieved from the db.,1.4.0,1.4.1,14,1,0,0,0,0,0,0,
3093,ambari-web,Andrii Tkach,Incorrect units of measure for 'HBase Master Heap' widget on Dashboard,'HBase Master Heap' widget on Dashboard displays parameters in TB (param1.png)  but real values are in MB (param0.png).,1.4.1,1.4.1,18,0,0,0,0,0,0,2,ambari-web/app/views/main/dashboard/widgets/hbase_master_heap.js;ambari-web/app/views/main/dashboard/widgets/namenode_heap.js;
3095,ambari-web,Andrii Tkach,Incorrect color of rack indicators on 'Heatmaps' page,Precondition: hadoop is installed. Total disk space for both machines is 100 GB. Used disk space is about 5-15%.Steps: Go to 'Heatmaps' page. Select 'Host Disk Space Used %' metric ('Maximum' input field has '100' value). Both indicators has green color (disk space usage is in 0-20% category). Choose 'Maximum' input field value to '99'.Result:One indicator has red color (79.2% - 99% category)  but real disk space usage is 8.3% and indicator should be green.,1.4.1,1.4.1,75,0,0,0,0,0,0,1,ambari-web/app/controllers/main/charts/heatmap_metrics/heatmap_metric.js;
3099,ambari-server,Siddharth Wagle,Cannot change JMX ports using Ambari configuration API,Ambari 1.2.5  attached the configs to the cluster  in order to provide ability for override behavior at the service and host component levels.The JMX ports read from the service configs can no longer be modified from their default values since the existing code reads the service configurations which do not exist.,1.4.0,1.4.1,51,1,0,0,0,0,0,0,
3105,ambari-web,Xi Wang,Random change of blocks for Summary and Alerts and health checks on some Service pages,The height of blocks 'Alerts and health checks' is changed sometimes after Service page refresh.It can change to normal sizes after another tries.Produced only in Firefox.,1.4.0,1.4.1,26,0,0,0,0,0,0,0,
3112,ambari-agent,Jaimin D Jetly,Security wizard: disabling security does not return to initial condition after enabling security fails.,Steps to reproduce:1. enable security WITHOUT pre-configuring kerberos on cluster and see failures on '3. Start Services';2. disable security.In the end DataNode fails on ALL hosts without a possibility to get started.When you try to start DataNode manually it also ends with error:err: /Stage[2]/Hdp-hadoop::Datanode/Hdp-hadoop::Service[datanode]/Hdp::Exec[su - hdfs -c 'export HADOOP_LIBEXEC_DIR=/usr/lib/hadoop/libexec &amp;&amp; /usr/lib/hadoop/sbin/hadoop-daemon.sh --config /etc/hadoop/conf start datanode']/Exec[su - hdfs -c 'export HADOOP_LIBEXEC_DIR=/usr/lib/hadoop/libexec &amp;&amp; /usr/lib/hadoop/sbin/hadoop-daemon.sh --config /etc/hadoop/conf start datanode']/returns: change from notrun to 0 failed: su - hdfs -c 'export HADOOP_LIBEXEC_DIR=/usr/lib/hadoop/libexec &amp;&amp; /usr/lib/hadoop/sbin/hadoop-daemon.sh --config /etc/hadoop/conf start datanode' returned 1 instead of one of [0] at /var/lib/ambari-agent/puppet/modules/hdp/manifests/init.pp:479,1.4.1,1.4.1,101,0,0,0,1,0,0,1,ambari-agent/src/main/puppet/modules/hdp-hadoop/manifests/service.pp;
3115,ambari-web,Srimanth Gunturi,HBase Read/Write request metrics seem to have changed for 2.x stack,See the screenshot for HBase Cumulative Requests graph.The graph does not seem like it's displaying cumulative read/write requests  but rather showing the rate... so the label no longer makes sense.This is on the 2.0.5 stack. On the 1.x  I believe this graph would show cumulative read/write requests (which were less useful).So for 2.x stack  we should probably change the label for this graph to say Reads/Writes per Second (or whatever we are showing - need to confirm).,1.4.0,1.4.1,77,1,0,0,0,0,0,0,
3119,ambari-server,Siddharth Wagle,NullPointerException thrown while retrieving ganglia properties,API Call:curl -u admin:admin http://localhost:8080/api/v1/clusters/c1/services?fields=components/ServiceComponentInfo components/host_components components/host_components/HostRoles components/host_components/metrics/jvm/memHeapUsedM components/host_components/metrics/jvm/memHeapCommittedM components/host_components/metrics/mapred/jobtracker/trackers_decommissioned components/host_components/metrics/cpu/cpu_wio components/host_components/metrics/rpc/RpcQueueTime_avg_time components/host_components/metrics/flume/flume components/host_components/metrics/yarn/QueueAmbari log:20:54:57 044 WARN [qtp912472968-20] ServletHandler:514 - /api/v1/clusters/c1/servicesjava.lang.NullPointerException at org.apache.ambari.server.controller.ganglia.GangliaPropertyProvider.getRRDRequests(GangliaPropertyProvider.java:225) at org.apache.ambari.server.controller.ganglia.GangliaPropertyProvider.populateResources(GangliaPropertyProvider.java:110) at org.apache.ambari.server.controller.internal.VersioningPropertyProvider.populateResources(VersioningPropertyProvider.java:98),1.4.1,1.4.1,25,0,0,0,0,0,0,0,
3124,ambari-web,Oleg Nechiporenko,Incorrect behavior after entering wrong current password while editing user;,1. Go to Admin page -&gt; Users tab2. Click Edit for some user3. Try to enter wrong value for Current Password field.The message does not tell me that my entered current password is wrong  so it can be confusing for user.Another scenario:1. Go to Admin page -&gt; Users tab2. Click Edit for some user3. Try to enter wrong value for Current Password field and don't fill fields for a new passwordIt don't really change the password but it still allows to enter wrong Current Password without any message,1.4.1,1.4.1,88,1,0,0,0,0,0,0,
3135,ambari-server,Myroslav Papirkovskyy,Out of memory issues with Request API on large cluster,Number of ExecutionCommandEntity objects keep growing and result in Out of memory on large cluster (100 nodes).Script to re-create the issue:&#91;root@domain user&#93;# cat test1.shfor i in{0..100}doecho 'doing $i'curl -u admin:admin 'http://domain.net:8080/api/v1/clusters/c1/requests?to=end&amp;page_size=10&amp;fields= tasks/Tasks/*' &gt; /dev/nullsleep 5done,1.4.0,1.4.1,35,1,0,0,0,1,0,0,
3136,ambari-server,Myroslav Papirkovskyy,Reduce the size of ExecutionCommand entity,Currently  each ExecutionCommandEntity stores the whole config blob. This is a severe duplication of data as tagged configuration information is already available as immutable entry.We need to reduce the footprint of ExecutionCommandEntity by storing only configuration tags. The tags can be replaced with actual configuration value when the command is handed off to the agent.We need to ensure that when Ambari is upgraded and there is a mix of ExecutionCommandEntity instances with and without embedded config - it works.,1.4.0,1.4.2,79,1,0,0,0,0,0,0,
3145,ambari-agent,Vitaly Brodetskyi,ambari-agent service script should return non-zero when the agent is not running,The ambari-agent service script should return non-zero when the agent is not running. For example  if a customer wants to have puppet ensure the service is always running  it will not start a killed service because it thinks it's already running when it returns 0.&#91;root@host-123-123-123 init.d&#93;# service ambari-agent statusambari-agent currently not runningUsage: /usr/sbin/ambari-agent {start|stop|restart|status}&#91;root@host-123-123-123 init.d&#93;# echo $?0For comparison...&#91;root@host-123-123-123 init.d&#93;# service winbind statuswinbindd is stopped&#91;root@host-123-123-123 init.d&#93;# echo $?3Possible fix:AMBARI_AGENT_PID_PATH='/var/run/ambari-agent/ambari-agent.pid';RES='3';if [ -f $AMBARI_AGENT_PID_PATH ]then RES='cat $AMBARI_AGENT_PID_PATH | xargs ps -f -p | wc -l'; AMBARI_AGENT_PID='cat $AMBARI_AGENT_PID_PATH';else RES=-1;fiif [ $RES -eq '2' ]then echo 'OK: Ambari agent is running &#91;PID:$AMBARI_AGENT_PID&#93;'; exit 0;else echo 'CRITICAL: Ambari agent is not running &#91;$AMBARI_AGENT_PID_PATH not found&#93;'; exit 2;fi,1.2.5,1.4.1,117,1,0,0,0,0,0,0,
3147,ambari-server,Sumit Mohanty,Modify ganglia config to match the data resolution of the older version,New ganglia version retains almost 50 times more data for higher resolution metrics collection. Ambari needs to modify the configuration to match the older resolution as the new default config has a very high disk space requirement.Looks like the default config for ganglia changed fromRRAs 'RRA:AVERAGE:0.5:1:244' 'RRA:AVERAGE:0.5:24:244' 'RRA:AVERAGE:0.5:168:244' 'RRA:AVERAGE:0.5:672:244' 'RRA:AVERAGE:0.5:5760:374'toRRAs 'RRA:AVERAGE:0.5:1:5856' 'RRA:AVERAGE:0.5:4:20160' 'RRA:AVERAGE:0.5:40:52704'Its an increase from 1350 data points to 78720. After reverting to older configuration the file size for a single metrics and its summary info are-rw-rw-rw- 1 nobody nobody 12224 Sep 7 18:29 ./HDPNameNode/c6402.ambari.apache.org/disk_free.rrd-rw-rw-rw- 1 nobody nobody 23656 Sep 7 18:29 ./HDPNameNode/__SummaryInfo__/disk_free.rrdIn contrast it was-rw-r--r-- 1 root root 630768 Sep 7 17:48 /tmp/rrds/HDPNameNode/c6402.ambari.apache.org/disk_free.rrd-rw-r--r-- 1 root root 1261000 Sep 7 17:47 /tmp/rrds/HDPNameNode/__SummaryInfo__/disk_free.rrdThe recommendation is to revert back to the old config (i.e. do not use the new default config). Confirming that with an older installation of Ambari.,1.4.0,1.4.1,150,1,0,0,0,0,0,0,
3148,ambari-agent,Vitaly Brodetskyi,Oozie install fails with 'could not connect to database' when choosing 'use existing mysql database ' and choosing 'new mysql database' for Hive within Ambari,PROBLEM: When installing with Ambari and selecting an existing MySQL database for oozie and a new MySQL database for Hive  then the Ambariinstall fails when installing the oozie database. The error thrown is 'could not connect to database' [it appears to drop the 'existing' databaseand you are required to start MySQL on the machine and create the database]BUSINESS IMPACT: This will affect all customers who choose an existing MySQL database for oozie and a new MySQL DB for hive when installing a cluster using AmbariSTEPS TO REPRODUCE: Choose an exisiting oozie MySQL database and point Ambari at this  and select a new Hive MySQL database on the installation optionsACTUAL BEHAVIOR: It seems that it drops the exisiting oozie database and then fails with an errot of could not connect (This is due to MySQL being down  but also the Oozie database is not there anymore)After starting MySQL and creating the database then the installer can continue from where it left off.EXPECTED BEHAVIOR: The installer should not stop MySQL and drop the oozie database if you select create a new Hive database and exisiting MySQL database for oozie.SUPPORT ANALYSIS: Reproduced in the lab in HDP 1.3.2 by following the steps above.,1.2.4,1.4.1,200,0,0,0,0,0,0,0,
3151,ambari-server,Sumit Mohanty,ambari-server command output should point to Apache Ambari documentation,ambari-server command outputs should point to a generic link for current ambari documentation.,1.4.1,1.4.1,13,1,0,0,0,0,0,0,
3153,ambari-agent,Jaimin D Jetly,Secure cluster: Yarn service check fails after configuring yarn for spnego authentication.,Yarn smoke test uses REST api exposed by ResourceManager to get its status. After configuring web authentication yarn client that is assigned yarn service check needs to negotiate 401 HTTP authentication response received while using REST api.,1.4.1,1.4.1,37,1,0,0,0,0,0,1,ambari-agent/src/main/puppet/modules/hdp-yarn/files/validateYarnComponentStatus.py;
3154,ambari-web,Oleg Nechiporenko,ZKFailoverController should be shown as a component that can be started/stopped in Host Details page,,1.4.1,1.4.1,1,0,0,0,0,0,0,0,
3160,ambari-agent,Vitaly Brodetskyi,WebHCat alert does not nave any description,Steps to reproduce1. Go to Services page2. click on different services. They all have a status and a message for status in 'Alerts and Health Checks' list (as example hive.png)3. WebHCat service has a status but does not have a status message,1.4.1,1.4.1,42,0,0,0,0,0,0,0,
3191,ambari-server,Sumit Mohanty,Cannot delete a stopped host_component in INSTALLED state,I have a host with 4 stopped host_components. When I issue a DELETE on say http://c6401:8080/api/v1/clusters/vmc/hosts/c6404.ambari.apache.org/host_components/DATANODEThe response is:{ 'status' : 500  'message' : 'org.apache.ambari.server.controller.spi.SystemException: An internal system exception occurred: To remove master or slave components they must be in MAINTENANCE/INIT/INSTALL_FAILED/UNKNOWN state. Current=INSTALLED.'},1.4.1,1.4.1,54,1,0,0,0,0,0,0,
3198,ambari-server,Dmytro Sen,ambari-server reset is broken on centos5.8,ambari-server reset fails due to syntax error in centos 5.8 (postgres 8.1).psql:/var/lib/ambari-server/resources/Ambari-DDL-Postgres-DROP.sql:18: LINE 1: DROP DATABASE IF EXISTS ambari;The IF EXISTS clause was only added to DROP command in PotgreSQL8.2.+Show warnings if any SQL commands failed during server reset or upgradestack,1.4.1,1.4.1,47,1,0,0,0,0,0,0,
3221,ambari-web,Xi Wang,NameNode Uptime does not appear,Due to backend change of the position of NameNode startTime property  this will not show up.,1.4.1,1.4.1,16,1,0,0,0,0,0,0,
3229,,Mahadev konar,Ambari does not set the correct value for 'templeton.storage.class' in webhcat-site.xml,Ambari does not set the correct value for 'templeton.storage.class' in webhcat-site.xmlIn an Ambari deployed cluster currently the following value in /etc/hcatalog/conf/webhcat-site.xml is set incorrectly: &lt;property&gt; &lt;name&gt;templeton.storage.class&lt;/name&gt; &lt;value&gt;org.apache.hcatalog.templeton.tool.ZooKeeperStorage&lt;/value&gt; &lt;/property&gt;With the change from HIVE-4895 this should be: &lt;property&gt; &lt;name&gt;templeton.storage.class&lt;/name&gt; &lt;value&gt;org.apache.hive.hcatalog.templeton.tool.ZooKeeperStorage&lt;/value&gt; &lt;/property&gt;All jobs involving MapReduce fail because of this issue.,1.4.1,1.4.1,56,1,0,0,0,0,0,0,
3240,ambari-server,Sumit Mohanty,URLStreamProvider reads are flooding the log,These logs do not need to be at INFO level. When user is using the UI then theer is roughly one log per second.06:56:34 232 INFO [pool-1-thread-12] URLStreamProvider:81 - readFrom spec:http://c6402.ambari.apache.org:50075/jmx06:56:34 235 INFO [pool-1-thread-5] URLStreamProvider:81 - readFrom spec:http://c6401.ambari.apache.org:50075/jmx06:56:34 248 INFO [qtp1620999494-18] URLStreamProvider:81 - readFrom spec:http://c6401.ambari.apache.org/cgi-bin/rrd.py?c=HDPSlaves&amp;h=c6401.ambari.apache.org c6402.ambari.apache.org&amp;m=cpu_wio jvm.JvmMetrics.MemHeapUsedM rpc.rpc.RpcQueueTimeAvgTime jvm.JvmMetrics.MemHeapCommittedM&amp;e=now&amp;pt=true...,1.4.1,1.4.1,53,0,0,0,0,0,0,0,
3251,ambari-server,Dmitry Lysnichenko,When Bind DN credentials are incorrect - we should log it,When integrating Ambari with LDAP if you specify the Bind DN  or Bind credentials that are invalid there is no logging to identify that the authentication fails  so the following search for the logging in user DN will fail. I had to use wireshark to figure out why the integration wasn't working.,1.2.5,1.4.1,52,1,0,0,0,0,0,0,
3252,ambari-server,Siddharth Wagle,Setup the krb5 Jaas configuration using 'ambari-server setup-security',1. Add 'ambari-server setup-security' to replace all of the following operations:'setup-https|setup-ganglia-https|setup-nagios-https|encrypt-passwords'2. Add new operation 'setup-kerberos-auth' to ask the user for: ambari.keytab ambari.principalRelated to  https://issues.apache.org/jira/browse/AMBARI-2941,1.4.1,1.4.1,29,1,0,0,1,0,0,0,
3255,ambari-web,Oleg Nechiporenko,Read-only views of security admin tab became editable after visiting other tabs on admin page,STR: Go to Admin page -&gt; Security tab Switch to another tab on admin page (Misc tab  HA tab  etc.) Go back to Security tab--------------------Verify that all input fields on this page are read-onlyExpected Result: Everything should be read-only.Actual Result: Some fields become editable .,1.4.1,1.4.1,51,0,0,0,1,0,0,0,
3258,ambari-web,Srimanth Gunturi,Provide UI page to enable/disable experimental functionality,We have various experimental functionality provided in UI. We need an easy UI page http://server:8080/#/experimental to enable/disable these functionalities.This will make it easy for users to test these functionalities and give feedback.Refresh of Ambari UI will clear the changes.,1.4.0,1.4.1,42,1,0,0,0,0,0,0,
3260,ambari-server,Siddharth Wagle,Fix text for custom JCE policy setup,Current text:-c JCE_POLICY  --jce-policy=JCE_POLICY Use specified jce_policy. Must be valid on all hostsThis is required only on ambari-server  the agents will download from the server.,1.4.1,1.4.1,32,1,0,0,0,0,0,0,
3261,,Jeff Sposetti,Cleanup UX for advanced database in 'ambari-server setup',Cleanup UX...Enter advanced database configuration [y/n] (n)? y==============================================================================Choose one of the following options:[1] - PostgreSQL (Embedded)[2] - Oracle==============================================================================Enter choice (1):,1.2.5,1.4.1,28,1,0,0,0,0,0,0,
3276,ambari-web,Xi Wang,Dashboard page: buttons are shifted if screen width is more than 1200px,,1.4.1,1.4.1,1,0,0,0,0,0,0,0,
3279,ambari-web,Xi Wang,Strange behavior of 'JobTracker CPU WIO' dashboard widget,This happened because when fixing an old issue  jobTrackerCpu got ignored about that fix.,1.4.1,1.4.1,15,1,0,0,0,0,1,0,
3285,ambari-web,Andrii Babiichuk,Help Text for NameService ID when enabling HA is random in responding to mouse movement and clicks.,,1.4.1,1.4.1,1,0,0,0,0,0,0,0,
3292,ambari-web,Jaimin D Jetly,Security wizard: On NameNode HA mode  General category should have spnego principal and keytab field,Earlier dfs.web.authentication.kerberos.keytab field was being used for NameNode and SNameNode component. So we planned to pull this key to NameNode category when HA is enabled as it's the only component then using the key.After HDFS-5091 fix  journalNode also uses this key.So instead of pulling this config key in NameNode section  it should be kept in General category and the description of this principal and keytab location field should be changed accordingly.,1.4.1,1.4.1,86,0,0,0,0,0,0,3,ambari-web/app/controllers/main/admin/security/add/step2.js;ambari-web/app/data/HDP2/secure_mapping.js;ambari-web/app/data/HDP2/secure_properties.js;
3296,ambari-agent,Vitaly Brodetskyi,SSH key in logs?,Notice after agent registration (automatic with SSH key)  I see the SSH key in the popup. Also see it in the ambari-agent.log.Not sure we want to capture this in the log and show in the UI?,1.4.1,1.4.1,36,1,0,0,0,0,0,0,
3301,,Mahadev konar,Unavailable stacks should be hidden.,Unavailable stacks should be hidden.,1.4.1,1.4.1,5,1,0,0,0,0,0,0,
3302,,Sumit Mohanty,Parameterize the repo url for latest stack,Allow the latest stack repo url to be parameterized for the build. This allows the build to cater to the stack repo as it goes through dev/private/public builds each with different URLs.,1.4.0,1.4.1,32,1,0,0,0,0,0,0,
3304,ambari-agent,Dmytro Shkvyra,Nagios alert text for NodeManagers should say 'live',Services &gt; YARNSee screen shot.Should say 'Percent NodeManagers live',1.4.1,1.4.1,9,1,0,0,0,0,0,0,
3307,ambari-web,Oleg Nechiporenko,Fix Unit tests and create new test for step3 installer,,1.4.1,1.4.1,1,1,0,0,0,0,0,0,
3310,ambari-web,Oleg Nechiporenko,HDFS service check should not be disabled when NN HA is enabled and one NN is down,HDFS service check should not be disabled when NN HA is enabled and one NN is down. In fact  service check passing is an indication that NN is available with one NN down.,1.4.1,1.4.1,33,1,0,0,0,0,0,0,
3315,ambari-web,Jaimin D Jetly,Security wizard: 'Create Principals and Keytabs' step doesn't save state after page refresh,,1.4.1,1.4.1,1,1,0,0,1,0,0,8,ambari-web/app/controllers/main/admin/security.js;ambari-web/app/controllers/main/admin/security/add/step2.js;ambari-web/app/controllers/main/admin/security/add/step3.js;ambari-web/app/controllers/main/admin/security/add/step4.js;ambari-web/app/controllers/main/admin/security/disable.js;ambari-web/app/routes/main.js;ambari-web/app/utils/ajax.js;ambari-web/app/utils/db.js;
3318,ambari-web,Yusaku Sako,Use correct case for YARN,,1.4.0,1.4.1,1,1,0,0,0,0,0,0,
3324,ambari-web,Andrii Tkach,UI optimization: constrain hostComponents model loading,Constrain loading hostComponents into model  so then it loads only on initial loading or when added new hostComponents.,1.4.1,1.4.1,18,1,0,0,0,0,0,1,ambari-web/app/mappers/service_mapper.js;
3328,ambari-agent,Dmitry Lysnichenko,Unit test for agents fail/hang at TestActionQueue and TestStackUpgrade.,Running mvn test on agent fails/hangs under Mac Os,1.4.2,1.4.2,9,1,0,0,0,0,0,0,
3332,ambari-web,Oleg Nechiporenko,switching to Configs tab causes Quick Links to disappear,In Ambari Web  browse to HDFS  YARN  MapReduce2  etc. Click on the Configs tab  the Quick Links option disappears.See the same regardless of 1.3.2 or 2.0.6  and tried on Firefox and Chrome,1.4.1,1.4.1,32,1,0,0,0,0,0,0,
3333,ambari-web,Andrii Tkach,'Services'  'Dashboard' 'Navigation errors,Navigation from Hosts to Services page or from Hosts to Dashboard pagesometimes fails (nothing happens besides highlighting 'Services' tab) and sometimes navigates to an empty page.Uncaught Error: assertion failed: calling set on destroyed object ember-latest.js:43Ember.assert ember-latest.js:43set ember-latest.js:1386Ember.Observable.Ember.Mixin.create.set ember-latest.js:7769App.MainServiceMenuView.Em.CollectionView.extend.renderOnRoute menu.js:52invokeAction ember-latest.js:3174iterateSet ember-latest.js:3156sendEvent ember-latest.js:3273notifyObservers ember-latest.js:1865Ember.notifyObservers ember-latest.js:1980propertyDidChange ember-latest.js:2613set ember-latest.js:1419(anonymous function) ember-latest.js:10459f.event.dispatch jquery-1.7.2.min.js:3h.handle.i jquery-1.7.2.min.js:3,1.4.1,1.4.1,56,1,0,0,0,0,0,4,ambari-web/app/app.js;ambari-web/app/views/main/host/summary.js;ambari-web/app/views/main/service/info/summary.js;ambari-web/app/views/wizard/step1_view.js;
3336,ambari-web,Andrii Babiichuk,HDFS health status when HA config'd,When NameNode HA is config'd:1) HDFS status green if and only if there is Active NameNode; red otherwise2) green -&gt; HDFS Service Stop enabled  HDFS Service Start disabled. red -&gt; HDFS Service Start enabled  HDFS Service Stop disabled,1.4.1,1.4.1,38,1,0,0,0,0,0,1,ambari-web/app/mappers/status_mapper.js;
3337,ambari-server; test,Artem Baranchuk,When invalid jce policy file path is specified  ambari-server setup silently switches over to downloading the file from public repo,When an non-existent file is provided as jce-policy parameter we should get ambari-server setup process failed instead of downloading the file from public repo.Also  if the path is a folder then we should gracefully error out instead of allowing shutil.copy to fail with an error stack.,1.4.1,1.4.1,46,1,0,0,0,0,0,0,
3350,,Erin A Boyd,ambari-agent RPM claims ownership of /usr/sbin,*This also affects trunk*The ambari-agent.spec (generated from rpm-maven-plugin) claims ownership of /usr/sbin $ grep sbin target/rpm/ambari-agent/SPECS/ambari-agent.spec | grep attr%attr(755 root root) /usr/sbinThis is a problem because the filesystem RPM owns /usr/sbin.According to rpm-maven-plugin documentation&#91;0&#93;  this is because the only file under /usr/sbin is ambari-agent and'directoryIncludedIf the value is true then the attribute string will be written for the directory if the sources identify all of the files in the directory (that is  no other mapping contributed files to the directory). This is the default behavior.'The 'no other mapping contributed files to the directory' bit is important.The solution is to add directoryInclude=false to the mapping.&#91;0&#93; http://mojo.codehaus.org/rpm-maven-plugin/map-params.html,1.2.5,1.4.3,107,1,0,0,0,0,0,0,
3356,ambari-web,Jaimin D Jetly,wrong property name for https address of NN in hdfs-site.xml,The property which defines the https address of namenode is dfs.namenode.https-address. In ambari   the property name is mentioned as 'dfs.https.namenode.https-address',1.4.1,1.4.1,21,1,0,0,0,0,0,2,ambari-server/src/main/python/UpgradeHelper_HDP2.py;ambari-web/app/data/HDP2/config_mapping.js;
3362,ambari-server,Sumit Mohanty,Modify the config mappings in the upgrade script to reflect the latest,Modify the upgrade mappings for hdfs-site  core-site  mapred-site  and global to reflect the latest.,1.4.1,1.4.1,14,1,0,0,0,0,0,0,
3363,ambari-agent,Jaimin D Jetly,wrong path being set for JSVC_HOME on suse OS in hadoop-env.sh.,JSVC_HOME is being set to /usr/lib/hadoop/sbin/Linux-amd64-64/ instead of /usr/lib/bigtop-utils.,1.4.1,1.4.1,9,1,0,0,0,0,0,1,ambari-agent/src/main/puppet/modules/hdp-hadoop/manifests/params.pp;
3397,ambari-web,Oleg Nechiporenko,Deploy progress bar is not correct,All ajax-requests are completed  but progress bar doesn't filled to 100%.,1.4.1,1.4.1,11,1,0,0,0,0,0,0,
3398,ambari-web,Andrii Babiichuk,The number of alerts in MapReduce item in menu gets out on the next line.,STD:Make the browser window's width less than actual width of the page.Go to Services page.Stop all services.Result:The number of alerts in MapReduce item in menu gets out on the next line.,1.4.1,1.4.2,31,1,0,0,0,0,0,2,ambari-web/app/styles/application.less;ambari-web/app/templates/main/service.hbs;
3402,ambari-server,Myroslav Papirkovskyy,ambari-server setup silently fails when it cannot connect to the remote oracle host,The oracle db was installed on a host where port 1521 was not accessible to the ambari-server host. However  'ambari-server setup' did not report failure.Enter advanced database configuration [y/n] (n)? y==============================================================================Choose one of the following options:[1] - PostgreSQL (Embedded)[2] - Oracle==============================================================================Enter choice (1): 2Hostname (localhost): test-sm1.iad1Port (1521):Select Oracle identifier type:1 - Service Name2 - SID(1):Service Name (ambari): XEUsername (ambari):Enter Database Password (bigdata):Copying JDBC drivers to server resources...Configuring remote database connection properties...Copying JDBC drivers to server resources...Ambari Server 'setup' completed successfully.,1.4.0,1.4.1,87,1,0,0,0,0,0,0,
3433,,Mahadev konar,Add hcat.bin to pig.properties for hcat integration,Add hcat.bin to pig.properties for hcat integration.hcat.bin=/usr/bin/hcat,1.4.1,1.4.1,7,1,0,0,0,0,0,0,
3434,ambari-web,Yusaku Sako,On 2.x stack  dfs.block.local-path-access.user should not be set in hdfs-site,,1.4.1,1.4.1,1,1,0,0,0,0,0,0,
3435,ambari-web,Jaimin D Jetly,YARN cluster should not have shared directories between yarn.nodemanager.local-dirs and yarn.nodemanager.log-dirs,,1.4.1,1.4.1,1,1,0,0,1,0,0,8,ambari-server/src/main/resources/stacks/HDP/2.0.5/services/YARN/configuration/yarn-site.xml;ambari-server/src/main/resources/stacks/HDP/2.0.6/services/YARN/configuration/yarn-site.xml;ambari-server/src/main/resources/stacks/HDPLocal/2.0.5/services/YARN/configuration/yarn-site.xml;ambari-server/src/main/resources/stacks/HDPLocal/2.0.6/services/YARN/configuration/yarn-site.xml;ambari-web/app/data/HDP2/config_mapping.js;ambari-web/app/data/HDP2/global_properties.js;ambari-web/app/data/HDP2/site_properties.js;ambari-web/app/models/service_config.js;
3437,ambari-agent,Siddharth Wagle,Incorrect alert for NodeManager,Error with RM nagios alert for rpc latency.[1380746845] SERVICE NOTIFICATION: nagiosadmin;&lt;hostaname&gt;;RESOURCEMANAGER::ResourceManager RPC latency;CRITICAL;notify-service-by-email;CRITICAL: Data inaccessible  Status code = 200,1.4.1,1.4.1,26,1,0,0,0,0,0,0,
3443,,Oleg Nechiporenko,'Assign Slaves and Clients' step. 'all | none' click error,Clicking on 'all|none' affects disabled checkboxes.,1.5.0,1.5.0,6,1,0,0,0,0,0,0,
3446,ambari-web,Andrii Babiichuk,When SSL is enabled on Hadoop JMX endpoints ResourceManager quick links become unavailable,When hadoop.ssl.enabled=true  ResourceManager port is 8090. When it is false  the port is still 8088.,1.4.1,1.4.1,15,1,0,0,0,0,0,4,ambari-web/app/assets/test/tests.js;ambari-web/app/models/quick_links.js;ambari-web/app/views/common/quick_view_link_view.js;ambari-web/test/views/common/quick_link_view_test.js;
3456,ambari-web,Andrii Babiichuk,Text of installation stage doesn't correspond to reality,STD:On the latter stages of installing cluster  refresh page 'Install  Start and Test'..Result:Appeared 'Next' button and progress of installation is setted to 100%  but message of installation on the second host says that the Nagios Server is not installed yet. After clicking 'Next' all seems good and Nagios Server is installed normally.,1.4.1,1.4.2,52,1,0,0,0,0,0,1,ambari-web/app/controllers/wizard/step9_controller.js;
3457,ambari-web,Yusaku Sako,When multiple MR2 Clients are installed  the label is a bit off,When multiple MR2 Clients are installed  the MR2 summary panel has a label like: '3 MapReduce2 Client s Installed' (with an unnecessary space),1.4.1,1.4.1,23,1,0,0,0,0,0,0,
3477,ambari-web,Andrii Tkach,JavaScript errors during service tab changing,Steps:Open browser console.Run start or stop operation for any service.Switch between some services repeatedly.Result:'Calling set on destroyed view' was appeared in console.,1.4.1,1.4.2,22,1,0,0,0,0,0,1,ambari-web/app/app.js;
3488,ambari-web,Andrii Tkach,Status does not show up for newly added hosts,The problem is that host can have actual status only when service mapper recieve response(could be long latency  about 10 - 12 seconds) with new hostComponents and then status mapper compute them and set status to host.,1.4.1,1.4.2,38,1,0,0,0,0,0,1,ambari-web/app/mappers/status_mapper.js;
3490,ambari-agent,Dmitry Lysnichenko,Remove RCO management logic at ambari-agent,In 1.5.0 release  ambari-agent will not need to process RCO to re-order/parallelizing tasks. Let's remove the code/unit-test and keep them aside in a JIRA targeted for release after 1.5.0. If possible  let's remove upgrade related code as well as there is no plan for automatic stack upgrade for Baikal. We can keep the python executor as there is a requirement for python executor.,1.5.0,1.5.0,63,1,0,0,0,0,0,0,
3491,ambari-web,Jaimin D Jetly,HBase Master/RegionServer can no longer be started after reconfiguring HBase or HDFS with NameNode HA enabled,,1.4.1,1.4.1,1,1,0,0,0,0,0,3,ambari-web/app/controllers/wizard/step8_controller.js;ambari-web/app/data/HDP2/config_mapping.js;ambari-web/app/utils/config.js;
3498,ambari-web,Jaimin D Jetly,Hbase secure config properties in HDP-2.x stack revert back to non-secure values on reconfiguration,,1.4.1,1.4.1,1,1,0,0,0,0,0,1,ambari-web/app/data/HDP2/config_mapping.js;
3507,ambari-web,Oleg Nechiporenko,'Assign Slaves' step. Error with installed NodeManagers,Installed NodeManagers don't appears as selected checkboxes on the 'Assign Slaves' step.,1.5.0,1.5.0,12,0,0,0,0,0,0,0,
3512,,Sumit Mohanty,Nagios doesn't start after upgrade [SLES11  1.3.2->2.0.6],check_cpu needs to be disabled for Suse for JobHistory server and ResourceManager,1.4.1,1.4.1,12,0,0,0,0,0,0,0,
3521,ambari-web,Andrii Babiichuk,Incorrect status counters on cluster deploy,In host stauts filter label shows incorrect number of hosts after deploy failed.Wrong progress bar color  on fail color should be red or yellow  instead of blue.,1.4.2,1.4.2,27,0,0,0,0,0,0,2,ambari-web/app/controllers/wizard/step9_controller.js;ambari-web/app/messages.js;
3528,ambari-web,Oleg Nechiporenko,DB url isn't calculated automatically,Select Hive or Oozie and go to step 'Customize services'.'Open' Oozie tab.Database Url is 'jdbc'.Click 'Existing MySQL Database'.Click 'New Derby Database'.Database Url became jdbc:derby:${oozie.data.dir}/${oozie.db.schema.name}-db;create=true.Expect:proper value should be right after step is loaded.,1.5.0,1.5.0,38,0,0,0,0,0,0,0,
3534,ambari-server; test,Artem Baranchuk,Hadoop Core Health Check script needs to be included in Ambari HDP installations,,1.4.0,1.4.2,1,0,0,0,0,0,0,0,
3535,ambari-web,Oleg Nechiporenko,skip 'Customize Services' step for services that can't be customized,Services like PIG  Sqoop can't be customized.Wizard should check services-list (that user want to add) and if no one service can't be customized  should skip 'Customize' step ('Back' click on the next step should also be verified).,1.5.0,1.5.0,37,0,0,0,0,0,0,0,
3537,ambari-agent,Dmytro Sen,Allow log4j properties to be applied via the API in Ambari for hadoop/oozie/hbase/hive/zookeeper/pig,Allow log4j properties to be applied via the API in Ambari for hadoop/oozie/hbase/hive/zookeeper/pig.,1.4.2,1.5.0,13,0,0,0,0,0,0,65,ambari-agent/src/main/python/resource_management/libraries/providers/__init__.py;ambari-agent/src/main/python/resource_management/libraries/providers/properties_file.py;ambari-agent/src/main/python/resource_management/libraries/resources/__init__.py;ambari-agent/src/main/python/resource_management/libraries/resources/properties_file.py;ambari-server/src/main/resources/stacks/HDP/1.3.3/hooks/before-START/scripts/params.py;ambari-server/src/main/resources/stacks/HDP/1.3.3/hooks/before-START/scripts/shared_initialization.py;ambari-server/src/main/resources/stacks/HDP/1.3.3/hooks/before-START/templates/log4j.properties.j2;ambari-server/src/main/resources/stacks/HDP/1.3.3/services/HBASE/configuration/hbase-log4j.xml;ambari-server/src/main/resources/stacks/HDP/1.3.3/services/HBASE/metainfo.xml;ambari-server/src/main/resources/stacks/HDP/1.3.3/services/HBASE/package/scripts/hbase.py;ambari-server/src/main/resources/stacks/HDP/1.3.3/services/HBASE/package/scripts/params.py;ambari-server/src/main/resources/stacks/HDP/1.3.3/services/HDFS/configuration/hdfs-log4j.xml;ambari-server/src/main/resources/stacks/HDP/1.3.3/services/HDFS/metainfo.xml;ambari-server/src/main/resources/stacks/HDP/1.3.3/services/HIVE/configuration/hive-exec-log4j.xml;ambari-server/src/main/resources/stacks/HDP/1.3.3/services/HIVE/configuration/hive-log4j.xml;ambari-server/src/main/resources/stacks/HDP/1.3.3/services/HIVE/metainfo.xml;ambari-server/src/main/resources/stacks/HDP/1.3.3/services/HIVE/package/scripts/hive.py;ambari-server/src/main/resources/stacks/HDP/1.3.3/services/HIVE/package/scripts/params.py;ambari-server/src/main/resources/stacks/HDP/1.3.3/services/MAPREDUCE/configuration/mapreduce-log4j.xml;ambari-server/src/main/resources/stacks/HDP/1.3.3/services/MAPREDUCE/metainfo.xml;ambari-server/src/main/resources/stacks/HDP/1.3.3/services/OOZIE/configuration/oozie-log4j.xml;ambari-server/src/main/resources/stacks/HDP/1.3.3/services/OOZIE/metainfo.xml;ambari-server/src/main/resources/stacks/HDP/1.3.3/services/OOZIE/package/scripts/oozie.py;ambari-server/src/main/resources/stacks/HDP/1.3.3/services/OOZIE/package/scripts/params.py;ambari-server/src/main/resources/stacks/HDP/1.3.3/services/OOZIE/package/templates/oozie-log4j.properties.j2;ambari-server/src/main/resources/stacks/HDP/1.3.3/services/PIG/configuration/pig-log4j.xml;ambari-server/src/main/resources/stacks/HDP/1.3.3/services/PIG/metainfo.xml;ambari-server/src/main/resources/stacks/HDP/1.3.3/services/PIG/package/scripts/params.py;ambari-server/src/main/resources/stacks/HDP/1.3.3/services/PIG/package/scripts/pig.py;ambari-server/src/main/resources/stacks/HDP/1.3.3/services/PIG/package/templates/log4j.properties.j2;ambari-server/src/main/resources/stacks/HDP/1.3.3/services/ZOOKEEPER/configuration/zookeeper-log4j.xml;ambari-server/src/main/resources/stacks/HDP/1.3.3/services/ZOOKEEPER/metainfo.xml;ambari-server/src/main/resources/stacks/HDP/1.3.3/services/ZOOKEEPER/package/scripts/params.py;ambari-server/src/main/resources/stacks/HDP/1.3.3/services/ZOOKEEPER/package/scripts/zookeeper.py;ambari-server/src/main/resources/stacks/HDP/1.3.3/services/ZOOKEEPER/package/templates/log4j.properties.j2;ambari-server/src/main/resources/stacks/HDP/2.1.1/hooks/before-START/scripts/params.py;ambari-server/src/main/resources/stacks/HDP/2.1.1/hooks/before-START/scripts/shared_initialization.py;ambari-server/src/main/resources/stacks/HDP/2.1.1/hooks/before-START/templates/log4j.properties.j2;ambari-server/src/main/resources/stacks/HDP/2.1.1/services/HBASE/configuration/hbase-log4j.xml;ambari-server/src/main/resources/stacks/HDP/2.1.1/services/HBASE/metainfo.xml;ambari-server/src/main/resources/stacks/HDP/2.1.1/services/HBASE/package/scripts/hbase.py;ambari-server/src/main/resources/stacks/HDP/2.1.1/services/HBASE/package/scripts/params.py;ambari-server/src/main/resources/stacks/HDP/2.1.1/services/HDFS/configuration/hdfs-log4j.xml;ambari-server/src/main/resources/stacks/HDP/2.1.1/services/HDFS/metainfo.xml;ambari-server/src/main/resources/stacks/HDP/2.1.1/services/HIVE/configuration/hive-exec-log4j.xml;ambari-server/src/main/resources/stacks/HDP/2.1.1/services/HIVE/configuration/hive-log4j.xml;ambari-server/src/main/resources/stacks/HDP/2.1.1/services/HIVE/metainfo.xml;ambari-server/src/main/resources/stacks/HDP/2.1.1/services/HIVE/package/scripts/hive.py;ambari-server/src/main/resources/stacks/HDP/2.1.1/services/HIVE/package/scripts/params.py;ambari-server/src/main/resources/stacks/HDP/2.1.1/services/OOZIE/configuration/oozie-log4j.xml;ambari-server/src/main/resources/stacks/HDP/2.1.1/services/OOZIE/metainfo.xml;ambari-server/src/main/resources/stacks/HDP/2.1.1/services/OOZIE/package/scripts/oozie.py;ambari-server/src/main/resources/stacks/HDP/2.1.1/services/OOZIE/package/scripts/params.py;ambari-server/src/main/resources/stacks/HDP/2.1.1/services/PIG/configuration/pig-log4j.xml;ambari-server/src/main/resources/stacks/HDP/2.1.1/services/PIG/metainfo.xml;ambari-server/src/main/resources/stacks/HDP/2.1.1/services/PIG/package/scripts/params.py;ambari-server/src/main/resources/stacks/HDP/2.1.1/services/PIG/package/scripts/pig.py;ambari-server/src/main/resources/stacks/HDP/2.1.1/services/PIG/package/templates/log4j.properties.j2;ambari-server/src/main/resources/stacks/HDP/2.1.1/services/YARN/configuration/yarn-log4j.xml;ambari-server/src/main/resources/stacks/HDP/2.1.1/services/YARN/metainfo.xml;ambari-server/src/main/resources/stacks/HDP/2.1.1/services/ZOOKEEPER/configuration/zookeeper-log4j.xml;ambari-server/src/main/resources/stacks/HDP/2.1.1/services/ZOOKEEPER/metainfo.xml;ambari-server/src/main/resources/stacks/HDP/2.1.1/services/ZOOKEEPER/package/scripts/params.py;ambari-server/src/main/resources/stacks/HDP/2.1.1/services/ZOOKEEPER/package/scripts/zookeeper.py;ambari-server/src/main/resources/stacks/HDP/2.1.1/services/ZOOKEEPER/package/templates/log4j.properties.j2;
3553,ambari-web,Jaimin D Jetly,NameNode HA wizard: Refreshing the wizard displays incorrect manual commands.,Install HDFS with customized hostname hdfs1. Start NameNode HA wizard and Refresh on step-2 (select host). Proceed ahead. Create checkpoint step asks to run command with incorrect user name:sudo su -l hdfs -c 'hdfs dfsadmin -safemode enter' Above command returns safemode: Access denied for user hdfs. Superuser privilege is required Actual command should be:sudo su -l hdfs1 -c 'hdfs dfsadmin -safemode enter',1.4.2,1.4.2,64,1,0,0,0,0,0,0,
3569,ambari-web,Oleg Nechiporenko,'Config' step refresh,Go to Config Step on the addServiceWizard.Refresh page.Got JS error  because selected services where not saved.Expect: get page with config list for selected services.,1.5.0,1.5.0,24,0,0,0,0,0,0,0,
3582,ambari-web,Srimanth Gunturi,Cleanup UI restart calculations using actual_configs,As documented in AMBARI-3531  the restart flags will be provided in host_components itself and services will have an API to get restart host_components easily. Due to this  there is no need for actual_configs on the client  and the code to calculate diffs with global properties.,1.4.1,1.4.2,56,1,0,0,0,0,0,0,
3584,ambari-web,Jaimin D Jetly,Reassign Master: Misc UI display fixes,This ticket mainly covers UI label and message changes in reassign master wizard.,1.4.2,1.4.2,13,1,0,0,0,0,0,9,ambari-web/app/config.js;ambari-web/app/controllers/main/service/reassign/step4_controller.js;ambari-web/app/controllers/main/service/reassign/step6_controller.js;ambari-web/app/messages.js;ambari-web/app/templates/main/admin/highAvailability/progress.hbs;ambari-web/app/templates/main/service/reassign/step1.hbs;ambari-web/app/views/main/service/reassign/step1_view.js;ambari-web/app/views/main/service/reassign/step4_view.js;ambari-web/app/views/main/service/reassign/step6_view.js;
3589,ambari-web,Oleg Nechiporenko,Common storage for different wizards,Some wizards (installer  addHosts  addServices) use common local storage objects.But each should has separated object (for example  based on controllerName).,1.4.2,1.4.2,20,1,0,0,0,0,0,0,
3594,ambari-web,Jaimin D Jetly,Service reconfiguration fails for multiple services,Service reconfiguration fails for HDFS  MapReduce and Hive service with js error. For other services it fails silently without any error (no API call is triggered).,1.4.2,1.4.2,26,1,0,0,0,0,0,4,ambari-web/app/controllers/main/service/info/configs.js;ambari-web/app/controllers/main/service/reassign_controller.js;ambari-web/app/utils/config.js;ambari-web/app/views/wizard/controls_view.js;
3609,ambari-agent,Trevor McKay,os_type_check.sh for RHEL is too restrictive (Server vs Workstation),The /etc/redhat-release on my RHEL6.4 dev box containsRed Hat Enterprise Linux Workstation release 6.4 (Santiago)os_type_check.sh is checking for 'Server' on rhel boxes. It should simply check for Red Hat Enterprise Linux and ignore text up to the version number.,1.4.2,,39,1,0,0,0,0,0,0,
3611,ambari-web,Xi Wang,Hosts: clarify which filter is in effect,1. Use a shadow with high contrast to make the current filter more visible.2. Show how many hosts total / how many are in the current view  and a 'Clear all filters' link.,1.4.2,1.4.2,33,1,0,0,0,0,0,0,
3613,ambari-web,Antonenko Alexander,Enable HA wizard loads after sign in,Steps: Go to 'Admin' page -&gt; 'High Availability' tab and run 'Enable NameNode HA' wizard. Close wizard. Sign out (or reopen browser). Sign in.Result:After sign in was opened first page of 'Enable NameNode HA' wizard instead 'Dashboard' page.,1.4.2,1.4.2,38,0,0,0,0,0,0,0,
3615,ambari-agent,Dmytro Sen,Ambari agent creates empty folder /var/ambari-agent,Ambari agent creates an empty directory /var/ambari-agent during installation.This directory isn't needed  /var/run/ambari-agent is used instead.,1.4.1,1.4.2,16,1,0,0,0,0,0,0,
3618,ambari-web,Xi Wang,host actions UI changes based on new stop/start all and delete func,1. Do the right-float on the action menus on the Components section.2. Rename buttons: on SERVICE PAGES: Maintenance --&gt;Service Actions...on HOST PAGES: Maintenance --&gt; Host Actions...on HOST PAGES / COMPONENT SECTION: Actions --&gt; Actions...,1.4.2,1.4.2,34,1,0,0,0,0,0,0,
3621,ambari-web,Andrii Babiichuk,cleanup dialog for unable to delete host,make dialog according to left mockup,1.4.2,1.4.2,6,1,0,0,0,0,0,2,ambari-web/app/messages.js;ambari-web/app/templates/main/host/details/raiseDeleteComponentErrorPopup.hbs;
3623,ambari-agent; test,Artem Baranchuk,LiveStatus of the component is not updated when username is changed,Steps to reproduce: On installer wizard  make install phase fail by killing any install task of master component. Go back and change hdfs username to hdfs1. Proceed ahead and installer wizard completes successfully. HDFS service is red. Nagios shows no alerts  but API returns INSTALLED status for all hdfs host components. UI impact: On starting HDFS  all tasks completes successfully with 100% green progress bar but service status always remains red. Restarting agent resolves the issue.Looks like AmbariConfig.servicesToPidNames is not getting updated when username is changed.,1.4.2,1.4.2,87,1,0,0,0,0,0,0,
3631,ambari-agent,Dmytro Shkvyra,traceback when attempting to stop ambari-agent as non-root,I attempted to stop the ambari-agent without going to root first. Prints a pretty bad traceback.&#91;vagrant@c6403 ~&#93;$ ambari-agent stop/usr/sbin/ambari-agent: line 66: /var/lib/ambari-agent/ambari-env.sh: Permission deniedVerifying Python version compatibility...Using python /usr/bin/python2.6Found ambari-agent PID: 2996Stopping ambari-agentTraceback (most recent call last):File '/usr/lib/python2.6/site-packages/ambari_agent/main.py'  line 235  in &lt;module&gt;main()File '/usr/lib/python2.6/site-packages/ambari_agent/main.py'  line 190  in mainsetup_logging(options.verbose)File '/usr/lib/python2.6/site-packages/ambari_agent/main.py'  line 73  in setup_loggingrotateLog = logging.handlers.RotatingFileHandler(logfile  'a'  10000000  25)File '/usr/lib64/python2.6/logging/handlers.py'  line 112  in initBaseRotatingHandler.init(self  filename  mode  encoding  delay)File '/usr/lib64/python2.6/logging/handlers.py'  line 64  in initlogging.FileHandler.init(self  filename  mode  encoding  delay)File '/usr/lib64/python2.6/logging/init.py'  line 827  in __initStreamHandler.init(self  self._open())File '/usr/lib64/python2.6/logging/init.py'  line 846  in _openstream = open(self.baseFilename  self.mode)IOError: &#91;Errno 13&#93; Permission denied: '/var/log/ambari-agent/ambari-agent.log'Removing PID file at /var/run/ambari-agent/ambari-agent.pidrm: cannot remove '/var/run/ambari-agent/ambari-agent.pid': Permission deniedambari-agent successfully stopped,1.4.2,1.4.2,107,1,0,0,0,0,0,0,
3645,ambari-web,Xi Wang,HA cluster: some dashboard's widgets contain 'Null'  'NaN' values after services stop,Steps:Stop YARN service.Go to 'Dashboard'.Result:'NodeManagers Live' widget contains 'null' values.Similar problem is present for 'HBase Ave Load' widget - 'NaN' value.,1.4.2,1.4.2,21,1,0,0,0,0,0,0,
3648,ambari-agent,Vitaly Brodetskyi,Failed to start Hive Metastore (centos5.8  Stack 2.0),Occurred during install as warning (could not start the service). Clicked next to continue  when into Ambari  then tried to start Hive there as well  same issue.,1.4.2,1.4.2,27,0,0,0,0,0,0,0,
3650,ambari-web,Andrii Tkach,Poll for host_components which have stale_configs,UI needs to know which host_components need restart due to stale_configs (saved but not picked up). Server API provide stale_configs flag per host-component. We need this polled and maintained on client model.,1.4.1,1.4.2,32,1,0,0,0,0,0,8,ambari-web/app/assets/data/services/host_component_stale_configs.json;ambari-web/app/controllers/global/cluster_controller.js;ambari-web/app/controllers/global/update_controller.js;ambari-web/app/controllers/main/service/info/configs.js;ambari-web/app/initialize.js;ambari-web/app/mappers/component_config_mapper.js;ambari-web/app/models/service.js;ambari-web/app/views/main/host/summary.js;
3674,ambari-web,Srimanth Gunturi,UI does not update active hbase master in display,When we have 3 HBase masters we show in UI that one of them is active. When the master is stopped  the other HBase master is not marked as active in UI. In API it does become active.,1.4.2,1.4.2,38,1,0,0,0,0,0,0,
3675,ambari-web,Jaimin D Jetly,Default value of 'Default virtual memory for a job's map-task' is not valid,The default value of 'Default virtual memory for a job's map-task' (in Customize Services page -&gt; MapReduce2 tab -&gt; General) was '619.5'.Warning hint says 'Must contain digits only'Value depends on quantity of installed components.,1.4.2,1.4.2,34,1,0,0,0,0,0,5,ambari-web/app/controllers/wizard/step7_controller.js;ambari-web/app/utils/config.js;ambari-web/app/utils/defaults_providers/yarn_defaults_provider.js;ambari-web/app/utils/helper.js;ambari-web/app/utils/string_utils.js;
3679,ambari-agent,Dmytro Shkvyra,Better error message needed when incompatible ambari-agents installed,On a few days old cluster I attempted to add a host. The add host failed due to ambari-server trying to install ambari-agent-1.4.1.17 and the repo having ambari-agent-1.4.1.23-1.The message in /var/run/ambari-server/bootstrap/11/hostname.log was:STDERRscp /usr/lib/python2.6/site-packages/ambari_server/setupAgent.py done for host srimanth1-5.c.pramod-thangali.internal  exitcode=0Copying files finishedRunning setup agent...STDOUTError: Nothing to do{'exitstatus': 1  'log': ('Loaded plugins: downloadonly  fastestmirror  security/nDetermining fastest mirrors/n * base: www.gtlib.gatech.edu/n * extras: centos.mirror.netriplex.com/n * updates: mirror.cogentco.com/nSetting up Install Process/nNo package ambari-agent-1.4.1.17 available./n'  None)},1.4.1,1.4.2,70,1,0,0,0,0,0,0,
3686,ambari-web,Antonenko Alexander,NameNode HA wizard (Configure Components step): Task 'Reconfigure HDFS' always fail  and user cannot proceed to next step,This task fails due to bad request:/api/v1/clusters/c1/hosts/HDFS_CLIENT/host_components/dev01.hortonworks.comShould be: api/v1/clusters/c1/hosts/dev01.hortonworks.com/host_components/HDFS_CLIENT,1.4.2,1.4.2,9,0,0,0,0,0,1,0,
3690,ambari-web,Yusaku Sako,Typo in text label on Hosts page,On the Hosts page  we have a typo in the label 'filterd'. Should be 'filtered'.,1.4.2,1.4.2,15,1,0,0,0,0,0,0,
3695,ambari-agent,Dmytro Shkvyra,'Confirm hosts' shows 'ntpd not running' warning  but it's running on host,STR: Install  setup and start Ambari server by default. Reach 'Choose services' phase of installer.Actual result:'Confirm hosts' shows warning that ntpd service isn't running on hosts  but it's running in console by command service ntpd status,1.4.2,1.4.2,45,1,0,0,0,0,0,0,
3698,ambari-web,Jaimin D Jetly,Modify UI text for host cleanup,python /usr/lib/python2.6/site-packages/ambari_agent/HostCleanup.py -s -k 'users'To cleanup in interactive mode  remove *-s* option. To cleanup all resources  including _users_  remove *-k users* option. Use *--help* for a list of available options. The motivation is to provide the conservative option but minimal detail to allow for full clean up.,1.4.2,1.4.2,63,1,0,0,0,0,0,2,ambari-web/app/messages.js;ambari-web/app/styles/application.less;
3701,ambari-server,Dmytro Shkvyra,Reduce logs emitted to report heartbeats from agents,For a 657 node cluster:~10 minute for 10 MB and 20 log files store about 200 minutes (~3 hours) of log. This is not ideal if an error overnight needs to be investigated. We should try for the log to last 24 hours - ideally 72 hours to account for weekends.-rw-r--r-- 1 root root 10485854 Oct 17 17:35 ambari-server.log.6-rw-r--r-- 1 root root 10485836 Oct 17 17:44 ambari-server.log.5-rw-r--r-- 1 root root 10485811 Oct 17 17:52 ambari-server.log.4-rw-r--r-- 1 root root 10485793 Oct 17 18:01 ambari-server.log.3-rw-r--r-- 1 root root 10485793 Oct 17 18:10 ambari-server.log.2-rw-r--r-- 1 root root 10485854 Oct 17 18:18 ambari-server.log.1,1.4.2,1.4.2,106,1,0,0,0,0,0,0,
3708,ambari-web,Srimanth Gunturi,Reconfigure of dynamic configs not showing modified values,Modifications of dynamic properties are being persisted on server  but default values are being shown in UI. Also  we should not validate dynamic configs which are of type string. mapreduce.map.java.opts mapreduce.reduce.java.opts yarn.app.mapreduce.am.command-opts,1.4.0,1.4.0; 1.4.2,32,1,0,0,0,0,0,0,
3713,ambari-web,Oleg Nechiporenko,When filtering on hosts  the table column sizes shift  should stay fixed.,For the 'defaultsProvider' and 'serviceValidator' functionalities  we need unit tests,1.4.2,1.4.2,10,1,0,0,0,0,0,0,
3715,ambari-web,Antonenko Alexander,Reassign Master Wizard does not display folder and hosts on 'Manual commands' page after browser reopening,Steps: Open 'Reassign Master Wizard' for NameNode or SNameNode. Go to 'Manual commands' page. Close browser and open it again.Result: Was opened 'Manual commands' page  but hostnames and foldername were replaced with '{1}'  '{2}' etc.Attached picture for other page  but behavior is similar.,1.4.2,1.4.2,43,1,0,0,0,0,0,0,
3720,ambari-web,Xi Wang,Provide read-only view of repo options in Ambari Web,If a user is using local repos  and customizes Advanced Repository Options during install  the user might need this info to debug post install (since it is used in Add Hosts)  for example.Note: We should show this information regardless if the user customizes repos or not during install.,1.4.2,1.4.2,48,1,0,0,0,0,0,1,ambari-web/app/utils/ajax.js;
3724,ambari-web,Andrii Tkach,Incorrect host status when slave down,When host has slave down status 'No Heartbeat' status is shown instead of 'Slave Down'.,1.4.2,1.4.2,15,1,0,0,0,0,0,1,ambari-web/app/models/host.js;
3726,ambari-web,Antonenko Alexander,Restart indicators for services and hosts disappear after some time.,Goto Service (that have stale configs) -&gt; configs   no restart indicators are shown. Refresh page  for 10-15 seconds you see indicators then they disappear. The same for host detail page,1.4.2,1.4.2,31,1,0,1,0,0,0,0,
3729,,Artem Baranchuk,Ganglia monitor started with second or third attempt on secure cluster,,1.4.1,1.4.3,1,1,0,0,0,0,0,0,
3738,ambari-web,Andrii Babiichuk,Background ops dialog checkbox UI cleanup,The OK and the text should be on the same centerline row.,1.4.2,1.4.2,12,1,0,0,0,0,0,3,ambari-web/app/styles/application.less;ambari-web/app/templates/common/modal_popup.hbs;ambari-web/app/views/common/modal_popup.js;
3739,ambari-server,Siddharth Wagle,Remove Exception message printed to log for successful starts,Following error messages are printed to log with default log level and are misleading.04:19:52 438 ERROR [main] MasterKeyServiceImpl:109 - Master key is not provided as a System property or an environment varialble.04:19:52 439 INFO [main] Configuration:415 - Credential provider creation failed.Master key initialization failed.,1.4.2,1.4.2,50,1,0,0,0,0,0,0,
3742,ambari-web,Andrii Babiichuk,HBase Links widget has 'more' button out of bounds and looks broken when there are multiple masters,When there are multiple HBase Masters  the HBase Links widget looks broken. Let's get rid of the 'and X Standby Masters' static text as it is not a link and not very useful.So the widget would look like:'HBase Master''X RegionServers''Master Web UI',1.4.2,1.4.2,42,1,0,0,0,0,0,4,ambari-web/app/messages.js;ambari-web/app/templates/main/dashboard/widgets/hbase_links.hbs;ambari-web/app/views/main/dashboard/service/hbase.js;ambari-web/app/views/main/dashboard/widgets/hbase_links.js;
3752,ambari-web,Srimanth Gunturi,MR jobs are hanging on a 2-node cluster with default configuration,This is a 2-node cluster with 2GB of RAM each. Cluster deployment goes fine but MR jobs do not complete resulting in service check failures for MR  OOZIE  Pig  etc.,1.4.2,1.4.2,30,1,0,0,0,1,0,0,
3759,ambari-web,Antonenko Alexander,Add host wizard: After successfully bootstrapping host  'next' button is disabled,See screenshot,1.4.2,1.4.2,2,1,0,0,0,0,0,0,
3760,ambari-web,Antonenko Alexander,Provide config-group support in add-host wizard,When adding hosts  a user should be able to select which config-groups this host belongs to. Configurations of that group (Default or config-group) will be applied on that host.,1.4.2,1.4.2,29,1,0,0,0,0,0,0,
3761,ambari-web,Andrii Babiichuk,'Uncaught exception' in JS while navigating through services on Services page,This one was discovered while quick navigating through services on Services page.To reproduce just try to click on services links fast.After that service content is not displayed.,1.4.2,1.4.2,27,1,0,0,0,0,0,1,ambari-web/app/views/common/quick_view_link_view.js;
3770,,Dmytro Shkvyra,Need better error log message when agent unable to reach server,http://hortonworks.com/community/forums/topic/installing-hdp2-0-6-on-centos6-4/The current ERROR in the agent log can be cryptic.,1.4.1,1.4.3,13,1,0,0,0,0,0,0,
3771,ambari-web,Andrii Babiichuk,Ambari should allow changing Ganglia cache location,Ambari allows changing Ganglia directory during installation  but not after the cluster is installed. We should allow changing this directory after cluster installed,1.4.1,1.4.2,23,1,0,0,0,0,0,4,ambari-web/app/data/HDP2/global_properties.js;ambari-web/app/data/global_properties.js;ambari-web/app/data/service_configs.js;ambari-web/app/models/service.js;
3779,,Tom Beerbower,During cluster install cannot go past Step0,UI makes a call to http://c6401.ambari.apache.org:8080/api/v1/stacks2/HDP/versions?fields=Versions operatingSystems/repositories/Repositories.The API is missing the operatingSystems info  except for the suse11 one:{ 'href' : 'http://c6401.ambari.apache.org:8080/api/v1/stacks2/HDP/versions?fields=Versions operatingSystems/repositories/Repositories'  'items' : [ { 'href' : 'http://c6401.ambari.apache.org:8080/api/v1/stacks2/HDP/versions/1.2.0'  'Versions' : { 'active' : false  'min_upgrade_version' : null  'parent_stack_version' : null  'stack_name' : 'HDP'  'stack_version' : '1.2.0' }  'operatingSystems' : [ ] }  { 'href' : 'http://c6401.ambari.apache.org:8080/api/v1/stacks2/HDP/versions/1.2.1'  'Versions' : { 'active' : false  'min_upgrade_version' : null  'parent_stack_version' : null  'stack_name' : 'HDP'  'stack_version' : '1.2.1' }  'operatingSystems' : [ ] }  { 'href' : 'http://c6401.ambari.apache.org:8080/api/v1/stacks2/HDP/versions/1.3.0'  'Versions' : { 'active' : false  'min_upgrade_version' : null  'parent_stack_version' : null  'stack_name' : 'HDP'  'stack_version' : '1.3.0' }  'operatingSystems' : [ ] }  { 'href' : 'http://c6401.ambari.apache.org:8080/api/v1/stacks2/HDP/versions/1.3.2'  'Versions' : { 'active' : true  'min_upgrade_version' : null  'parent_stack_version' : null  'stack_name' : 'HDP'  'stack_version' : '1.3.2' }  'operatingSystems' : [ ] }  { 'href' : 'http://c6401.ambari.apache.org:8080/api/v1/stacks2/HDP/versions/1.3.3'  'Versions' : { 'active' : true  'min_upgrade_version' : null  'parent_stack_version' : null  'stack_name' : 'HDP'  'stack_version' : '1.3.3' }  'operatingSystems' : [ ] }  { 'href' : 'http://c6401.ambari.apache.org:8080/api/v1/stacks2/HDP/versions/2.0.5'  'Versions' : { 'active' : false  'min_upgrade_version' : null  'parent_stack_version' : null  'stack_name' : 'HDP'  'stack_version' : '2.0.5' }  'operatingSystems' : [ ] }  { 'href' : 'http://c6401.ambari.apache.org:8080/api/v1/stacks2/HDP/versions/2.0.6'  'Versions' : { 'active' : true  'min_upgrade_version' : null  'parent_stack_version' : null  'stack_name' : 'HDP'  'stack_version' : '2.0.6' }  'operatingSystems' : [ { 'href' : 'http://c6401.ambari.apache.org:8080/api/v1/stacks2/HDP/versions/2.0.6/operatingSystems/centos5'  'OperatingSystems' : { 'os_type' : 'centos5'  'stack_name' : 'HDP'  'stack_version' : '2.0.6' }  'repositories' : [ ] }  { 'href' : 'http://c6401.ambari.apache.org:8080/api/v1/stacks2/HDP/versions/2.0.6/operatingSystems/centos6'  'OperatingSystems' : { 'os_type' : 'centos6'  'stack_name' : 'HDP'  'stack_version' : '2.0.6' }  'repositories' : [ ] }  { 'href' : 'http://c6401.ambari.apache.org:8080/api/v1/stacks2/HDP/versions/2.0.6/operatingSystems/oraclelinux5'  'OperatingSystems' : { 'os_type' : 'oraclelinux5'  'stack_name' : 'HDP'  'stack_version' : '2.0.6' }  'repositories' : [ ] }  { 'href' : 'http://c6401.ambari.apache.org:8080/api/v1/stacks2/HDP/versions/2.0.6/operatingSystems/oraclelinux6'  'OperatingSystems' : { 'os_type' : 'oraclelinux6'  'stack_name' : 'HDP'  'stack_version' : '2.0.6' }  'repositories' : [ ] }  { 'href' : 'http://c6401.ambari.apache.org:8080/api/v1/stacks2/HDP/versions/2.0.6/operatingSystems/redhat5'  'OperatingSystems' : { 'os_type' : 'redhat5'  'stack_name' : 'HDP'  'stack_version' : '2.0.6' }  'repositories' : [ ] }  { 'href' : 'http://c6401.ambari.apache.org:8080/api/v1/stacks2/HDP/versions/2.0.6/operatingSystems/redhat6'  'OperatingSystems' : { 'os_type' : 'redhat6'  'stack_name' : 'HDP'  'stack_version' : '2.0.6' }  'repositories' : [ ] }  { 'href' : 'http://c6401.ambari.apache.org:8080/api/v1/stacks2/HDP/versions/2.0.6/operatingSystems/sles11'  'OperatingSystems' : { 'os_type' : 'sles11'  'stack_name' : 'HDP'  'stack_version' : '2.0.6' }  'repositories' : [ ] }  { 'href' : 'http://c6401.ambari.apache.org:8080/api/v1/stacks2/HDP/versions/2.0.6/operatingSystems/suse11'  'OperatingSystems' : { 'os_type' : 'suse11'  'stack_name' : 'HDP'  'stack_version' : '2.0.6' }  'repositories' : [ { 'href' : 'http://c6401.ambari.apache.org:8080/api/v1/stacks2/HDP/versions/2.0.6/operatingSystems/suse11/repositories/HDP-2.0.6'  'Repositories' : { 'base_url' : 'http://public-repo-1.hortonworks.com/HDP/suse11/2.x/updates/2.0.6.0'  'default_base_url' : 'http://public-repo-1.hortonworks.com/HDP/suse11/2.x/updates/2.0.6.0'  'mirrors_list' : null  'os_type' : 'suse11'  'repo_id' : 'HDP-2.0.6'  'repo_name' : 'HDP'  'stack_name' : 'HDP'  'stack_version' : '2.0.6' } } ] } ] } ]},1.4.2,1.4.2,438,1,0,0,0,0,0,29,ambari-server/src/main/java/org/apache/ambari/server/api/handlers/QueryCreateHandler.java;ambari-server/src/main/java/org/apache/ambari/server/api/query/QueryImpl.java;ambari-server/src/main/java/org/apache/ambari/server/api/resources/ResourceInstance.java;ambari-server/src/main/java/org/apache/ambari/server/api/services/persistence/PersistenceManagerImpl.java;ambari-server/src/main/java/org/apache/ambari/server/controller/AmbariManagementControllerImpl.java;ambari-server/src/main/java/org/apache/ambari/server/controller/OperatingSystemResponse.java;ambari-server/src/main/java/org/apache/ambari/server/controller/RepositoryResponse.java;ambari-server/src/main/java/org/apache/ambari/server/controller/RootServiceComponentResponse.java;ambari-server/src/main/java/org/apache/ambari/server/controller/RootServiceHostComponentResponse.java;ambari-server/src/main/java/org/apache/ambari/server/controller/StackConfigurationResponse.java;ambari-server/src/main/java/org/apache/ambari/server/controller/StackServiceComponentResponse.java;ambari-server/src/main/java/org/apache/ambari/server/controller/StackServiceResponse.java;ambari-server/src/main/java/org/apache/ambari/server/controller/StackVersionResponse.java;ambari-server/src/main/java/org/apache/ambari/server/controller/internal/ClusterResourceProvider.java;ambari-server/src/main/java/org/apache/ambari/server/controller/internal/OperatingSystemResourceProvider.java;ambari-server/src/main/java/org/apache/ambari/server/controller/internal/RepositoryResourceProvider.java;ambari-server/src/main/java/org/apache/ambari/server/controller/internal/RootServiceComponentResourceProvider.java;ambari-server/src/main/java/org/apache/ambari/server/controller/internal/RootServiceHostComponentResourceProvider.java;ambari-server/src/main/java/org/apache/ambari/server/controller/internal/RootServiceResourceProvider.java;ambari-server/src/main/java/org/apache/ambari/server/controller/internal/StackConfigurationResourceProvider.java;ambari-server/src/main/java/org/apache/ambari/server/controller/internal/StackResourceProvider.java;ambari-server/src/main/java/org/apache/ambari/server/controller/internal/StackServiceComponentResourceProvider.java;ambari-server/src/main/java/org/apache/ambari/server/controller/internal/StackServiceResourceProvider.java;ambari-server/src/main/java/org/apache/ambari/server/controller/internal/StackVersionResourceProvider.java;ambari-server/src/main/java/org/apache/ambari/server/controller/internal/TaskResourceProvider.java;ambari-server/src/test/java/org/apache/ambari/server/api/handlers/QueryCreateHandlerTest.java;ambari-server/src/test/java/org/apache/ambari/server/api/services/PersistenceManagerImplTest.java;ambari-server/src/test/java/org/apache/ambari/server/controller/internal/RepositoryResourceProviderTest.java;ambari-server/src/test/java/org/apache/ambari/server/controller/internal/StackResourceProviderTest.java;
3791,ambari-web,Antonenko Alexander,Provide add/remove/rename/duplicate actions in manage-config-groups dialog,Various config-group actions (add/remove/rename/duplicate) should be provided in the manage-config-groups dialog. Any of these should not rely on the Save button  but are immediately persisted via API.,1.4.2,1.4.2,27,0,0,0,0,0,0,0,
3793,ambari-agent,Vitaly Brodetskyi,Do not store disks_info in DB. Store it as dynamic info in memory that can be used to show on the UI.,Currently  we store disks info in DB and this information is never updated after registration. As disks details can change (space availability changes  disks get mounted/unmounted  etc.) the persisted information is not useful.We should instead hold the details in memory and refresh it at certain intervals (e.g. once every 10 minutes) and then alert if space availability hits some lower limit.,1.4.1,1.5.0,61,0,0,0,0,0,0,0,
3805,ambari-web,Oleg Nechiporenko,'Add service' if nothing to add,Disable and gray out the Add Services button if there aren't any more services to be added.Upon hover  show a tooltip saying 'No more services to be added'.Although we hide the 'Add Component' button when no more components are to be added  we don't actually like that and want to move towards 'disabling/graying out with hover tooltip' pattern.,1.5.0,1.5.0,58,0,0,0,0,0,0,0,
3815,ambari-web,Antonenko Alexander,Remove  Rename actions enabled for 'Default' config group,In the Manager Configuration Groups dialog I selected the Default config-group  and the actions to remove and rename config-group are enabled. These ops are not allowed for Default config-group.,1.4.3,1.4.3,29,0,0,0,0,0,0,0,
3824,ambari-web,Andrii Tkach,Provide change config-group action on host configs,On a host's configs page  provide a Change action beside config-group to switch from one group to another  or to Default.,1.4.1,1.4.3,21,0,0,0,0,0,0,5,ambari-web/app/controllers/main/host/configs_service.js;ambari-web/app/messages.js;ambari-web/app/templates/common/configs/service_config.hbs;ambari-web/app/utils/config.js;ambari-web/app/views/common/configs/services_config.js;
3836,ambari-web,Antonenko Alexander,Unable to close manage-config-groups dialog when only Default group present,I had only the Default config-group when I launched the manage config-groups dialog. When I clicked on Cancel or X  it would not close dialog with the following error:Uncaught TypeError: Cannot read property 'id' of null This was in method updateConfigGroupOnServicePage() at the first line belowselectedConfigGroup = managedConfigGroups.findProperty('id'  selectedConfigGroup.id); if(selectedConfigGroup){ mainServiceInfoConfigsController.set('selectedConfigGroup'  selectedConfigGroup); }else{ mainServiceInfoConfigsController.set('selectedConfigGroup'  managedConfigGroups.findProperty('isDefault'  true)); },1.4.3,1.4.3,73,0,0,0,0,0,0,0,
3838,ambari-web,Mikhail Bayuk,Services sidebar for host configs needs vertical gap,When you go to host configs page  there is no gap between the services sidebar and the tabs. This should be changed so that the config-group bar and services sidebar have the same gap from the tabs at top.,1.4.3,1.4.3,39,0,0,0,0,0,0,0,
3842,ambari-web,Andrii Babiichuk,Host configs page should properly order services,When App.supports.hostOverridesHost is enabled  and you visit the configs page for a host  the services are in some random order. They should be in the same order as the services page.Also  there is a small empty entry in the menu  which gives like a 5px extra space between some services. You can even hover on this empty entry and it will highlight.,1.4.3,1.4.3,62,0,0,0,0,0,0,5,ambari-web/app/mappers/service_mapper.js;ambari-web/app/models/service.js;ambari-web/app/utils/misc.js;ambari-web/app/views/main/host/configs_service_menu.js;ambari-web/app/views/main/service/menu.js;
3844,ambari-web,Aleksandr Kovalenko,Error in saving host for newly created config group,After creating new Config Group in Manage Configuration Groups dialog try to add host to this group and save. Also sometimes '+' button to add hosts is disabled for newly created group.,1.4.3,1.4.3,32,0,0,0,0,0,0,0,
3857,ambari-web,Oleg Nechiporenko,Clicking on Settings link navigates to login page for a non-admin user.,This happens because non-admin users are not authorized to make POST/PUT calls to any resource  including 'persist'.For now  let's hide 'Settings' if the user is a non-admin user.,1.4.2,1.4.2,28,0,0,0,0,0,0,0,
3864,ambari-web,Xi Wang,JS Error in 'Add Host Wizard' if we proceed with failed registered hosts,1. Add two hosts in Add Host Wizard.2. In Conform Hosts step  one registered successfully  the other failed.3. Proceed to next  JS error happened when deploy  wizard UI hang up.,1.4.2,1.4.2,30,0,0,0,0,0,0,0,
3868,ambari-web,Jaimin D Jetly,Add host fails after configuring NN HA with JavaScript error,,1.4.2,1.4.2,1,0,0,0,0,0,0,1,ambari-web/app/models/service_config.js;
3873,ambari-server,Eugene Chekanskiy,Unittests for User resource an all it's attributes,Test resource User of resource management . Test all actions and all the attributes. Please make sure we mock to check both cases when user already exists and when it's not.Note here we should not call directly provider methods like action_create  but make resource management library do that for us  by calling env.run(). In other case test won't cover resources definitions  and other import logic,1.5.0,1.5.0,65,0,0,0,0,0,0,0,
3877,ambari-web,Andrii Babiichuk,Duplicate config-group action not duplicate configs,Override like 3 configs in a config group and save. Now go to the Manage Config Groups dialog and select this group and click on Duplicate action. A popup with name and description pops up and hitting OK creates the duplicated config group.Though this duplicated config group has the correct name/description  it does not have the duplicated configs (3 that we overrode). When doing the POST call  we should populate the desired_configs to be the exact same as the source config-group.,1.4.3,1.4.3,81,0,0,0,0,0,0,2,ambari-web/app/controllers/main/service/manage_config_groups_controller.js;ambari-web/app/utils/ajax.js;
3878,ambari-web,Xi Wang,ResourceManager Heap metrics is not correct on Ambari console,PROBLEM: The ResourceManager Heap metrics on Ambari web console doesn't show the correct value  not only the current heap usage doesn't reflect the correct usage  but also the total heap size doesn't match what we configure for the ResourceManager Heap size  even the total heap size number is changing constantly.,1.4.2,1.4.2,50,0,0,0,0,0,0,0,
3881,ambari-web,Jaimin D Jetly,UI incorrect behavior during upgrade,This issue was discovered while upgrading the cluster to hash 87adc8c2d29b20a30f01e54c12f67dcbbe34b32e of 1.4.2 branch. The logic inside configuration_controller.js function getConfigsByTags(tagObject) has a reference to undefined variable and js error was encountered. This happened when any of the service page was rendered and program flow from quick_view_link_view.js function didInsertElement() -&gt; setQuickLinks() -&gt; loadTags() -&gt; loadTagsSuccess(data) -&gt; getSecurityProperties() -&gt; configurationController.getConfigsByTags(tag),1.4.2,1.4.2,58,0,0,0,0,0,0,0,
3882,ambari-web,Xi Wang,Background operations popup window minimum size should be fixed when narrowing down the browser,,1.4.2,1.4.2,1,0,0,0,0,0,0,0,
3888,ambari-web,Denys Buzhor,Incorrect restart required tooltip view,When components and hosts required to restart we show refresh icon near the service name. On icon hover event we show tooltip with count of components and hosts.,1.4.3,1.4.3,28,0,0,0,0,0,0,0,
3890,ambari-web,Denys Buzhor,Background operations: two scrollbars  if width is lower then 1450px,Screenshot attached.,1.4.3,1.4.3,2,0,0,0,0,0,0,0,
3897,ambari-web,Srimanth Gunturi,Restart indicator flags not showing up for HDP 1.3.x stack services,When config-groups are used for HDP 1.3.x stack services  the stale_configs are always false.,1.4.3,1.4.3,14,0,0,0,0,0,0,0,
3899,ambari-web,Jaimin D Jetly,'HDFS Short-circuit read' config property is repeated,,1.4.2,1.4.2,1,0,0,0,0,0,0,1,ambari-web/app/data/HDP2/global_properties.js;
3900,ambari-web,Jeff Sposetti,Modify messages from 'reassign master' to 'move master',,1.4.2,1.4.2,1,0,0,0,0,0,0,0,
3911,ambari-web,Srimanth Gunturi,Security Wizard: Service Configuration page is broken,Trying to enable security  the configurations page is blank.,1.4.3,1.4.3,9,0,0,0,0,0,0,0,
3914,ambari-web,Andrii Tkach,Add Host wizard stuck on configuration step,Cluster should have service(HDFS PIG SQOOP) which doesn't have any slave or client host-components.1. Run Add Host wizard2. Proceed to configuration stepResult: Wizard popup stuck in loading processJS error:Uncaught TypeError: Cannot call method 'get' of undefined app.js:10245(anonymous function) app.js:10245App.AddHostController.App.WizardController.extend.loadServiceConfigGroups app.js:10242(anonymous function) app.js:43659f.Callbacks.o vendor.js:95f.Callbacks.p.add vendor.js:95(anonymous function) app.js:43657f.Callbacks.o vendor.js:95f.Callbacks.p.fireWith vendor.js:95f.Callbacks.p.fire vendor.js:95(anonymous function),1.4.3,1.4.3,55,0,0,0,0,0,0,3,ambari-web/app/controllers/main/host/add_controller.js;ambari-web/app/mappers/server_data_mapper.js;ambari-web/app/mappers/status_mapper.js;
3921,ambari-web,Andrii Tkach,Hovers stay after manage-config-groups dialog is closed,I opened the manage-config-groups dialog and hovered on one of the actions (remove host from config-group). Then I saved or cancelled to close the dialog. The hover still remains in the middle of page.I have seen this in other usages as well. We need to make sure that all hovers are closed when the focus is lost.,1.4.3,1.4.3,57,0,0,0,0,0,0,14,ambari-web/app/controllers/wizard/step3_controller.js;ambari-web/app/utils/helper.js;ambari-web/app/views/common/configs/services_config.js;ambari-web/app/views/main/dashboard/service.js;ambari-web/app/views/main/dashboard/service/yarn.js;ambari-web/app/views/main/dashboard/widget.js;ambari-web/app/views/main/host.js;ambari-web/app/views/main/host/details.js;ambari-web/app/views/main/host/summary.js;ambari-web/app/views/main/service.js;ambari-web/app/views/main/service/info/summary.js;ambari-web/app/views/main/service/manage_config_groups_view.js;ambari-web/app/views/main/service/menu.js;ambari-web/app/views/wizard/step6_view.js;
3925,ambari-web,Antonenko Alexander,Adding host to multiple groups at the same time fails,Steps:1. Create 2 config groups2. Rename 1 config group3. Add hosts to renamed config group4. Add host to other config group.Result:Save stops working. Error in the JS console.Error in JS console:Uncaught TypeError: Cannot call method 'sort' of undefined manage_config_groups_controller.js:460(anonymous function) manage_config_groups_controller.js:460(anonymous function) manage_config_groups_controller.js:458ComputedPropertyPrototype.get ember-latest.js:2949get ember-latest.js:1355getPath ember-latest.js:1477get ember-latest.js:1348Ember.Observable.Ember.Mixin.create.get ember-latest.js:7695App.ModalPopup.show.onPrimary item.js:251newFunc ember-latest.js:949ActionHelper.registeredActions.(anonymous function).handler ember-latest.js:19458(anonymous function) ember-latest.js:11250f.event.dispatch jquery-1.7.2.min.js:3h.handle.i,1.4.3,1.4.3,62,0,0,0,0,0,0,0,
3930,ambari-web,Andrii Tkach,Missing host message on cluster deploy,When execute any service check  host message become empty. Server return  unsupported on UI  command of task - 'SERVICE_CHECK'.,1.4.3,1.4.3,19,0,0,0,0,0,0,1,ambari-web/app/controllers/wizard/step9_controller.js;
3938,ambari-web,Yusaku Sako,JS error when switching config groups in Hive / Oozie service config pages,,1.4.3,1.4.3,1,0,0,0,0,0,0,0,
3953,ambari-agent,Dmytro Sen,HBase Master alerts are confusing in multi-master environment,When multiple HBase Masters are set up  HBase service-level alert section shows multiples of the following: HBase Master process HBase Master Web UI HBase Master CPU utilizationThe label is exactly the same for all masters  so you can't distinguish which alert is for which master. Ambari should mirror what ambari does for NameNode alerts so that the user can tell them apart (append hostname in the alert label).,1.4.2,1.4.2,70,0,0,0,0,0,0,1,ambari-agent/src/main/puppet/modules/hdp-nagios/templates/hadoop-services.cfg.erb;
3954,ambari-web,Oleg Nechiporenko,hbase.zookeeper.quorum changing inconsistently on hosts after adding ZookeeperServer,Issue 1:Steps followed: 1. Install a 3-node cluster with Hbase and Zookeeper and 3 zookeeper servers. 2. After installation on each host the property hbase.zookeeper.quorum in /etc/hbase/conf/hbase-site.xml has:&lt;name&gt;hbase.zookeeper.quorum&lt;/name&gt; &lt;value&gt;c6401.ambari.apache.org c6402.ambari.apache.org c6403.ambari.apache.org&lt;/value&gt;3. After adding a host with Hbase Region Server  and after that a ZookeeperServer to it  the property on the added c6404.ambari.apache.org host has the same value  as in 2. 4. After restarting HBase master on c6401 (which is proposed by UI)  the property value on c6401 becomes:  &lt;name&gt;hbase.zookeeper.quorum&lt;/name&gt; &lt;value&gt;c6401.ambari.apache.org&lt;/value&gt;. On other hosts it remains unchanged. 5. After restarting HbaseRegionServers on the rest of the hosts (not proposed by ui)  the property changes too  to the same value  as in 4. __________________________________________________________Issue 2:Property templeton.zookeeper.hosts in /etc/hcatalog/conf/webhcat-site.xmlPrior to adding a zookeeperServer on host c6404  config on WebHCat server lookes like:[root@c6402 vagrant]# cat /etc/hcatalog/conf/webhcat-site.xml |grep templeton.zookeeper.hosts -C 2 &lt;configuration&gt; &lt;property&gt; &lt;name&gt;templeton.zookeeper.hosts&lt;/name&gt; &lt;value&gt;c6401.ambari.apache.org:2181 c6402.ambari.apache.org:2181 c6403.ambari.apache.org:2181&lt;/value&gt; &lt;/property&gt;After adding a ZookeeperServer on c6404 and restarting WebHCatServer on c6402: [root@c6402 vagrant]# cat /etc/hcatalog/conf/webhcat-site.xml |grep templeton.zookeeper.hosts -C 2 &lt;/property&gt; &lt;property&gt; &lt;name&gt;templeton.zookeeper.hosts&lt;/name&gt; &lt;value&gt;c6401.ambari.apache.org&lt;/value&gt; &lt;/property&gt;__________________________________________________________Issue 3. On a 3-node cluster with HA-enbaled  property ha.zookeeper.quorum in /etc/hadoop/conf/core-site.xml  has the same value on all hosts:  &lt;name&gt;ha.zookeeper.quorum&lt;/name&gt; &lt;value&gt;c6401.ambari.apache.org:2181 c6402.ambari.apache.org:2181 c6403.ambari.apache.org:2181&lt;/value&gt;It doesn't change on either of the hosts after adding c6404 to the cluster  installing ZookeeperServer on it and restarting HDFS.,1.4.2,1.4.2,235,0,0,0,0,0,0,0,
3981,ambari-server,Artem Baranchuk,Services mysteriously disappear after Stack upgrade,,1.4.2,1.4.2,1,0,0,0,0,0,0,0,
3982,ambari-web,Xi Wang,Background operations window  called from wizard doesn't react to 'Do not show this dialog...' flag,STR:Go through the Reassign NameNode wizard.On the last step click on the Start All Services link.Change the state of flag Do not show this dialog again when starting a background operation.Click OK.Click Start All Services link again.Result: State of flag was not changed.,1.4.2,1.4.3,43,0,0,0,0,0,0,0,
3984,ambari-web,Xi Wang,Config Groups: Background popup show up needs to be integrated when restarting components,1. Change config group for a service.2. Click 'Stop components' on service config page.3. Click 'Start components' on the same page.Actual results:Background Operations popup will always show up. (as attached)Expected results:Load the 'do not show this dialog..' flag first  then determine if show this popup.,1.4.2,1.4.3,45,0,0,0,0,0,0,0,
3986,ambari-web,Denys Buzhor,YARN and MapReduce2 configs is not displayed,In Services -&gt; Configs YARN and MapReduce2 configs is not displayed.,1.4.3,1.4.3,11,0,0,0,0,0,0,0,
3987,,Tom Beerbower,Resource providers are set with wrong stack version.,AbstractProviderModule.updateClusterVersion sets the cluster version for the resource providers with the following ... PropertyHelper.MetricsVersion version = clusterVersion.startsWith('HDP-1') ? PropertyHelper.MetricsVersion.HDP1 : PropertyHelper.MetricsVersion.HDP2;So  the Cluster/version property set to 'HDPLocal-1.3.2' will incorrectly be detected as HDP2. This causes the property providers to use the wrong metric mapping files which causes many JMX properties not to be set properly.,1.4.2,1.4.2,63,0,0,0,0,0,0,2,ambari-server/src/main/java/org/apache/ambari/server/controller/internal/AbstractProviderModule.java;ambari-server/src/test/java/org/apache/ambari/server/controller/internal/AbstractProviderModuleTest.java;
3991,ambari-web,Andrii Babiichuk,Manage config group links needed in save config-group confirmation,When any service config-group is saved  we have a confirmation popup saying save was successful. We should enhance that popup to have a button to Manage Config Groups dialog  along with appropriate message. When button is clicked  the popup should go away and the Manage Config Groups dialog should show.,1.4.3,1.4.3,50,0,0,0,0,0,0,4,ambari-web/app/messages.js;ambari-web/app/styles/application.less;ambari-web/app/templates/common/configs/saveConfigGroup.hbs;ambari-web/app/utils/config.js;
3992,ambari-web,Oleg Nechiporenko,After making config changes w/o saving  prompt user if they try to navigate away,1) Browse to Services &gt; HDFS &gt; Configs2) Change some props3) Do not click save4) Browse away  to Summary or to another serviceUser would have lost config changes. We should prompt before allowing user to navigate away from Configs.'You have unsaved changes. Save changes or discard?'&#91;Discard&#93; &#91;Save&#93;,1.4.3,1.4.3,49,0,0,0,0,0,0,0,
3997,ambari-server,Siddharth Wagle,Config-Group POST call should tolerate name reuse,Cluster wide we prohibit reuse of config-group name. However names can be reused across services. The API should be updated to tolerate POST/PUT of similar named config-groups.,1.4.3,1.4.3,27,0,0,0,0,0,0,0,
3999,ambari-web,Xi Wang,Long host names are inconvenient for viewing in background operations popup,Steps: Open background operations window and select any operation.Result: If the host name is too long  they are not placed on designated place.Solution:If the host name is too long  we show part of the string with '...' at the end.Also the string should keep in a single line all the time,1.4.2,1.4.3,51,0,0,0,0,0,0,0,
4003,ambari-web,Denys Buzhor,Add Service Wizard: Customize Services configs are not displayed.,In 'Customize services' step in 'Add Service Wizard' config group and configs are not displayed. See screenshot.,1.4.3,1.4.3,17,0,0,0,0,0,0,4,ambari-web/app/controllers/installer.js;ambari-web/app/controllers/main/service/add_controller.js;ambari-web/app/controllers/wizard.js;ambari-web/app/routes/add_service_routes.js;
4004,ambari-web,Andrii Tkach,Duplicate hosts after closing addServiceWizard,Install cluster with 2 hosts (with HDFS  ZooKeeper).Go to Add Service Wizard.Select some configurable service.Go to Step 4 (Customize services).Close wizard.Go to Hosts page.Result:each host appears two times.,1.4.3,1.4.3,28,0,0,0,0,0,0,1,ambari-web/app/controllers/wizard/step7_controller.js;
4012,ambari-web,Xi Wang,NameNode max heap is not showing in HDP 1.3.2 stack,Reason:We use in-consistent value to show Heap size for different components.And some of them are missing.Solution:Make sure all Heap size percentage value (including NN  RM  JT and HBase Master) use the same property.,1.4.2,1.4.2,33,0,0,0,0,0,0,0,
4024,,Mahadev konar,HiveSchema file for Hive should be hive-schema-0.12.0.oracle.sql,HiveSchema file for Hive should be hive-schema-0.12.0.oracle.sql,1.4.2,1.4.2,7,0,0,0,0,0,0,0,
4028,ambari-web,Andrii Tkach,Dashboard quick links polls desired_configs every 6s,On the dashboard  calls to /clusters/{clusterName}?fields=Clusters/desired_configs are made every 6s. We need to verify if this really is necessary. Initial investigation revealed calls from quick-links  where links were set based on security being enabled. But there is no need to poll every 6s for this.,1.4.3,1.4.3,52,0,0,0,0,0,0,1,ambari-web/app/views/common/quick_view_link_view.js;
4040,ambari-web,Aleksandr Kovalenko,In installer  behavior of actions in manage config-groups dialog different from reconfigure,During reconfigure  in the Manage Config Groups dialog  the actions below the config-groups table (left table - Add/Remove/Duplicate/Rename) are immediate - you do not need to hit Save. Save is only for host membership changes. If host membership changes  the actions under left-table are disabled till Save. During install however  all actions are allowed till Save is hit. If you rename/duplicate and hit Cancel  all changes are lost - something which does not happen during reconfigure.The installer dialog should have similar behavior to reconfigure dialog.,1.4.3,1.4.3,85,0,0,0,0,0,0,0,
4044,ambari-web,Oleg Nechiporenko,Refactor templates and popups,,1.4.3,1.4.3,1,0,0,0,0,0,0,0,
4048,ambari-web,Mikhail Bayuk,Minor manage-config-group dialog UI changes,Label on top of left hand config-group table should be removed Left hand table and right hand table should occupy 1/3 and 2/3 of the dialog.,1.4.3,1.4.3,27,0,0,0,0,0,0,0,
4052,ambari-web,Denys Buzhor,Rename config-group dialog should allow only description change also,We wanted to change just the config-group description  but were unable to change without changing the name. The rename config-group dialog should allow changing description only also.,1.4.3,1.4.3,28,0,0,0,0,0,0,0,
4054,ambari-web,Oleg Nechiporenko,Need to show stale-config indicator on hosts page,We show the restart indicator for stale-configs on services and individual host. Since we already have that information on the client  we need to show that on the Hosts page table. We need a filter to select stale-config hosts  and also show beside each host the stale-config indicator.,1.4.3,1.4.3,48,0,0,0,0,0,0,0,
4058,ambari-server,Sumit Mohanty,ambari-agent/server should start automatically upon reboot,ambari-agent and server are not set to start automatically  so if a machine reboots it becomes inaccessible.,1.4.3,1.4.3,17,0,0,0,0,0,0,0,
4069,ambari-web,Xi Wang,Add hosts  if using Local Repository  UI incorrectly says 'no',On review page of install wizard/add host wizard -List the repos with their OS-Say 'Repositories'  not 'Local Repository'-Not a yes or no,1.4.2,1.4.3,21,0,0,0,0,0,0,0,
4076,ambari-web,Mikhail Bayuk,Installer's host list doesn't show masters at top,Installer's host list should show masters at top,1.2.3,1.5.0,8,0,0,0,0,0,0,0,
4089,ambari-web,Oleg Nechiporenko,HDFS/ZKFC relations in EmberData,After enabling HA go to hosts page.Open host's page for host that has ZKFC.ZKFC doesn't have service.Expect:ZKFC should have HDFS as service.,1.4.3,1.4.3,22,0,0,0,0,0,0,0,
4092,ambari-web,Andrii Babiichuk,Need tooltip showing error why local repo is bad,I selected HDP 2.0.8 stack and Centos5 base-url was bad. The reason was given in the response - but it is not shown anywhere in UI. On the red exclamation mark we need a tooltip showing the error message from server along with HTTP error code.,1.4.3,1.4.3,46,0,0,0,0,0,0,4,ambari-web/app/controllers/installer.js;ambari-web/app/templates/wizard/step1.hbs;ambari-web/app/views/wizard/step1_view.js;ambari-web/app/controllers/installer.js;
4104,ambari-agent,Dmytro Sen,TestHardware.test_fqdnDomainHostname() fails,The unit test failsFAIL: test_fqdnDomainHostname (TestHardware.TestHardware)----------------------------------------------------------------------Traceback (most recent call last): File '/home/dmitry/incubator-ambari/ambari-common/src/test/python/mock/mock.py'  line 1199  in patched return func(*args  **keywargs) File '/home/dmitry/incubator-ambari/ambari-agent/src/test/python/ambari_agent/TestHardware.py'  line 83  in test_fqdnDomainHostname self.assertEquals(result['hostname']  'ambari')AssertionError: 'dmitry-pc' != 'ambari',1.5.0,1.5.0,36,0,0,0,0,0,0,1,ambari-agent/src/test/python/ambari_agent/TestHardware.py;
4106,ambari-web,Andrii Babiichuk,Should not allow blank config group name,1) Create config group2) just enter a &lt;space&gt; for the name3) That enables the OK button to save4) You can save that config group w/o a name.is reproducible on installer (works fine after installation),1.4.3,1.4.3,34,0,0,0,0,0,0,1,ambari-web/app/controllers/main/service/manage_config_groups_controller.js;
4118,ambari-web,Oleg Nechiporenko,Manage Config Group link appears on host detail page (and cannot dismiss it once opened),,1.4.3,1.4.3,1,0,0,0,0,0,0,0,
4129,ambari-web,Jaimin D Jetly,HA wizard not accessible after upgrade,,1.4.3,1.4.3,1,0,0,0,0,0,1,6,ambari-web/app/controllers/main/admin/highAvailability_controller.js;ambari-web/app/controllers/main/host/details.js;ambari-web/app/controllers/main/service.js;ambari-web/app/controllers/main/service/item.js;ambari-web/app/routes/main.js;ambari-web/app/utils/db.js;
4132,ambari-server,Siddharth Wagle,Stale config indicator not shown when reconfiguring WebHCat  Ganglia  Nagios  ZooKeeper,Steps: Create a config group for any of the mentioned services and add a host to the config group. Save the config group.Result:Restart indicators do not appear.,1.4.3,1.4.3,29,0,0,0,0,0,0,0,
4135,ambari-web,Oleg Nechiporenko,Review page doesn't have info about Repositories,Load Repositories info in the same way as for add Host Wizard.,1.5.0,1.5.0,12,0,0,0,0,0,0,0,
4145,ambari-agent; ambari-server,Dmytro Sen,Ability to restart a component,Add option to Actions menu for 'restart'. That should queue the stop and start tasks.We should assume 'RESTART' as a default command. The base/default implementation is to call STOP and then START.,1.4.1,1.5.0,32,0,0,0,0,0,0,12,ambari-agent/src/main/python/ambari_agent/CustomServiceOrchestrator.py;ambari-agent/src/main/python/resource_management/libraries/script/script.py;ambari-server/src/main/java/org/apache/ambari/server/RoleCommand.java;ambari-server/src/main/java/org/apache/ambari/server/agent/ExecutionCommand.java;ambari-server/src/main/java/org/apache/ambari/server/agent/HeartBeatHandler.java;ambari-server/src/main/java/org/apache/ambari/server/controller/AmbariCustomCommandExecutionHelperImpl.java;ambari-server/src/main/java/org/apache/ambari/server/metadata/ActionMetadata.java;ambari-server/src/main/java/org/apache/ambari/server/state/ComponentInfo.java;ambari-server/src/main/resources/stacks/HDP/2.0._/services/HBASE/metainfo.xml;ambari-server/src/main/resources/stacks/HDP/2.0._/services/HBASE/package/scripts/hbase_regionserver.py;ambari-server/src/test/java/org/apache/ambari/server/agent/TestHeartbeatHandler.java;ambari-server/src/test/java/org/apache/ambari/server/api/util/StackExtensionHelperTest.java;
4152,contrib,Oleg Nechiporenko,Service Config page shows a blank page after enabling security (JS error),UI don't respond after enabling security,1.4.3,1.4.3,6,0,0,0,0,0,0,0,
4171,ambari-web,Oleg Nechiporenko,Fix UI Unit tests,,1.5.0,1.5.0,1,0,0,0,0,0,0,0,
4177,ambari-agent,Dmytro Shkvyra,YARN check execute fails on install,YARN check execute fails on install. See attached logs.IP Address on Hosts Page is shown as OS NOT SUPPORTED (w/o js errors  cluster installed using regular Nano-CentOS5.9 image type),1.4.3,1.4.3,29,0,0,0,0,0,0,0,
4184,,Mahadev konar,Fix versions of rpms in the stack to match the installed ones.,Fix versions of rpms in the stack to match the installed ones.,1.4.3,1.4.3,12,0,0,0,0,0,0,0,
4186,ambari-web,Oleg Nechiporenko,Global configs are not sent to server,On the Deploy step Global Configs are not sent to server.So  Nagios and Ganglia (if installed via add service wizard) don't have any configs in service config page.,1.5.0,1.5.0,28,0,0,0,0,0,0,0,
4195,ambari-web,Andrii Babiichuk,Misalignment of 'Filter' combobox on installer when browser window is narrow,,1.4.3,1.4.3,1,0,0,0,0,0,0,2,ambari-web/app/styles/application.less;ambari-web/app/templates/common/configs/service_config.hbs;
4200,ambari-web,Jeff Sposetti,Minor UI cleanup - remove double-borders  reduce text,Remove double borders on alerts and host component page sections Remove some text to not wrap in 'delete host' dialog Remove 'Hosts' table header to clean-up config group dialog,1.4.2,1.5.0,32,0,0,0,0,0,0,3,ambari-web/app/messages.js;ambari-web/app/styles/application.less;ambari-web/app/templates/main/service/manage_configuration_groups_popup.hbs;
4206,ambari-server,Sumit Mohanty,Significant lag between host status update and slave/master component start/stop,Steps: Go to any host with slave component (DataNode  for example). Click 'Stop' options for slave component.Result: status marker for slave component start blinking red  but status marker for host behaves strangely: sometimes it also start blinking red immediately/ sometimes changes status to not-blinking red only after slave component stopping will be ended.The same for slave component starting.,1.4.3,1.5.0,58,0,0,0,0,0,0,0,
4207,ambari-web,Andrii Babiichuk,Frontend: History server should be managed as separate component,For stack 1.x history server will be as separate master component. Add ability to choose host on which this component will be installed. Set value for 'mapreduce.history.server.http.address'  i.e. &lt;historyserverHost&gt;:&lt;historyServerPort&gt;.,1.2.4,1.5.0,29,0,0,0,0,0,0,9,ambari-web/app/controllers/main/admin/security/add/step2.js;ambari-web/app/controllers/main/service/info/configs.js;ambari-web/app/data/global_properties.js;ambari-web/app/data/service_components.js;ambari-web/app/data/service_configs.js;ambari-web/app/mappers/server_data_mapper.js;ambari-web/app/mappers/service_metrics_mapper.js;ambari-web/app/models/service/mapreduce.js;ambari-web/app/models/service_config.js;
4211,ambari-web,Andrii Tkach,Empty content of review step in Add Host wizard,JS error: Uncaught TypeError: Cannot call method 'forEach' of undefined,1.4.3,1.4.3,17,0,0,0,0,0,0,1,ambari-web/app/controllers/wizard/step8_controller.js;
4217,ambari-web,Aleksandr Kovalenko,Mirroring page redesign,Redesign existing Mirroring page with datasets table according to new attached mockups.,1.5.0,1.5.0,12,0,0,0,0,0,0,0,
4220,ambari-web,Jeff Sposetti,Padding for config override properties,,1.4.3,1.5.0,1,0,0,0,0,0,0,0,
4224,ambari-server,Sumit Mohanty,When issuing Start/Stop of host components then predicate stale_config=true does not work,See the series of curl calls below.There are no components with stale configs but 4 components are being stopped. There are only 4 because Ambari only allows INSTALL call on already installed clients[root@c6401 vagrant]# curl -i -uadmin:admin -H 'X-Requested-By: ambari' http://c6401.ambari.apache.org:8080/api/v1/clusters/c1/host_components?HostRoles/stale_configs=true{ 'href' : 'http://c6401.ambari.apache.org:8080/api/v1/clusters/c1/host_components?HostRoles/stale_configs=true'  'items' : [ ]}[root@c6401 vagrant]# curl -i -uadmin:admin -H 'X-Requested-By: ambari'-d '{'HostRoles': { 'state': 'INSTALLED'}}' -X PUT http://c6401.ambari.apache.org:8080/api/v1/clusters/c1/host_components?HostRoles/stale_configs=true{ 'href' : 'http://c6401.ambari.apache.org:8080/api/v1/clusters/c1/requests/14'  'Requests' : { 'id' : 14  'status' : 'InProgress' }}[root@c6401 vagrant]# curl -i -uadmin:admin -H 'X-Requested-By: ambari' http://c6401.ambari.apache.org:8080/api/v1/clusters/c1/requests/14{ 'href' : 'http://c6401.ambari.apache.org:8080/api/v1/clusters/c1/requests/14'  'Requests' : { 'aborted_task_count' : 0  'cluster_name' : 'c1'  'completed_task_count' : 0  'failed_task_count' : 0  'id' : 14  'progress_percent' : 9.0  'queued_task_count' : 4  'request_context' : ''  'request_status' : 'PENDING'  'task_count' : 4  'timed_out_task_count' : 0 }  'tasks' : [ { 'href' : 'http://c6401.ambari.apache.org:8080/api/v1/clusters/c1/requests/14/tasks/178'  'Tasks' : { 'cluster_name' : 'c1'  'id' : 178  'request_id' : 14 } }  { 'href' : 'http://c6401.ambari.apache.org:8080/api/v1/clusters/c1/requests/14/tasks/179'  'Tasks' : { 'cluster_name' : 'c1'  'id' : 179  'request_id' : 14 } }  { 'href' : 'http://c6401.ambari.apache.org:8080/api/v1/clusters/c1/requests/14/tasks/180'  'Tasks' : { 'cluster_name' : 'c1'  'id' : 180  'request_id' : 14 } }  { 'href' : 'http://c6401.ambari.apache.org:8080/api/v1/clusters/c1/requests/14/tasks/181'  'Tasks' : { 'cluster_name' : 'c1'  'id' : 181  'request_id' : 14 } } ]},1.4.3,1.4.3,217,0,0,0,0,0,0,0,
4225,ambari-web,Yusaku Sako,Starting/Stopping components based on restart indicator floods request history and execution queue,When starting/stopping components based on the Start/Stop Components buttons that show up after service reconfiguration  it creates one request per component (as shown in the Background Operations popup). This floods the request history and the user cannot see what has been done prior. From the user's standpoint  Start Components and Stop Components actions should each show up as one request.Also  this has major performance implications  since multiple requests cannot be processed in parallel by the server (unlike tasks within a single request).,1.4.3,1.4.3,82,0,0,0,0,1,0,0,
4231,ambari-web,Denys Buzhor,Storm: Update Dashboard / Services to support Storm,Define mock data and make this functional in App.testMode.E2E integration will be a separate task.,1.5.0,1.5.0,15,0,0,0,0,0,0,2,ambari-web/app/assets/data/services/HDP2/services.json;ambari-web/app/models/service.js;
4247,ambari-web,Andrii Tkach,Restart marker does not show up sometimes in the Hosts page,After reconfiguring  restart indicators do not show up on the Host pages sometimes.Clicking on an individual host shows the restart indicator in the Host Details page.,1.4.3,1.5.0,27,0,0,0,0,0,0,3,ambari-web/app/controllers/global/update_controller.js;ambari-web/app/models/host.js;ambari-web/app/views/main/host.js;
4265,,Jeff Sposetti,Add env AMBARI_JVM_ARGS to ambari-server start,Useful if you want to set AMBARI_JVM_ARGS in the environment. For example: Setting http proxy that Ambari Serverexport AMBARI_JVM_ARGS='-Dhttp.proxyHost=the.proxy.host -Dhttp.proxyPort=1234'ambari-server start,1.4.3,1.5.0,28,0,0,0,0,0,0,0,
4279,ambari-agent; test,Dmitry Lysnichenko,Status commands are not executed for new services,For new services (those  that are not hardcoded at LiveStatus.py)  status commands are not executed.,1.5.0,1.5.0,15,0,0,0,0,0,0,0,
4284,ambari-web,Oleg Nechiporenko,Alerts  Restart  Maintenance elements in the Hosts filters,Move this 3 elements to the second line (under All  Healthy...).Also refactor their code-realization.,1.5.0,1.5.0,14,0,0,0,0,0,0,0,
4299,ambari-server,Myroslav Papirkovskyy,Ambari server unit test failure,Results :Failed tests: testDoWork(org.apache.ambari.server.state.scheduler.BatchRequestJobTest): (..)Tests run: 1265  Failures: 1  Errors: 0  Skipped: 8,1.5.0,1.5.0,19,0,0,0,0,0,0,0,
4300,ambari-web,Andrii Tkach,Service tab: growing number of calls to update alerts,After routing by services on Service page number of calls to server(to get Alerts) grows.Also mock json with alerts need to be added.,1.5.0,1.5.0,23,0,0,0,0,0,0,7,ambari-web/app/assets/data/alerts/HDP2/alerts.json;ambari-web/app/assets/data/alerts/HDP2/host_alerts.json;ambari-web/app/assets/data/alerts/HDP2/service_alerts.json;ambari-web/app/assets/data/hosts/HDP2/hosts.json;ambari-web/app/assets/data/services/HDP2/services.json;ambari-web/app/controllers/main/alerts_controller.js;ambari-web/app/utils/ajax.js;
4306,ambari-server,Siddharth Wagle,Request Schedule status not updated for Point in time execution request,API call:curl -u admin:admin -H 'X-Requested-By:ambari' -i -X POST -d '[{'RequestSchedule':{'batch':[{'requests':[{'order_id' : '1' 'type':'POST' 'uri':'/api/v1/clusters/c1/requests' 'RequestBodyInfo':{'RequestInfo':{'context':'Restart Nagios' 'command':'RESTART' 'service_name':'NAGIOS' 'component_name':'NAGIOS_SERVER' 'hosts':'c6401.ambari.apache.org'}}}]} {'batch_settings':{'batch_separation_in_seconds':120 'task_failure_tolerance':1}}]}}]' http://c6401.ambari.apache.org:8080/api/v1/clusters/c1/request_schedulesRequest Schedule:{href: 'http://c6401.ambari.apache.org:8080/api/v1/clusters/c1/request_schedules/23' RequestSchedule: {batch: {batch_requests: [{order_id: 1 request_type: 'POST' request_uri: '/api/v1/clusters/c1/requests' request_body: '{'RequestInfo':{'context':'Restart Nagios' 'command':'RESTART' 'service_name':'NAGIOS' 'component_name':'NAGIOS_SERVER' 'hosts':'c6401.ambari.apache.org'}}' request_status: 'InProgress' return_code: 202}] batch_settings: {batch_separation_in_seconds: 120 task_failure_tolerance_limit: 1}} cluster_name: 'c1' description: null id: 23 last_execution_status: 'InProgress' schedule: null status: 'SCHEDULED'}},1.5.0,1.5.0,98,0,0,0,0,0,0,0,
4312,ambari-web,Denys Buzhor,Storm: Install wizard. Add master components Storm UI Server  DRPC Server  LogViewer Server,Add new master components to Install Wizard -&gt; Assign Masters page.,1.5.0,1.5.0,11,0,0,0,0,0,0,9,ambari-web/app/assets/data/configurations/cluster_level_configs.json;ambari-web/app/controllers/wizard/step5_controller.js;ambari-web/app/data/HDP2/global_properties.js;ambari-web/app/data/service_components.js;ambari-web/app/data/service_configs.js;ambari-web/app/mappers/server_data_mapper.js;ambari-web/app/models/host_component.js;ambari-web/app/models/quick_links.js;ambari-web/app/models/service_config.js;
4316,ambari-web,Denys Buzhor,Storm: Add Storm UI Server  DRPC Server  LogViewer Server components config categories.,Add master components Storm UI Server  DRPC Server  Log Viewer Server. Create config categories for components. Replace exist configs according to categories.,1.5.0,1.5.0,22,1,0,0,0,0,0,2,ambari-web/app/data/HDP2/site_properties.js;ambari-web/app/utils/helper.js;
4318,ambari-web,Oleg Nechiporenko,Service Restart All action cleanup,1. There is no need to send request to restart clients.2. When user clicks on Restart All actions  components start restarting immediately. But all other actions shows confirmation popup like 'Are you sure?' (Start  Stop  Run Service Check etc).,1.5.0,1.5.0,39,1,0,0,0,0,0,0,
4319,ambari-agent; ambari-server; test,Dmitry Lysnichenko,Task timeout should be a configurable knob at the ambari-server,Task timeout is a configurable knob at the ambari-agent.timeout_seconds = 600This opens up the possibility of different timeout value at different agent instances as well as different value between the server and the agent. This can lead to state where server may have timed out the tasks but agent may not have. The other way is benign.This config can be moved to the server and server can hand it off to the agent when agent registers. This also makes it easier to manage the timeout value.,1.5.0,1.5.0,87,1,0,0,0,0,0,0,
4333,ambari-web,Antonenko Alexander,Incorrect behavior of 'Save' button in 'Manage Configuration Groups' window,Steps: Go to 'Customize Services' page. Open 'Manage Configuration Groups' window for any service. Add new custom group and assign host to it. Save changes. Open 'Manage Configuration Groups' window again. Select custom group and remove assigned host.Result: 'Save' button is disabled  'Add hosts' also is disabled.Note: after selecting default group 'Save' button become active.Also if after all steps try to add hosts to custom group  'Save' button will not be active.,1.5.0,1.5.0,72,0,0,0,0,0,0,0,
4336,,Mahadev konar,Move 1.3.4 stack to 1.3.3 using the python libraries.,Move 1.3.4 stack to 1.3.3 using the pythin libraries.,1.5.0,1.5.0,9,1,0,0,0,0,0,0,
4341,,Mahadev konar,Rename 2.0.8 to 2.1.1 in the stack definition.,Rename 2.0.8 to 2.1.1 in the stack definition.,1.5.0,1.5.0,8,1,0,0,0,0,0,0,
4349,ambari-web,Oleg Nechiporenko,Slaves API-calls,For Slaves (DataNodes  NodeManagers  RegionServers  or TaskTrackers): Start Stop Restart Decommission Recommission,1.5.0,1.5.0,12,1,0,0,0,0,0,0,
4354,ambari-agent,Dmytro Shkvyra,HostCleanup should also clean /tmp/hadoop-*,HostCleanup should also check the following directories (and clean):/tmp/hadoop-*For example  if the /tmp/hadoop-nagios directory is present  but it doesn't have the right ownership/perms for nagios user  the Hive Metastore Nagios alert will occur. I saw this after doing an install on an un-clean machine.Hive Metastore statusCRIT for about a minuteCRITICAL: Error accessing Hive Metastore status [Error creating temp dir in hadoop.tmp.dir /tmp/hadoop-nagios due to Permission denied]An easy way to reproduce this:1) Perform install2) Go to Nagios server machine3) Change perms on /tmp/hadoop-nagios so that the nagios user does not have access4) The Nagios alert will fire,1.4.2,1.5.1,104,1,0,0,0,0,0,0,
4355,ambari-server,Siddharth Wagle,Add relocate resources scripts to the pom file,The relocate resources python script is not a part of the rpm package.,1.5.0,1.5.0,13,1,0,0,0,0,0,0,
4361,ambari-web,Srimanth Gunturi,Rolling restart failure tolerance should be percentage values,Currently when we make rolling restart API calls  the task_failure_tolerance value is given as count of hosts. Rather it should be percentage of total hosts.,1.5.0,1.5.0,25,1,0,0,0,0,0,0,
4365,ambari-server,Sumit Mohanty,Action definitions should be provided as declarative resources - read from XML files,Currently  action definition are stored in database. This is not in-line with the declarative definition of stack and custom commands (as part of stack). The custom actions are essentially same as custom commands except they are defined at the level of clusters. So we should move the custom actions to XML formatted files that ambari-server can read when starting up. This means that when one needs to make any edit they will have to restart ambari-server. This requirement is OK as adding/modifying custom actions is not a frequently done operation.,1.5.0,1.5.0,90,1,0,0,0,0,0,0,
4367,ambari-web,Andrii Tkach,Alerts block shows spinner if Nagios not installed,When Nagios not installed Alerts block should show message that it's not installed instead of spinner.,1.5.0,1.5.0,16,0,0,0,0,0,0,1,ambari-web/app/controllers/main/alerts_controller.js;
4380,ambari-web,Oleg Nechiporenko,Hosts API-calls,For each host:P0: Start All Components Stop All ComponentsP1: Restart All Components,1.5.0,1.5.0,12,1,0,0,0,0,0,0,
4383,ambari-server,Eugene Chekanskiy,Datanode data directory is not created correctly,dfs.datanode.data.dir must be handled as comma separated directories.,1.5.0,1.5.0,8,1,0,0,0,0,0,0,
4395,ambari-server,Dmytro Shkvyra,ambari-server should use repo when downloading jdk 7,,1.5.0,1.5.0,1,0,0,0,0,0,0,0,
4396,ambari-web,Oleg Nechiporenko,Misc code cleanup,,1.5.0,1.5.0,1,1,0,0,0,0,0,0,
4402,ambari-server,Siddharth Wagle,Delete Config Group Host mapping broken due to error introduced by perf patch,Unit test: org.apache.ambari.server.state.ConfigGroupTest#testRemoveHostThis unit test is not a part of 1.4.3 branch  it was added later. (trunk)Exception thrown during ConfigGroupImpl.removeHost()2014-01-06 17:46:35 989 ERROR [main] configgroup.ConfigGroupImpl (ConfigGroupImpl.java:removeHost(274)) - Failed to delete config group host mapping  clusterName = foo  id = 1  hostname = h1java.lang.IllegalArgumentException: Object: org.apache.ambari.server.orm.cache.ConfigGroupHostMappingImpl@cc34948d is not a known entity type. at org.eclipse.persistence.internal.sessions.UnitOfWorkImpl.performRemove(UnitOfWorkImpl.java:3538) at org.eclipse.persistence.internal.jpa.EntityManagerImpl.remove(EntityManagerImpl.java:518) at org.apache.ambari.server.orm.dao.ConfigGroupHostMappingDAO.removeByPK(ConfigGroupHostMappingDAO.java:250) at com.google.inject.persist.jpa.JpaLocalTxnInterceptor.invoke(JpaLocalTxnInterceptor.java:58) at org.apache.ambari.server.state.configgroup.ConfigGroupImpl.removeHost(ConfigGroupImpl.java:272) at com.google.inject.persist.jpa.JpaLocalTxnInterceptor.invoke(JpaLocalTxnInterceptor.java:66) at org.apache.ambari.server.state.cluster.ClustersImpl.deleteConfigGroupHostMapping(ClustersImpl.java:640) at org.apache.ambari.server.state.cluster.ClustersImpl.unmapHostFromCluster(ClustersImpl.java:615) at org.apache.ambari.server.state.ConfigGroupTest.testRemoveHost(ConfigGroupTest.java:203),1.5.0,1.5.0,76,0,0,0,0,0,1,0,
4404,ambari-web,Srimanth Gunturi,mapreduce.task.io.sort.mb max value should not exceed 1024mb,https://issues.apache.org/jira/browse/MAPREDUCE-5028https://issues.apache.org/jira/browse/MAPREDUCE-2308,1.4.4,1.4.4,7,1,0,0,0,1,0,0,
4405,ambari-server,Sumit Mohanty,Remove property fs.checkpoint.size during upgrade,Property fs.checkpoint.size is deprecated. The upgrade script should remove it. Users can add the replacement themselves - dfs.namenode.checkpoint.txns.,1.4.4,1.4.4,18,1,0,0,0,0,0,0,
4408,ambari-web,Srimanth Gunturi,Background operations dialog in weird state after exception,Background operations dialog goes into a weird state after hitting an exception with request_schedule information. It always expects request_schedule information to be present.,1.5.0,1.5.0,23,1,0,1,0,0,0,0,
4416,ambari-server,Dmytro Shkvyra,HDFS start failed on 2.1.1 stack,STR: Deployed minimal cluster with HDFS and ZK. HDFS start failed. Added YARN+MR2  Nagios and Ganglia. Picture with HDFS was the same.Output:Fail: Execution of 'ulimit -c unlimited &amp;&amp; if [ 'ulimit -c' != 'unlimited' ]; then exit 77; fi &amp;&amp; export HADOOP_LIBEXEC_DIR=/usr/lib/hadoop/libexec &amp;&amp; /usr/lib/hadoop/sbin/hadoop-daemon.sh --config /etc/hadoop/conf start secondarynamenode' returned 1. -bash: line 0: ulimit: core file size: cannot modify limit: Operation not permittedFull folders with logs are attached.,1.5.0,1.5.0,74,1,0,0,0,0,0,0,
4420,ambari-server,Siddharth Wagle,ORA-01795: maximum number of expressions in a list is 1000 for Oracle DB,PROBLEM:ORA-01795: maximum number of expressions in a list is 1000 in Ambari Server log. Customer recently upgraded to Ambari 1.4.2Error is:08:54:51 320 ERROR [qtp1280560314-2070] ReadHandler:84 - Caught a runtime exception executing a queryLocal Exception Stack: Exception [EclipseLink-4002] (Eclipse Persistence Services - 2.4.0.v20120608-r11652): org.eclipse.persistence.exceptions.DatabaseExceptionInternal Exception: java.sql.SQLSyntaxErrorException: ORA-01795: maximum number of expressions in a list is 1000Error Code: 1795Call: SELECT task_id  attempt_count  event  exitcode  host_name  last_attempt_time  request_id  role  role_command  stage_id  start_time  status  std_error  std_out FROM host_role_command WHERE (task_id IN (? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?)) ORDER BY task_id bind =&gt; [2551 parameters bound]Query: ReadAllQuery(referenceClass=HostRoleCommandEntity sql='SELECT task_id  attempt_count  event  exitcode  host_name  last_attempt_time  request_id  role  role_command  stage_id  start_time  status  std_error  std_out FROM host_role_command WHERE (task_id IN ?) ORDER BY task_id') at org.eclipse.persistence.exceptions.DatabaseException.sqlException(DatabaseException.java:333) at org.eclipse.persistence.internal.databaseaccess.DatabaseAccessor.basicExecuteCall(DatabaseAccessor.java:646) at org.eclipse.persistence.internal.databaseaccess.DatabaseAccessor.executeCall(DatabaseAccessor.java:537) at org.eclipse.persistence.internal.sessions.AbstractSession.basicExecuteCall(AbstractSession.java:1800)STEPS TO REPRODUCE: Over 1000 entries in the host_role_command and execution_command tables when oracle is used for Ambari backend databseACTUAL BEHAVIOR: Oracle throws the errorEXPECTED BEHAVIOR: There should be a limit to prevent this (possibly modify the syntax of the oracle query),1.5.0; 1.5.1; 1.4.4; 1.6.0; 1.6.1,1.4.4; 1.7.0,170,1,0,0,0,0,0,0,
4425,ambari-agent,Vitaly Brodetskyi,Add upgradestack support for MySQL,Similar to Oracle/Postgres we need to make sure that ambari-server upgradestack works for MySQL,1.5.0,1.5.0,14,1,0,0,0,0,0,0,
4433,ambari-web,Jeff Sposetti,Ambari version info should be visible in UI,There is currently no easy way to find the version of Ambari that is in use from the Ambari Web interface. This info should be accessible via an 'about' link in Ambari Web,1.4.3,1.5.0,33,1,0,0,0,0,0,6,ambari-web/app/controllers/application.js;ambari-web/app/controllers/global/cluster_controller.js;ambari-web/app/messages.js;ambari-web/app/styles/application.less;ambari-web/app/templates/application.hbs;ambari-web/app/templates/common/about.hbs;
4501,ambari-web,Oleg Nechiporenko,health status yellow (lost heartbeat) not showing icon,See attached. Using 1.5.0.335On Hosts page. Other pages seem fine.,1.5.0,1.5.0,10,0,0,0,0,0,0,0,
4521,ambari-web,Oleg Nechiporenko,Bulk Ops: Restart on Slaves should popup rolling restart dialog,When performing Restart on Slaves via Bulk Ops menu on the Hosts page  Restart should popup the rolling restart dialog  just like it does when Restarting Slaves under Service Actions.,1.5.0,1.5.0,30,1,0,0,0,0,0,0,
4523,ambari-agent,Perry Tian,Host registering failure from primary/agent os checking on centos6,I am using Ambari (1.4.3.38) for hadoop cluster installation and management. All the cluster nodes are built on centos 6.0.During the ambari server installation  ambari-server recognized the primary/cluster os as redhat6 (see ambari.properties). During the ambari agent bootstrap/host register  ambari-agent regonized the agent os as centos linux6 (see log). From log files (ambari-server.log  ambari-agent.log)  I found the inconsistence caused the warning of ambari-agent bootstrapping and failure of host registering.I'm still not sure why this happen  but I guess it's caused by the differene of os checking methods among ambari server side code  ambari-agent bootstrap script (os_type_check.sh based on os release file) and registering script (Controller.py/Register.py based on os hardware profile) .I just share to see if anyone can fix the issue.BTW  for me  to solve the problem  I manually edited the script files to make it work temporarily:To avoid warning of agent bootstrapping  in os_type_check.sh  add current_os=$RH6 above the echo line or add res=0 after case statement;To make the node register work  in Controller.py  add data=data.replace('centos linux' 'redhat') before sending registering request;Thanks.,1.4.3,1.5.1,170,1,0,0,0,0,0,0,
4526,ambari-server,Eugene Chekanskiy,Oozie Server installation fails when Falcon is selected,,1.5.0,1.5.0,1,1,0,0,0,0,0,0,
4534,ambari-web,Andrii Babiichuk,Add ability to delete individual DataNode  TaskTracker  NodeManager  and RegionServer from Host Details page,Note: We let the user delete Storm Supervisor already.,1.5.0,1.5.0,9,1,0,0,0,0,0,1,ambari-web/app/app.js;
4551,ambari-web,Andrii Babiichuk,Alert count badge and restart indicator issues,The alert badge shown in the left nav shows up a bit strange (too little padding on the right). Also  when the restart indicator appears  the padding for the alert badge fixes itself  but the restart indicator appears too close. See attached.,1.5.0,1.5.0,42,1,0,0,0,0,0,2,ambari-web/app/styles/application.less;ambari-web/app/templates/main/service/menu_item.hbs;
4552,ambari-web,Andrii Babiichuk,OOS status for component on host detail page makes button too big,,1.5.0,1.5.0,1,1,0,0,0,0,0,4,ambari-web/app/messages.js;ambari-web/app/styles/application.less;ambari-web/app/templates/main/host/details/host_component.hbs;ambari-web/app/views/main/host/details/host_component_view.js;
4556,ambari-web,Oleg Nechiporenko,Refactor and Unit tests for host summary,,1.5.0,1.5.0,1,1,0,0,0,0,0,0,
4560,ambari-web,Jaimin D Jetly,BG operation pop-up: JS error encountered on clicking on host in progress state.,,1.5.0,1.5.0,1,1,0,0,0,0,0,0,
4561,ambari-web,Yusaku Sako,Falcon Client install task shows up as just 'install' rather than 'Falcon Client install',See attached.,1.5.0,1.5.0,2,0,0,0,0,0,0,0,
4566,ambari-web,Srimanth Gunturi,Jobs: implement the TEZ DAG page/panel,Need a graph implemented to show the Tez DAG for Hive queries,1.5.0,1.5.0,12,1,0,0,0,0,0,0,
4567,ambari-web,Xi Wang,Ambari should check that there is enough disk space during installation,Add a new category in 'Hosts Check' popup after registering hosts.So for '/' mountpoint  we check if the disk free space is larger than 2.0GB.And for '/usr/lib' or '/usr'  check the free space is larger than 1.0GB. Then show related warning message if any of them got space shortage.,1.4.0,1.5.0,49,0,0,0,0,0,0,0,
4570,ambari-server,Sumit Mohanty,Various issues related to decommission support,Tracking few issues related to decommission support Even with HBase HA only one master should be used for decommission Alternatively  for HDFS/MR/YARN use all master host components Do not use 'default' method while using python based system resources Add support for command details and custom command names,1.5.0,1.5.0,47,1,0,0,0,0,0,0,
4574,ambari-web,Andrii Babiichuk,Upon restart of ambari-server  the service status on Dashboard page remain unchanged,After ambari-server restart  if FE remains at the Dashboard page  the service status (Yellow buttons) never gets updated even if the API indicates that the status are all Green/Red. In my case  never is 6 minutes.Upon refresh or moving to other tabs the view is promptly updated.,1.5.0,1.5.0,47,1,0,0,0,0,0,2,ambari-web/app/router.js;ambari-web/app/routes/installer.js;
4575,ambari-web,Oleg Nechiporenko,Host Details > Actions pulldown likes to hide,Actions pull down on the Host Detail page likes to hide itself when it's open. This is a bit annoying.,1.5.0,1.5.0,20,1,0,0,0,0,0,0,
4600,ambari-server,Dmytro Shkvyra,Remove --jce-policy from warning statement,We have removed option -c or --jce-policy. So the warning message should not use that option in the help statement.jce_download_fail_msg = ' Failed to download JCE Policy archive : {0}. ' / 'Please check that JCE Policy archive is available ' / 'at {1} . Also you may install JCE Policy archive manually using ' / '--jce-policy command line argument.'.format('{0}'  jce_url),1.5.0,1.5.0,67,0,0,0,0,0,0,0,
4601,ambari-web,Andrii Babiichuk,adding more master components styling is missing,,1.5.0,1.5.0,1,0,0,0,0,0,0,1,ambari-web/app/controllers/wizard/step5_controller.js;
4603,ambari-web,Andrii Babiichuk,Host names goes under text  icons,see attached,1.5.0,1.5.0,2,1,0,0,0,0,0,4,ambari-web/app/models/host.js;ambari-web/app/styles/application.less;ambari-web/app/templates/main/host.hbs;ambari-web/app/templates/main/service/info/summary/master_components.hbs;
4605,ambari-web,Oleg Nechiporenko,Host details: clients list disappears,Go to host page with some clients installedRefresh itGot: clients are not displayed on the pageExpected: list of installed clients,1.5.0,1.5.0,20,0,0,0,0,0,0,0,
4608,ambari-web,Andrii Babiichuk,medkit-icons are shifted out of their places  in hosts table in Safari.,,1.5.0,1.5.0,1,0,0,0,0,0,0,1,ambari-web/app/styles/application.less;
4612,ambari-server,Siddharth Wagle,Exception on deploing step: java.sql.BatchUpdateException: ORA-00942,Exception trace:18:27:19 191 WARN [qtp1643608425-22] ServletHandler:514 - /api/v1/clusters/c1/servicesjavax.persistence.RollbackException: Exception [EclipseLink-4002] (Eclipse Persistence Services - 2.4.0.v20120608-r11652): org.eclipse.persistence.exceptions.DatabaseExceptionInternal Exception: java.sql.BatchUpdateException: ORA-00942: table or view does not existError Code: 942 at org.eclipse.persistence.internal.jpa.transaction.EntityTransactionImpl.commitInternal(EntityTransactionImpl.java:102) at org.eclipse.persistence.internal.jpa.transaction.EntityTransactionImpl.commit(EntityTransactionImpl.java:63) at com.google.inject.persist.jpa.JpaLocalTxnInterceptor.invoke(JpaLocalTxnInterceptor.java:87),1.5.0,1.5.0,39,0,0,0,0,0,0,0,
4635,ambari-web,Antonenko Alexander,'SNN Process' alert displays after HA enabled successfully,STR:1. Install  setup and start Ambari server by default.2. Deploy Hadoop by default (stack 2.0.6  choose all services to install).3. Enable HA.4. Wait for at least 150 seconds.4. Go to HDFS Service/Hosts page page.Actual result:'Secondary NameNode Process' alert displayed.Expected result:There should not be 'Secondary NameNode' alert on page.,1.4.1,1.5.0,48,1,0,0,0,0,0,0,
4637,ambari-web,Andrii Tkach,The user is not always redirected to the login page when unauthenticated,1. Try to enable HA with fail on 9th step for Start All services2. Use link http://&lt;host&gt;:8080/#/main/admin/highAvailability/enable/step13. HA Wizard is shown without previously loaded Login Page (see url and js errors in attached screenshot)Expexted result:Login Page should be loaded firts.,1.5.0,1.5.0,40,1,0,0,0,0,0,10,ambari-web/app/models/cluster_states.js;ambari-web/app/router.js;ambari-web/app/routes/add_host_routes.js;ambari-web/app/routes/add_security.js;ambari-web/app/routes/add_service_routes.js;ambari-web/app/routes/high_availability_routes.js;ambari-web/app/routes/main.js;ambari-web/app/routes/reassign_master_routes.js;ambari-web/app/routes/rollbackHA_routes.js;ambari-web/app/routes/stack_upgrade.js;
4643,ambari-server,Siddharth Wagle,Restart All fails for Client only components,Restart for a service calls stop and start on all components. Currently there is no implementation for stopping a client component. This leads to error message: 'Stop not implemented for component',1.5.0,1.5.0,34,1,0,0,0,0,0,0,
4658,ambari-web,Andrii Tkach,Routes are incorrect after launching wizard,Steps to reproduce:1. Launch Add Service wizard2. Close wizard3. Go by link #/main/services/add/step1 (type it in address bar)The router goes to nonexistent page '#/main/services/add/summary'.,1.5.0,1.5.0,24,1,0,0,0,0,0,4,ambari-web/app/routes/add_host_routes.js;ambari-web/app/routes/add_service_routes.js;ambari-web/app/routes/main.js;ambari-web/app/routes/reassign_master_routes.js;
4662,ambari-web,Denys Buzhor,Install Wizard: Assign Masters: some selects disabled,Step to reproduce.Go untill to Customize Services Page.Click to Choose Services menu link.Go to Assign Masters page.,1.5.0,1.5.0,18,0,0,0,0,0,0,0,
4673,ambari-web,Oleg Nechiporenko,Bulk Ops: add Supervisor to Bulk Ops on Hosts page,Add Supervisor to Hosts page's Bulk Ops menu if Storm is installed.Decommission and Recommission should be disabled  as Supervisors do not support these operations.,1.5.0,1.5.0,24,1,0,0,0,0,0,0,
4682,ambari-web,Denys Buzhor,Customize Services page of Add Service Wizard offers to customize already installed Oozie,Steps to reproduce: Deploy cluster without Ooozie and some other customizable service. Go to the Add Service wizard. Add Oozie service. Fail starting Oozie server. Close add service wizard. Ensure that Oozie was added as service. Go again to Add Service Wizard and choose some customizable service. Go to Customize Services page.Result: Customize Services page proposes to customize Oozie  but it was already added to the cluster during installation.,1.5.0,1.5.0,69,1,0,0,0,0,0,0,
4687,ambari-server,Eugene Chekanskiy,Write unnitests for HDFS install script on HDP1 and HDP2,,1.5.0,1.5.0,1,1,0,0,0,0,0,0,
4693,ambari-web,Oleg Nechiporenko,Hosts table: sort order arrows should be close to the respective column label,The sort order arrows are right-justified within the column.This makes it look like the arrows apply to the column next to it.Instead  we should show the arrows right next to the respective column label.Like:Name (arrows) IP Address (arrows)Not:Name (arrows) IP Address,1.5.0,1.5.0,53,0,0,0,0,0,0,0,
4700,ambari-server,Ivan Kozlov,Oozie tests fails,Oozie tests fail,1.5.0,1.5.0,3,0,0,0,0,0,0,0,
4708,ambari-agent; ambari-server,Dmytro Sen,Actual configs not updated after restart of host component,Updated HDFS configs aren't applied after RESTART.Steps: On a 3 node cluster  create a ConfigGroup for datanode. Override heap size to 1025m instead of 1024m Restart DN.Result: The /var/lib/ambari-agent/data/config.json  has the correct values for the config type:'global': {'2': 'version1392171779044'  'tag': 'version1'} The API call still shows global as default version:http://hostname1:8080/api/v1/clusters/c1/hosts/hostname1/host_components/DATANODE Note:It works after agent is restarted.{global: {overrides: {2: 'version1392171779044'} default: 'version1'}The cause is that hooks aren't executed for the custom_command like RESTART. Since configs for HDFS are generated in hook.py  we must execute hook.py before custom commands or move config generation from hook.py.,1.5.0,1.5.0,126,0,0,0,0,0,0,0,
4710,ambari-server,Eugene Chekanskiy,Add unittets for hooks in secured mode.,,1.5.0,1.5.0,1,0,0,0,1,0,0,0,
4737,ambari-server,Eugene Chekanskiy,Falcon Server can not be restarted,,1.5.0,1.5.0,1,0,0,0,0,0,0,0,
4741,ambari-agent,Vitaly Brodetskyi,Alerts for ATS Component,Impl alert for ATS server ATS process (running / not running)Note: this alert should be disabled/removed when ATS gets deleted (when Kerb is enabled).,1.5.0,1.5.0,24,0,0,0,0,0,0,0,
4745,ambari-web,Denys Buzhor,Value 'storm.zookeeper.servers' not changing after adding new ZK server,After adding new ZK server needs to change value of storm.zookeeper.servers property.,1.5.0,1.5.0,12,0,0,0,0,0,0,0,
4750,ambari-web,Srimanth Gunturi,Tez DAG UI not showing due to changed ATS responses,ATS has changed structure of http://server:8188:8188/ws/v1/apptimeline/HIVE_QUERY_ID/&lt;id&gt; where the entire query JSON structure is now represented as a string under 'otherinfo/query'. UI will need to deserialize this string back into JSON and continue.,1.5.0,1.5.0,35,0,0,0,0,0,0,0,
4764,ambari-server,Dmytro Shkvyra,AmbariManagementControllerTest Test fails with unable to delete the last user.,AmbariManagementControllerTest Test fails with unable to delete the last user.Results :Tests in error: testDeleteUsers(org.apache.ambari.server.controller.AmbariManagementControllerTest): Could not remove user user1. System should have at least one user with administrator role. Tests run: 1404  Failures: 0  Errors: 1  Skipped: 7,1.5.0,1.5.0,46,0,0,0,0,0,0,0,
4772,ambari-web,Jaimin D Jetly,Security Wizard: History Server should be a different section for MR service.,Earlier History Server was not a different service component and was always co-hosted with JobTracker for HDP-1.x. So we had a same section for Job Tracker and History server in security wizard config page.After AMBARI-2617 and AMBARI-4207 fix  it's possible to have JobTracker and History Server on different host via Ambari web-ui. With this capability it's important to show Job History Server as a different section in Security Wizard MR service config page.,1.5.0,1.5.0,96,0,0,0,0,0,0,0,
4777,ambari-web,Andrii Tkach,Restart indicators work incorrectly after adding component,STR: Deploy cluster with DataNodes on 2 from 3 hosts. Change DataNode maximum Java heap size from 1024 to 1025. Check that Restart indicators appeared and 2 DataNodes require restart. Add DataNode on missing host. Change property DataNode maximum Java heap size back to 1024.Result: Those two DataNodes still require restart and added DataNode not.Gluster properties shouldn't be added unless GLUSTERFS is installed.,1.5.0,1.5.0,63,0,0,0,0,0,0,4,ambari-web/app/controllers/main/service/info/configs.js;ambari-web/app/controllers/wizard/step8_controller.js;ambari-web/app/data/HDP2/config_mapping.js;ambari-web/app/utils/config.js;
4779,ambari-web,Oleg Nechiporenko,Add services wizard throw JS exception,See attached. During Customize Services.I installed a cluster w/o Storm  and went to add Storm.,1.5.0,1.5.0,15,0,0,0,0,0,0,0,
4787,ambari-agent,Vitaly Brodetskyi,/var/lib/hadoop-hdfs/ location does not has +x permission for others,The file defined by dfs.domain.socket.path must give +x permission for other user. &lt;property&gt; &lt;name&gt;dfs.domain.socket.path&lt;/name&gt; &lt;value&gt;/var/lib/hadoop-hdfs/dn_socket&lt;/value&gt; &lt;/property&gt;Currently  In ambari installed cluster  /var/lib/hadoop-hdfs does not give +x permission to other user[root@ambari-sec-1392876050-hdfs-re-8 ~]# stat /var/lib/hadoop-hdfs/ File: '/var/lib/hadoop-hdfs/' Size: 4096 Blocks: 8 IO Block: 4096 directoryDevice: 803h/2051d Inode: 1182008 Links: 3Access: (0750/drwxr-x---) Uid: ( 1005/ hdfs) Gid: ( 500/ hadoop)Access: 2014-02-18 18:10:35.000000000 -0800Modify: 2014-02-20 07:50:55.274766162 -0800Change: 2014-02-20 07:50:55.274766162 -0800Due to this Issue  hadoop commands are seeing below WARN messages. 2014-02-18 05:54:32 734|beaver.machine|INFO|RUNNING: /usr/bin/hdfs dfs -tail /user/hrt_qa/hdfsRegressionData/smallFiles/smallRDFile7552014-02-18 05:54:35 528|beaver.machine|INFO|14/02/18 05:54:35 WARN hdfs.BlockReaderLocal: error creating DomainSocket2014-02-18 05:54:35 528|beaver.machine|INFO|java.net.ConnectException: connect(2) error: Permission denied when trying to connect to '/var/lib/hadoop-hdfs/dn_socket'2014-02-18 05:54:35 528|beaver.machine|INFO|at org.apache.hadoop.net.unix.DomainSocket.connect0(Native Method)2014-02-18 05:54:35 529|beaver.machine|INFO|at org.apache.hadoop.net.unix.DomainSocket.connect(DomainSocket.java:250)2014-02-18 05:54:35 529|beaver.machine|INFO|at org.apache.hadoop.hdfs.DomainSocketFactory.createSocket(DomainSocketFactory.java:158)2014-02-18 05:54:35 529|beaver.machine|INFO|at org.apache.hadoop.hdfs.BlockReaderFactory.nextDomainPeer(BlockReaderFactory.java:691)2014-02-18 05:54:35 529|beaver.machine|INFO|at org.apache.hadoop.hdfs.BlockReaderFactory.createShortCircuitReplicaInfo(BlockReaderFactory.java:439)2014-02-18 05:54:35 529|beaver.machine|INFO|at org.apache.hadoop.hdfs.client.ShortCircuitCache.create(ShortCircuitCache.java:669)The expected Permissions on this location is as below.[root@ambari-sec-1392876050-yarn-10 ~]# stat /var/lib/hadoop-hdfs/ File: '/var/lib/hadoop-hdfs/' Size: 4096 Blocks: 8 IO Block: 4096 directoryDevice: 803h/2051d Inode: 1181767 Links: 3Access: (0751/drwxr-x--x) Uid: ( 1005/ hdfs) Gid: ( 500/ hadoop)Access: 2014-02-20 18:00:06.586040913 -0800Modify: 2014-02-20 07:06:28.267889888 -0800Change: 2014-02-20 17:59:56.629052410 -0800,1.5.0,1.5.0,182,0,0,0,0,0,0,0,
4788,ambari-web,Jaimin D Jetly,NameNode fails to start due to 'fs.defaultFS' being null,,1.5.0,1.5.0,1,0,0,0,0,0,0,0,
4790,,Mahadev konar,Skip Failing tests for now.,Skip Failing tests for now.,1.5.0,1.5.0,5,0,0,0,0,0,0,0,
4794,ambari-web,Jaimin D Jetly,Reconfiguring memory related properties of a service suffixes 'm' to memory related properties of other service.,,1.5.0,1.5.0,1,0,0,0,0,0,0,0,
4796,ambari-server,Sumit Mohanty,Do not automatically put host component in Maintenance Mode upon decommissioning (and out of Maintenance Mode when recommissioning),We originally wanted to couple decom/recom with putting the host component in / out of maintenance mode.After experimenting  we decided to undo that. This is the JIRA for the Ambari BE changes.,1.5.0,,32,0,0,0,0,0,0,0,
4800,ambari-web,Oleg Nechiporenko,Hosts table UI cleanup,1) has too much padding (See attached.)2) the sorting carets should have more padding-left so there is a bit more space between the column label3) the checkboxes should have more left padding. They are not balanced.4) The checkboxes and status icons are not vert centered with the hostname text.5) The input field for searching the hostname column should take up more horizontal space. with all that blank  makes it look like there is a missing column.,1.5.0,1.5.0,76,0,0,0,0,0,0,0,
4809,ambari-server,Eugene Chekanskiy,Allow Falcon to be configured with keytab/security and custom params,,1.5.0,1.5.0,1,0,0,0,0,0,0,0,
4818,ambari-web,Denys Buzhor,Do not show 'restart' op on non-admin user,1) As admin  change a config but do not perform the restarts2) Create a test user (non-admin)3) login as test user4) in host details page  operation to restart is shown. Should not be shown,1.5.0,1.5.0,35,0,0,0,0,0,0,0,
4821,ambari-web,Andrii Tkach,Navigation from Hosts page to HostDetailsPage breaks occasionally,STR: 1. Navigate to hosts page  wait for page loaded. 2. Click specific hosts link. 3. Wait for HostDetails page loaded. 4. Click Back. 5. Iterate. Actual result: sometimes the Hosts page hangs not resulting in presenting a HostDetails page. Speed of attached videos is 5 times faster than real.,1.5.0,1.5.0,51,0,0,0,0,1,0,1,ambari-web/app/views/main/host.js;
4841,ambari-web,Andrii Tkach,Incorrect behavior of HA wizard on second step,STR:1) Deploy cluster by default;2) Go to HA wizard3) Second wizard stepExpected result:1) In 'Additional NameNode' combobox should NOT be ability to choose host where NameNode component already installed.2) In 'JournalNode' comboboxes should NOT be ability to choose more than one JournalNode on one hostActual results:1) In 'Additional NameNode' combobox can be chosen host with already installed NameNode (see first screenshot)2) JournalNode components might be chosen to install for any host  including case when three JournalNode's might be installed on one host (see second screenshot).,1.5.0,1.5.0,85,0,0,0,0,0,0,5,ambari-web/app/controllers/main/admin/highAvailability/step2_controller.js;ambari-web/app/controllers/wizard/step5_controller.js;ambari-web/app/messages.js;ambari-web/app/templates/main/admin/highAvailability/step2.hbs;ambari-web/app/views/wizard/step5_view.js;
4842,ambari-server,Eugene Chekanskiy,Update falcon install scripts to recent changes,Following features must be implemented: /apps/falcon directory on hdfs and owned by falcon user make falcon able to be runned from custom user change alerts text,1.5.0,1.5.0,26,0,0,0,0,0,0,0,
4843,ambari-agent,Vitaly Brodetskyi,Ambari DDL for MySQL should not create ambarirca database,Ambari-DDL-MySQL-CREATE.sql includes 'create ambarirca' database.CREATE DATABASE ambarirca;USE ambarirca;1) At minimum  this DDL should not be creating an ambarirca database and instead mix in the RCA tables with core Ambari tables (that's how Oracle DDL does it &#8211; I think). Not ideal but better than creating an ambarirca database in this script (a user would be surprised to see this).2) Alternatively  we need to split out RCA DDL from the core Ambari. We can doc that if you plan to use HDP 1.3.x stack that you need to to setup an RCA database (since RCA is only applicable to those with HDP 1.3.x stack). If we go this route  for consistency  we would need to do the same for the oracle DDL.Note: Right now  looks like the oracle DDL just puts the RCA tables in the same database as ambari core tables (basically #1 above).,1.5.0,1.5.0,151,0,0,0,0,0,0,0,
4872,ambari-agent,Vitaly Brodetskyi,Nagios alerts are not shown on SUSE,STR:1. Deploy cluster by default scenario w/o Storm and Falcon.2. Go to HDFS service page.3. Go to Nagios service page.4. Navigate to Nagios Web UI.5. Enter credentials nagiosadmin/passwordActual results: There are no alerts on service page. Web UI is unavailable due to ERROR 403.Screenshots attached.,1.5.0,1.5.0,45,0,0,0,0,0,0,0,
4893,ambari-server,Siddharth Wagle,Avoid printing stacktrace for state machine exceptions,Log gets filled on install failure.13:28:08 856 WARN [qtp615964260-72] HeartBeatHandler:361 - State machine exceptionorg.apache.ambari.server.state.fsm.InvalidStateTransitionException: Invalid event: HOST_SVCCOMP_OP_SUCCEEDED at INSTALL_FAILED at org.apache.ambari.server.state.fsm.StateMachineFactory.doTransition(StateMachineFactory.java:297) at org.apache.ambari.server.state.fsm.StateMachineFactory.access$300(StateMachineFactory.java:39) at org.apache.ambari.server.state.fsm.StateMachineFactory$InternalStateMachine.doTransition(StateMachineFactory.java:440) at org.apache.ambari.server.state.svccomphost.ServiceComponentHostImpl.handleEvent(ServiceComponentHostImpl.java:730) at com.google.inject.persist.jpa.JpaLocalTxnInterceptor.invoke(JpaLocalTxnInterceptor.java:66),1.5.0,1.5.0,35,0,0,0,0,0,0,0,
4895,,Dmytro Sen,License header is repeated in oozie-log4j.properties,# Licensed to the Apache Software Foundation (ASF) under one or more contributor license agreements. See the NOTICE file distributed with this work for additional information regarding copyright ownership. The ASF licenses this file to you under the Apache License  Version 2.0 (the 'License'); you may not use this file except in compliance with the License. You may obtain a copy of the License at##http://www.apache.org/licenses/LICENSE-2.0# Unless required by applicable law or agreed to in writing  software distributed under the License is distributed on an 'AS IS' BASIS  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND  either express or implied. See the License for the specific language governing permissions and limitations under the License.# http://www.apache.org/licenses/LICENSE-2.0# Unless required by applicable law or agreed to in writing  software distributed under the License is distributed on an 'AS IS' BASIS  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND  either express or implied. See the License for the specific language governing permissions and limitations under the License. See accompanying LICENSE file.#,1.5.0,1.5.0,170,0,0,0,0,0,0,2,ambari-server/src/main/resources/stacks/HDP/1.3.2/services/OOZIE/configuration/oozie-log4j.xml;ambari-server/src/main/resources/stacks/HDP/2.0.6/services/OOZIE/configuration/oozie-log4j.xml;
4902,ambari-web,Jaimin D Jetly,Service Check does not work,,1.5.0,1.5.0,1,0,0,0,0,0,0,0,
4909,ambari-web,Oleg Nechiporenko,Slave component should include 'restart' command on host details page 'Actions',Slave components (such as DataNode  NodeManager  RegionServer  Supervisor  Ganglia Monitor) should include a 'Restart' command in their 'Actions' menu on the host details page.The Restart option should be shown and enabled when the component is started.,1.5.0,1.5.0,36,0,0,0,0,0,0,0,
4939,ambari-agent; ambari-server,Dmytro Shkvyra,Ganglia alerts after adding YARN+MR2,STR: Deploy cluster with HDFS+ZK  Nagios  Ganglia. Add YARN+MR2  Tez services.Result: Alerts Ganglia Monitor process for HistoryServer and Ganglia Monitor process for ResourceManager don't dissappear after restarting all services,1.5.0,1.5.0,29,0,0,0,0,0,0,0,
4947,ambari-agent,Vitaly Brodetskyi,Change Hive alerts to move away from Hive metadata queries to port checks,1) remove 'Hive Metastore status' alert2) add 'Hive Metastore process' alert3) add 'HiveServer2 process' alert,1.5.0,1.5.0,15,0,0,0,0,0,0,0,
4954,ambari-agent,Vitaly Brodetskyi,After configuring NNHA  nn process alerts don't work,1) Configure NN HA2) stack 2.0.6 (but check stack 2.1 as well)3) Two alerts show' check_tcp: Port must be a positive integer'NameNode process on c6401.ambari.apache.orgNameNode process on c6402.ambari.apache.org4) Looked at /etc/nagios/objects/hadoop-services.cfg5) Saw:define service { host_name c6401.ambari.apache.org use hadoop-service service_description NAMENODE::NameNode process on c6401.ambari.apache.org servicegroups HDFS check_command check_tcp_wrapper!//test!-w 1 -c 1 normal_check_interval 0.5 retry_check_interval 0.25 max_check_attempts 3}define service { host_name c6402.ambari.apache.org use hadoop-service service_description NAMENODE::NameNode process on c6402.ambari.apache.org servicegroups HDFS check_command check_tcp_wrapper!//test!-w 1 -c 1 normal_check_interval 0.5 retry_check_interval 0.25 max_check_attempts 3}Notice in the above //test is the name of my nameservice.Attaching screen shot of my config. So looks like it's grabbing port from the wrong prop.,1.5.0,1.5.0,114,0,0,0,0,0,0,0,
4970,ambari-web,Mikhail Bayuk,Jobs popup message clicking continues to stay on the same page,1. Click on an app on ATS/jobs page which is running 2. It pops up a window with message 'Tez DAG has no ID associated with name hrt_qa_20140228161212_a5713292-8213-43a3-b61e-06685799a5b3'3. Press OK and the page refreshes and pops up the same window again.4. This goes on forever until the user closes the browser or enters a different URLInstead  the page should be redirected back to &lt;ambari server URL&gt;/#/main/jobs,1.5.0,1.5.0,66,0,0,0,0,0,0,0,
4983,ambari-server,Siddharth Wagle,During upgrade. migrate decommissioned DN hosts list to the new format,The details of how the notion of a decommissioned DN is stored has changed for 1.5.0. Add support to modify persisted data when Ambari is upgraded to 1.5.0.,1.5.0,1.5.0,28,0,0,0,0,0,0,0,
4986,ambari-web,Andrii Tkach,Reduce loading time of Host Warnings popup,Wizard-&gt;Confirm Hosts step:1. Refactor parsing of json response with hosts warnings.2. Reduce latency on opening Host Warnings popup.,1.5.0,1.5.0,18,0,0,0,0,1,0,3,ambari-web/app/controllers/wizard/step3_controller.js;ambari-web/app/templates/wizard/step3_host_warnings_popup.hbs;ambari-web/app/utils/helper.js;
5020,ambari-server,Dmitry Lysnichenko,Lost heartbeat on host but ganglia shows a heartbeat lost,3 hosts  third-host has only Ganglia monitor and Datanode.I kill the third machine agent. Hosts page correctly shows heartbeat lost.On the services page  ganglia shows 'yellow'  even though the ganglia server host is fine.Ganglia service should considered started if Ganglia Server is started.,1.5.0,1.5.0,43,0,0,0,0,0,0,0,
5028,,Mahadev konar,Hive Service Check Failed during Install Wizard,Hive Service Check Failed during Install Wizard,1.5.0,1.5.0,7,0,0,0,0,0,0,0,
5036,ambari-server; test,Dmitry Lysnichenko,Secured: Start All Services task got stuck forever,Deployed 2-node cluster. Added 3rd node. Enabled security.After steps above on all 3 hosts tasks jammed and don't want to perform or fail for a very long time.VMs are alive  ambari-server and all ambari-agents are running.Finally got a reproduce using 2 commandscurl 'http://vm-0.vm:8080/api/v1/clusters/cc/services?params/run_smoke_test=false' -X PUT -H 'X-Requested-By: X-Requested-By' -u admin:admin --data '{'RequestInfo': {'context': 'Start All Services'}  'Body': {'ServiceInfo': {'state': 'STARTED'}}}' ; sleep 3; curl 'http://vm-0.vm:8080/api/v1/clusters/cc/hosts/vm-0.vm/host_components/APP_TIMELINE_SERVER' -X DELETE -H 'X-Requested-By: X-Requested-By' -u admin:adminThe way to reproduce is a bit different compared to an original description (I issue a DELETE request in 3 seconds after START_ALL_SERVICES request has been issued)  but the symptoms are the same: ServiceComponentHostNotFoundException exception is posted to log and operation is stuck on stage that contains 'App Timeline Server Start' command.,1.5.0,1.5.1,141,0,0,0,0,1,0,0,
5040,ambari-server,Dmytro Sen,2-way auth fails when using jdk7,Steps to reproduce:On the Ambari Server host  open /etc/ambari-server/conf/ambari.properties with a text editor.Add the following property:security.server.two_way_ssl = trueError messageINFO 2014-03-07 13:57:17 184 security.py:184 - Agent certificate not exists  sending sign requestINFO 2014-03-07 13:57:17 335 security.py:89 - SSL Connect being called.. connecting to the serverERROR 2014-03-07 13:57:17 414 security.py:76 - Two-way SSL authentication failed. Ensure that server and agent certificates were signed by the same CA and restart the agent. In order to receive a new agent certificate  remove existing certificate file from keys directory. As a workaround you can turn off two-way SSL authentication in server configuration(ambari.properties) Exiting..,1.5.0,1.5.0,101,0,0,0,0,0,0,6,ambari-server/conf/unix/ca.config;ambari-server/pom.xml;ambari-server/src/main/java/org/apache/ambari/server/configuration/Configuration.java;ambari-server/src/main/java/org/apache/ambari/server/security/CertificateManager.java;ambari-server/src/main/resources/ca.config;ambari-server/src/test/java/org/apache/ambari/server/security/CertGenerationTest.java;
5043,ambari-server,Yusaku Sako,oozie-site.xml defaults need to be updated for 2.1 stack,oozie-site.xml needs the following two services added to the list of services:org.apache.oozie.service.XLogStreamingService (needed to display logs)org.apache.oozie.service.JobsConcurrencyService (needed to run Recovery Service - for example  this would handle jobs that are dangling and stuck in RUNNING state),1.5.1,1.5.1,36,0,0,0,0,0,0,0,
5051,ambari-web,Oleg Nechiporenko,Start all services silently fails when a service is not startable,I clicked on Start All services button and nothing happened. Turns out that on the API call  the server throws a 500 exception that is silently lost. We should show in a dialog the error response from server. Similarly for Stop All action.PUT http://c6401:8080/api/v1/clusters/c1/services?params/run_smoke_test{'RequestInfo': {'context' :'_PARSE_.START.ALL_SERVICES'}  'Body': {'ServiceInfo': {'state': 'START{ 'status' : 500  'message' : 'org.apache.ambari.server.controller.spi.SystemException: An internal system exception occurred: Invalid transition for servicecomponenthost  clusterName=c1  clusterId=3  serviceName=OOZIE  componentName=OOZIE_SERVER  hostname=c6402.ambari.apache.org  currentState=INSTALL_FAILED  newDesiredState=STARTED'},1.5.0,1.5.0,99,0,0,0,0,0,0,0,
5060,ambari-web,Jaimin D Jetly,Security Wizard: enable Kerberos setup for Storm,1) Following jaas.conf file needs to be on all storm component hosts:Client { com.sun.security.auth.module.Krb5LoginModule required useKeyTab=true keyTab='$keytab' storeKey=true useTicketCache=false serviceName='zookeeper' principal='$principal';};2) In YAML  following java configurations should have jaas.conf options:nimbus.childopts: '-Djava.security.auth.login.config=/path/to/jaas.conf'ui.childopts: '-Djava.security.auth.login.config=/path/to/jaas.conf'supervisor.childopts: '-Djava.security.auth.login.config=/path/to/jaas.conf',1.5.0,1.6.0,33,0,0,0,0,0,0,0,
5097,ambari-web,Jaimin D Jetly,Retry failure after installation failure triggers start all services request,Steps to reproduce: Make Install all services request fail. Hit on Retry button. Make retry attempt to install all services fail.This will trigger start all services call and error pop-up will be displayed.Expected behavior: Start all services call should not be called.,1.5.0,1.5.0,42,0,0,0,0,0,0,0,
5103,ambari-web,Oleg Nechiporenko,Maintenance Mode: maintenance icon changes on Host Details page,For host components whose service is in maintenance mode  the maintenance mode icon should be displayed to the right of the service name and we should display the host component health (green / red  etc) on the far left.When the host itself is in maintenance mode  we should not show any maintenance mode icon on the host component (unless the service is in maintenance mode). This allows the UI to distinguish which host components are in service-derived maintenance mode vs host-derived. Also  on this page  host-level operations apply to all but the host components in service-derived maintenance mode (regardless of the host maintenance mode)  so this display is more natural and easier to understand for the end user.,1.5.0,1.5.0,118,0,0,0,0,0,0,0,
5112,ambari-agent,Dmytro Sen,hadoop-mapreduce.jobsummary.log is empty when specified custom YARN Log Dir,Reproduced with such preconditions:On Customize Services page specify 'YARN Log Dir Prefix' to some custom dir. After deploying  run MapReduce2 Service check and check that:hadoop-mapreduce.jobsummary.log is empty  but /var/log/hadoop-yarn/yarn/hadoop-mapreduce.jobsummary.log contains jobs records.,1.5.0,1.5.0,32,0,0,0,0,0,0,10,ambari-server/src/main/resources/stacks/HDP/1.3.2/services/MAPREDUCE/configuration/mapreduce-log4j.xml;ambari-server/src/main/resources/stacks/HDP/2.0.6/services/YARN/configuration/yarn-log4j.xml;ambari-server/src/main/resources/stacks/HDP/2.0.6/services/YARN/package/scripts/resourcemanager.py;ambari-server/src/main/resources/stacks/HDP/2.0.6/services/YARN/package/scripts/yarn.py;ambari-server/src/test/python/stacks/2.0.6/YARN/test_historyserver.py;ambari-server/src/test/python/stacks/2.0.6/YARN/test_mapreduce2_client.py;ambari-server/src/test/python/stacks/2.0.6/YARN/test_nodemanager.py;ambari-server/src/test/python/stacks/2.0.6/YARN/test_resourcemanager.py;ambari-server/src/test/python/stacks/2.0.6/YARN/test_yarn_client.py;ambari-server/src/test/python/stacks/2.1/YARN/test_apptimelineserver.py;
5123,ambari-web,Oleg Nechiporenko,Background Operations window does not appear after triggering Rolling Restart,STR: Deploy cluster. Check that flag Do not show the Background Operations dialog when starting an operation is set to false. Click Restart DataNodes in Actions menu of HDFS. Click 'Trigger Restart' in appeared modal window.Result: Background Operations was not appeared.,1.5.0,1.5.0,41,0,0,0,0,0,0,0,
5128,ambari-web,Andrii Babiichuk,Rolling Restart dialog shows incorrect message that slaves won't be restarted when service is in maintenance mode,The fix for this issue would be to display that the slaves whose host is in 'host' maintenance mode will be skipped.For example  we have 3 hosts (host1  host2  and host3) with NodeManager installed on each. Say host3 is in maintenance mode.Rolling Restart dialog should say '1 NodeManager in maintenance mode will not be restarted'.,1.5.0,1.5.0,55,0,0,0,0,0,0,1,ambari-web/app/views/common/rolling_restart_view.js;
5146,ambari-agent,Vitaly Brodetskyi,After Ambari is upgraded to 1.5.0  previous JAVA_HOME is overwritten to /usr/jdk64/jdk1.6.0_3,After upgrading Ambari from 1.2.5 to 1.5.0 and Stack from 1.3.2 to 2.0.10When starting HDFS service  Datanode and SNameNode on the agent host failed to start due to JAVA_HOME=cbin/java is missing. In ambari.properties  java.home=/usr/jdk64/jdk1.6.0_3 after upgrade.,1.5.0,1.5.0,36,0,0,0,0,0,0,0,
5156,ambari-agent,Siddharth Wagle,Hive CLI using Tez runtime does not start by throwing HDFS exception,In a cluster node we had set the below in /etc/hive/conf/hive-site.xml&lt;property&gt; &lt;name&gt;hive.jar.directory&lt;/name&gt; &lt;value&gt;hdfs:///apps/hive/install&lt;/value&gt;&lt;/property&gt;The HDFS folder has the following contents# hadoop fs -ls -R /apps/hive/drwxr-xr-x - hive hdfs 0 2014-03-19 17:10 /apps/hive/install-rwxr-xr-x 3 hive hdfs 14719276 2014-03-19 17:10 /apps/hive/install/hive-exec.jardrwxrwxrwx - hive hdfs 0 2014-03-19 17:08 /apps/hive/warehouseAs user ambari-qa I run the hive command to hit this exception$ hiveLogging initialized using configuration in file:/etc/hive/conf.dist/hive-log4j.propertiesException in thread 'main' java.lang.RuntimeException: org.apache.hadoop.security.AccessControlException: Permission denied: user=ambari-qa  access=WRITE  inode='/apps/hive/install':hive:hdfs:drwxr-xr-x at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkFsPermission(FSPermissionChecker.java:265) at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:251) at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:232) at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:176) at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5481) at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5463) at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkAncestorAccess(FSNamesystem.java:5437) at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInternal(FSNamesystem.java:2265) at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2218) at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2171) at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:517) at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:354) at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java) at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585) at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928) at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2003) at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1999) at java.security.AccessController.doPrivileged(Native Method) at javax.security.auth.Subject.doAs(Subject.java:415) at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1548) at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1997) at org.apache.hadoop.hive.ql.session.SessionState.start(SessionState.java:345) at org.apache.hadoop.hive.cli.CliDriver.run(CliDriver.java:682) at org.apache.hadoop.hive.cli.CliDriver.main(CliDriver.java:626) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:606) at org.apache.hadoop.util.RunJar.main(RunJar.java:212)Caused by: org.apache.hadoop.security.AccessControlException: Permission denied: user=ambari-qa  access=WRITE  inode='/apps/hive/install':hive:hdfs:drwxr-xr-x at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkFsPermission(FSPermissionChecker.java:265) at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:251) at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:232) at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:176) at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5481) at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5463) at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkAncestorAccess(FSNamesystem.java:5437) at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInternal(FSNamesystem.java:2265) at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2218) at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2171) at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:517) at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:354) at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java) at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585) at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928) at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2003) at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1999) at java.security.AccessController.doPrivileged(Native Method) at javax.security.auth.Subject.doAs(Subject.java:415) at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1548) at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1997) at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57) at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45) at java.lang.reflect.Constructor.newInstance(Constructor.java:526) at org.apache.hadoop.ipc.RemoteException.instantiateException(RemoteException.java:106) at org.apache.hadoop.ipc.RemoteException.unwrapRemoteException(RemoteException.java:73) at org.apache.hadoop.hdfs.DFSOutputStream.newStreamForCreate(DFSOutputStream.java:1602) at org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1461) at org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1386) at org.apache.hadoop.hdfs.DistributedFileSystem$6.doCall(DistributedFileSystem.java:394) at org.apache.hadoop.hdfs.DistributedFileSystem$6.doCall(DistributedFileSystem.java:390) at org.apache.had,1.5.0,1.5.0,232,0,0,0,0,1,0,0,
5173,ambari-server,Dmytro Sen,The status of App Timeline Server affect the health status of YARN service.,When stopping ATS  YARN service indicator blinks red giving the idea that YARN is going down and become solid red after that. YARN service should not be indicated as STOPPED if ATS is down.,1.5.0,1.5.1,34,0,0,0,0,0,0,1,ambari-server/src/main/resources/stacks/HDP/2.1/services/YARN/metainfo.xml;
5223,ambari-agent,Vitaly Brodetskyi,hive-env.sh overwrites user value of HIVE_AUX_JARS_PATH,This line at the bottom of hive-env.sh disregards any user-provided values  masking them from the launch script.# Folder containing extra ibraries required for hive compilation/execution can be controlled by:export HIVE_AUX_JARS_PATH=/usr/lib/hcatalog/share/hcatalog/hcatalog-core.jarThis breaks this feature for users of both the environment export HIVE_AUX_JARS_PATH='my custom value' and the command line hive --auxpath 'my custom value' .,1.2.5,1.5.1,59,0,0,0,0,0,0,0,
5235,ambari-web,Jaimin D Jetly,Add component of clients in Ambari doesn't work in a secured cluster,The reason of bug is wrong query formation while triggering API to create clients on host.The data sent with the POST call to create client components on the host is:{'RequestInfo':{'context':'Install Clients'} 'Body':{'host_components':[{'HostRoles':{'component_name':'CLIENTS'}}]}}This is incorrect. There is no component with name 'CLIENTS'.,1.4.4,1.5.1,46,0,0,0,0,0,0,0,
5244,ambari-web,Oleg Nechiporenko,Wizard Step7 JS error on load page (add service wizard),Add Nagios  Ganglia via Add Service WizardProceed to step 'Customize Services'JS-error appears about null-object:/app/controllers/wizard/step7_controller.js : loadServiceTagsSuccess()if (serviceConfigsDef.sites.indexOf(site) &gt; -1)Also  HDFS by default is selected as active tab  but one of the 'new' services (Nagios for example) should be selected.,1.5.1,1.5.1,39,0,0,0,0,0,0,0,
5246,ambari-web,Andrii Babiichuk,Mistake in title of operation 'Restart APP_TIMELINE_SERVER on ...,We should show displayName  not componentName,1.5.0,1.5.1,6,0,0,0,0,0,0,1,ambari-web/app/controllers/main/host/details.js;
5258,ambari-web,Oleg Nechiporenko,Installer: 'Undo' button for repo BaseURL does not work,STR: during installer phase go to &lt;cluster&gt;:8080 /#/installer/step1 ; Change/delete any of BaseURL of repos ; Click 'Undo' buttonActual Results:Undo button does not work. Moreover  if we click Undo after any update of text in BaseURL  it leads to cleanup of it value atall.,1.5.0; 1.5.1,1.5.0; 1.5.1,46,0,0,0,0,0,0,0,
5264,ambari-agent,Vitaly Brodetskyi,Ganglia Server goes to 'installed' state after double 'Ganglia rrdcached base directory' config changing,STR:1) Deploy cluster by default2) Go to Ganglia service page -&gt; Config tab 3) Change value 'Ganglia rrdcached base directory' (e.g. /var/lib/ganglia/rrd8)4) Restart Ganglia5) Change 'Ganglia rrdcached base directory' back to old value (by default - /var/lib/ganglia/rrds)6) Restart GangliaExpected result: Ganglia should be restarted successfullyCurrent result: Ganglia Server goes to 'installed' state and stuck thereError message from gmetad file:=============================Starting hdp-gmetad...=============================Base directory (-b) resolved via file system links!Please consult rrdcached '-b' documentation!Consider specifying the real directory (/var/lib/ganglia/rrd8)chgrp: cannot access '/var/run/ganglia/hdp/rrdcached.sock': No such file or directorychgrp: cannot access '/var/run/ganglia/hdp/rrdcached.limited.sock': No such file or directoryFailed to start /usr/bin/rrdcachedNot starting /usr/sbin/gmetad because starting /usr/bin/rrdcached failed.root 16990 0.0 0.0 108164 1560 ? S 03:19 0:00 /bin/bash --login -c service hdp-gmetad start &gt;&gt; /tmp/gmetad.log 2&gt;&amp;1 ; /bin/ps auwx | /bin/grep [g]metad &gt;&gt; /tmp/gmetad.log 2&gt;&amp;1,1.5.0,1.5.0,134,0,0,0,0,0,0,0,
5274,ambari-web,Aleksandr Kovalenko,Supervisor under supervision fails w/o ganglia server,JMXetricAgent instrumented JVM  see https://github.com/ganglia/jmxetricMar 28  2014 6:40:13 PM info.ganglia.jmxetric.JMXetricAgent premainSEVERE: Exception starting JMXetricAgentjava.net.UnknownHostException: {0}: Name or service not known at java.net.Inet6AddressImpl.lookupAllHostAddr(Native Method) at java.net.InetAddress$1.lookupAllHostAddr(InetAddress.java:901) at java.net.InetAddress.getAddressesFromNameService(InetAddress.java:1293) at java.net.InetAddress.getAllByName0(InetAddress.java:1246) at java.net.InetAddress.getAllByName(InetAddress.java:1162) at java.net.InetAddress.getAllByName(InetAddress.java:1098) at java.net.InetAddress.getByName(InetAddress.java:1048) at info.ganglia.gmetric4j.gmetric.AbstractProtocol.&lt;init&gt;(AbstractProtocol.java:29) at info.ganglia.gmetric4j.gmetric.Protocolv31x.&lt;init&gt;(Protocolv31x.java:34) at info.ganglia.gmetric4j.gmetric.GMetric.&lt;init&gt;(GMetric.java:108) at info.ganglia.jmxetric.XMLConfigurationService.configureGangliaFromXML(XMLConfigurationService.java:165) at info.ganglia.jmxetric.XMLConfigurationService.configure(XMLConfigurationService.java:67) at info.ganglia.jmxetric.JMXetricAgent.premain(JMXetricAgent.java:51) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:606) at sun.instrument.InstrumentationImpl.loadClassAndStartAgent(InstrumentationImpl.java:382) at sun.instrument.InstrumentationImpl.loadClassAndCallPremain(InstrumentationImpl.java:397)The reason here is this config send from ui:...childopts: '-javaagent:/usr/lib/storm/contrib/storm-jmxetric/lib/jmxetric-1.0.4.jar=host={0} ...'it can't find hostname {0}  however this works fine:...childopts: '-javaagent:/usr/lib/storm/contrib/storm-jmxetric/lib/jmxetric-1.0.4.jar=host= port...'So let's leave it as empty if no ganglia server is present,1.5.1,1.5.1,111,0,0,0,0,0,0,2,ambari-server/src/main/resources/stacks/HDP/2.1/services/STORM/configuration/storm-site.xml;ambari-web/app/controllers/wizard/step7_controller.js;
5282,ambari-server; test,Dmitry Lysnichenko,supervisor.enable should be removed from Ambari's Storm Config section,Ambari exposes the supervisor.enable property and in some early builds defaults it to true which causes the supervisor's to not launch workers assigned to them. The supervisor's will start up  the assignments are there  but the supervisor's just ignore them. We need to remove the supervisor.enable from Ambari as it seems like a very dangerous switch that doesn't have broad applicability.,1.5.1,1.5.1,62,0,0,0,0,0,0,0,
5301,ambari-web,Andrii Tkach,Table of Confirm Hosts step is collapsed,Steps to reproduce:1. Run hosts registration2. Switch to Registering category3. Wait till all hosts become registeredResult: Table is collapsed.JS error occured: Uncaught Error: assertion failed: calling set on destroyed object,1.5.1,1.5.1,36,0,0,0,0,0,0,2,ambari-web/app/views/wizard/step3_view.js;ambari-web/app/views/wizard/step9_view.js;
5310,ambari-web,Yusaku Sako,Don't do server-client version match check if App.version have not been set on ambari-web,With the new server-client version match check introduced  it is a bit annoying when building ambari-web locally and testing on the server for e2e testing  as the server and client versions must match exactly or you cannot proceed. We'll disable the check if App.version == ''.,1.5.1,1.5.1,46,0,0,0,0,0,0,0,
5311,ambari-web,Yusaku Sako,Falcon fails to deploy,Looks like Falcon service definition on the stack has changed by AMBARI-5278.Currently  any new definition of globals require duplicating them in the UI code but that was not done  so this is breaking Falcon installation.,1.5.1,1.5.1,43,0,0,0,0,0,0,0,
5313,ambari-web,Oleg Nechiporenko,Icon 'Asterisk' on 'Assign Masters'/-Slaves steps does not display with 8-bit depth,,1.5.1,1.5.1,1,0,0,0,0,0,0,0,
5332,,Mahadev konar,Print better logs for openssl issues on centos/rhel 6.5.,Print better logs for openssl issues on centos/rhel 6.5.,1.5.1,1.5.1,9,0,0,0,0,0,0,0,
5340,ambari-web,Antonenko Alexander,Tez DAG Operator hover text not wrapping wide content,When a Hive Tez DAG operator has a plan with very wide content  the text is not wrapped and hence bleeds out of the hover box. An additional problem is that this causes the hover to lose focus and hence close - thereby user cannot even see the hover (opens &amp; closes almost instantly).,1.5.1,1.5.1,54,0,0,0,0,0,0,0,
5342,ambari-server,Dmytro Sen,Ambari YARN UI - Quick Link - JMX breaks if RM port is changed,If you change RM port from 8088 to 50030 for migration of 1.x to 2.x   JVM metrics and few others are missing which results in yarn service summary page having multiple fields with n/a value.Step1: Change property below yarn.resourcemanager.webapp.address = localhost:50030Step 2: Start the service Click on Dashboard JMX is issue  Quick links is issue. RM gets started successfully.,1.4.3,1.5.1,60,0,0,0,0,0,0,2,ambari-server/src/main/java/org/apache/ambari/server/controller/internal/AbstractProviderModule.java;ambari-server/src/test/java/org/apache/ambari/server/controller/internal/JMXHostProviderTest.java;
5344,ambari-server,Myroslav Papirkovskyy,Error with finding FK constraint,Steps: Install Ambari-1.3.2 with Oracle DB. Upgrade ambari to 1.5.0 Run 'ambari-server upgrade' command.Seems like check before execute doesn't work for Oracle. Since we ignore failures this is not block the upgrade.Exception:16:41:36 719 WARN [main] DBAccessorImpl:416 - Error executing query: ALTER TABLE clusterconfigmapping ADD CONSTRAINT FK_clustercfgmap_cluster_id FOREIGN KEY (cluster_id) REFERENCES clusters (cluster_id)java.sql.SQLSyntaxErrorException: ORA-02275: such a referential constraint already exists in the table at oracle.jdbc.driver.T4CTTIoer.processError(T4CTTIoer.java:445) at oracle.jdbc.driver.T4CTTIoer.processError(T4CTTIoer.java:396) at oracle.jdbc.driver.T4C8Oall.processError(T4C8Oall.java:879) at oracle.jdbc.driver.T4CTTIfun.receive(T4CTTIfun.java:450) at oracle.jdbc.driver.T4CTTIfun.doRPC(T4CTTIfun.java:192) at oracle.jdbc.driver.T4C8Oall.doOALL(T4C8Oall.java:531) at oracle.jdbc.driver.T4CStatement.doOall8(T4CStatement.java:193) at oracle.jdbc.driver.T4CStatement.executeForRows(T4CStatement.java:1033) at oracle.jdbc.driver.OracleStatement.doExecuteWithTimeout(OracleStatement.java:1329) at oracle.jdbc.driver.OracleStatement.executeInternal(OracleStatement.java:1909) at oracle.jdbc.driver.OracleStatement.execute(OracleStatement.java:1871) at oracle.jdbc.driver.OracleStatementWrapper.execute(OracleStatementWrapper.java:318) at org.apache.ambari.server.orm.DBAccessorImpl.executeQuery(DBAccessorImpl.java:413) at org.apache.ambari.server.orm.DBAccessorImpl.executeQuery(DBAccessorImpl.java:399) at org.apache.ambari.server.orm.DBAccessorImpl.addFKConstraint(DBAccessorImpl.java:262) at org.apache.ambari.server.upgrade.UpgradeCatalog150.executeDDLUpdates(UpgradeCatalog150.java:375) at org.apache.ambari.server.upgrade.AbstractUpgradeCatalog.upgradeSchema(AbstractUpgradeCatalog.java:177) at org.apache.ambari.server.upgrade.SchemaUpgradeHelper.executeUpgrade(SchemaUpgradeHelper.java:174) at org.apache.ambari.server.upgrade.SchemaUpgradeHelper.main(SchemaUpgradeHelper.java:234)16:41:36 720 WARN [main] DBAccessorImpl:264 - Add FK constraint failed  constraintName = FK_clustercfgmap_cluster_id  tableName = clusterconfigmapping  errorCode = 2275  message = ORA-02275: such a referential constraint already exists in the table,1.5.0,1.5.1,137,0,0,0,0,0,0,0,
5359,test,Dmitry Lysnichenko,unittest NagiosPropertyProviderTest fails,testNoNagiosServerCompoonent(org.apache.ambari.server.controller.nagios.NagiosPropertyProviderTest): Expected no alertstestNoNagiosService(org.apache.ambari.server.controller.nagios.NagiosPropertyProviderTest): Expected no alerts,1.5.1,1.5.1,7,0,0,0,0,0,0,0,
5362,ambari-agent,Siddharth Wagle,Automatic bootstrap failed on CentOS 6.5 (No module named common_functions),SSH bootstrap of agents failed on CentOS 6.5.==========================Copying OS type check script...==========================Could not create directory '/root/.ssh'.Warning: Permanently added 'c6502.ambari.apache.org 192.168.65.102' (RSA) to the list of known hosts.scp /usr/lib/python2.6/site-packages/ambari_server/os_check_type.pyhost=c6502.ambari.apache.org  exitcode=0==========================Running OS type check...==========================Traceback (most recent call last): File '/tmp/os_check_type1396641340.py'  line 22  in &lt;module&gt; from common_functions import OSCheckImportError: No module named common_functionsConnection to c6502.ambari.apache.org closed.SSH command execution finishedhost=c6502.ambari.apache.org  exitcode=1ERROR: Bootstrap of host c6502.ambari.apache.org fails because previous action finished with non-zero exit code (1)ERROR MESSAGE: tcgetattr: Invalid argumentConnection to c6502.ambari.apache.org closed.STDOUT: Traceback (most recent call last): File '/tmp/os_check_type1396641340.py'  line 22  in &lt;module&gt; from common_functions import OSCheckImportError: No module named common_functionsConnection to c6502.ambari.apache.org closed.,1.5.1,1.5.1,110,0,0,0,0,0,0,0,
5371,ambari-web,Oleg Nechiporenko,Dashboard: dashboard actions do not work for non-admin users,For non-admin users action 'Switch to classic dashboard' returns JS error and 'Reset all widgets to default' action throws to Login page.,1.5.1,1.6.0,22,0,0,0,0,0,0,0,
5381,ambari-web,Xi Wang,Installer: 'Undo' button for repo BaseURL is unnecessarily present,STR:on Installer phase go to &lt;cluster&gt;:8080 /#/installer/step1Do not do any updates of 'Base Url' fieldcheck the 'Undo' button for 2.1 stack.Actual Result:Undo is present for all 3 Os reposExpected Result:Undo should be present only after any update of 'BaseURL' field----------Seems  functionally this does not affect us  but might be confusing for users.,1.5.1,1.5.1,52,0,0,0,0,0,1,0,
5382,ambari-server,Myroslav Papirkovskyy,Schema Upgrade failed when upgrading to 1.5.1,While upgrade  schema upgrade fails.Example error output (Oracle):rg.apache.ambari.server.AmbariException: Current database store version is not compatible with current server version  serverVersion=1.5.1.96  schemaVersion=1.4.1.25 at org.apache.ambari.server.controller.AmbariServer.checkDBVersion(AmbariServer.java:479) at org.apache.ambari.server.controller.AmbariServer.run(AmbariServer.java:149) at org.apache.ambari.server.controller.AmbariServer.main(AmbariServer.java:528)and Postgres 11:39:27 364 ERROR [main] AmbariServer:531 - Failed to run the Ambari Serverorg.apache.ambari.server.AmbariException: Current database store version is not compatible with current server version  serverVersion=1.5.1.96  schemaVersion=1.5.0 at org.apache.ambari.server.controller.AmbariServer.checkDBVersion(AmbariServer.java:479) at org.apache.ambari.server.controller.AmbariServer.run(AmbariServer.java:149) at org.apache.ambari.server.controller.AmbariServer.main(AmbariServer.java:528),1.5.1,1.5.1,72,0,0,0,0,0,0,0,
5386,ambari-web,Yusaku Sako,Deploy stuck during generating tasks on Review page (not always reproduced),After the user clicks 'Deploy' in the Installer Wizard  sometimes an error is shown showing 'java.lang.IllegalArgumentException: Could not access base url'. This happens while the wizard tries to save the user-specified repo base URLs.Installer should not be performing validation during deploy  because it had already been done during Select Stacks.,1.5.1,1.5.1,51,0,0,0,0,0,0,0,
5402,ambari-web,Andrii Babiichuk,Remove classic dashboard view from Ambari,remove classic dashboard from Ambari  as it's not used any more and doesn't support new services,1.6.0,1.6.0,16,0,0,0,0,0,0,46,ambari-web/app/templates/main/dashboard.hbs;ambari-web/app/templates/main/dashboard/service/flume.hbs;ambari-web/app/templates/main/dashboard/service/hbase.hbs;ambari-web/app/templates/main/dashboard/service/hdfs.hbs;ambari-web/app/templates/main/dashboard/service/hive.hbs;ambari-web/app/templates/main/dashboard/service/mapreduce.hbs;ambari-web/app/templates/main/dashboard/service/mapreduce2.hbs;ambari-web/app/templates/main/dashboard/service/oozie.hbs;ambari-web/app/templates/main/dashboard/service/storm.hbs;ambari-web/app/templates/main/dashboard/service/yarn.hbs;ambari-web/app/templates/main/dashboard/service/zookeeper.hbs;ambari-web/app/templates/main/service/info/summary.hbs;ambari-web/app/templates/main/service/services/flume.hbs;ambari-web/app/templates/main/service/services/hbase.hbs;ambari-web/app/templates/main/service/services/hdfs.hbs;ambari-web/app/templates/main/service/services/hive.hbs;ambari-web/app/templates/main/service/services/mapreduce.hbs;ambari-web/app/templates/main/service/services/mapreduce2.hbs;ambari-web/app/templates/main/service/services/oozie.hbs;ambari-web/app/templates/main/service/services/storm.hbs;ambari-web/app/templates/main/service/services/yarn.hbs;ambari-web/app/templates/main/service/services/zookeeper.hbs;ambari-web/app/views.js;ambari-web/app/views/main/dashboard.js;ambari-web/app/views/main/dashboard/service.js;ambari-web/app/views/main/dashboard/service/flume.js;ambari-web/app/views/main/dashboard/service/hbase.js;ambari-web/app/views/main/dashboard/service/hdfs.js;ambari-web/app/views/main/dashboard/service/hive.js;ambari-web/app/views/main/dashboard/service/mapreduce.js;ambari-web/app/views/main/dashboard/service/mapreduce2.js;ambari-web/app/views/main/dashboard/service/oozie.js;ambari-web/app/views/main/dashboard/service/storm.js;ambari-web/app/views/main/dashboard/service/yarn.js;ambari-web/app/views/main/dashboard/service/zookeeper.js;ambari-web/app/views/main/service/service.js;ambari-web/app/views/main/service/services/flume.js;ambari-web/app/views/main/service/services/hbase.js;ambari-web/app/views/main/service/services/hdfs.js;ambari-web/app/views/main/service/services/hive.js;ambari-web/app/views/main/service/services/mapreduce.js;ambari-web/app/views/main/service/services/mapreduce2.js;ambari-web/app/views/main/service/services/oozie.js;ambari-web/app/views/main/service/services/storm.js;ambari-web/app/views/main/service/services/yarn.js;ambari-web/app/views/main/service/services/zookeeper.js;
5406,ambari-agent,Erin A Boyd,Pig unit test class named wrong,Typo in unit test. File said class was Hcat rather than Pig,1.5.0; 1.4.4; 1.6.0,1.6.0,12,0,1,0,0,0,0,0,
5412,ambari-agent,Vitaly Brodetskyi,Operation 'Supervisor start' failed during installation but all supervisors are alive,STR:1. Deploy Hadoop by default scenario with all services.2. Try to start Storm.Actual results: 'Start All Services' operation failed because of 'Supervisor start' failed. 'Start Storm' operation does not contain 'Supervisor start' popups  but all supervisors are STARTED after it have finished.,1.5.1,1.5.1,44,0,0,0,0,0,0,0,
5413,ambari-agent,Siddharth Wagle,OS type check for centos 6.5 can fail if the /etc/issue has CentOS Linux release 6.5,I tried default centos 6.5 it works fine. But if I change /etc/issues and /etc/redhat-release to say:CentOS Linux release 6.5 (Final)then the registration fails with:INFO 2014-04-09 14:39:22 501 security.py:51 - SSL connection established. Two-way SSL authentication is turned off on the server.ERROR 2014-04-09 14:39:22 563 Controller.py:100 - Cannot register host with not supported os type  hostname=c6501.ambari.apache.org  serverOsType=redhat6  agentOstype=centos linux6In the agent logs.By default centos 6.5 has:CentOS release 6.5 (Final)but sometimes can have:CentOS Linux release 6.5 (Final),1.5.1,1.5.1,74,0,0,0,0,0,0,0,
5433,,Sumit Mohanty,Add Host failed on upgraded cluster on Suse,This is due to upgrade. We need to change it manually after upgrade://Now we have (redhat  suse  debian  other_detected_by_python)vi /etc/ambari-server/conf/ambari.properties(server.os_type=sles11) --&gt;( server.os_type=suse11)+restart the serverShould upgrade automatically deal with this?old code: os_info = platform.linux_distribution( None  None  None  ['SuSE'  'redhat' ]  0 ) os_name = os_info[0].lower() if os_name == 'suse': os_name = 'sles' os_version = os_info[1].split('.'  1)[0] master_os_type = os_name + os_version write_property(OS_TYPE_PROPERTY  master_os_type),1.5.1,1.5.1,70,0,0,0,0,0,0,0,
5445,ambari-server,Dmytro Sen,When new host components are created thru API  some indication should be given that Nagios has to be restarted,Need to fix this on API side,1.5.0,1.6.0,7,0,0,0,0,0,0,20,ambari-server/src/main/java/org/apache/ambari/server/agent/HeartBeatHandler.java;ambari-server/src/main/java/org/apache/ambari/server/api/services/AmbariMetaInfo.java;ambari-server/src/main/java/org/apache/ambari/server/controller/AmbariManagementControllerImpl.java;ambari-server/src/main/java/org/apache/ambari/server/orm/entities/HostComponentDesiredStateEntity.java;ambari-server/src/main/java/org/apache/ambari/server/state/ConfigHelper.java;ambari-server/src/main/java/org/apache/ambari/server/state/ServiceComponentHost.java;ambari-server/src/main/java/org/apache/ambari/server/state/ServiceInfo.java;ambari-server/src/main/java/org/apache/ambari/server/state/svccomphost/ServiceComponentHostImpl.java;ambari-server/src/main/java/org/apache/ambari/server/upgrade/UpgradeCatalog160.java;ambari-server/src/main/resources/Ambari-DDL-MySQL-CREATE.sql;ambari-server/src/main/resources/Ambari-DDL-Oracle-CREATE.sql;ambari-server/src/main/resources/Ambari-DDL-Postgres-CREATE.sql;ambari-server/src/main/resources/stacks/HDP/1.3.2/services/GANGLIA/metainfo.xml;ambari-server/src/main/resources/stacks/HDP/1.3.2/services/NAGIOS/metainfo.xml;ambari-server/src/main/resources/stacks/HDP/2.0.6/services/GANGLIA/metainfo.xml;ambari-server/src/main/resources/stacks/HDP/2.0.6/services/NAGIOS/metainfo.xml;ambari-server/src/test/java/org/apache/ambari/server/agent/TestHeartbeatHandler.java;ambari-server/src/test/java/org/apache/ambari/server/controller/AmbariManagementControllerTest.java;ambari-server/src/test/java/org/apache/ambari/server/upgrade/UpgradeCatalog160Test.java;ambari-server/src/test/resources/stacks/HDP/2.0.5/services/NAGIOS/metainfo.xml;
5455,ambari-web,Srimanth Gunturi,Ambari configuration for map join conversion and tez container size seems wrong,For hive:hive.auto.convert.join.noconditionaltask.size is set to 1000000000 This should be a fraction (1/3) of the container size.hive.tez.java.opts has '-Xmx1024m'This is different from both map and reduce sizes. Desired values are: map size if map size &gt; 2g else reduce sizemap size is set on the same cluster to ~500mbThe settings as the are will lead to many failed queries because the mapjoin conversion is to aggressive. If we don't change the container sizes based on cluster configs we will see wide spread problems with containers being killed or perf problems.,1.5.1,1.5.1,93,0,0,0,0,0,0,0,
5457,ambari-web,Andrii Babiichuk,Host Checks: alternatives check results are not surfaced in Host Check popup,Ambari Agent  as part of host checks  identifies conflicting 'alternatives' settings and reports back inside the 'last_agent_env' object.UI is not surfacing this in Host Checks popup.We should have a section called 'Alternatives Issues' and list out the alternatives names.For example: 'last_agent_env' : { 'stackFoldersAndFiles' : [ ... ]  'alternatives' : [ { 'name' : 'zookeeper-conf'  'target' : '/etc/zookeeper/conf.dist' }  { 'name' : 'hadoop-conf'  'target' : '/etc/hadoop/conf.dist' }  ]  'existingUsers' : [ .... ]  'existingRepos' : [ ... ]  ...In the above case  we want to highlight the fact that hadoop-conf and zookeeper-conf have conflicts.Alternatives Issues--------The following alternatives should be removedAlternativeshadoop-conf Exists on 3 hostszookeeper-conf Exists on 3 hosts,1.5.1,1.6.0,128,0,0,0,0,0,0,3,ambari-web/app/controllers/wizard/step3_controller.js;ambari-web/app/messages.js;ambari-web/app/templates/wizard/step3_host_warnings_popup.hbs;
5459,,Dmytro Sen,Usability: Improve Stack Definition support for repositories,1) Remove HDP-UTILS from Ambari .repo  and move into the HDP Stack Definition (Ambari does not depend on HDP-UTILS so this causes confusion  makes it harder to doc local repo setup  and is unclear on failures if not setup correctly).2) Requires support for multiple repositories in a Stack Definition  and ability to specify multiple repositories from UI.,1.6.0,1.6.0,57,0,0,0,0,0,0,20,ambari-server/src/main/resources/stacks/HDP/1.3.2/repos/repoinfo.xml;ambari-server/src/main/resources/stacks/HDP/1.3.3/repos/repoinfo.xml;ambari-server/src/main/resources/stacks/HDP/2.0.6/repos/repoinfo.xml;ambari-server/src/main/resources/stacks/HDP/2.0.6/services/GANGLIA/metainfo.xml;ambari-server/src/main/resources/stacks/HDP/2.0.6/services/NAGIOS/metainfo.xml;ambari-server/src/main/resources/stacks/HDP/2.0/repos/repoinfo.xml;ambari-server/src/main/resources/stacks/HDP/2.1/repos/repoinfo.xml;ambari-server/src/main/resources/stacks/HDP/1.3.2/repos/repoinfo.xml;ambari-server/src/main/resources/stacks/HDP/1.3.3/repos/repoinfo.xml;ambari-server/src/main/resources/stacks/HDP/1.3/repos/repoinfo.xml;ambari-server/src/main/resources/stacks/HDP/2.0.6/repos/repoinfo.xml;ambari-server/src/main/resources/stacks/HDP/2.0/repos/repoinfo.xml;ambari-server/src/main/resources/stacks/HDP/2.1/repos/repoinfo.xml;ambari-server/src/main/resources/stacks/HDP/1.3.2/repos/repoinfo.xml;ambari-server/src/main/resources/stacks/HDP/1.3.3/repos/repoinfo.xml;ambari-server/src/main/resources/stacks/HDP/2.0.6/repos/repoinfo.xml;ambari-server/src/main/resources/stacks/HDP/2.0.6/services/GANGLIA/metainfo.xml;ambari-server/src/main/resources/stacks/HDP/2.0.6/services/NAGIOS/metainfo.xml;ambari-server/src/main/resources/stacks/HDP/2.0/repos/repoinfo.xml;ambari-server/src/main/resources/stacks/HDP/2.1/repos/repoinfo.xml;
5472,ambari-server,Dmytro Sen,Use SchemaTool in Hive for init metastore DB schema,When Ambari create the metastore database in MySQL it uses auto create feature. This does not create the transaction tables  so any ACID operations (including streaming ingest) will not work.,1.5.1,1.6.0,30,0,0,0,0,0,0,2,ambari-server/src/main/resources/stacks/HDP/2.0.6/services/HIVE/package/scripts/hive.py;ambari-server/src/test/python/stacks/2.1/HIVE/test_hive_metastore.py;
5511,ambari-web,Antonenko Alexander,Misleading hardcoded command in paragraph 2 on step 'Manual commands' of 'Move Master' wizard,STR:1. Deploy cluster with multiplied NN directory(in our case /grid/0/hadoop/hdfs/namenode  /grid/1/hadoop/hdfs/namenode).2. Start NN moving.3. Reach step 'Manual commands'.Actual results:Paragraph 1 contains information about all dirs we should move.Paragraph 2 contains message 'Login to the target host XXX and change permissons for the NameNode dirs by running:' and only one command with hardcoded NN dir:chown -R hdfs:hadoop /hadoop/hdfs/namenode/Screenshot attached.When there are multiple directories specified  we need to show the actual path (but replace commas with a space).In case of '/grid/0/hadoop/hdfs/namenode /grid/1/hadoop/hdfs/namenode' as in the attached image  we should display:chown -R hdfs:hadoop /grid/0/hadoop/hdfs/namenode /grid/1/hadoop/hdfs/namenode,1.5.1,1.6.0,97,1,0,0,0,0,0,0,
5512,ambari-web,Antonenko Alexander,Move wizard and HA wizard gets stuck on any deploy step,Because of JS error (page refresh makes no effect).,1.6.0,1.6.0,9,0,0,0,0,0,0,0,
5524,ambari-web,Oleg Nechiporenko,Unit tests for number_utils  string_utils  validator and misc files.,Create unit tests for following files:utils/misc.jsutils/number_utils.jsutils/string_utils.jsutils/validator.js,1.6.0,1.6.0,6,0,0,0,0,0,0,0,
5531,ambari-web,Srimanth Gunturi,Switch SQL standard authorization to be off by default.,For Ambari 1.5.1 SQL standard authorization was on by default.Users with certification suites are running into problems related to this feature (which were not bugs in the auth systems  rather they were additional requirements to using it). This needs to be turned off by default. The feature is controlled by:hive.security.authorization.enabledWe want the default value to be set to false in Ambari 1.6.0.,1.6.0,1.6.0,62,0,0,0,0,0,0,0,
5543,ambari-web,Oleg Nechiporenko,Unit tests for steps 6 (with small refactor),,1.6.0,1.6.0,1,0,0,0,0,0,0,0,
5546,,Dmytro Sen,Call for requests with 'page_size' always return 10 most recent,Problem:Call: /api/v1/clusters/cl1/requests?to=end&amp;page_size=20Actually result: return most recent 10 requestsExpected result: return most recent 20 requests.Call: /api/v1/clusters/cl1/requests?from=start&amp;page_size=3Actually result: return first 3 requests started from the first in most recent 10Expected result: return first 3 requests started from the very first('install services')In this case  we can never get history requests made before most recent 10.,1.6.0,1.6.1,52,0,0,0,0,0,0,11,ambari-server/src/main/java/org/apache/ambari/server/actionmanager/ActionDBAccessor.java;ambari-server/src/main/java/org/apache/ambari/server/actionmanager/ActionDBAccessorImpl.java;ambari-server/src/main/java/org/apache/ambari/server/actionmanager/ActionManager.java;ambari-server/src/main/java/org/apache/ambari/server/api/query/QueryImpl.java;ambari-server/src/main/java/org/apache/ambari/server/api/services/BaseRequest.java;ambari-server/src/main/java/org/apache/ambari/server/controller/internal/RequestResourceProvider.java;ambari-server/src/main/java/org/apache/ambari/server/controller/utilities/PropertyHelper.java;ambari-server/src/main/java/org/apache/ambari/server/orm/dao/HostRoleCommandDAO.java;ambari-server/src/test/java/org/apache/ambari/server/actionmanager/TestActionDBAccessorImpl.java;ambari-server/src/test/java/org/apache/ambari/server/actionmanager/TestActionManager.java;ambari-server/src/test/java/org/apache/ambari/server/controller/internal/RequestResourceProviderTest.java;
5551,ambari-web,Jaimin D Jetly,Checkbox 'client' without upper case letter,,1.6.0,1.6.0,1,0,0,0,0,0,0,0,
5555,ambari-web,Oleg Nechiporenko,NameNode HA wizard: Review page appears blank,,1.6.0,1.6.0,1,0,0,0,0,0,0,0,
5558,ambari-web,Andrii Babiichuk,Navigating back from Host page to Heatmaps page is broken,STR: Go to Dashboard page. Switch to 'Heatmaps' tab. Click on first host. On host page click 'Back'.Actual result: Appeared 'Cluster Status and Metrics' tab.Expected result: Should appear 'Heatmaps' tab.,1.6.0,1.6.0,30,0,0,0,0,0,0,2,ambari-web/app/routes/main.js;ambari-web/app/views/main/dashboard.js;
5569,ambari-web,Oleg Nechiporenko,Fix UI Unit tests,,1.6.0,1.6.0,1,0,0,0,0,0,0,0,
5571,ambari-web,Aleksandr Kovalenko,Restart option is enabled for components in 'Decommissioned' state but it should not,'Restart' option should not be enabled if a slave component is in 'decommissioned' state  but it is.STR:1) Go to 'Host details' page2) Make any slave component 'Decommissioned'Actual result: 'Restart' option is enabled (see screenshot)Expected result: 'Restart' option should be disabled.,1.6.0,1.6.0,40,0,0,0,0,0,0,0,
5577,ambari-server,Dmitry Lysnichenko,Turn Off Maintenance Mode for HDFS does not work (problems with ambari-agent),STR:Turn On Maintenance Mode for HDFSTurn Off Maintenance Mode for HDFSExpected result:Have not problems with ambari-agent.Actual result:Have problems with ambari-agent.,1.6.0,1.6.0,20,0,0,0,0,0,0,0,
5603,ambari-web,Xi Wang,Ambari version is unknown during installer via UI,During installer user does not see Ambari Version from UI (see screenshot)  but on monitoring phase it's available in the same Admin -&gt; About,1.6.0,1.6.0,24,0,0,0,0,0,0,0,
5605,ambari-web,Xi Wang,Usability UX: Default key actions for dialog boxes,PROBLEM: Default action for dialog boxes in AmbariUSE CASE: Ambari UI doesn't allow you to press enter and trigger default actions. When a default action is high lighted 'green button' you should be able to hit enter and have the action be triggered. In this case add hit enter should make okay button trigger. Also  pressing escape should cancel the dialog box.,1.5.0,1.6.1,62,0,0,0,0,0,0,0,
5607,,Michael Harp,Yarn Nodemanager Metrics only update every few minutes,Yarn Nodemanager Metrics take far too long between updates.To demonstrate:Run Terasort or anything that runs mapreduce:hdfs dfs -mkdir -p benchmarks/terasorthadoop jar /usr/lib/hadoop-mapreduce/hadoop-mapreduce-examples.jar teragen -Dmapred.map.tasks=72 -Dmapred.reduce.tasks=36 1000000 benchmarks/terasort/inputhadoop jar /usr/lib/hadoop-mapreduce/hadoop-mapreduce-examples.jar terasort -Dmapred.map.tasks=72 -Dmapred.reduce.tasks=36 benchmarks/terasort/input benchmarks/terasort/outputhdfs dfs -rm -R -skipTrash benchmarks/terasortThen repeatedly probe the API at:https://&lt;server&gt;:8081/api/v1/clusters/c1/services/YARN/components/NODEMANAGER?fields=host_components/metrics/yarnIt usually takes 2-3 minutes to see the metrics update  very repeatable.,1.5.1,1.6.1,68,0,0,0,0,1,0,2,ambari-server/src/main/resources/stacks/HDP/1.3.2/services/GANGLIA/package/files/rrd.py;ambari-server/src/main/resources/stacks/HDP/2.0.6/services/GANGLIA/package/files/rrd.py;
5612,ambari-web,Oleg Nechiporenko,Unit tests for object_utils  date  ui_effects  updater,Create unit tests for following files: utils/object.js utils/date_utils.js utils/ui_effects_utils.js utils/updater.js,1.6.0,1.6.0,10,0,0,0,0,0,0,0,
5622,ambari-server,Myroslav Papirkovskyy,'Upgrading schema' failed during upgrading to 1.6.0,Postgres issue:new restart_required relies on eclipselink default type converters  we avoided this in pastorg.postgresql.util.PSQLException: ERROR: column 'restart_required' is of type boolean but expression is of type integer Hint: You will need to rewrite or cast the expression. Position: 57 at org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2161) at org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:1890) at org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:255) at org.postgresql.jdbc2.AbstractJdbc2Statement.execute(AbstractJdbc2Statement.java:559) at org.postgresql.jdbc2.AbstractJdbc2Statement.executeWithFlags(AbstractJdbc2Statement.java:403) at org.postgresql.jdbc2.AbstractJdbc2Statement.executeUpdate(AbstractJdbc2Statement.java:331) at org.apache.ambari.server.orm.DBAccessorImpl.updateTable(DBAccessorImpl.java:447) at org.apache.ambari.server.orm.DBAccessorImpl.addColumn(DBAccessorImpl.java:371) at org.apache.ambari.server.upgrade.UpgradeCatalog160.executeDDLUpdates(UpgradeCatalog160.java:72) at org.apache.ambari.server.upgrade.AbstractUpgradeCatalog.upgradeSchema(AbstractUpgradeCatalog.java:177) at org.apache.ambari.server.upgrade.SchemaUpgradeHelper.executeUpgrade(SchemaUpgradeHelper.java:176) at org.apache.ambari.server.upgrade.SchemaUpgradeHelper.main(SchemaUpgradeHelper.java:225)MySQL issue:Inreresting MySQL feature  there should be no space between function name and parenthesis18:57:00 629 WARN [main] DBAccessorImpl:469 - Error executing query: insert into request(request_id  cluster_id  request_context  start_time  end_time  create_time) select distinct s.request_id  s.cluster_id  s.request_context  coalesce (cmd.start_time  -1)  coalesce (cmd.end_time  -1)  -1 from (select distinct request_id  cluster_id  request_context from stage ) s left join (select request_id  min(start_time) as start_time  max(end_time) as end_time from host_role_command group by request_id) cmd on s.request_id=cmd.request_idcom.mysql.jdbc.exceptions.jdbc4.MySQLSyntaxErrorException: FUNCTION ambari.coalesce does not exist at sun.reflect.GeneratedConstructorAccessor14.newInstance(Unknown Source) at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45) at java.lang.reflect.Constructor.newInstance(Constructor.java:526) at com.mysql.jdbc.Util.handleNewInstance(Util.java:411) at com.mysql.jdbc.Util.getInstance(Util.java:386) at com.mysql.jdbc.SQLError.createSQLException(SQLError.java:1054) at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:4237) at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:4169) at com.mysql.jdbc.MysqlIO.sendCommand(MysqlIO.java:2617) at com.mysql.jdbc.MysqlIO.sqlQueryDirect(MysqlIO.java:2778) at com.mysql.jdbc.ConnectionImpl.execSQL(ConnectionImpl.java:2828) at com.mysql.jdbc.ConnectionImpl.execSQL(ConnectionImpl.java:2777) at com.mysql.jdbc.StatementImpl.execute(StatementImpl.java:949) at com.mysql.jdbc.StatementImpl.execute(StatementImpl.java:795) at org.apache.ambari.server.orm.DBAccessorImpl.executeQuery(DBAccessorImpl.java:466) at org.apache.ambari.server.orm.DBAccessorImpl.executeQuery(DBAccessorImpl.java:452) at org.apache.ambari.server.upgrade.UpgradeCatalog150.executeDDLUpdates(UpgradeCatalog150.java:325) at org.apache.ambari.server.upgrade.AbstractUpgradeCatalog.upgradeSchema(AbstractUpgradeCatalog.java:177) at org.apache.ambari.server.upgrade.SchemaUpgradeHelper.executeUpgrade(SchemaUpgradeHelper.java:176) at org.apache.ambari.server.upgrade.SchemaUpgradeHelper.main(SchemaUpgradeHelper.java:225),1.6.0,1.6.0,189,0,0,0,0,0,0,0,
5628,ambari-web,Srimanth Gunturi,Explicitly disabling datanucleus l2 cache for hive,Ambari installations of hive currently do not set any datanucleus related properties. There is such a thing as a datanucleus l2 cache  that is pretty bad for hive in a distributed environment if it is set. (If there is a lone embedded hive instance  with no other codepaths to the db  then it's fine  but that never happens in a distributed environment.)By default  if no setting is present  datanucleus defaults the l2 cache to being on  so hive ups the ante by defaulting to turning it off by default if no other setting is configured.Now  in a war of 'defaults'  the hive default should win  but this is an area where we have had recurring support issues from clients that turn it on expecting improved performance. Thus  I'd like ambari installed hive-site.xml to explicitly have this config parameter turned off  with a comment asking users to not switch it on as it impacts hive negatively.The parameter in question is 'datanucleus.cache.level2.type'   and it's value should be 'none'. (Note that I've seen some older configs that seem to do things like turning datanucleus.cache.level2 = false and stuff like that  that is bogus config and does nothing and should not be assumed to be a catch-all enabler.)As a comment  I'd like the following comment 'Disables datanucleus l2 cache. This must be set to 'none' for hive to work properly' or something to that effect.,1.5.1,1.6.1,232,0,0,0,0,0,0,0,
5633,ambari-agent,Dmitry Lysnichenko,Start Services command gets stuck for about 30 mins,On Security wizard Start Services command ZOOKEEPER_SERVER Start task scheduled on ambari-server host remained in QUEUED status for about 30 mins and other non-completed commands were in PENDING status. For this time interval no command was in IN_PROGRESS status.Later executing stop all services command on the same cluster also made ZOOKEEPER_SERVER Stop task scheduled on ambari-server host to remain in QUEUED status for around 20 mins.,1.5.1,1.6.0,65,0,0,0,0,0,0,0,
5643,ambari-web,Jaimin D Jetly,Add Services is disabled after upgrading the stack from HDP-2.0 to HDP-2.1,Prior to upgrade  launch Add Services wizard using Ambari 1.5.0 (crucial step) Upgrade stack to a stack with new services and Ambari to 1.5.1 Add Services button is disabled  even though there are services that have not been added to the cluster,1.5.1,1.6.0,43,0,0,0,0,0,0,0,
5646,ambari-web,Srimanth Gunturi,Jobs dont show up as links for a moment when page is visited,I had a couple of finished jobs showing the jobs page. Then I clicked on one job and went back to the jobs page. For a moment both jobs were not shown as links - though they are clickable. This is basically an appearance issue where the job doesnt look like a link for a moment.,1.6.0,1.6.0,56,0,0,0,0,0,0,0,
5656,ambari-web,Xi Wang,Views: do not let the user click on the Views icon in the top nav,When clicking on the Views icon in the top nav  the page content turns blank.We will show a view index page in a later release  but for now  let's just disable clicking on that icon.,1.6.0,1.6.0,35,0,0,0,0,0,0,0,
5668,ambari-web,Aleksandr Kovalenko,JobsDiagnostic|2.1.1: No job status and end time is shown for interrupted job,Enabled tez engine for hive;Executed select query;If while job is running I stop it by double pressign CTRL-C in hive shell then job will not have end time shown in jobs table and no failed icon (red X)  but in job details it will have status 'killed' and correct end time.If job is killed with yarn application -kill it will have correct end time and failed icon displayed in jobs table  but in job details it will not have neither status nor end time.,1.5.1,1.6.1,84,0,0,0,0,0,0,0,
5669,ambari-web,Xi Wang,Alternatives issues has error message (missing translation),Build 1.6.0-151Missing translation: installer.step3.hostWarningsPopup.alternatives.emptyinstaller.step3.hostWarningsPopup.alternatives.empty,1.6.0,1.6.0,4,0,0,0,0,0,0,0,
5688,,Dmytro Sen,Zookeeper smoke test failed after being triggered after deleting a host  containing ZookeeperServer,1. Stopped all host components on a host ( to be deleted) with ZookeeperServer. 2. Deleted a host from cluster. 3. Ran Zookeeper Service Check.Actual result: failed. Expected: ok.,1.5.0,1.6.1,29,0,0,0,0,0,0,10,ambari-server/src/main/java/org/apache/ambari/server/api/services/AmbariMetaInfo.java;ambari-server/src/main/java/org/apache/ambari/server/api/util/StackExtensionHelper.java;ambari-server/src/main/java/org/apache/ambari/server/controller/AmbariManagementControllerImpl.java;ambari-server/src/main/java/org/apache/ambari/server/state/ServiceInfo.java;ambari-server/src/main/resources/stacks/HDP/1.3.2/services/ZOOKEEPER/metainfo.xml;ambari-server/src/main/resources/stacks/HDP/2.0.6/services/ZOOKEEPER/metainfo.xml;ambari-server/src/test/java/org/apache/ambari/server/api/services/AmbariMetaInfoTest.java;ambari-server/src/test/java/org/apache/ambari/server/api/util/StackExtensionHelperTest.java;ambari-server/src/test/java/org/apache/ambari/server/controller/AmbariManagementControllerTest.java;ambari-server/src/test/resources/stacks/HDP/2.0.7/services/ZOOKEEPER/metainfo.xml;
5692,ambari-web,Oleg Nechiporenko,Unit tests for utils/config.js part 1,Update unit tests for utils/config.js.,1.6.0,1.6.1,5,0,0,0,0,0,0,0,
5714,ambari-web,Xi Wang,Views list not loading in Ambari Web,In build 1.6.0-159  the views call is being made but it's not listing the views in the dropdown.This was due to the API change and Ambari Web hasn't adjusted yet to this introduction of /versions/.,1.6.0,1.6.0,35,0,0,0,0,0,0,0,
5716,ambari-web,Jaimin D Jetly,Disable security fails occasionally,There is a possibility that 'Start all Services' command will fail on Disable Security wizard if App.Service DS model was not populated on the load of 'Disable security page' (timing issue). We need to make sure that the Service model has populated before the 'Disable Security page' is rendered.,1.6.0,1.6.0,49,0,0,0,1,0,0,0,
5720,,Jonathan Hurley,pig.properties should set pig.location.check.strict to false,pig.properties should set pig.location.check.strict to false,1.6.0,1.6.1,6,0,0,0,0,0,0,0,
5722,,Jonathan Hurley,All Services Fail To Deploy Due To Agent Parsing Exception,When deploying a brand new cluster  all services fail to install due to a parsing exception thrown from the Ambari Agents.File '/usr/lib/python2.6/site-packages/ambari_agent/CustomServiceOrchestrator.py'  line 113  in runCommandjson_path = self.dump_command_to_json(command)File '/usr/lib/python2.6/site-packages/ambari_agent/CustomServiceOrchestrator.py'  line 209  in dump_command_to_jsoncommand'clusterHostInfo' = manifestGenerator.decompressClusterHostInfo(command'clusterHostInfo')File '/usr/lib/python2.6/site-packages/ambari_agent/manifestGenerator.py'  line 116  in decompressClusterHostInfoindexes = convertRangeToList(v)File '/usr/lib/python2.6/site-packages/ambari_agent/manifestGenerator.py'  line 57  in convertRangeToListraise AgentException.AgentException('Broken data in given range  expected - ''m-n'' or ''m''  got : ' + str(r))AgentException: 'Broken data in given range  expected - m-n or m  got : -1he command being sent is{hs_host=[2]  namenode_host=[1]  snamenode_host=[2]  zookeeper_hosts=[0-2]  ganglia_server_host=[1]  nm_hosts=[0]  ganglia_monitor_hosts=[0-2]  all_hosts=[c6403.ambari.apache.org  c6401.ambari.apache.org  c6402.ambari.apache.org]  rm_host=[2]  app_timeline_server_hosts=[2]  slave_hosts=[0]  ambari_server_host=[-1]  nagios_server_host=[1]  all_ping_ports=[8670:0-2]}Notice the ambari-server-host which was added in that commit; it value is 1which would not parse correctly in manifestGenerator.pyI suspect Git e667dc7c9870864ff537374c819b7c1d1dd88e98 caused this problem.Steps to reproduce:1) Provision 3 c64 hosts2) Wipe your server database and re-create it with the embedded PSQL script3) Attempt to provision a cluster with various services.All services will fail to deploy b/c of the above exception. This was working without issues before the above suspect commit.,1.6.0,1.6.0,165,0,0,0,0,0,1,0,
5726,ambari-web,Jaimin D Jetly,Adding Oozie failed at service check,This happens because HDFS and YARN/MapReduce requires to be restarted for Oozie smoke test to pass successfullyAs a fix to this issue: Don't run smoke test on 'Install  Start and Test' page of the add service wizard. Review page should ask user to restart all stale services.,1.5.0,1.6.0,47,0,0,0,0,0,0,0,
5730,ambari-agent,Vitaly Brodetskyi,Space Error in container-executor.cfg,There is a space between 'banned.user' and '=' which make configuration here is ignored by container-executor  so some default banned users works to include hdfs. Space should be deleted between 'banned.user' and '='yarn.nodemanager.local-dirs=/grid/0/hadoop/yarn/local /grid/1/hadoop/yarn/localyarn.nodemanager.log-dirs=/grid/0/hadoop/yarn/log /grid/1/hadoop/yarn/logyarn.nodemanager.linux-container-executor.group=hadoopbanned.users = hdfs yarn mapred binmin.user.id=1000It should be banned.users=hdfs yarn mapred bin,1.6.0,1.6.0,50,0,0,0,0,0,0,0,
5735,ambari-server,Dmitry Lysnichenko,HDP deployment failed in CentOS5,Fail: Execution of 'mkdir -p /tmp/HDP-artifacts/ ; curl --noproxy hadoop -kf --retry 10 http://hadoop:8080/resources//jdk-7u45-linux-x64.tar.gz -o /tmp/HDP-artifacts//jdk-7u45-linux-x64.tar.gz' returned 2. curl: option --noproxy: is unknownversion of curl that is available at Centos 5 and SLES 11 SP1 seems to have no support for '--noproxy' option.But such workaround works:no_proxy=i.ua curl http://www.i.ua -iI'm going to replace all '--noproxy' invocations with usage of $no_proxy env variable.,1.6.0,1.6.0,78,0,0,0,0,0,0,0,
5739,ambari-web,Jaimin D Jetly,File View Cleanup,A few items that need to be rectified for the File view submission:1. Modify code to abide by Ambari Coding Standards2. JavaDoc Interfaces and Methods.https://cwiki.apache.org/confluence/display/AMBARI/Coding+Guidelines+for+Ambari.,1.6.0,1.6.0,28,0,0,0,0,0,0,0,
5751,ambari-server,Myroslav Papirkovskyy,Ambari upgrade to Ambari-1.6.0 from Ambari-1.5.1 logs PSQLException,Following upgrade documentation at http://docs.hortonworks.com/HDPDocuments/Ambari-1.5.1.0/bk_upgrading_Ambari/content/ambari-chap7_2x.html On executing ambari-server upgrade  PSQLException is logged inambari-server.log:21:36:20 498 INFO [main] SchemaUpgradeHelper:211 - Upgrading schema to target version = 1.6.021:36:20 528 INFO [main] SchemaUpgradeHelper:220 - Upgrading schema from source version = 1.5.1.11021:36:20 530 INFO [main] SchemaUpgradeHelper:141 - Upgrade path: [{ org.apache.ambari.server.upgrade.UpgradeCatalog160$$EnhancerByGuice$$ff8a4f66: sourceVersion = null  targetVersion = 1.6.0 }]21:36:20 530 INFO [main] SchemaUpgradeHelper:171 - Executing DDL upgrade...21:36:20 533 INFO [main] DBAccessorImpl:463 - Executing query: ALTER SCHEMA ambari OWNER TO 'ambari';21:36:20 534 INFO [main] DBAccessorImpl:463 - Executing query: ALTER ROLE 'ambari' SET search_path to 'ambari';21:36:20 598 INFO [main] DBAccessorImpl:463 - Executing query: CREATE TABLE hostgroup_configuration (blueprint_name VARCHAR(255) NOT NULL  hostgroup_name VARCHAR(255) NOT NULL  type_name VARCHAR(255) NOT NULL  config_data BYTEA NOT NULL  PRIMARY KEY (blueprint_name  hostgroup_name  type_name))21:36:20 962 INFO [main] DBAccessorImpl:463 - Executing query: CREATE TABLE viewentity (id BIGINT NOT NULL  view_name VARCHAR(255) NOT NULL  view_instance_name VARCHAR(255) NOT NULL  class_name VARCHAR(255) NOT NULL  id_property VARCHAR(255)  PRIMARY KEY (id))21:36:21 010 INFO [main] DBAccessorImpl:463 - Executing query: ALTER TABLE hostcomponentdesiredstate ADD restart_required BOOLEAN21:36:21 078 INFO [main] DBAccessorImpl:463 - Executing query: ALTER TABLE hostgroup_configuration ADD CONSTRAINT FK_hg_config_blueprint_name FOREIGN KEY (blueprint_name) REFERENCES hostgroup (blueprint_name)21:36:21 084 WARN [main] DBAccessorImpl:469 - Error executing query: ALTER TABLE hostgroup_configuration ADD CONSTRAINT FK_hg_config_blueprint_name FOREIGN KEY (blueprint_name) REFERENCES hostgroup (blueprint_name)org.postgresql.util.PSQLException: ERROR: there is no unique constraint matching given keys for referenced table 'hostgroup' at org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2161) at org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:1890) at org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:255) at org.postgresql.jdbc2.AbstractJdbc2Statement.execute(AbstractJdbc2Statement.java:559) at org.postgresql.jdbc2.AbstractJdbc2Statement.executeWithFlags(AbstractJdbc2Statement.java:403) at org.postgresql.jdbc2.AbstractJdbc2Statement.execute(AbstractJdbc2Statement.java:395) at org.apache.ambari.server.orm.DBAccessorImpl.executeQuery(DBAccessorImpl.java:466) at org.apache.ambari.server.orm.DBAccessorImpl.executeQuery(DBAccessorImpl.java:452) at org.apache.ambari.server.orm.DBAccessorImpl.addFKConstraint(DBAccessorImpl.java:337) at org.apache.ambari.server.orm.DBAccessorImpl.addFKConstraint(DBAccessorImpl.java:321) at org.apache.ambari.server.upgrade.UpgradeCatalog160.executeDDLUpdates(UpgradeCatalog160.java:85) at org.apache.ambari.server.upgrade.AbstractUpgradeCatalog.upgradeSchema(AbstractUpgradeCatalog.java:250) at org.apache.ambari.server.upgrade.SchemaUpgradeHelper.executeUpgrade(SchemaUpgradeHelper.java:176) at org.apache.ambari.server.upgrade.SchemaUpgradeHelper.main(SchemaUpgradeHelper.java:225)21:36:21 089 WARN [main] DBAccessorImpl:339 - Add FK constraint failed  constraintName = FK_hg_config_blueprint_name  tableName = hostgroup_configurationorg.postgresql.util.PSQLException: ERROR: there is no unique constraint matching given keys for referenced table 'hostgroup' at org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2161) at org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:1890) at org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:255) at org.postgresql.jdbc2.AbstractJdbc2Statement.execute(AbstractJdbc2Statement.java:559) at org.postgresql.jdbc2.AbstractJdbc2Statement.executeWithFlags(AbstractJdbc2Statement.java:403) at org.postgresql.jdbc2.AbstractJdbc2Statement.execute(AbstractJdbc2Statement.java:395) at org.apache.ambari.server.orm.DBAccessorImpl.executeQuery(DBAccessorImpl.java:466) at org.apache.ambari.server.orm.DBAccessorImpl.executeQuery(DBAccessorImpl.java:452) at org.apache.ambari.server.orm.DBAccessorImpl.addFKConstraint(DBAccessorImpl.java:337) at org.apache.ambari.server.orm.DBAccessorImpl.addFKConstraint(DBAccessorImpl.java:321) at org.apache.ambari.server.upgrade.UpgradeCatalog160.executeDDLUpdates(UpgradeCatalog160.java:85) at org.apache.ambari.server.upgrade.AbstractUpgradeCatalog.upgradeSchema(AbstractUpgradeCatalog.java:250) at org.apache.ambari.server.upgrade.SchemaUpgradeHelper.executeUpgrade(SchemaUpgradeHelper.java:176) at org.apache.ambari.server.upgrade.SchemaUpgradeHelper.main(SchemaUpgradeHelper.java:225),1.6.0,1.6.0,295,0,0,0,0,0,0,0,
5753,ambari-web,Jaimin D Jetly,Storm fails to start after disabling security,nimbus.childopts  ui.childopts and supervisor.childopts points to sasl configuration files after the security is disabled. web-ui should remove -Djava.security.auth.login.config parameter from these properties while disabling security.,1.6.0,1.6.0,25,0,0,0,0,0,0,0,
5761,ambari-server,Myroslav Papirkovskyy,2000-node cluster testing: during install phase of cluster deployment  install tasks were stuck in PENDING state,ActionScheduler is stucked when adding tasks to ActionQueue on large clusters (&gt;1000 nodes),1.6.0,1.6.1,13,0,0,0,0,1,0,0,
5778,ambari-server,Myroslav Papirkovskyy,In some upgrade scenarios  Ambari Web's persist key-value store state causes the UI to act unpredictably,During Ambari upgrade  automatically clear the persist state to prevent potential issues with Ambari Web not working properly (this was observed a number of times on upgraded clusters). Currently  we make the following call to get out of the inconsistent state so that Ambari Web works properly:curl -i -u admin:admin -H 'X-Requested-By: ambari' -X POST -d '{ 'CLUSTER_CURRENT_STATUS': '{/'clusterState/':/'CLUSTER_STARTED_5/'}' }' http://localhost:8080/api/v1/persistWe need to do something equivalent during upgrade.,1.5.1,1.6.0,81,0,0,0,0,0,0,0,
5779,ambari-server,Myroslav Papirkovskyy,Recommission a DN fails when https is enabled in Ambari server,After https is enable in Ambari server  Recommission a DN will fails with the following error message found in the Ambari-server log:WARN &#91;qtp1103265648-610&#93; nio:651 - javax.net.ssl.SSLException: Received fatal alert: certificate_unknown 00:32:05 458 INFO &#91;ExecutionScheduler_Worker-1&#93; JobRunShell:207 - Job LinearExecutionJobs.BatchRequestJob-2-1 threw a JobExecutionException: org.quartz.JobExecutionException: org.apache.ambari.server.AmbariException: Exception occurred while performing request &#91;See nested exception: org.apache.ambari.server.AmbariException: Exception occurred while performing request&#93; at org.apache.ambari.server.scheduler.AbstractLinearExecutionJob.execute(AbstractLinearExecutionJob.java:94) at org.quartz.core.JobRunShell.run(JobRunShell.java:202) at org.quartz.simpl.SimpleThreadPool$WorkerThread.run(SimpleThreadPool.java:573) Caused by: org.apache.ambari.server.AmbariException: Exception occurred while performing request at org.apache.ambari.server.scheduler.ExecutionScheduleManager.executeBatchRequest(ExecutionScheduleManager.java:479) at org.apache.ambari.server.state.scheduler.BatchRequestJob.doWork(BatchRequestJob.java:77) at org.apache.ambari.server.scheduler.AbstractLinearExecutionJob.execute(AbstractLinearExecutionJob.java:88) ... 2 more Caused by: com.sun.jersey.api.client.ClientHandlerException: javax.net.ssl.SSLHandshakeException: java.security.cert.CertificateException: No name matching localhost found at com.sun.jersey.client.urlconnection.URLConnectionClientHandler.handle(URLConnectionClientHandler.java:149) at com.sun.jersey.api.client.filter.CsrfProtectionFilter.handle(CsrfProtectionFilter.java:97) at org.apache.ambari.server.security.authorization.internal.InternalTokenClientFilter.handle(InternalTokenClientFilter.java:39) at com.sun.jersey.api.client.Client.handle(Client.java:648) at com.sun.jersey.api.client.WebResource.handle(WebResource.java:670) at com.sun.jersey.api.client.WebResource.method(WebResource.java:311) at org.apache.ambari.server.scheduler.ExecutionScheduleManager.performApiRequest(ExecutionScheduleManager.java:619) at org.apache.ambari.server.scheduler.ExecutionScheduleManager.executeBatchRequest(ExecutionScheduleManager.java:469) ... 4 more Caused by: javax.net.ssl.SSLHandshakeException: java.security.cert.CertificateException: No name matching localhost found at sun.security.ssl.Alerts.getSSLException(Alerts.java:192) at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1884) at sun.security.ssl.Handshaker.fatalSE(Handshaker.java:276) at sun.security.ssl.Handshaker.fatalSE(Handshaker.java:270) at sun.security.ssl.ClientHandshaker.serverCertificate(ClientHandshaker.java:1341) at sun.security.ssl.ClientHandshaker.processMessage(ClientHandshaker.java:153) at sun.security.ssl.Handshaker.processLoop(Handshaker.java:868) at sun.security.ssl.Handshaker.process_record(Handshaker.java:804) at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:1016) at sun.security.ssl.SSLSocketImpl.performInitialHandshake(SSLSocketImpl.java:1312) at sun.security.ssl.SSLSocketImpl.startHandshake(SSLSocketImpl.java:1339) at sun.security.ssl.SSLSocketImpl.startHandshake(SSLSocketImpl.java:1323) at sun.net.www.protocol.https.HttpsClient.afterConnect(HttpsClient.java:563) at sun.net.www.protocol.https.AbstractDelegateHttpsURLConnection.connect(AbstractDelegateHttpsURLConnection.java:185) at sun.net.www.protocol.http.HttpURLConnection.getOutputStream(HttpURLConnection.java:1091) at sun.net.www.protocol.https.HttpsURLConnectionImpl.getOutputStream(HttpsURLConnectionImpl.java:250),1.6.0,1.6.0,152,0,0,0,0,0,0,0,
5782,ambari-web,Jaimin D Jetly,View: Files UI clean-up and adjustments,,1.6.0,1.6.0,1,0,0,0,0,0,0,0,
5783,,Siddharth Wagle,Pig fails to install through blueprint,During installation through blueprint pig install fails with next exception:Traceback (most recent call last): File '/var/lib/ambari-agent/cache/stacks/HDP/2.0.6/services/PIG/package/scripts/pig_client.py'  line 41  in &lt;module&gt; PigClient().execute() File '/usr/lib/python2.6/site-packages/resource_management/libraries/script/script.py'  line 112  in execute method(env) File '/var/lib/ambari-agent/cache/stacks/HDP/2.0.6/services/PIG/package/scripts/pig_client.py'  line 30  in install self.configure(env) File '/var/lib/ambari-agent/cache/stacks/HDP/2.0.6/services/PIG/package/scripts/pig_client.py'  line 35  in configure pig() File '/var/lib/ambari-agent/cache/stacks/HDP/2.0.6/services/PIG/package/scripts/pig.py'  line 40  in pig properties=params.pig_properties) File '/usr/lib/python2.6/site-packages/resource_management/core/base.py'  line 148  in __init__ self.env.run() File '/usr/lib/python2.6/site-packages/resource_management/core/environment.py'  line 149  in run self.run_action(resource  action) File '/usr/lib/python2.6/site-packages/resource_management/core/environment.py'  line 115  in run_action provider_action() File '/usr/lib/python2.6/site-packages/resource_management/libraries/providers/properties_file.py'  line 48  in action_create mode = self.resource.mode File '/usr/lib/python2.6/site-packages/resource_management/core/base.py'  line 148  in __init__ self.env.run() File '/usr/lib/python2.6/site-packages/resource_management/core/environment.py'  line 149  in run self.run_action(resource  action) File '/usr/lib/python2.6/site-packages/resource_management/core/environment.py'  line 115  in run_action provider_action() File '/usr/lib/python2.6/site-packages/resource_management/core/providers/system.py'  line 96  in action_create content = self._get_content() File '/usr/lib/python2.6/site-packages/resource_management/core/providers/system.py'  line 136  in _get_content return content() File '/usr/lib/python2.6/site-packages/resource_management/core/source.py'  line 47  in __call__ return self.get_content() File '/usr/lib/python2.6/site-packages/resource_management/core/source.py'  line 126  in get_content rendered = self.template.render(self.context) File '/usr/lib/python2.6/site-packages/jinja2/environment.py'  line 891  in render return self.environment.handle_exception(exc_info  True) File '&lt;template&gt;'  line 2  in top-level template code File '/usr/lib/python2.6/site-packages/jinja2/filters.py'  line 176  in do_dictsort return sorted(value.items()  key=sort_func)AttributeError: 'unicode' object has no attribute 'items',1.6.1,1.6.1,206,0,0,0,0,0,0,0,
5855,ambari-web,Andrii Babiichuk,Global properties are not being surfaced on service config page,Post install  Global properties are not being surfaced on service config page.,1.6.1,1.6.1,13,0,0,0,0,0,0,1,ambari-web/app/controllers/main/service/info/configs.js;
5866,ambari-web,Oleg Nechiporenko,Populate actions drop down of Slider App details page,Slider App details page should have an actions dropdown with the following actions Freeze: show when status == RUNNING Thaw: show when status == FROZEN Flex: show when status != FINISHED Destroy: show when status == FROZENExcept for Thaw  all actions will show a confirmation dialog. Hitting OK will make the call. Destroy should call DELETE on the app endpoint Freeze and Thaw should call PUT on app endpoint app state being set to FROZEN or RUNNING.,1.6.1,1.6.1,77,1,0,0,0,0,0,0,
5886,ambari-server,Srimanth Gunturi,Implement app_types endpoint to provide app definitions,Slider Apps View should provide /api/v1/app_types endpoint to provide definitions of various app_types supported by this Slider Apps View. Only apps in this type can be created through UI.,1.6.1,1.6.1,29,1,0,0,0,0,0,0,
5894,ambari-web,Oleg Nechiporenko,New slider app wizard should show app-types from /apptypes endpoint,Currently the new slider app wizard shows hardcoded app-types. We should instead show only those app-types which are returned by http://c6401:8080/api/v1/views/SLIDER/versions/1.0.0/instances/SLIDER_1/apptypes?fields=* endpoint.{ 'href' : 'http://c6401:8080/api/v1/views/SLIDER/versions/1.0.0/instances/SLIDER_1/apptypes?fields=*'  'items' : [ { 'href' : 'http://c6401:8080/api/v1/views/SLIDER/versions/1.0.0/instances/SLIDER_1/apptypes/ACCUMULO'  'id' : 'ACCUMULO'  'instance_name' : 'SLIDER_1'  'typeComponents' : [ { 'id' : 'ACCUMULO_MASTER'  'name' : 'ACCUMULO_MASTER'  'category' : 'MASTER'  'displayName' : 'ACCUMULO_MASTER'  'priority' : 1  'instanceCount' : 0  'maxInstanceCount' : 0  'yarnMemory' : 1024  'yarnCpuCores' : 1 }  { 'id' : 'ACCUMULO_MONITOR'  'name' : 'ACCUMULO_MONITOR'  'category' : 'MASTER'  'displayName' : 'ACCUMULO_MONITOR'  'priority' : 3  'instanceCount' : 0  'maxInstanceCount' : 0  'yarnMemory' : 1024  'yarnCpuCores' : 1 }  { 'id' : 'ACCUMULO_GC'  'name' : 'ACCUMULO_GC'  'category' : 'MASTER'  'displayName' : 'ACCUMULO_GC'  'priority' : 4  'instanceCount' : 0  'maxInstanceCount' : 0  'yarnMemory' : 1024  'yarnCpuCores' : 1 }  { 'id' : 'ACCUMULO_TRACER'  'name' : 'ACCUMULO_TRACER'  'category' : 'MASTER'  'displayName' : 'ACCUMULO_TRACER'  'priority' : 5  'instanceCount' : 0  'maxInstanceCount' : 0  'yarnMemory' : 1024  'yarnCpuCores' : 1 }  { 'id' : 'ACCUMULO_TSERVER'  'name' : 'ACCUMULO_TSERVER'  'category' : 'SLAVE'  'displayName' : 'ACCUMULO_TSERVER'  'priority' : 2  'instanceCount' : 0  'maxInstanceCount' : 0  'yarnMemory' : 1024  'yarnCpuCores' : 1 }  { 'id' : 'ACCUMULO_CLIENT'  'name' : 'ACCUMULO_CLIENT'  'category' : 'CLIENT'  'displayName' : 'ACCUMULO_CLIENT'  'priority' : 0  'instanceCount' : 0  'maxInstanceCount' : 0  'yarnMemory' : 1024  'yarnCpuCores' : 1 } ]  'typeDescription' : 'The Apache Accumulo sorted  distributed key/value store is a robust /n scalable  high performance data storage system that features cell-based/n access control and customizable server-side processing. It is based on/n Google's BigTable design and is built on top of Apache Hadoop /n Zookeeper  and Thrift./n Requirements:/n 1. Ensure parent dir for path (accumulo-site/instance.dfs.dir) is accessible to the App owner.'  'typeName' : 'ACCUMULO'  'typePackageFileName' : 'accumulo_v151.zip'  'typeVersion' : '1.5.1'  'version' : '1.0.0'  'view_name' : 'SLIDER'  'typeConfigs' : { 'agent.conf' : '/slider/agent/conf/agent.ini'  'application.def' : '/slider/accumulo_v151.zip'  'config_types' : 'accumulo-site'  'java_home' : '/usr/jdk64/jdk1.7.0_45'  'package_list' : 'files/accumulo-1.5.1-bin.tar.gz'  'site.accumulo-site.gc.port.client' : '0'  'site.accumulo-site.general.classpaths' : '$ACCUMULO_HOME/lib/accumulo-server.jar /n$ACCUMULO_HOME/lib/accumulo-core.jar /n$ACCUMULO_HOME/lib/accumulo-start.jar /n$ACCUMULO_HOME/lib/accumulo-fate.jar /n$ACCUMULO_HOME/lib/accumulo-proxy.jar /n$ACCUMULO_HOME/lib/[^.].*.jar /n$ZOOKEEPER_HOME/zookeeper[^.].*.jar /n$HADOOP_CONF_DIR /n$HADOOP_PREFIX/[^.].*.jar /n$HADOOP_PREFIX/lib/[^.].*.jar /n$HADOOP_PREFIX/share/hadoop/common/.*.jar /n$HADOOP_PREFIX/share/hadoop/common/lib/.*.jar /n$HADOOP_PREFIX/share/hadoop/hdfs/.*.jar /n$HADOOP_PREFIX/share/hadoop/mapreduce/.*.jar /n$HADOOP_PREFIX/share/hadoop/yarn/.*.jar /n/usr/lib/hadoop/.*.jar /n/usr/lib/hadoop/lib/.*.jar /n/usr/lib/hadoop-hdfs/.*.jar /n/usr/lib/hadoop-mapreduce/.*.jar /n/usr/lib/hadoop-yarn/.*.jar '  'site.accumulo-site.instance.dfs.dir' : '/apps/accumulo/data'  'site.accumulo-site.instance.secret' : 'DEFAULT'  'site.accumulo-site.instance.zookeeper.host' : '${ZK_HOST}'  'site.accumulo-site.master.port.client' : '0'  'site.accumulo-site.monitor.port.client' : '${ACCUMULO_MONITOR.ALLOCATED_PORT}'  'site.accumulo-site.monitor.port.log4j' : '0'  'site.accumulo-site.trace.port.client' : '0'  'site.accumulo-site.trace.token.property.password' : 'secret'  'site.accumulo-site.trace.user' : 'root'  'site.accumulo-site.tserver.cache.data.size' : '7M'  'site.accumulo-site.tserver.cache.index.size' : '20M'  'site.accumulo-site.tserver.memory.maps.max' : '80M'  'site.accumulo-site.tserver.port.client' : '0'  'site.accumulo-site.tserver.sort.buffer.size' : '50M'  'site.accumulo-site.tserver.walog.max.size' : '100M'  'site.global.accumulo_instance_name' : 'instancename'  'site.global.accumulo_root_password' : 'secret'  'site.global.app_install_dir' : '${AGENT_WORK_ROOT}/app/install'  'site.global.app_log_dir' : '${AGENT_LOG_ROOT}/app/log'  'site.global.app_pid_dir' : '${AGENT_WORK_ROOT}/app/run'  'site.global.app_root' : '${AGENT_WORK_ROOT}/app/install/accumulo-1.5.1'  'site.global.app_user' : 'yarn'  'site.global.gc_heapsize' : '64m'  'site.global.hadoop_conf_dir' : '/etc/hadoop/conf'  'site.global.hadoop_prefix' : '/usr/lib/hadoop'  'site.global.master_heapsize' : '128m'  'site.global.monitor_heapsize' : '64m'  'site.global.other_heapsize' : '128m'  'site.global.security_enabled' : 'false'  'site.global.tserver_heapsize' : '128m'  'site.global.user_group' : 'hadoop'  'site.global.zookeeper_home' : '/usr/lib/zookeeper' } }  { 'href' : 'http://c6401:8080/api/v1/views/SLIDER/versions/1.0.0/instances/SLIDER_1/apptypes/HBASE'  'id' : 'HBASE'  'instance_name' : 'SLIDER_1'  'typeComponents' : [ { 'id' : 'HBASE_MASTER'  'name' : 'HBASE_MASTER'  'category' : 'MASTER'  'displayName' : 'HBASE_MASTER'  'priority' : 1  'instanceCount' : 1  'maxInstanceCount' : 2  'yarnMemory' : 1024  'yarnCpuCores' : 1 }  { 'id' : 'HBASE_REGIONSERVER'  'name' : 'HBASE_REGIONSERVER'  'category' : 'SLAVE'  'displayName' : 'HBASE_REGIONSERVER'  'priority' : 2  'instanceCount' : 1  'maxInstanceCount' : 0  'yarnMemory' : 1024  'yarnCpuCores' : 1 }  { 'id' : 'HBASE_CLIENT'  'name' : 'HBASE_CLIENT'  'category' : 'CLIENT'  'displayName' : 'HBASE_CLIENT'  'priority' : 0  'instanceCount' : 0  'maxInstanceCount' : 0  'yarnMemory' : 1024  'yarnCpuCores' : 1 } ]  'typeDescription' : 'Apache HBase is the Hadoop database  a distributed  scalable  big data store./n Requirements:/n 1. Ensure parent dir for path (hbase-site/hbase.rootdir) is accessible to the App owner./n 2. Ensure ZK root (hbase-site/zookeeper.znode.parent) is unique for the App instance.'  'typeName' : 'HBASE'  'typePackageFileName' : 'hbase_v096 (1).zip'  'typeVersion' : '0.96.0.2.1.1'  'version' : '1.0.0'  'view_name' : 'SLIDER'  'typeConfigs' : { 'agent.conf' : '/slider/agent/conf/agent.ini'  'application.def' : '/slider/hbase_v096.zip'  'config_types' : 'core-site hdfs-site hbase-site'  'java_home' : '/usr/jdk64/jdk1.7.0_45'  'package_list' : 'files/hbase-0.96.1-hadoop2-bin.tar.gz'  'site.core-site.fs.defaultFS' : '${NN_URI}'  'site.global.app_install_dir' : '${AGENT_WORK_ROOT}/app/install'  'site.global.app_log_dir' : '${AGENT_LOG_ROOT}/app/log'  'site.global.app_pid_dir' : '${AGENT_WORK_ROOT}/app/run'  'site.global.app_root' : '${AGENT_WORK_ROOT}/app/install/hbase-0.96.1-hadoop2'  'site.global.app_user' : 'yarn'  'site.global.ganglia_server_host' : '${NN_HOST}'  'site.global.ganglia_server_id' : 'Application1'  'site.global.ganglia_server_port' : '8667'  'site.global.hbase_master_heapsize' : '1024m'  'site.global.hbase_regionserver_heapsize' : '1024m'  'site.global.security_enabled' : 'false'  'site.global.user_group' : 'hadoop'  'site.hbase-site.hbase.client.keyvalue.maxsize' : '10485760'  'site.hbase-site.hbase.client.scanner.caching' : '100'  'site.hbase-site.hbase.cluster.distributed' : 'true'  'site.hbase-site.hbase.defaults.for.version.skip' : 'true'  'site.hbase-site.hbase.hregion.majorcompaction' : '86400000'  'site.hbase-site.hbase.hregion.max.filesize' : '10737418240'  'site.hbase-site.hbase.hregion.memstore.block.multiplier' : '2'  'site.hbase-site.hbase.hregion.memstore.flush.size' : '134217728'  'site.hbase-site.hbase.hregion.memstore.mslab.enabled' : 'true'  'site.hbase-site.hbase.hstore.blockingStoreFiles' : '10'  'site.hbase-site.hbase.hstore.compactionThreshold' : '3'  'site.hbase-site.hbase.hstore.flush.retries.number' : '120'  'site.hbase-site.hbase.local.dir' : '${hbase.tmp.dir}/local'  'site.hbase-site.hbase.master.info.port' : '${HBASE_MASTER.ALLOCATED_PORT}'  'site.hbase-site.hbase.regionserver.global.memstore.lowerLimit' : '0.38'  'site.hbase-site.hbase.regionserver.global.memstore.upperLimit' : '0.4'  'site.hbase-site.hbase.regionserver.handler.count' : '60'  'site.hbase-site.hbase.regionserver.info.port' : '0'  'site.hbase-site.hbase.regionserver.port' : '0'  'site.hbase-site.hbase.rootdir' : '${NN_URI}/apps/hbase/data'  'site.hbase-site.hbase.security.authentication' : 'simple'  'site.hbase-site.hbase.security.authorization' : 'false'  'site.hbase-site.hbase.stagingdir' : '${NN_URI}/apps/hbase/staging'  'site.hbase-site.hbase.superuser' : 'yarn'  'site.hbase-site.hbase.tmp.dir' : '${AGENT_WORK_ROOT}/work/app/tmp'  'site.hbase-site.hbase.zookeeper.property.clientPort' : '2181'  'site.hbase-site.hbase.zookeeper.quorum' : '${ZK_HOST}'  'site.hbase-site.hbase.zookeeper.useMulti' : 'true'  'site.hbase-site.hfile.block.cache.size' : '0.40'  'site.hbase-site.zookeeper.session.timeout' : '30000'  'site.hbase-site.zookeeper.znode.parent' : '/hbase-unsecure'  'site.hdfs-site.dfs.namenode.http-address' : '${NN_HOST}:50070'  'site.hdfs-site.dfs.namenode.https-address' : '${NN_HOST}:50470' } }  { 'href' : 'http://c6401:8080/api/v1/views/SLIDER/versions/1.0.0/instances/SLIDER_1/apptypes/STORM'  'id' : 'STORM'  'instance_name' : 'SLIDER_1'  'typeComponents' : [ { 'id' : 'NIMBUS'  'name' : 'NIMBUS'  'category' : 'MASTER'  'displayName' : 'NIMBUS'  'priority' : 1  'instanceCount' : 0  'maxInstanceCount' : 0  'yarnMemory' : 1024  'yarnCpuCores' : 1 }  { 'id' : 'STORM_REST_API'  'name' : 'STORM_REST_API'  'category' : 'MASTER'  'displayName' : 'STORM_REST_API'  'priority' : 2  'instanceCount' : 0  'maxInstanceCount' : 0  'yarnMemory' : 1024  'yarnCpuCores' : 1 }  { 'id' : 'SUPERVISOR'  'name' : 'SUPERVISOR'  'category' : 'SLAVE'  'displayName' : 'SUPERVISOR'  'priority' : 5  'instanceCount' : 0  'maxInstanceCount' : 0  'yarnMemory' : 1024  'yarnCpuCores' : 1 }  { 'id' : 'STORM_UI_SERVER'  'name' : 'STORM_UI_SERVER'  'category' : 'MASTER'  'displayName' : 'STORM_UI_SERVER'  'priority' : 3  'instanceCount' : 0  'maxInstanceCount' : 0  'yarnMemory' : 1024  'yarnCpuCores' : 1 }  { 'id' : 'DRPC_SERVER'  'name' : 'DRPC_SERVER'  'category' : 'MASTER'  'displayName' : 'DRPC_SERVER'  'priority' : 4  'instanceCount' : 0  'maxInstanceCount' : 0  'yarnMemory' : 1024  'yarnCpuCores' : 1 } ]  'typeDescription' : 'Apache Hadoop Stream processing framework'  'typeName' : 'STORM'  'typePackageFileName' : 'storm_v091.zip'  'typeVersion' : '0.9.1.2.1'  'version' : '1.0.0'  'view_name' : 'SLIDER'  'typeConfigs' : { 'agent.conf' : '/slider/agent/conf/agent.ini'  'application.def' : '/slider/storm_v091.zip'  'config_types' : 'storm-site'  'java_home' : '/usr/jdk64/jdk1.7.0_45'  'package_list' : 'files/apache-storm-0.9.1.2.1.1.0-237.tar.gz'  'site.global.app_root' : '${AGENT_WORK_ROOT}/app/install/apache-storm-0.9.1.2.1.1.0-237'  'site.global.app_user' : 'yarn'  'site.global.ganglia_server_host' : '${NN_HOST}'  'site.global.ganglia_server_id' : 'Application2'  'site.global.rest_api_admin_port' : '${STORM_REST_API.ALLOCATED_PORT}'  'site.global.rest_api_port' : '${STORM_REST_API.ALLOCATED_PORT}'  'site.global.security_enabled' : 'false'  'site.global.user_group' : 'hadoop'  'site.storm-site.dev.zookeeper.path' : '${AGENT_WORK_ROOT}/app/tmp/dev-storm-zookeeper'  'site.storm-site.drpc.childopts' : '-Xmx768m'  'site.storm-site.drpc.invocations.port' : '${DRPC_SERVER.ALLOCATED_PORT}'  'site.storm-site.drpc.port' : '${DRPC_SERVER.ALLOCATED_PORT}'  'site.storm-site.drpc.queue.size' : '128'  'site.storm-site.drpc.request.timeout.secs' : '600'  'site.storm-site.drpc.worker.threads' : '64'  'site.storm-site.java.library.path' : '/usr/local/lib:/opt/local/lib:/usr/lib'  'site.storm-site.logviewer.appender.name' : 'A1'  'site.storm-site.logviewer.childopts' : '-Xmx128m'  'site.storm-site.logviewer.port' : '${SUPERVISOR.ALLOCATED_PORT}'  'site.storm-site.nimbus.childopts' : '-Xmx1024m -Djava.security.auth.login.config=/etc/storm/storm_jaas.conf -javaagent:${AGENT_WORK_ROOT}/app/install/apache-storm-0.9.1.2.1.1.0-237/contrib/storm-jmxetric/lib/jmxetric-1.0.4.jar=host={0} port=8669 wireformat31x=true mode=multicast config=${AGENT_WORK_ROOT}/app/install/apache-storm-0.9.1.2.1.1.0-237/contrib/storm-jmxetric/conf/jmxetric-conf.xml process=Nimbus_JVM'  'site.storm-site.nimbus.cleanup.inbox.freq.secs' : '600'  'site.storm-site.nimbus.file.copy.expiration.secs' : '600'  'site.storm-site.nimbus.host' : '${NIMBUS_HOST}'  'site.storm-site.nimbus.inbox.jar.expiration.secs' : '3600'  'site.storm-site.nimbus.monitor.freq.secs' : '10'  'site.storm-site.nimbus.reassign' : 'true'  'site.storm-site.nimbus.supervisor.timeout.secs' : '60'  'site.storm-site.nimbus.task.launch.secs' : '120'  'site.storm-site.nimbus.task.timeout.secs' : '30'  'site.storm-site.nimbus.thrift.max_buffer_size' : '1048576'  'site.storm-site.nimbus.thrift.port' : '${NIMBUS.ALLOCATED_PORT}'  'site.storm-site.nimbus.topology.validator' : 'backtype.storm.nimbus.DefaultTopologyValidator'  'site.storm-site.storm.cluster.mode' : 'distributed'  'site.storm-site.storm.local.dir' : '${AGENT_WORK_ROOT}/app/tmp/storm'  'site.storm-site.storm.local.mode.zmq' : 'false'  'site.storm-site.storm.messaging.netty.buffer_size' : '5242880'  'site.storm-site.storm.messaging.netty.client_worker_threads' : '1'  'site.storm-site.storm.messaging.netty.max_retries' : '30'  'site.storm-site.storm.messaging.netty.max_wait_ms' : '1000'  'site.storm-site.storm.messaging.netty.min_wait_ms' : '100'  'site.storm-site.storm.messaging.netty.server_worker_threads' : '1'  'site.storm-site.storm.messaging.transport' : 'backtype.storm.messaging.netty.Context'  'site.storm-site.storm.thrift.transport' : 'backtype.storm.security.auth.SimpleTransportPlugin'  'site.storm-site.storm.zookeeper.connection.timeout' : '15000'  'site.storm-site.storm.zookeeper.port' : '2181'  'site.storm-site.storm.zookeeper.retry.interval' : '1000'  'site.storm-site.storm.zookeeper.retry.intervalceiling.millis' : '30000'  'site.storm-site.storm.zookeeper.retry.times' : '5'  'site.storm-site.storm.zookeeper.root' : '/storm'  'site.storm-site.storm.zookeeper.servers' : '['${ZK_HOST}']'  'site.storm-site.storm.zookeeper.session.timeout' : '20000'  'site.storm-site.supervisor.childopts' : '-Xmx256m -Djava.security.auth.login.config=/etc/storm/storm_jaas.conf -Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.ssl=false -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.port=${SUPERVISOR.ALLOCATED_PORT} -javaagent:${AGENT_WORK_ROOT}/app/install/apache-storm-0.9.1.2.1.1.0-237/contrib/storm-jmxetric/lib/jmxetric-1.0.4.jar=host={0} port=8669 wireformat31x=true mode=multicast config=${AGENT_WORK_ROOT}/app/install/apache-storm-0.9.1.2.1.1.0-237/contrib/storm-jmxetric/conf/jmxetric-conf.xml process=Supervisor_JVM'  'site.storm-site.supervisor.enable' : 'true'  'site.storm-site.supervisor.heartbeat.frequency.secs' : '5'  'site.storm-site.supervisor.monitor.frequency.secs' : '3'  'site.storm-site.supervisor.slots.ports' : '[${SUPERVISOR.ALLOCATED_PORT}  ${SUPERVISOR.ALLOCATED_PORT}]'  'site.storm-site.supervisor.worker.start.timeout.secs' : '120'  'site.storm-site.supervisor.worker.timeout.secs' : '30'  'site.storm-site.task.heartbeat.frequency.secs' : '3'  'site.storm-site.task.refresh.poll.secs' : '10'  'site.storm-site.topology.acker.executors' : 'null'  'site.storm-site.topology.builtin.metrics.bucket.size.secs' : '60'  'site.storm-site.topology.debug' : 'false'  'site.storm-site.topology.disruptor.wait.strategy' : 'com.lmax.disruptor.BlockingWaitStrategy'  'site.storm-site.topology.enable.message.timeouts' : 'true'  'site.storm-site.topology.error.throttle.interval.secs' : '10'  'site.storm-site.topology.executor.receive.buffer.size' : '1024'  'site.storm-site.topology.executor.send.buffer.size' : '1024'  'site.storm-site.topology.fall.back.on.java.serialization' : 'true'  'site.storm-site.topology.kryo.factory' : 'backtype.storm.serialization.DefaultKryoFactory'  'site.storm-site.topology.max.error.report.per.interval' : '5'  'site.storm-site.topology.max.spout.pending' : 'null'  'site.storm-site.topology.max.task.parallelism' : 'null'  'site.storm-site.topology.message.timeout.secs' : '30'  'site.storm-site.topology.optimize' : 'true'  'site.storm-site.topology.receiver.buffer.size' : '8'  'site.storm-site.topology.skip.missing.kryo.registrations' : 'false'  'site.storm-site.topology.sleep.spout.wait.strategy.time.ms' : '1'  'site.storm-site.topology.spout.wait.strategy' : 'backtype.storm.spout.SleepSpoutWaitStrategy'  'site.storm-site.topology.state.synchronization.timeout.secs' : '60'  'site.storm-site.topology.stats.sample.rate' : '0.05'  'site.storm-site.topology.tick.tuple.freq.secs' : 'null'  'site.storm-site.topology.transfer.buffer.size' : '1024'  'site.storm-site.topology.trident.batch.emit.interval.millis' : '500'  'site.storm-site.topology.tuple.serializer' : 'backtype.storm.serialization.types.ListDelegateSerializer'  'site.storm-site.topology.worker.childopts' : 'null'  'site.storm-site.topology.worker.shared.thread.pool.size' : '4'  'site.storm-site.topology.workers' : '1'  'site.storm-site.transactional.zookeeper.port' : 'null'  'site.storm-site.transactional.zookeeper.root' : '/transactional'  'site.storm-site.transactional.zookeeper.servers' : 'null'  'site.storm-site.ui.port' : '${STORM_UI_SERVER.ALLOCATED_PORT}'  'site.storm-site.worker.childopts' : '-Xmx768m -javaagent:${AGENT_WORK_ROOT}/app/install/apache-storm-0.9.1.2.1.1.0-237/contrib/storm-jmxetric/lib/jmxetric-1.0.4.jar=host={0} port=8669 wireformat31x=true mode=multicast config=${AGENT_WORK_ROOT}/app/install/apache-storm-0.9.1.2.1.1.0-237/contrib/storm-jmxetric/conf/jmxetric-conf.xml process=Worker_%ID%_JVM'  'site.storm-site.worker.heartbeat.frequency.secs' : '1'  'site.storm-site.zmq.hwm' : '0'  'site.storm-site.zmq.linger.millis' : '5000'  'site.storm-site.zmq.threads' : '1' } } ]},1.6.1,1.6.1,1904,1,0,0,0,0,0,0,
5895,,Dmitry Lysnichenko,Suppress any debug and info messages from package managers in setupAgent.py,During bootstrapping of agents  installation retrieve versions of available packages from system package manager. After some test was founded that in different situations package managers can produce specific info/debug output which can be reason of wrong parsing of output.Example:Zypper command:se2mon1400652583-9:/etc/zypp/repos.d # zypper search -s --match-exact ambari-agent Building repository 'Hortonworks Data Platform Utils Version - HDP-UTILS-1.1.0.16' cache &#91;done&#93;Building repository 'Hortonworks Data Platform Utils Version - HDP-UTILS-1.1.0.17' cache &#91;done&#93;Building repository 'Hosted (SLES_11)' cache &#91;done&#93;Building repository 'ambari-1.6.0 - Updates' cache &#91;done&#93;Building repository 'Ambari 1.x' cache &#91;done&#93;Building repository 'PostgreSQL and related packages (SLE_11_SP3)' cache &#91;done&#93;Loading repository data...Reading installed packages...S | Name | Type | Version | Arch | Repository -----------------------------------+---------------------- ambari-agent  package  1.6.0-46  x86_64  ambari-1.6.0 - Updates ambari-agent  package  1.2.0.1-1  x86_64  Ambari 1.xParsed as: Building repository 'ambari-1.6.0 We should suppress any debug/info output in setupAgent.py to avoid any unexpected situation.,1.6.1,1.6.1,162,0,0,0,0,0,0,0,
5915,ambari-web,Jaimin D Jetly,View: Files UI clean-up and adjustments (PART 2),As a part of this ticket 1) Remove rename icon from infront of the file and make it a different column.2) reorder the icon bar in the sequence Download  Move  Rename and Delete,1.6.0,1.6.1,32,1,0,0,0,0,0,0,
5922,ambari-server,Siddharth Wagle,Predicates don't work on fields with float values,API should be able to process filter with predicates(&lt; &gt; =) for fields with float values; For example field: metrics/load/load_one.Currently the Greater than predicate will fail for values in between 0.0 and 1.0,1.6.1,1.6.1,31,1,0,0,0,0,0,0,
5930,,Jonathan Hurley,Some HBase properties are empty  but required to be filled,This HBase properties are empty after install via blueprint: hbase.coprocessor.region.classes hbase.coprocessor.master.classesBut they required to be filled.After enabling security they became filled.,1.6.0,1.6.1,21,0,0,0,0,0,0,0,
5932,ambari-web,Antonenko Alexander,Slider apps table does not remove entry when app is removed,Lets say I have a running app. I freeze it and then destroy it. The app goes away from the /apps response. However the UI still continues to show it. I think the mapper is not removing deleted entries from the model.Mapper should remove entries not being sent by /apps.,1.6.1,1.6.1,50,1,0,0,0,0,0,0,
5935,ambari-server,Myroslav Papirkovskyy,Maintenance state and status commands perf improvements.,getEffectiveState should not fetch map of all hosts every time Status commands should not be sent until component is installed,1.6.0,1.6.1,21,1,0,0,0,0,0,0,
5941,,Shivani Gupta,Ambari should generate config files in sorted order,Ambari should generate config files sorted by key. It would make doing compares between files much easier.,1.5.1,1.7.0,17,1,0,0,0,0,0,0,
5956,ambari-agent,Vitaly Brodetskyi,DB connection check error if jdk_name does not exist.,We can get such situation when user using custom java.,1.6.1,1.7.0,10,1,0,0,0,0,0,0,
5957,ambari-server,Dmitry Lysnichenko,Bootstrap API call says bootstrap is running even though all agents have installed and registered,UI keeps showing that the agents are being installed  because the bootstrap API GET call keeps returning that hostsStatus/status is RUNNINGI suspected time.sleep(1) instruction. If restart takes too long time  situation  when ambari-agent.log has not been created yet is possible. So  tail command returned not 0 retcode and exit from procedure. But in logs I cant see any non-zero retcodes. Thus  too short logs could be explaned by this issue.,1.6.1,1.6.1,71,0,0,0,0,0,0,0,
5960,,Jeff Sposetti,Add support for auth proxy,When using a proxy for internet access  add support to set properties for proxy user and password.Dhttp.proxyUser=someUserName -Dhttp.proxyPassword=somePassword,1.5.0,1.6.1,18,1,0,0,0,0,0,0,
5994,ambari-web,Andrii Babiichuk,Storm UI in Ambari quick link fails when Storm UI server is not co-hosted with nimbus host,quick link for Storm UI was linked with nimbus server. it should use Storm UI server host.,1.6.0,1.6.1,17,1,0,0,0,0,0,2,ambari-web/app/models/quick_links.js;ambari-web/app/views/common/quick_view_link_view.js;
6003,ambari-web,Aleksandr Kovalenko,metrics hostname is not correct for storm,Some of the storm configs have extra 'localhost' appended to the host name.'nimbus.childopts' : '-Xmx1024m -Djava.security.auth.login.config=/etc/storm/conf/storm_jaas.conf -javaagent:/usr/lib/storm/contrib/storm-jmxetric/lib/jmxetric-1.0.4.jar=host=c6401.ambari.apache.orglocalhost port=8649 wireformat31x=true mode=multicast config=/usr/lib/storm/contrib/storm-jmxetric/conf/jmxetric-conf.xml process=Nimbus_JVM''supervisor.childopts' : '-Xmx256m -Djava.security.auth.login.config=/etc/storm/conf/storm_jaas.conf -Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.ssl=false -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.port=56431 -javaagent:/usr/lib/storm/contrib/storm-jmxetric/lib/jmxetric-1.0.4.jar=host=c6401.ambari.apache.orglocalhost port=8650 wireformat31x=true mode=multicast config=/usr/lib/storm/contrib/storm-jmxetric/conf/jmxetric-conf.xml process=Supervisor_JVM''worker.childopts' : '-Xmx768m -javaagent:/usr/lib/storm/contrib/storm-jmxetric/lib/jmxetric-1.0.4.jar=host=c6401.ambari.apache.orglocalhost port=8650 wireformat31x=true mode=multicast config=/usr/lib/storm/contrib/storm-jmxetric/conf/jmxetric-conf.xml process=Worker_%ID%_JVM',1.6.1,1.6.1,28,0,0,0,0,0,0,0,
6014,,Jonathan Hurley,HDFS alert hangs for a long time after enabling Maintenance mode,STR: Stop HDFS with started Nagios service. Turn on Maintenance mode for HDFS.Result: All alerts dissapear  except 'HDFS capacity utilization' - it hangs for a long time (in my case it was smthng about 10-11 minutes),1.6.0,1.6.1,36,1,0,0,0,1,0,0,
6034,ambari-web,Antonenko Alexander,Services -> Configs page for Yarn  HIVE  MapReduce services is not displayed,Config page for services that use App.YARNDefaultsProvider is not displayed.Following JS error thrown:Uncaught TypeError: Cannot call method 'forEach' of null yarn_defaults_provider.js:291,1.6.1,1.6.1,27,0,0,0,0,0,0,0,
6044,ambari-agent,Vitaly Brodetskyi,Issues with jdbc properties,remove dots in --help params description and in warningscopy fails if jdbc selected by --jdbc-driver is already in resourceshide other points of ambari-server setup if jdbc options are passed and server is running,1.6.1,1.6.1,34,0,0,0,0,0,0,0,
6045,ambari-web,Andrii Tkach,Master components are missing,Master components info is missing in service summary.,1.6.1,1.6.1,8,1,0,0,0,0,0,1,ambari-web/app/mappers/service_metrics_mapper.js;
6048,ambari-agent,Dmitry Lysnichenko,Ambari Agent script should check for running processes before starting,PROBLEM: If the Ambari Agent installation fails for whatever reason then a process of ambari-agent is left running. This results in the ambari-agent status to show as it not running. If you then start another ambari-agent it dies because the port is already in use.If the script could check the PID file and check for a running process then it would resolve this issue.BUSINESS IMPACT: Not a huge business impact as the workaround is to kill the running ambari-agent processWorkaround: Kill running ambari-agent process before startingANALYSIS: I cannot reproduce this issue in house and the SE who raised it can not reproduce on demand.,1.6.1,1.6.1,104,1,0,0,0,1,0,0,
6053,ambari-web,Andrii Tkach,Add Host wizard get stuck on Confirm Hosts step,,1.6.1,1.6.1,1,1,0,0,0,0,0,4,ambari-web/app/controllers/main/host/add_controller.js;ambari-web/app/controllers/wizard/step2_controller.js;ambari-web/app/controllers/wizard/step3_controller.js;ambari-web/app/views/main/host/add_view.js;
6056,,Jonathan Hurley,Agent Custom Command Output Coerces Integers to Floats,When posting a command such as{ 'RequestInfo': { 'action': 'check_host'  'context': 'Check host'  'parameters': { 'check_execute_list': 'host_resolution_check'  'hosts': 'c6401.ambari.apache.org  c6402.ambari.apache.org  c6403.ambari.apache.org  foobar'  'threshold': '20' } }  'Requests/resource_filters': [ { 'hosts': 'c6401.ambari.apache.org c6402.ambari.apache.org' } ]The returned result from the custom action has some integer values coerced into floats: 'structured_out' : { 'host_resolution_check' : { 'exit_code' : '0'  'failed_count' : 0.0  'failures' : [ ]  'message' : 'All hosts resolved to an IP address.'  'success_count' : 4.0 }The structured_output written out to disk does NOT have the float values:{'host_resolution_check': {'failures': []  'message': 'All hosts resolved to an IP address.'  'failed_count': 0  'success_count': 4  'exit_code': '0'}} Therefore this is a problem with the framework and not the command.,1.6.1,1.6.1,167,1,0,0,0,0,0,0,
6059,,Jeff Sposetti,Add refreshQueues custom command to YARN service,Call refreshqueues from the REST API (replace resource.manager.host and YourClusterName). And be sure to include header 'X-Requested-By' : 'ambari' and set authentication.POST/api/v1/clusters/YourClusterName/requests/{ 'RequestInfo' : { 'command' : 'REFRESHQUEUES'  'context' : 'Refresh YARN Capacity Scheduler' }  'Requests/resource_filters': [{ 'service_name' : 'YARN'  'component_name' : 'RESOURCEMANAGER'  'hosts' : 'resource.manager.host' }]},1.6.1,1.6.1,66,0,0,0,0,0,0,0,
6063,ambari-server,Dmytro Sen,'ambari-server start command' hangs if was executed via ssh command,Problem:Ambari Server command 'ssh root@vmhost ambari-server start' hangs on message 'Ambari Server 'start' completed successfully.'. Same command executed successfully on the local console  as a result this behavior can be reproduced only via remote execution of commands.How to reproduce: Deploy server Stop server locally Start server from another host using ssh command,1.6.1,1.6.1,54,1,0,0,0,0,0,4,ambari-server/src/main/python/ambari-server.py;ambari-server/src/main/python/ambari_server/utils.py;ambari-server/src/test/python/TestAmbariServer.py;ambari-server/src/test/python/TestUtils.py;
6080,ambari-web,Aleksandr Kovalenko,Hosts Components filter on Service summary page doesn't work,When user clicks on some component filter on Service summary page  it opens hosts page  but filter is not applied.,1.6.1,1.6.1,20,1,0,0,0,0,0,0,
6087,ambari-web,Oleg Nechiporenko,Multiple ATS appear on YARN summary page,STR1. Go to add Service Wizard.2. Select some new services and proceed to deploy.3. Close Wizard (Esc-button).4. Wait a little bit (maybe page-refresh needed).5. Go to YARN summary.6. New 'none' components will appear periodically.See screenshot.,1.6.1,1.6.1,35,1,0,0,0,0,0,0,
6106,ambari-server,Siddharth Wagle,Customize the Hadoop metrics sink to write to MySQL store,The SqlServerSink should support pushing metrics to MySQL store.This Jira addresses changes needed to support sink to a MySQL store.,1.7.0,1.6.1,20,1,0,0,0,0,0,0,
6112,ambari-web,Andrii Tkach,Filter by alerts fails on Hosts table,Steps to reproduce:1. Go to Hosts page2. Choose filter AlertsResult:Hosts are not filtered by alerts.The request with filter by alerts has incorrect url data.,1.6.1,1.6.1,24,1,0,0,0,0,0,3,ambari-web/app/controllers/global/update_controller.js;ambari-web/app/controllers/main/host.js;ambari-web/app/data/host/categories.js;
6113,ambari-agent,Vitaly Brodetskyi,Nagios install fails on SLES due to php5-json not available,Using SLES 11 SP3 quick-start image on EC2. Doesn't look like php5-json is available  but php53-json is available.WORKAROUND:I modified NAGIOS/metainfo.xml and this worked. &lt;package&gt; &lt;name&gt;php5*-json&lt;/name&gt; &lt;/package&gt;,1.6.1,1.6.1,35,1,0,0,0,0,0,0,
6123,ambari-web,Xi Wang,issues with dialog keypresses,1) on 'manage config groups' pressing return does something even though return is not valid (i.e. can't save)2) Once you press return in #1  then you have to press esc twice to close the dialog3) once you open the nested dialog (to add a group)  esc closes the parent  then esc again  closes the nested dialog4) once you open the nested dialog  also notice it doesn't start focus on the name field  you have to click to get that focus.,1.6.1,1.6.1,80,0,0,0,0,0,0,0,
6125,ambari-client,Janos Matyas,Ambari Groovy client enhancements,Ambari REST client (Groovy) enhancements -refactor - simplified unit tests taking leverage groovy's metaclass capabilities-more REST calls implemented-api compatibility with version 1.6.0,1.6.0; 1.6.1,1.7.0,22,0,0,1,0,0,0,0,
6137,ambari-web,Andrii Babiichuk,Bulk operations confirmation popup,Hosts page  'Actions' menu (dropdown)Each action shows confirmation popup with list of affected hosts.For big cluster this may be 2000+ hosts.If there are more than 3 hosts  then show 'host1  host2  host3  and X more hosts show all',1.6.1,1.6.1,38,0,0,0,0,0,0,6,ambari-web/app/controllers/wizard/step8_controller.js;ambari-web/app/messages.js;ambari-web/app/styles/application.less;ambari-web/app/templates/main/host/bulk_operation_confirm_popup.hbs;ambari-web/app/views/main/host.js;ambari-web/test/controllers/wizard/step8_test.js;
6140,ambari-web,Antonenko Alexander,Step3. Hosts checks requests,Proceed to step3  wait while registration is complete.Host checks requests are set every second.UI should set next request only when previous is completed.,1.6.1,1.6.1,23,0,0,0,0,0,0,0,
6146,ambari-web,Xi Wang,It's not possible to input 'Enter' on 'Target hosts' textarea on 2nd step of Installer wizard',It's not possible to input 'Enter' on 'Target hosts' textarea.,1.6.1,1.6.1,10,0,0,0,0,0,0,0,
6147,ambari-web,Xi Wang,Ambari Dashboard page  click NameNode link returns wrong page,STR:1. go to dashboard page2. click NameNode link inside HDFS Links widget.instead of go to NameNode host detail page  it returns an empty page,1.6.1,1.6.1,24,0,0,0,0,0,0,0,
6155,ambari-web,Oleg Nechiporenko,JS error on POST config group request (step7 installer),Go to installer step7Click override for some propertySelect 'New Config Group'Click 'OK'JS-error appears - 404 error. Missing clusterName in request URL.,1.6.1,1.6.1,21,0,0,0,0,0,0,0,
6162,ambari-web,Oleg Nechiporenko,Behavior change: host filtering no longer handles startsWith matches,If I have a host that has IP 10.0.2.15  in Ambari 1.6.0 if I start to filter by IP (by typing 10.0....)  the hosts that match 'startsWith' stay displayed.In Ambari 1.6.1  now it only does exact match  so once I start typing  all hosts disappear until I finally type the whole thing in for exact match.Hosts/ip.matches(10),1.6.1,1.6.1,56,0,0,0,0,0,0,0,
6169,ambari-web,Jaimin D Jetly,Installer wizard: ambari web-client issues invalid requests after switching stacks,Steps To Reproduce Select 2.X stack and go ahead to 'Select Services' page Navigate back to 'Select Stack' page and select 1.x stack Go ahead to step-8 'Review' page. On clicking next  API call to create components for HDFS service fails with UI displaying an error message.Invalid Request: Unsupported or invalid component in stack  clusterName=cc  serviceName=HDFS  componentName=JOURNALNODE  stackInfo=HDP-1.3,1.6.1,1.6.1,65,0,0,0,0,0,0,0,
6184,ambari-agent,Dmitry Lysnichenko,Incorrect value for started_count of Datanode component,STR:  Installed a 3-node cluster for HDP 1.3 stack HDFS+MapReduce+Nagios+Ganglia+zooKeeper installed with slave components installed on all 3 hosts. Enable security with no kerberos setup On expected failure of security wizard  Disable security. After successfully disabling security  Following API returns incorrect number for started_count of Datanode. It says 0 but Datanode is actually running on all hostshttp://server:8080/api/v1/clusters/c1/components/?ServiceComponentInfo/category.in(SLAVE CLIENT)&amp;fields=ServiceComponentInfo/service_name ServiceComponentInfo/installed_count ServiceComponentInfo/started_count ServiceComponentInfo/total_count&amp;minimal_response=trueReason:During wrong kerberos setup DN processes fail to start  but leave stale pid file owned by root. Next one DN start command starts DN process  but can not override pid file. So the server considers DN as stopped. If we start DN once more  commands fail soon after start (due to lock file at data dir owned by already running DN). Agent reports to server that DN is not running  so server displays a correct information from his point of view.,1.6.1,1.6.1,148,0,0,0,0,0,0,0,
6194,ambari-web,Xi Wang,Unsuitable height of dropdown menu on metrics page,STR:Delete all widgets from dashboard.Go to Metrics-&gt;Add menu.Result: Appeared inappropriate dropdown: bad_metrics.png,1.6.1,1.6.1,12,0,0,0,0,0,0,0,
6197,ambari-web,Jaimin D Jetly,Decommissioned running DataNode has 'delete' menu item in action pulldown,Delete operation is not allowed for a hostComponent if it is in STARTED state.Currently delete menu item is shown when a hostComponent is flagged decommissioned and in STARTED state. Performing delete operation in this condition returns API 500 server error. If the hostComponent is brought in INSTALLED state with the decommissioned flag and then delete operation is performed then it happens as expectedDelete menu item should be shown When hostComponent is in INSTALLED state and should be grayed when it is in STARTED state. ambari-web client should not consider decommission status of a hostComponent while validating the required condition to enable/disable 'delete' menu item.,1.6.1,1.7.0,104,0,0,0,0,0,0,0,
6199,ambari-web,Jaimin D Jetly,ListBoxes with hostnames on 'Select Hosts' page of 'Enable NameNode HA Wizard' do not work,On the second step of HA 'Enable NameNode HA Wizard' do not work listboxes with hostnames. Real additional components position does not depend from values in listboxes (see screenshots).It is possible to choose any host in any listbox  which is incorrect.,1.6.1,1.6.1,41,0,0,0,0,0,0,0,
6201,,John Speidel,Fix sub-resource names in /stacks API,The /stacks api uses sub-resource names such as stackServices and serviceComponents instead of services and components which are the names of the resources specified in the URL. These incorrect resource names would need to be used in any queries for stack resources.For example:To get stack service named HDFS the URL would be:api/v1/stacks/HDP/versions/2.1/services/HDFSBut  if we wanted to do a query of for HDFS services across all versions:api/v1/stacks/HDP/versions?stackServices/StackServices/service_name=HDFSInstead this should be:api/v1/stacks/HDP/versions?services/StackServices/service_name=HDFSFix all sub-resource names that are returned and fix sub-resource names used in queries and partial response.,1.6.0,1.6.1,85,0,0,0,0,0,0,0,
6203,ambari-web,Andrii Tkach,Unable to assign host in HA wizard,STR:1. Open HA wizard2. Proceed to Select Host step3. Try to select host for any master componentResult:nothing changing  js error emerge.,1.6.1,1.6.1,21,0,0,0,0,0,0,2,ambari-web/app/styles/application.less;ambari-web/app/templates/main/admin/highAvailability/step2.hbs;
6206,ambari-web,Aleksandr Kovalenko,BGO popup: Incorrect number of tasks in category,Tasks with 'aborted' status are not included in any 'Aborted' category.,1.6.1,1.6.1,11,0,0,0,0,0,0,0,
6207,ambari-web,Antonenko Alexander,Installer Wizard Step 7-8: namenode_heapsize property incorrect value.,On the Step 7 namenode_heapsize value is empty and on deploy even if its value filled it saved as 'm' which cause error on NameNode startup.Part of object passed for configuration saving:namenode_heapsize: 'm'namenode_opt_maxnewsize: '200m'namenode_opt_newsize: '200m'nodemanager_heapsize: '1024',1.6.1,1.6.1,42,0,0,0,0,0,0,0,
6208,ambari-web,Antonenko Alexander,Nagios 'Restart all components' button does not work,On service page for Nagios  under 'Service actions' menu  'Restart all' operation does not work correctly. There is dialog window after pressing  but after confirmation there is not any activity. In API there is not any new request.Note: described situation relates only for Nagios. Other services make restart correctly (including generating new requests in API).,1.6.1,1.6.1,55,0,0,0,0,0,0,0,
6215,ambari-web,Antonenko Alexander,Default add host sequence triggers many unseen before cluster-wide operations,I've added 1 host through the add host wizardon deploy step all hosts were present. and install operations were performed on all of them.,1.6.1,1.6.1,24,0,0,0,0,0,0,0,
6221,ambari-server,Myroslav Papirkovskyy,Ambari Server reset show wrong commands for DB manipulation,When performing ambari-server reset with external DB  ambari-server does nothing but outputs commands for resetting it manually.But:1. Commands are wrong  at least on Suse:su -postgres --command=psql -f /var/lib/ambari-server/resources/Ambari-DDL-Postgres-DROP.sql -v username=''ambari'' -v password=''bigdata''su: invalid option -- 'o'Try 'su --help' for more information.2. This commands should take in account that external DB can be located on the another host.3. Maybe the best option would be to give user ability to reset automatically  for example via command line switch like ambari-server reset -a,1.6.1,1.6.1,98,0,0,0,0,0,0,0,
6228,ambari-web,Xi Wang,host checks 'Show Report' link is missing from dialog,On 'Confirm Hosts' step &gt; Hosts Check popup window  the 'Show Reports' link is missing even if the host check warnings existed.Reason:The newly added hosts checks (jdk  disk  repo and hostNameResolution) dont trigger the ''show reports' link to show up.,1.6.1,1.6.1,40,0,0,0,0,0,0,0,
6234,ambari-server,Dmitry Lysnichenko,Security issue - private key password show in logs,During generating private key and certificates using openssl password of key shown in logs:11:21:30 735 INFO [main] ShellCommandUtil:44 - Command openssl genrsa -des3 -passout pass:**** -out /var/lib/ambari-server/keys/ca.key 4096 was finished with exit code: 0 - the operation was completely successfully.11:21:30 750 INFO [main] ShellCommandUtil:44 - Command openssl req -passin pass:**** -new -key /var/lib/ambari-server/keys/ca.key -out /var/lib/ambari-server/keys/ca.csr -batch was finished with exit code: 0 - the operation was completely successfully.11:21:30 766 INFO [main] ShellCommandUtil:44 - Command open**** ca -create_serial -out /var/lib/ambari-server/keys/ca.crt -days 365 -keyfile /var/lib/ambari-server/keys/ca.key -key vgGAzzSaCPkI3F7UU7qZZY6CahDUTSnY7B9a8TH0YiGDB10LdJ -selfsign -extensions jdk7_ca -config /var/lib/ambari-server/keys/ca.config -batch -infiles /var/lib/ambari-server/keys/ca.csr was finished with exit code: 0 - the operation was completely successfully.11:21:30 773 INFO [main] ShellCommandUtil:44 - Command openssl pkcs12 -export -in /var/lib/ambari-server/keys/ca.crt -inkey /var/lib/ambari-server/keys/ca.key -certfile /var/lib/ambari-server/keys/ca.crt -out /var/lib/ambari-server/keys/keystore.p12 -password pass:**** -passin pass:**** see '-key vgGAzzSaCPkI3F7UU7qZZY6CahDUTSnY7B9a8TH0YiGDB10LdJ',1.6.1,1.6.1,131,0,0,0,1,0,0,0,
6236,ambari-web,Oleg Nechiporenko,Hosts page: there is no indication that filtering/sorting/paging is happening or not (confusing),In 1.6.1  filtering/sorting/paging on the Hosts page has been converted from client-side to server-side in order to address scalability issues.As a result of that  the responsiveness of UI is dependent upon how quickly the server can respond to filtering/sorting/paging calls (and also depends on the network). While UI is waiting for the new table content to come from the server  there should be some indication that work is in progress. For example  we can put an overlay on the table with a spinner (gray out the table with a spinner on top - kind of like when switching filters on JIRA's Agile Board).,1.6.1,1.6.1,103,0,0,0,0,0,0,0,
6244,ambari-web,Xi Wang,Restart icon is present after Service Actions->Restart all button click.,STR:Change property for some service (Hive as example)Save changesClick Service Actions-&gt;Restart all buttonActual result:Service Actions-&gt;Restart all button does not work (do nothing). Restart passed  but restart icon still present.Expected result:Service Actions-&gt;Restart all button works. Restart passed  restart icon is not present after action.,1.6.1,1.6.1,43,0,0,0,0,0,0,0,
6247,ambari-web,Antonenko Alexander,Add host stops all services,STR Install cluster Add hostActual resultAfter adding host all components on all hosts are stoppedExpected resultAll components on all hosts are started,1.6.1,1.6.1,22,0,0,0,0,0,0,0,
6265,ambari-web,Xi Wang,Have spinners instead of charts at Dashboard and Service tabs on IE 11,STR:1) Deploy cluster with defualt settings.2) Navigate on Dashboard pageExpected result:All charts are present.Actual result:Have spinners instead some charts.,1.6.1,1.6.1,19,0,0,0,0,0,0,0,
6266,contrib,Artem Baranchuk,Get sql metrics logic should be reviewed,,1.6.1,1.6.1,1,0,0,0,0,0,0,2,contrib/ambari-scom/ambari-scom-server/src/main/java/org/apache/ambari/scom/SQLPropertyProvider.java;contrib/ambari-scom/ambari-scom-server/src/test/java/org/apache/ambari/scom/SQLPropertyProviderTest.java;
6267,ambari-web,Andrii Tkach,Add Services fails with a server error under some conditions,Upon clicking on 'Deploy' from Review page in Add Services Wizard  sometimes the UI shows a server error saying 'Resource Already Exists'.It looks like the UI is trying to add client components on hosts that already have them.I've seen it for HDFS_CLIENT  MAPREDUCE2_CLIENT  etc.  when trying to add Oozie (for sure)  Storm (I think)  and possibly others.,1.6.1,1.6.1,57,0,0,0,0,0,0,2,ambari-web/app/controllers/wizard/step8_controller.js;ambari-web/app/utils/ajax/ajax.js;
6268,ambari-web,Antonenko Alexander,step 6 pagination is slow,,1.6.1,1.6.1,1,0,0,0,0,1,0,0,
6270,ambari-server; stacks,Andrew Onischuk,Repoinfo.xml should use family tag rather than type tag,That is a bit confusing we should change that  since we changed the way itworks &lt;os type='redhat6'&gt;should be &lt;os family='redhat6'&gt;,1.7.0,2.0.0,20,0,0,0,0,0,0,0,
6273,ambari-web,Antonenko Alexander,Manage Config Groups: if Ganglia is not installed config group popup doesn't appear,We take some data from Ganglia metrics for hosts and if Ganglia is not installed browser throw js error which blocks popup initializing.,1.6.1,1.6.1,23,0,0,0,0,0,0,0,
6276,ambari-web,Andrii Babiichuk,Prompt to put Service in Maintenance Mode when doing Rolling Restart / Service Stop,When initiating Rolling Restart / Service Stop  they would like an option (via a checkbox  for example) to put the service in maintenance mode (if it is not already in MM) to avoid getting a lot of alerts.,1.5.0,1.7.0,38,0,0,0,0,0,0,7,ambari-web/app/controllers/main/service/item.js;ambari-web/app/templates/common/confirmation_feedback.hbs;ambari-web/app/templates/common/rolling_restart_view.hbs;ambari-web/app/utils/ajax/ajax.js;ambari-web/app/utils/batch_scheduled_requests.js;ambari-web/app/views/common/modal_popup.js;ambari-web/app/views/common/rolling_restart_view.js;
6292,ambari-web,Greg Hill,Python client caches curl flags between requests causing problems,Currently if you use the python client  if you issue a DELETE request followed by a GET request  that GET request becomes a DELETE request. You can imagine why that's undesirable.The problem is that we set the CUSTOMREQUEST field on the DELETE  but we don't unset it on the next GET. pycurl sees it still set and assumes we're still doing a DELETE.,1.6.0; 1.6.1,1.7.0,63,0,0,0,0,0,0,0,
6295,ambari-web,Srimanth Gunturi,UI freezes for more than 2 seconds  every 15 seconds  on 2K-node cluster,It seems that we call App.componentConfigMapper every 15 seconds.This mapper takes more than 2 seconds to run. While the mapper is running  the entire UI is frozen.,1.6.1,1.6.1,28,0,0,0,0,1,0,0,
6298,ambari-server,Siddharth Wagle,Custom Command execution takes too long,It takes significant amount of time to populate clusterHostInfo for every Execution Cmd on a 2000 node cluster.org.apache.ambari.server.utils.StageUtils.getClusterHostInfo(Map  Cluster),1.6.1,1.6.1,19,0,0,0,0,0,0,0,
6299,ambari-server,Siddharth Wagle,JMXPropertyProvider makes call to endpoint without checking support for properties,Causes CPU usage go upto 1500 % and UI becomes unusable.1000's of Exception:00:01:50 666 ERROR [pool-1-thread-17] JMXPropertyProvider:539 - Caught exception getting JMX metrics : Connection refusedAll JMX endpoints called for any JMX metric.,1.6.1,1.6.1,39,0,0,0,0,1,0,0,
6311,ambari-web,Antonenko Alexander,Bulk Ops only targets a maximum of 'page size' hosts,It seems that the max number of target hosts for a bulk operation is capped by the current 'page size' on the Hosts page.For example  on the 2K cluster with 2K DataNodes: Go to Hosts page Click on Actions. Either going to Filtered Hosts (2005) or All Hosts (2005)  select 'DataNodes &gt; Stop' A confirmation popup tells me that 50 DataNodes are about to be stopped. This should have been ~ 2000 DataNodes instead. 50 is the current page size on the Hosts page that I set.Another scenario: Set page size to 50. Select 100 hosts using 'check all'  'next page'  then 'check all' Go to 'Actions &gt; Selected Hosts &gt; DataNodes &gt; Stop'. Again  it tries to perform actions on only 50 DataNodes.,1.6.1,1.6.1,124,0,0,0,0,0,0,0,
6322,ambari-web,Srimanth Gunturi,Choosing bulk hosts to decommission on 120 node cluster on the hosts page just spins.,Steps to reproduce1. Filter by DataNodes2. Increase the page size to 503. Select all 50 and decommision datanodes.This ends up with a spinner .This might be a blocker. Attaching snapshot.,1.6.1,1.6.1,30,0,0,0,0,0,0,0,
6327,ambari-web,Srimanth Gunturi,Rolling Restart: 'only start stale' checkbox not worked functionally,Rolling restart page  there is a ' Only restart NodeManagers with stale configs' checkbox  nothing happened no matter if that one was checked or not. 1. On service(HDFS or YARN) actions &gt; restart all DN (NM). All DN(NM) will be restart no matter if the ' Only restart NodeManagers with stale configs' option checked.,1.6.1,1.6.1,54,0,0,0,0,0,0,0,
6332,ambari-web,Andrii Babiichuk,Bulk Decommission: Background Operation Popup content looks broken,header in task details popup looks broken when we run decommission for many Datanodes.,1.6.1,1.6.1,14,0,0,0,0,0,0,3,ambari-web/app/templates/wizard/step9/step9HostTasksLogPopup.hbs;ambari-web/app/styles/application.less;ambari-web/app/templates/common/host_progress_popup.hbs;
6335,ambari-web,Andrii Tkach,Add service wizard removes any new property added to core-site and global after cluster installation,,1.6.1,1.6.1,1,0,0,0,0,0,0,4,ambari-web/app/controllers/global/cluster_controller.js;ambari-web/app/controllers/wizard/step7_controller.js;ambari-web/app/controllers/wizard/step8_controller.js;ambari-web/app/utils/config.js;
6337,ambari-web,Aleksandr Kovalenko,Hosts page. Incorrect total number of hosts after filtering by installed component,STR1. Go to hosts page2. Filter by Components. Check DATANODE3. At Bottom right corner I see Show 10 | 1-10 of 10,1.6.1,1.6.1,22,0,0,0,0,0,0,0,
6340,ambari-web,Aleksandr Kovalenko,filtering by selected hosts resets pagination,1. page size 102. select all 10 hosts on first page3. go to page 2  select 2 hosts (total 12 selection)4. click on '12 host selected' and it goes to page 1  1-10 of 12 hosts (correct)5. click to go to page 2 (to see the 2 hosts selected) but it resets to page 1  1-10 of 103,1.6.1,1.6.1,58,0,0,0,0,0,0,0,
6349,ambari-web,Srimanth Gunturi,After changing property and clicking save button in MapReduce Config Page  no comfirmation popup,STR1. Go to MapReduce Config Page2. Change JobTracker new generation size with a new value3. Clike Save buttonResult no confirmation popup  and save button turns grey  when switching pages the save button in the warning popup is not working neither.,1.6.1,1.6.1,40,0,0,0,0,0,0,0,
6350,ambari-web,Andrii Tkach,Unable to restart all host-components on 110 node cluster,On a 110 node cluster I went to the hosts page and went into All Hosts &gt; Hosts &gt; Restart All Components. Following that I got an error dialog (image attached) and the below exceptions in the log21:03:20 017 ERROR [qtp1391464722-1188] AmbariJpaLocalTxnInterceptor:114 - [DETAILED ERROR] Rollback reason:Local Exception Stack:Exception [EclipseLink-4002] (Eclipse Persistence Services - 2.4.0.v20120608-r11652): org.eclipse.persistence.exceptions.DatabaseExceptionInternal Exception: java.sql.BatchUpdateException: Batch entry 0 INSERT INTO requestoperationlevel (operation_level_id  cluster_name  host_component_name  host_name  level_name  request_id  service_name) VALUES (2  'Horton'  NULL  'horton-1.c.pramod-thangali.internal horton-10.c.pramod-thangali.internal horton-100.c.pramod-thangali.internal horton-101.c.pramod-thangali.internal horton-103.c.pramod-thangali.internal horton-104.c.pramod-thangali.internal horton-105.c.pramod-thangali.internal horton-106.c.pramod-thangali.internal horton-107.c.pramod-thangali.internal horton-108.c.pramod-thangali.internal horton-109.c.pramod-thangali.internal horton-11.c.pramod-thangali.internal horton-12.c.pramod-thangali.internal horton-13.c.pramod-thangali.internal horton-14.c.pramod-thangali.internal horton-15.c.pramod-thangali.internal horton-16.c.pramod-thangali.internal horton-17.c.pramod-thangali.internal horton-18.c.pramod-thangali.internal horton-19.c.pramod-thangali.internal horton-2.c.pramod-thangali.internal horton-20.c.pramod-thangali.internal horton-21.c.pramod-thangali.internal horton-22.c.pramod-thangali.internal horton-23.c.pramod-thangali.internal horton-24.c.pramod-thangali.internal horton-25.c.pramod-thangali.internal horton-26.c.pramod-thangali.internal horton-27.c.pramod-thangali.internal horton-28.c.pramod-thangali.internal horton-29.c.pramod-thangali.internal horton-3.c.pramod-thangali.internal horton-30.c.pramod-thangali.internal horton-31.c.pramod-thangali.internal horton-32.c.pramod-thangali.internal horton-33.c.pramod-thangali.internal horton-34.c.pramod-thangali.internal horton-35.c.pramod-thangali.internal horton-36.c.pramod-thangali.internal horton-37.c.pramod-thangali.internal horton-38.c.pramod-thangali.internal horton-39.c.pramod-thangali.internal horton-4.c.pramod-thangali.internal horton-40.c.pramod-thangali.internal horton-41.c.pramod-thangali.internal horton-42.c.pramod-thangali.internal horton-43.c.pramod-thangali.internal horton-44.c.pramod-thangali.internal horton-45.c.pramod-thangali.internal horton-46.c.pramod-thangali.internal horton-47.c.pramod-thangali.internal horton-48.c.pramod-thangali.internal horton-49.c.pramod-thangali.internal horton-5.c.pramod-thangali.internal horton-50.c.pramod-thangali.internal horton-51.c.pramod-thangali.internal horton-52.c.pramod-thangali.internal horton-53.c.pramod-thangali.internal horton-54.c.pramod-thangali.internal horton-55.c.pramod-thangali.internal horton-56.c.pramod-thangali.internal horton-57.c.pramod-thangali.internal horton-58.c.pramod-thangali.internal horton-59.c.pramod-thangali.internal horton-6.c.pramod-thangali.internal horton-60.c.pramod-thangali.internal horton-61.c.pramod-thangali.internal horton-62.c.pramod-thangali.internal horton-63.c.pramod-thangali.internal horton-64.c.pramod-thangali.internal horton-65.c.pramod-thangali.internal horton-66.c.pramod-thangali.internal horton-67.c.pramod-thangali.internal horton-68.c.pramod-thangali.internal horton-69.c.pramod-thangali.internal horton-7.c.pramod-thangali.internal horton-70.c.pramod-thangali.internal horton-71.c.pramod-thangali.internal horton-72.c.pramod-thangali.internal horton-73.c.pramod-thangali.internal horton-74.c.pramod-thangali.internal horton-75.c.pramod-thangali.internal horton-76.c.pramod-thangali.internal horton-77.c.pramod-thangali.internal horton-78.c.pramod-thangali.internal horton-79.c.pramod-thangali.internal horton-8.c.pramod-thangali.internal horton-80.c.pramod-thangali.internal horton-81.c.pramod-thangali.internal horton-82.c.pramod-thangali.internal horton-83.c.pramod-thangali.internal horton-84.c.pramod-thangali.internal horton-85.c.pramod-thangali.internal horton-86.c.pramod-thangali.internal horton-87.c.pramod-thangali.internal horton-88.c.pramod-thangali.internal horton-9.c.pramod-thangali.internal horton-90.c.pramod-thangali.internal horton-91.c.pramod-thangali.internal horton-92.c.pramod-thangali.internal horton-93.c.pramod-thangali.internal horton-94.c.pramod-thangali.internal horton-95.c.pramod-thangali.internal horton-96.c.pramod-thangali.internal horton-97.c.pramod-thangali.internal horton-98.c.pramod-thangali.internal horton-99.c.pramod-thangali.internal horton-master-1.c.pramod-thangali.internal horton-master-2.c.pramod-thangali.internal horton-master-3.c.pramod-thangali.internal'  'Host'  25  NULL) was aborted. Call getNextException to see the cause.Error Code: 0Call: INSERT INTO requestoperationlevel (operation_level_id  cluster_name  host_component_name  host_name  level_name  request_id  service_name) VALUES (?  ?  ?  ?  ?  ?  ?) bind =&gt; [7 parameters bound]Query: InsertObjectQuery(org.apache.ambari.server.orm.entities.RequestResourceFilterEntity@2c6ae575) at org.eclipse.persistence.exceptions.DatabaseException.sqlException(DatabaseException.java:333) at org.eclipse.persistence.internal.databaseaccess.DatabaseAccessor.processExceptionForCommError(DatabaseAccessor.java:1501) at org.eclipse.persistence.internal.databaseaccess.DatabaseAccessor.executeJDK12BatchStatement(DatabaseAccessor.java:875) at org.eclipse.persistence.internal.databaseaccess.ParameterizedSQLBatchWritingMechanism.executeBatchedStatements(ParameterizedSQLBatchWritingMechanism.java:145) at org.eclipse.persistence.internal.databaseaccess.ParameterizedSQLBatchWritingMechanism.appendCall(ParameterizedSQLBatchWritingMechanism.java:88) at org.eclipse.persistence.internal.databaseaccess.DatabaseAccessor.basicExecuteCall(DatabaseAccessor.java:571) at org.eclipse.persistence.internal.databaseaccess.DatabaseAccessor.executeCall(DatabaseAccessor.java:537) at org.eclipse.persistence.internal.sessions.AbstractSession.basicExecuteCall(AbstractSession.java:1800) at org.eclipse.persistence.sessions.server.ClientSession.executeCall(ClientSession.java:286) at org.eclipse.persistence.internal.queries.DatasourceCallQueryMechanism.executeCall(DatasourceCallQueryMechanism.java:207) at org.eclipse.persistence.internal.queries.DatasourceCallQueryMechanism.executeCall(DatasourceCallQueryMechanism.java:193) at org.eclipse.persistence.internal.queries.DatasourceCallQueryMechanism.insertObject(DatasourceCallQueryMechanism.java:342) at org.eclipse.persistence.internal.queries.StatementQueryMechanism.insertObject(StatementQueryMechanism.java:162) at org.eclipse.persistence.internal.queries.StatementQueryMechanism.insertObject(StatementQueryMechanism.java:177) at org.eclipse.persistence.internal.queries.DatabaseQueryMechanism.insertObjectForWrite(DatabaseQueryMechanism.java:471) at org.eclipse.persistence.queries.InsertObjectQuery.executeCommit(InsertObjectQuery.java:80) at org.eclipse.persistence.queries.InsertObjectQuery.executeCommitWithChangeSet(InsertObjectQuery.java:90) at org.eclipse.persistence.internal.queries.DatabaseQueryMechanism.executeWriteWithChangeSet(DatabaseQueryMechanism.java:286) at org.eclipse.persistence.queries.WriteObjectQuery.executeDatabaseQuery(WriteObjectQuery.java:58) at org.eclipse.persistence.queries.DatabaseQuery.execute(DatabaseQuery.java:852) at org.eclipse.persistence.queries.DatabaseQuery.executeInUnitOfWork(DatabaseQuery.java:751) at org.eclipse.persistence.queries.ObjectLevelModifyQuery.executeInUnitOfWorkObjectLevelModifyQuery(ObjectLevelModifyQuery.java:108) at org.eclipse.persistence.queries.ObjectLevelModifyQuery.executeInUnitOfWork(ObjectLevelModifyQuery.java:85) at org.eclipse.persistence.internal.sessions.UnitOfWorkImpl.internalExecuteQuery(UnitOfWorkImpl.java:2875) at org.eclipse.persistence.internal.sessions.AbstractSession.executeQuery(AbstractSession.java:1602) at org.eclipse.persistence.internal.sessions.AbstractSession.executeQuery(AbstractSession.java:1584) at org.eclipse.persistence.internal.sessions.AbstractSession.executeQuery(AbstractSession.java:1535) at org.eclipse.persistence.internal.sessions.CommitManager.commitNewObjectsForClassWithChangeSet(CommitManager.java:224) at org.eclipse.persistence.internal.sessions.CommitManager.commitAllObjectsForClassWithChangeSet(CommitManager.java:191) at org.eclipse.persistence.internal.sessions.CommitManager.commitAllObjectsWithChangeSet(CommitManager.java:136) at org.eclipse.persistence.internal.sessions.AbstractSession.writeAllObjectsWithChangeSet(AbstractSession.java:3914) at org.eclipse.persistence.internal.sessions.UnitOfWorkImpl.commitToDatabase(UnitOfWorkImpl.java:1419) at org.eclipse.persistence.internal.sessions.RepeatableWriteUnitOfWork.commitToDatabase(RepeatableWriteUnitOfWork.java:634) at org.eclipse.persistence.internal.sessions.UnitOfWorkImpl.commitToDatabaseWithChangeSet(UnitOfWorkImpl.java:1509) at org.eclipse.persistence.internal.sessions.RepeatableWriteUnitOfWork.commitRootUnitOfWork(RepeatableWriteUnitOfWork.java:266) at org.eclipse.persistence.internal.sessions.UnitOfWorkImpl.commitAndResume(UnitOfWorkImpl.java:1147) at org.eclipse.persistence.internal.jpa.transaction.EntityTransactionImpl.commitInternal(EntityTransactionImpl.java:84) at org.eclipse.persistence.internal.jpa.transaction.EntityTransactionImpl.commit(EntityTransactionImpl.java:63) at org.apache.ambari.server.orm.AmbariJpaLocalTxnInterceptor.invoke(AmbariJpaLocalTxnInterceptor.java:91) at com.google.inject.internal.InterceptorStackCallback$InterceptedMethodInvocation.proceed(InterceptorStackCallback.java:72) at com.google.inject.internal.InterceptorStackCallback.intercept(InterceptorStackCallback.java:52) at org.apache.ambari.server.actionmanager.ActionDBAccessorImpl$$EnhancerByGuice$$ddd0d231.persistActions(&lt;generated&gt;) at org.apache.ambari.server.actionmanager.ActionManager.sendActions(ActionManager.java:95) at org.apache.ambari.server.actionmanager.ActionManager.sendActions(ActionManager.java:84) at org.apache.ambari.server.controller.AmbariManagementControllerImpl.createAction(AmbariManagementControllerImpl.java:2583) at org.apache.ambari.server.controller.internal.RequestResourceProvider$1.invoke(RequestResourceProvider.java:124) at org.apache.ambari.server.controller.internal.RequestResourceProvider$1.invoke(RequestResourceProvider.java:121) at org.apache.ambari.server.controller.internal.AbstractResourceProvider.createResources(AbstractResourceProvider.java:237) at org.apache.ambari.server.controller.internal.RequestResourceProvider.createResources(RequestResourceProvider.java:121) at org.apache.ambari.server.controller.internal.ClusterControllerImpl.createResources(ClusterControllerImpl.java:274) at org.apache.ambari.server.api.services.persistence.PersistenceManagerImpl.create(PersistenceManagerImpl.java:75) at org.apache.ambari.server.api.handlers.CreateHandler.persist(CreateHandler.java:36) at org.apache.ambari.server.api.handlers.BaseManagementHandler.handleRequest(BaseManagementHandler.java:72) at org.apache.ambari.server.api.services.BaseRequest.process(BaseRequest.java:135) at org.apache.ambari.server.api.services.BaseService.handleRequest(BaseService.java:103) at org.apache.ambari.server.api.services.BaseService.handleRequest(BaseService.java:72) at org.apache.ambari.server.api.services.RequestService.createRequests(RequestService.java:119) at sun.reflect.GeneratedMethodAccessor113.invoke(Unknown Source),1.6.1,1.6.1,236,0,0,0,0,0,0,2,ambari-web/app/utils/batch_scheduled_requests.js;ambari-web/test/controllers/main/host_test.js;
6359,ambari-web,Antonenko Alexander,Hosts page : mysterious 'selected hosts' keep coming back,See attached video.Somehow  there are always 10 hosts selected. After explicitly hitting 'clear selection'  page refresh somehow reverts back to 10 hosts being selected.,1.6.1,1.6.1,24,0,0,0,0,1,0,0,
6369,ambari-web,Xi Wang,hostname wrapping with icon asterisks on assign slaves,see attached.,1.6.1,1.6.1,3,0,0,0,0,0,0,0,
6376,ambari-web,Aleksandr Kovalenko,Excessive requests are sending on hosts page,When we open hosts page  we can see  that we have excessive requests as spinner appears two times one after another.,1.6.1,1.6.1,21,0,0,0,0,0,0,0,
6379,ambari-web,Andrii Tkach,In Host Detailed Page  decommissioned NM is labeled as STOPPED,In Yarn Service page  NodeManagers Status: 3 active / 0 lost / 0 unhealthy / 0 rebooted / 1 decommissionedIn Host Detailed Page of that decommissioned NM  the state of the NM is labeled as 'stopped'  which is not consistent comparing to Service page.API call:'href' : 'http://172.18.145.115:8080/api/v1/clusters/cl1/hosts/us3mon1404188570-3.cs1cloud.internal/host_components/NODEMANAGER'  'HostRoles' : { 'cluster_name' : 'cl1'  'component_name' : 'NODEMANAGER'  'desired_admin_state' : 'DECOMMISSIONED'  'desired_stack_id' : 'HDP-2.1'  'desired_state' : 'STARTED'  'host_name' : 'us3mon1404188570-3.cs1cloud.internal'  'maintenance_state' : 'OFF'  'service_name' : 'YARN'  'stack_id' : 'HDP-2.1'  'stale_configs' : false  'state' : 'INSTALLED' As a result  user cannot start the NodeManger as it is considered to be decommissioned by ResourceManger.,1.6.1,1.6.1,99,0,0,0,0,0,0,0,
6402,ambari-web,Oleg Nechiporenko,Many services failed to start when using custom user names and groups,On Customize services page set next values for users and groups:Name: ValueProxy group for Hive WebHCat Oozie and Falcon: custom-usersgrHDFS User: custom-hdfsMapReduce User: custom-mapredYARN User: custom-yarnHBase User: custom-hbaseHive User: custom-hiveHCat User: custom-hcatWebHCat User: custom-hcatOozie User: custom-oozieFalcon User: custom-falconStorm User: custom-stormZooKeeper User: custom-zookeeperGanglia User: custom-nobodyNagios User: custom-nagiosNagios Group: custom-nagiosgrSmoke Test User: ambari-qaTez User: custom-tezHadoop Group: custom-hadoopgrSkip group modifications during install: falseAfter deploy many services fail to start:MapReduce  Hbase  Hive  WebHcat  Falcon  OozieSame error for all:Call From ins1404365245-9.cs1cloud.internal/172.18.145.154 to localhost:8020 failed on connection exception: java.net.ConnectException: Connection refused; For more details see: http://wiki.apache.org/hadoop/ConnectionRefused,1.6.1,1.6.1,91,0,0,0,0,0,0,0,
6405,ambari-web,Aleksandr Kovalenko,Move Wizard: get stuck if wizard is running second time for the same component without page refresh,STR:1. Run Move Wizard for some master component.2. Do not click Complete button after all operation will be finished. Close wizard (confirm closing).3. Without page refresh open wizard for the same master component and try it to reassign to another host (ex. back to the previous host).Wizard will get stuck  as source host for master component will be calculated incorrectly.This issue is related to host components mapper. After first running of move wizard in the model there were 2 masters one with host before moving and the new one. Old host component was deleted on server but UI model still contains it. And it brakes algorithm of calculating source host on assign master step.,1.6.1,1.6.1,114,0,0,0,0,1,0,0,
6406,ambari-web,Andrii Tkach,Move Wizard: assign master step next button is not disabled  when host input has error,When Move Wizard is running on cluster with a large number of hosts  assign master step has input to enter hostname instead of select dropdown. If this dropdown is empty  it shows an error. But if in the same time target host was selected correctly the next button is enabled.,1.6.1,1.6.1,50,0,0,0,0,0,0,2,ambari-web/app/controllers/main/service/reassign/step2_controller.js;ambari-web/app/controllers/wizard/step5_controller.js;
6409,infra,Alejandro Fernandez,Postgres create script generates errors for clusterconfig,Manually running the postgres create sql script encountered errors.Errors: psql:Ambari-DDL-Postgres-CREATE.sql:22: ERROR: column 'config_attributes' specified more than once psql:Ambari-DDL-Postgres-CREATE.sql:103: ERROR: relation 'clusterconfig' does not exist psql:Ambari-DDL-Postgres-CREATE.sql:126: ERROR: relation 'clusterconfig' does not existRepro Steps:1. Spin up a CentOS 6.4 VM vagrant up c6401 vagrant ssh c6401 sudo su - wget http://public-repo-1.hortonworks.com/ambari/centos6/1.x/updates/1.6.0/ambari.repo cp ambari.repo /etc/yum.repos.d yum install ambari-server -y2. Setup a postgres database vi /etc/yum.repos.d/CentOS-Base.repo edit the &#91;base&#93; and &#91;updates&#93; sections by adding the following line without quotes  'exclude=postgresql*' yum localinstall http://yum.postgresql.org/9.3/redhat/rhel-6-x86_64/pgdg-centos93-9.3-1.noarch.rpm yum install postgresql-server cd /etc/yum.repos.d/ service postgresql initdb chkconfig postgresql on service postgresql start3. Run the script cp /vagrant/Ambari-DDL-Postgres-CREATE.sql /var/lib/ambari-server/resources/ (assuming you have the latest file from trunk) cp /var/lib/ambari-server/resources/Ambari-DDL-Postgres-CREATE.sql /var/lib/pgsql/ su - postgres psql Follow step #1 at http://docs.hortonworks.com/HDPDocuments/Ambari-1.6.0.0/bk_ambari_reference/content/nndb-using-ambari-postgresql.html where $AMBARIDATABASE is ambari  $AMBARIUSER is postgres  and $AMBARISCHEMA is ambari. /i Ambari-DDL-Postgres-CREATE.sql;Then verify the errors. When done  issue /q on the psql command line to exit.,1.7.0,1.7.0,157,0,0,0,0,0,0,0,
6418,ambari-web,Andrii Tkach,Config pages load slowly on 2k-node cluster for some services,On the 2k-node cluster  service config pages load slowly (though the load time has improved significantly from before).The load time depends on the service.Here are some sample load times:HDFS: 5sYARN: 17sMR2: 16sTEZ: 10sHBASE: 3sHIVE: 13sWEBHCAT: 3sFALCON: 3sSTORM: 17sOOZIE: 11sGANGLIA: 1sNAGIOS: 1sZOOKEEPER: 2sPIG: 2sSQOOP: n/a (no config page),1.6.1,1.7.0,47,0,0,0,0,1,0,5,ambari-web/app/controllers/main/service/info/configs.js;ambari-web/app/data/global_properties.js;ambari-web/app/utils/ajax/ajax.js;ambari-web/app/utils/configs/defaults_providers/defaultsProvider.js;ambari-web/app/utils/configs/defaults_providers/yarn_defaults_provider.js;
6426,site,Alejandro Fernandez,Link to ExtJS license in 'Choose Services' page has moved,Step 4 of the Ambari installer has a broken link.When 'Choosing Services'  the link for the 'ExtJS' library license under the 'Oozie' service has moved from http://www.sencha.com/products/extjs/license/It should be updated to the URL below since it covers that Ext JS is available under GPL v3 license:http://www.sencha.com/legal/open-source-faq/,1.6.1,1.7.0,52,0,0,0,0,0,1,0,
6439,ambari-web,Andrii Babiichuk,Filter state does not clear in Background Operation popup and causes a lot of confusion,In the Background Operations popup  the filter state persists at the Host and Task levels  even after closing the popup (the filter should be cleared once the user goes back up one level or closes the popup).This causes a lot of confusion because the user will expect these filters to be cleared but instead cannot see the hosts and tasks that they are expecting.,1.6.1,1.6.1,64,0,0,0,0,0,0,1,ambari-web/app/utils/host_progress_popup.js;
6440,ambari-web,Aleksandr Kovalenko,Unable to move NameNode,STR: Enabled NNHA.Active NameNode is on suse1101 hostStandby NameNode is on suse1102 host Stopped SNN. Opened move NN wizardResult: Next button is active when I choose existing topology (suse1101 and suse1102)Next button is inactive when I choose custom topology (suse1103 and suse1101)UPD: Reproduced also on non-HA cluster.,1.6.1,1.6.1,48,0,0,0,0,0,0,0,
6442,ambari-web,Antonenko Alexander,JS error occurs periodically when Job Details page is opened,'Uncaught TypeError: Cannot read property 'properties' of undefined'at /ambari-web/app/views/common/quick_view_link_view.js:246,1.6.1,1.7.0,9,0,0,0,0,1,0,0,
6471,ambari-web,Srimanth Gunturi,Add Services Wizard can corrupt config files unpredictably,Testing using the 1.6.1 RC bits (branch-1.6.1  hash=ffb702b252a8b979529864ec5579465a122060b5) revealed that Add Services can corrupt config files in an unpredictable manner.We have seen: adding Pig resulted in core-site dropping all existing properties except for 'hadoop.proxyuser.falcon.hosts and hadoop.proxyuser.falcon.groups' add Storm resulted in core-site retaining all existing properties but dropping hadoop.proxyuser.* settings for all services except Falcon adding Storm dropped a number of existing properties in yarn-site (and NodeManagers can no longer restart after that)The bottomline here is that behavior seems pretty random (adding the same service on different clusters results in different behavior).Also  when adding a service  certain configs (like hdfs-site) were not cloned while most other configs (like yarn-site  mapred-site) get cloned even if no property changes are made regardless of which service is added.Update: changes to hdfs-site during Add Services Wizard never persists.,1.6.1,1.6.1,133,0,0,0,0,0,0,0,
6477,ambari-web,Andrii Babiichuk,AddHost Wizard: error for existing host is not present,STR: Click AddHost Type existing host Click 'Register and Confirm' buttonActual result: There present only message about 'SSH Private Key is required'Excpected Result: SHould be also present message like 'These hosts are already exists'.---------------------------------Note: the excpected message only present if we type/select ss key and will click 'Register and Confirm',1.6.0,1.7.0,56,0,0,0,0,0,0,1,ambari-web/app/controllers/wizard/step2_controller.js;
6483,ambari-web,Oleg Nechiporenko,JS errors on Jobs page if ATS is stopped,If ATS stopped  Jobs page continuously produces following js errors:NetworkError: 400 Bad Request - http://172.18.145.185:8080/proxy?url=http://us1mon1402550931-re-5.cs1cloud.internal:8188/ws/v1/timeline/HIVE_QUERY_ID?fields=events primaryfilters otherinfo&amp;secondaryFilter=tez:true&amp;limit=11&amp;_=1402578530622'proxy?...8530622'NetworkError: 400 Bad Request - http://172.18.145.185:8080/proxy?url=http://us1mon1402550931-re-5.cs1cloud.internal:8188/ws/v1/timeline/HIVE_QUERY_ID?limit=1&amp;secondaryFilter=tez:true&amp;_=1402578531674'proxy?...8531674'NetworkError: 400 Bad Request - http://172.18.145.185:8080/proxy?url=http://us1mon1402550931-re-5.cs1cloud.internal:8188/ws/v1/timeline/HIVE_QUERY_ID?limit=1&amp;secondaryFilter=tez:true&amp;_=1402578537654',1.7.0,1.7.0,40,1,0,0,0,0,0,0,
6491,ambari-web,Antonenko Alexander,Default config group name contains 'undefined' instead of service name in Manage Config Groups popup,,1.7.0,1.7.0,1,0,0,0,0,0,0,0,
6499,ambari-web,Oleg Nechiporenko,Unable to proceed from step 4 of installer if YARN-dependent services are selected but YARN isn't (HDP 2.0),STROn step 4 of Install Wizard  select any of the services dependent on YARN (Piq  Oozie  Hive) but don't select YARN itself. Press 'Next' button.Expected resultPopup with the info about YARN dependence appears.Actual resultNothing happens. JS error occurs:Uncaught TypeError: Cannot read property 'get' of undefinedatapp/controllers/wizard/step4_controller.js:180,1.7.0,1.7.0,59,0,0,0,0,0,0,0,
6504,ambari-web,Aleksandr Kovalenko,Incorrect errors count for YARN on step 7 of Install Wizard (HDP 2.0),'Customize Services' step indicates that 8 YARN properties need revision but no one is highlighted as incorrect.,1.7.0,1.7.0,17,0,0,0,0,0,0,0,
6521,ambari-web,Xi Wang,Hostname case sensitivity,Hostname CaSe SeNsiTiVity causes hostnames don't match error.'in the install wizard  the hostnames MUST be lower case in the user input  otherwise the 'hostnames don't match' during the install and it fails. Ambari should tolower() both hosts before comparing.'Effected Install/Add Host Wizard.,1.6.0,1.7.0,42,0,0,0,0,0,0,0,
6525,ambari-web,Andrii Babiichuk,Unable to install cluster after coming back to step 1 and selecting different stack version,STRProceed to step 7 of Install Wizard. Return to step 1 and choose a different stack version. Go forward.ResultUnable to proceed from step 3. JS error occurs:Uncaught Error: &lt;DS.StateManager:ember26192&gt; could not respond to event didChangeData in state rootState.loaded.updated.uncommitted.WorkaroundTo log out and log in again before perforfing installation with different stack version.,1.7.0,1.7.0,61,0,0,0,0,0,0,2,ambari-web/app/controllers/wizard/step7_controller.js;ambari-web/app/mappers/stack_service_mapper.js;
6527,,subin,Ambari support on CentOS7 /RHEL7 - I,Background : Centos7 is very different from centos6.5 and currently Ambari &amp; HDP are not supported on Centos7Supporting Ambari on CentOS7/RHEL7 has multiple elements :1)mvn build of Ambari should be successful. document required steps in wiki.2)Ambari server &amp; agent should be modified to support centos7/redhat7. following changes are necessary :2.1)/usr/lib/python2.6 symbolic link .2.2)code changes to add redhat7 as a new OS family.3)HDP centos7 rpms + new repo to be made available to deploy different services on centos7/redhat7 .Currently centos7 is not supported by the Ambari/HDP build team.This JIRA captures 2.2),1.7.0,,98,1,0,0,0,0,0,0,
6539,ambari-web,Oleg Nechiporenko,Create main page with table of jobs,,1.7.0,1.7.0,1,1,0,0,0,0,0,0,
6544,ambari-web,Xi Wang,Add ZKFC component to summary page (when NNHA enabled),Add ZKFC component on summary page. Each Zkfc should under related Namenode  with a smaller size.,1.4.0,1.7.0,16,1,0,0,0,0,0,0,
6558,ambari-web,Xi Wang,FE allows add host on host that is in UNKNOWN state (agent was stopped),added a host to a cluster (manually installed and started an agent)http://c6403.ambari.apache.org:8080/api/v1/hosts/c6401.ambari.apache.org{ 'href' : 'http://c6403.ambari.apache.org:8080/api/v1/hosts/c6401.ambari.apache.org'  'Hosts' : { 'host_health_report' : ''  'host_name' : 'c6401.ambari.apache.org'  'host_state' : 'HEALTHY'  'host_status' : 'HEALTHY' }}After the agent is stopped for the host{ 'href' : 'http://c6403.ambari.apache.org:8080/api/v1/hosts/c6401.ambari.apache.org'  'Hosts' : { 'host_health_report' : ''  'host_name' : 'c6401.ambari.apache.org'  'host_state' : 'HEARTBEAT_LOST'  'host_status' : 'UNKNOWN' }}At this point I can perform AddHost and start the wizard. But AddHost will eventually fail - although now I see it just waiting.We need some form of error indication when host is not lost.,1.5.0,1.7.0,103,0,0,0,0,0,0,0,
6568,ambari-web,Jaimin D Jetly,Service pluggability: New added services in the stack has Add Property link in log-4j and env categories,,1.7.0,1.7.0,1,1,0,0,0,0,0,0,
6570,ambari-web,Oleg Nechiporenko,Fast user can skip 'Customize Services' step (add service wizard) while configs are not loaded,STR Install cluster Go to Add Service Wizard Proceed to step 'Customize services' While configs are loading click 'Next'.If user tried to install services with configs that should be provided manually using UI (like Nagios)  he will get JS-error on next step.,1.7.0,1.7.0,42,0,0,0,0,0,0,0,
6571,ambari-web,Oleg Nechiporenko,'all/none' links affect already installed services on 'Select Services' step,,1.7.0,1.7.0,1,0,0,0,0,0,0,0,
6575,ambari-web,Antonenko Alexander,Linked Ganglia charts from Host Details page don't show any graphs (except on NameNode host),The UI links to Ganglia Web to display the graphs for a specific host as http://&lt;ganglia-host&gt;/ganglia/mobile_helper.php?show_host_metrics=1&amp;h=&lt;target-fqdn&gt;&amp;c=HDPNameNode&amp;r=hour&amp;cs=&amp;ce=Note that c=HDPNameNode is static.I believe this worked before as the NameNode gmond was repeated on all the hosts (we should not have and this has been fixed but now it's causing this issue).For this ticket  let's change the call the UI makes from 'HDPNameNode' to 'HDPSlaves' and verify that host-level Ganglia links work for all hosts on a multi-node cluster (including hosts with clients only).,1.7.0,1.7.0,81,1,0,0,0,0,0,0,
6585,site,Alejandro Fernandez,Deleted hosts come back to life after ambari-server restart,When attempting to delete a host through the UI  and then re-add it  the re-add operation fails because a record already exists in the clusterhostmapping table.This can be reproduced as follows (host names will change of course) 1. Create a cluster and add a host so that it is populated in the clusterhostmapping table.2. Make sure the agent is running.3. On the server  run ambari-server restart  and immediately run the following repeatedly in another terminal window before the restart finishes  curl --write-out %{http_code} --show-error -u admin:admin -H 'X-Requested-By:1' -i -X DELETE http://c6404.ambari.apache.org:8080/api/v1/clusters/dev/hosts/c6407.ambari.apache.orgHTTP/1.1 200 OKSet-Cookie: AMBARISESSIONID=z91px2l41uc6dwjv52zl2mcu;Path=/Expires: Thu  01 Jan 1970 00:00:00 GMTContent-Type: text/plainContent-Length: 0Server: Jetty(7.6.7.v20120910)4. Quickly verify that the host name is removed from the clusterhostmapping table.5. On the agent  run ambari-agent restart  and repeatedly requery the clusterhostmapping table  until the record is reinserted (should take no more than 30 seconds to appear).6. Run the curl command to attempt to re-add the host  and receive the error message curl --write-out %{http_code} --show-error -u admin:admin -H 'X-Requested-By:1' -i POST http://c6404.ambari.apache.org:8080/api/v1/clusters/dev/hosts/c6407.ambari.apache.orgHTTP/1.1 500 Exception [EclipseLink-4002] (Eclipse Persistence Services - 2.4.0.v20120608-r11652): org.eclipse.persistence.exceptions.DatabaseException Internal Exception: java.sql.BatchUpdateException: Batch entry 0 INSERT INTO ClusterHostMapping (cluster_id  host_name) VALUES (2  'c6407.ambari.apache.org') was aborted. Call getNextException to see the cause. Error Code: 0 Call: INSERT INTO ClusterHostMapping (cluster_id  host_name) VALUES (?  ?) bind =&gt; [2 parameters bound]Set-Cookie: AMBARISESSIONID=1je1wahcml82f11gjrserxgdyl;Path=/Content-Type: text/plain;charset=ISO-8859-1Content-Length: 530Server: Jetty(7.6.7.v20120910){ 'status': 500  'message': 'Exception [EclipseLink-4002] (Eclipse Persistence Services - 2.4.0.v20120608-r11652): org.eclipse.persistence.exceptions.DatabaseException/nInternal Exception: java.sql.BatchUpdateException: Batch entry 0 INSERT INTO ClusterHostMapping (cluster_id  host_name) VALUES (2  /u0027c6407.ambari.apache.org/u0027) was aborted. Call getNextException to see the cause./nError Code: 0/nCall: INSERT INTO ClusterHostMapping (cluster_id  host_name) VALUES (?  ?)/n/tbind /u003d/u003e [2 parameters bound]'At this point  here is the state of the tables.select * from clusterhostmapping where host_name = 'c6407.ambari.apache.org'; cluster_id | host_name------------+------------------------- 2 | c6407.ambari.apache.orgselect * from hoststate where host_name = 'c6407.ambari.apache.org'; agent_version | available_mem | current_state | health_status | host_name | time_in_state | maintenance_state---------------------+---------------+---------------+----------------------------------------------+-------------------------+---------------+------------------- {'version':'1.6.0'} | 250232 | INIT | {'healthStatus':'HEALTHY' 'healthReport':''} | c6407.ambari.apache.org | 1405718796141 | {'2':'ON'}I then deleted both records  restarted the server  and was then able to add the host successfully.This is a bug in the persistence layer.,1.6.1,1.7.0,360,1,0,0,0,0,0,0,
6587,ambari-server,Siddharth Wagle,Views: exception on server restart after creating view instance,1) installed the files view (built from source)2) I created an instance of the viewPOSThttp://c6401.ambari.apache.org:8080/api/v1/views/FILES/versions/0.1.0/instances/MyFiles[ {'ViewInstanceInfo' : { 'properties' : { 'dataworker.defaultFs' : 'webhdfs://c6401.ambari.apache.org:50070'  'dataworker.username' : 'ambari-qa' } }} ]3) I restart ambari-server and get this exception  so ambari-server can't start up. If I delete the view jar and restart  then I can get ambari-server to start.00:41:59 433 INFO [main] Server:266 - jetty-7.6.7.v2012091000:41:59 914 WARN [main] WebAppContext:489 - Failed startup of context o.e.j.w.WebAppContext{/views/FILES/0.1.0/MyFiles file:/var/lib/ambari-server/resources/views/work/FILES%7B0.1.0%7D/} /var/lib/ambari-server/resources/views/work/FILES{0.1.0}java.util.zip.ZipException: invalid entry size (expected 12027 but got 11985 bytes) at java.util.zip.ZipInputStream.readEnd(ZipInputStream.java:403) at java.util.zip.ZipInputStream.read(ZipInputStream.java:195),1.7.0,1.7.0,108,1,0,0,0,0,0,0,
6589,ambari-web,Jaimin D Jetly,Management Console: UI Layout  Basic Routing and Create User Management Page (with mock data),,1.7.0,1.7.0,1,1,0,0,0,0,0,0,
6603,ambari-web,Srimanth Gunturi,Install wizard should have ability to load default 'final' configs  and save them,In Ambari if a stack service has configs with final=true  then during install wizard these configs should have the final-checkbox checked. Also  if the user changes these checkboxes  the values should be stored in the properties_attributes of configs when Deploy is hit.,1.7.0,1.7.0,42,0,0,0,0,0,0,0,
6609,ambari-server,Dmytro Sen,Ambari-DDL-Postgres-CREATE.sql fix for CLUSTER.OPERATE,,1.7.0,1.7.0,1,0,0,0,0,0,0,1,ambari-server/src/main/resources/Ambari-DDL-Postgres-CREATE.sql;
6622,ambari-server,Srimanth Gunturi,BlueprintResourceProviderTest fails on exception message assertion,testDecidePopulationStrategy_unsupportedSchema(org.apache.ambari.server.controller.internal.BlueprintResourceProviderTest) Time elapsed: 0.02 sec &lt;&lt;&lt; FAILURE!java.lang.AssertionError:Expected: (exception with message a string containing 'Configuration definition schema is not supported' and an instance of java.lang.IllegalArgumentException) got: &lt;java.lang.IllegalArgumentException: 'Configuration format provided in Blueprint is not supported'&gt;,1.7.0,1.7.0,43,0,0,0,0,0,0,0,
6623,test,Alejandro Fernandez,Fix unit tests that are broken after AMBARI-6533,Unit tests are broken after commit f3aab68ec417d8e2c39c216962e1e1d47d56d401The root cause is the properties in InMemoryDefaultTestModule.java.,1.7.0,1.7.0,14,0,0,0,0,0,0,0,
6626,ambari-web; site,Jaimin D Jetly,HDP-1.3 stack shows HUE in select services page,HUE is defined in HDP-1.3.2 stack with configuration sites but there is no agent scripts defining configure/stop/start/status functions for the service.HUE is not supported to work with Ambari. In that case we should not expose HUE via stack definition API as supported service of HDP-1.x stack.,1.7.0,1.7.0,46,0,0,0,0,0,0,0,
6628,ambari-server,Srimanth Gunturi,Cannot start ambari-server due to empty metainfo table,Trying to deploy latest trunk build ambari-server-1.7.0-70 and hit the following when running ambari-server startambari-server.log01:30:53 074 INFO [main] AmbariServer:157 - ********* Meta Info initialized **********01:30:53 086 INFO [main] ClustersImpl:103 - Initializing the ClustersImpl01:30:53 679 INFO [main] AmbariManagementControllerImpl:230 - Initializing the AmbariManagementControllerImpl01:30:53 894 INFO [main] AmbariServer:487 - Checking DB store version01:30:53 894 WARN [main] AmbariServer:502 - Current database store version is not compatible with current server version  serverVersion=null  schemaVersion=null01:30:53 895 ERROR [main] AmbariServer:592 - Failed to run the Ambari Serverorg.apache.ambari.server.AmbariException: Current database store version is not compatible with current server version  serverVersion=null  schemaVersion=null at org.apache.ambari.server.controller.AmbariServer.checkDBVersion(AmbariServer.java:503) at org.apache.ambari.server.controller.AmbariServer.run(AmbariServer.java:164) at org.apache.ambari.server.controller.AmbariServer.main(AmbariServer.java:589)The metainfo table is empty with no values indicating version of Ambari installed.,1.7.0,1.7.0,115,0,0,0,0,0,0,0,
6630,ambari-web,Jaimin D Jetly,Add Service wizard: Retry installation functionality does not work,API triggered on clicking Retry button results in failure with 400 status code,1.7.0,1.7.0,13,0,0,0,0,1,0,0,
6638,ambari-web,Andrii Tkach,Config categories aren't displayed on 'Configure Services' step of Secrity Wizard,See the screenshot attached.JS error Uncaught TypeError: Cannot read property 'filterProperty' of undefined at ambari-web/app/views/common/configs/services_config.js:338,1.7.0,1.7.0,29,1,0,0,0,0,0,2,ambari-web/app/controllers/main/admin/security/add/step2.js;ambari-web/app/views/common/configs/services_config.js;
6640,ambari-web,Andrii Babiichuk,Memory leaks during tabs switching on 'Customize Services' page,Steps:Go to 'Customize services page'.Switch to other tab many a time (50 switches = about 100MB).Result: firefox browser gets 1.2 GB in memory.,1.5.0,1.7.0,23,1,0,0,0,0,0,6,ambari-web/app/templates/common/configs/service_config.hbs;ambari-web/app/templates/common/configs/service_config_category.hbs;ambari-web/app/templates/common/configs/service_config_wizard.hbs;ambari-web/app/templates/common/configs/services_config.hbs;ambari-web/app/views/common/configs/services_config.js;ambari-web/test/views/common/configs/services_config_test.js;
6664,ambari-agent,Vitaly Brodetskyi,Oozie service can not be started on Ambari server with external Postgres,STR: Install single node cluster with Postgres 9 server as Ambari and Oozie DB (Stack - 2.0). Postgres server should be on dedicated host; Start all services.Actual result: Oozie server will not start.Error message for Oozie:2014-07-23 08:42:57 947 - Error while executing command 'start':Traceback (most recent call last): File '/usr/lib/python2.6/site-packages/resource_management/libraries/script/script.py'  line 111  in execute method(env) File '/var/lib/ambari-agent/cache/stacks/HDP/2.0.6/services/OOZIE/package/scripts/oozie_server.py'  line 43  in start oozie_service(action='start') File '/var/lib/ambari-agent/cache/stacks/HDP/2.0.6/services/OOZIE/package/scripts/oozie_service.py'  line 43  in oozie_service Execute( db_connection_check_command  tries=5  try_sleep=10) File '/usr/lib/python2.6/site-packages/resource_management/core/base.py'  line 148  in __init__ self.env.run() File '/usr/lib/python2.6/site-packages/resource_management/core/environment.py'  line 149  in run self.run_action(resource  action) File '/usr/lib/python2.6/site-packages/resource_management/core/environment.py'  line 115  in run_action provider_action() File '/usr/lib/python2.6/site-packages/resource_management/core/providers/system.py'  line 239  in action_run raise exFail: Execution of '/usr/jdk64/jdk1.7.0_45/bin/java -cp /usr/lib/ambari-agent/DBConnectionVerification.jar:/usr/lib/oozie/libserver/postgresql-9.0-801.jdbc4.jar org.apache.ambari.server.DBConnectionVerification jdbc:postgresql://&lt;host&gt;:5432/ooziedb oozieuser [PROTECTED] org.postgresql.Driver' returned 1. ERROR: Unable to connect to the DB. Please check DB connection properties.java.lang.ClassNotFoundException: org.postgresql.Driver,1.7.0,1.7.0,134,1,0,0,0,0,0,0,
6667,,Jonathan Hurley,Unit test failures on jenkins for Ambari 1.7.0 related to alerts.,Tests run locally and pass 100% consistently.These test results are fishy; they randomly fail on different OS deployments. Even the simple logic ones fail. There are only 5 alert targets ever created  yet there are 9 returned sometimes. I'm wondering if this is because we tried to load some data in the @BeforeClass instead of @Before - maybe there's a weird Guice/JUnit race condition going on.I can't say I can fix this with confidence since I can't reproduce it. I'm going to move some things to @Before and hope it helps.java.lang.AssertionError: expected:&lt;5&gt; but was:&lt;9&gt; at org.junit.Assert.fail(Assert.java:93) at org.junit.Assert.failNotEquals(Assert.java:647) at org.junit.Assert.assertEquals(Assert.java:128) at org.junit.Assert.assertEquals(Assert.java:472) at org.junit.Assert.assertEquals(Assert.java:456) at org.apache.ambari.server.orm.dao.AlertDispatchDAOTest.testFindAllTargets(AlertDispatchDAOTest.java:117),1.7.0,1.7.0,113,1,0,0,0,0,0,0,
6672,ambari-agent,Vitaly Brodetskyi,Oozie fails for stack 2.0 and 2.1,,1.7.0,1.7.0,1,1,0,0,0,0,0,0,
6716,ambari-web,Antonenko Alexander,'Refresh configs' action doesn't work for Flume,STR: Deployed cluster with Flume  without Flume Agents. Added Flume agent on each host. Configured 7 agents  assigned to different hosts. Changed config of one Flume agent. Clicked 'Refresh configs' action.Result: Nothing happened.,1.7.0,1.7.0,33,0,0,0,0,0,0,0,
6721,ambari-web,Yusaku Sako,Capacity Scheduler config cannot be saved,STR: Go to YARN &gt; Config Under 'Scheduler' section  modify 'Capacity Scheduler' configs. Hit Save. The page reloads. The modifications are reverted back.,1.7.0,1.7.0,23,0,0,0,0,0,0,0,
6729,ambari-web,Aleksandr Kovalenko,RM HA wizard is experimental but shouldn't be,Installed 1.7.0 build and RM HA is not available unless I go enable #experimental.Should not be experimental. RM HA is available with HDP 2.1+ Stack (but not with HDP 2.0.* stack).,1.7.0,1.7.0,31,1,0,0,0,0,0,0,
6735,ambari-web,Aleksandr Kovalenko,Once RM HA is config'd  none of the RM summary info or RM dashboard widgets show data,Configure RM HA. None of the summary info shows in Services &gt; YARN &gt; Summary All of the RM Dashboard widgets show N/A,1.7.0,1.7.0,25,0,0,0,0,0,0,0,
6741,ambari-web,Andrii Babiichuk,On HDFS config page edit boxes with memory size values have incorrect behavior.,Go to HDFS config page.Change Name Node java heap size.Save configs.'Successful' message appears  but on config page edit boxes have wrong values.After clicking 'OK' fields get right value again.Same issue reproduced on Nano but it looks like there it fails to save configs.,1.7.0,1.7.0,43,1,0,0,0,0,0,2,ambari-web/app/controllers/main/service/info/configs.js;ambari-web/test/controllers/main/service/info/config_test.js;
6744,ambari-web,Aleksandr Kovalenko,'Select Host' page on Resource Manager HA Enabling wizard does not save selected values after next/back steps,STR:1) Deploy cluster2) Go to Enable Resourse Manager Enable HA wizard3) Go to 'Select Host' page4) Select some different from default value in combobox 'Additional Resourse manager'5) Click 'Next' and go to 'Review' page6) Click 'Back' and again go to 'Select Host' page.Actual result: value in 'Additional Resourse Manager' is default againExpected result: value in 'Additional Resourse Manager' is the same with choosen previously.,1.7.0,1.7.0,64,1,0,0,0,1,0,0,
6749,,Jonathan Hurley,Flume service should be in STARTED state when no agents configured,When installing Flume service by default if we dont configure any agents  we end up with Flume being the only service shown in a red STOPPED state. For the case where there are no agents  this should be set to STARTED.,1.7.0,1.7.0,41,1,0,0,0,0,0,2,ambari-server/src/main/resources/stacks/HDP/2.0.6/services/FLUME/package/scripts/flume_handler.py;ambari-server/src/test/python/stacks/2.0.6/FLUME/test_flume.py;
6751,ambari-web,Xi Wang,HostNames and Slaves broken in two lines on Assign Slaves step,On Assign Slaves step  elements in the table got broken in two lines.see attached.,1.7.0,1.7.0,14,0,0,0,0,0,0,0,
6754,ambari-web,Aleksandr Kovalenko,Resource Manager HA: after enabling RM HA  UI does not display standby and active Resource Managers on Summary tab,STR:1) Deploy 3-node cluster2) Enable RM HA3) Go to YARN Service page  Summary tabResult: There are not Resource Managers on Summary tab4) Select config tab and after that return back to Summary tabResult: Summary tab is as expected,1.7.0,1.7.0,38,1,0,0,0,0,0,0,
6769,ambari-web,Andrii Babiichuk,Add security configs on Add service wizard,add service wizard doesn't add secure cinfigs,1.5.0,1.7.0,7,1,0,0,0,0,0,14,ambari-web/app/controllers/global/cluster_controller.js;ambari-web/app/controllers/main/admin/highAvailability_controller.js;ambari-web/app/controllers/main/admin/security/add/step4.js;ambari-web/app/controllers/main/host/details.js;ambari-web/app/controllers/main/service/item.js;ambari-web/app/controllers/wizard/step7_controller.js;ambari-web/app/controllers/wizard/step8_controller.js;ambari-web/app/mixins.js;ambari-web/app/mixins/wizard/addSecurityConfigs.js;ambari-web/app/views/main/admin/highAvailability_view.js;ambari-web/test/controllers/main/admin/security/add/step4_test.js;ambari-web/test/controllers/wizard/step8_test.js;ambari-web/test/mixins/wizard/addSeccurityConfigs_test.js;ambari-web/app/templates/main/admin/highAvailability.hbs;
6782,ambari-web,Jaimin D Jetly,Wizard: Adding Master component does not create and install the master host component,STR: On 3-node cluster  Go to Assign Masters page. Add another HBase Master. (Note: HBase Master and ZK server are only addable components.) Go forward to the review page. Review page will show correct information that 2 HBase master are selected for installation Eventually on deploying the cluster installation  HBase Master is only created and installed on the host that was a default selection on Assign Master page,1.6.1,1.7.0,68,0,0,0,0,0,0,0,
6787,ambari-web,Xi Wang,Cleanup of Cluster > Admin tab,1. Remove 'Users' and 'Access' category from 'Admin' tab on the main menu.2. Rename 'Clusters' --&gt; 'Repositories'3. Rename 'misc' --&gt; 'Service Accounts',1.7.0,1.7.0,22,1,0,0,0,0,0,0,
6788,ambari-web,Aleksandr Kovalenko,Ambari installation webhcat templeton.hive.properties set thrift host name to be localhost,PROBLEM:default installation of Ambari sets webhcat-site.xmltempleton.hive.properties=hive.metastore.local=false  hive.metastore.uris=thrift://localhost:9933  hive.metastore.sasl.enabled=falsethe proper value should be the FQDN of the thrift host name  plus hive.metastore.execute.setugi=truefor example:hive.metastore.local=false  hive.metastore.uris=thrift://this.fqdn.com:9933  hive.metastore.sasl.enabled=false hive.metastore.execute.setugi=true,1.6.0,1.7.0,24,0,0,0,0,0,0,0,
6793,ambari-web,Aleksandr Kovalenko,Need ResourceManager UI Quicklinks for active / standby,Similar to NN HA.,1.7.0,1.7.0,4,0,0,0,0,0,0,0,
