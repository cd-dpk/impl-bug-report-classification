issue_id,reporter,component,keywords,pre_sum,summary,pre_des,description,des-1,des-2,des-3,des-4,des-5,files,Surprising
92,Eric Yang,ambari-agent,0,Agent should retry heartbeat message  if controller did not receive the heartbeat, agent retri heartbeat messag control not receiv heartbeat,If the heartbeat was not received correctly by the controller  then it should retry., heartbeat not receiv correctli control retri retri,0,0,0,0,0,0,0 
192,Ramya Sunil,null,0,Check for NN safemode during restarts, check NN safemod restart,There is no checks for safemode when we reconfigure the cluster., no check safemod reconfigur cluster cluster,0,0,0,0,0,CHANGES.txt;hmc/puppet/modules/hdp-hadoop/manifests/hdfs/service_check.pp;,1 
198,Jitendra Nath Pandey,ambari-server,0,Dependency of templeton on hcat client, depend templeton hcat client,hcat client should be installed at the templeton server node., hcat client instal templeton server node node,0,0,0,0,0,CHANGES.txt;hmc/php/puppet/genmanifest/PuppetClassDependencies.php;,1 
199,Jitendra Nath Pandey,ambari-server,0,Remove import of mysql puppet module from manifest., remov import mysql puppet modul manifest manifest,Remove import of mysql puppet module from manifest because this module is deprecated., remov import mysql puppet modul manifest modul deprec deprec,0,0,0,0,0,CHANGES.txt;hmc/php/puppet/genmanifest/generateManifest.php;,1 
202,Ramya Sunil,null,0,Add check to verify jdk path after install, add check verifi jdk path instal,After the jdk install  we do not validate the path. This causes problems during service start in later stages., jdk instal not valid path path caus problem servic start later stage stage,0,0,0,0,0,CHANGES.txt;hmc/puppet/modules/hdp/manifests/java/package.pp;,1 
207,Jitendra Nath Pandey,ambari-server,0,PHP Notice: Undefined variable: manifest in /usr/share/hmc/php/puppet/genmanifest/hostsConfig.php, PHP notic notic undefin variabl variabl manifest usr share hmc php puppet genmanifest hostsConfig php usr share hmc php puppet genmanifest host config php,Undefined variable used., undefin variabl use use,0,0,0,0,0,0,1 
208,Hitesh Shah,null,0,Support filtering hosts based on discovery status, support filter host base discoveri statu,Api to get hosts should allow filtering out bad hosts, api get host allow filter bad host,0,0,0,0,0,0,0 
217,vitthal (Suhas) Gogate,null,0,Alert table on the right needs to be tied visually/verbally to the context/content it is displaying, alert tabl right need tie visual verbal visual verbal context content context content display,Currently in Dashboard when service entry is clicked  right side alerts table caption does not indicate that it is showing alerts related to that service. So Cpation of the table should change indicating the corresponding service name., current dashboard servic entri click right side alert tabl caption not indic show alert relat servic servic cpation tabl chang indic correspond servic name name,0,0,0,0,0,0,1 
222,vitthal (Suhas) Gogate,null,0,Remove the word alert from all the Nagios alerts descriptions., remov word alert nagio alert descript descript,IT is sort of redundant.., sort redund redund,0,0,0,0,0,0,1 
226,Suresh Srinivas,null,0,Make the daemon names and other field names consistent, make daemon name field name consist,Following names need to be consistent: Hdfs -&gt; HDFS Mapreduce -&gt; MapReduce Zookeeper -&gt; ZooKeeper HADOOP -&gt; Hadoop, follow name need consist consist hdf gt gt HDFS mapreduc gt gt MapReduce map reduc zookeep gt gt ZooKeeper zoo keeper HADOOP gt gt hadoop,0,0,0,0,0,0,1 
232,Vikram Dixit K,null,0,Enable LZO should show checkbox instead of text, enabl LZO show checkbox instead text,Currently the enable lzo option shows a text box that needs to be filled with true/false. Changing the UI element to checkbox., current enabl lzo option show text box need fill true fals true fals chang UI element checkbox checkbox,0,0,0,0,0,0,1 
236,Jitendra Nath Pandey,ambari-server,0,Increase puppet agent timeout., increas puppet agent timeout timeout,Puppet agent timeout should be increases as sometimes (possibly due to a bug in ruby) puppet master takes long time to compile and send back the catalog., puppet agent timeout increas sometim possibl due bug rubi rubi puppet master take long time compil send back catalog catalog,0,0,0,0,0,0,0 
237,Jitendra Nath Pandey,ambari-server,0,Refactor puppet kick loop to easily change retries and timeouts., refactor puppet kick loop easili chang retri timeout timeout,Refactor puppet kick loop to easily change retries and timeouts., refactor puppet kick loop easili chang retri timeout timeout,0,0,0,0,0,0,0 
245,Jitendra Nath Pandey,ambari-server,0,Support data cleanup if installation fails., support data cleanup instal fail fail,We need to support data cleanup so that a cluster can be re-installed in case of failures., need support data cleanup cluster instal instal case failur failur,0,0,0,0,0,0,0 
247,Varun Kapoor,null,0,Replace index.php with clusters.php, replac index php index php cluster php cluster php,Like the title says: overwrite index.php with the contents of clusters.php  making sure to add a link to the AddNodesWizard as well., like titl say say overwrit index php index php content cluster php cluster php make sure add link AddNodesWizard add node wizard well well,0,0,0,0,0,0,0 
249,Vikram Dixit K,null,0,Uninstall support from UI, uninstal support UI,Uninstall/wipeout support from UI., uninstal wipeout uninstal wipeout support UI UI,0,0,0,0,0,0,0 
252,Varun Kapoor,null,0,Remove 'Playground' files from HMC, remov playground playground file HMC,There's a bunch of (temporary playground) files that got wrongly committed to the HMC codebase  so this is to remove all of them and get things into a cleaner state (at least on the face of things)., bunch temporari playground playground file got wrongli commit HMC codebas remov get thing cleaner state least face thing thing,0,0,0,0,0,0,0 
253,Ramya Sunil,null,0,Support uninstall state in mysql modules, support uninstal state mysql modul,Currently  there is no support for uninstall of mysql package., current no support uninstal mysql packag packag,0,0,0,0,0,0,0 
255,Varun Kapoor,null,0,Rename/Relocate files as appropriate, renam reloc renam reloc file appropri,There's some images in the html/ directory (that should be in images/)  there's .html files whose extension should be changed to .htmli  and such  that would be nice to clean up., imag html html directori imag imag html file whose extens chang htmli would nice clean,0,0,0,0,0,0,0 
256,Ramya Sunil,null,0,Update hive config to enable authorization, updat hive config enabl author,In /etc/hive/conf/hive-site.xml&lt;property&gt; &lt;name&gt;hive.security.authorization.enabled&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;description&gt;enable or disable the hive client authorization&lt;/description&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;hive.security.authorization.manager&lt;/name&gt; &lt;value&gt;org.apache.hcatalog.security.HdfsAuthorizationProvider&lt;/value&gt; &lt;description&gt;the hive client authorization manager class name. The user defined authorization class should implement interface org.apache.hadoop.hive.ql.security.authorization.HiveAuthorizationProvider. &lt;/description&gt;&lt;/property&gt;In /etc/hive/conf/hive-env.sh  add -export HIVE_AUX_JARS_PATH=/usr/lib/hcatalog/share/hcatalog/hcatalog-0.4.0.jar, etc hive conf hive site xml lt properti gt etc hive conf hive site xml lt properti gt lt name gt hive secur author enabl lt name gt lt name gt hive secur author enabl lt name gt lt valu gt true lt valu gt lt valu gt true lt valu gt lt descript gt enabl lt descript gt enabl disabl hive client author lt descript gt lt properti gt lt properti gt author lt descript gt lt properti gt lt properti gt lt name gt hive secur author manag lt name gt lt name gt hive secur author manag lt name gt lt valu gt org apach hcatalog secur HdfsAuthorizationProvider lt valu gt lt valu gt org apach hcatalog secur hdf author provid lt valu gt lt descript gt lt descript gt hive client author manag class name name user defin author class implement interfac org apach hadoop hive ql secur author HiveAuthorizationProvider org apach hadoop hive ql secur author hive author provid lt descript gt lt properti gt lt descript gt lt properti gt etc hive conf hive env sh etc hive conf hive env sh add export HIVE_AUX_JARS_PATH usr lib hcatalog share hcatalog hcatalog jar HIVE AUX JARS PATH usr lib hcatalog share hcatalog hcatalog jar,0,0,0,0,0,0,0 
257,Arpit Gupta,site,0,Manage services section will have any empty section when no client only components installed, manag servic section empti section no client compon instal,On the manage services page we have a section for client only services that have no long running processes.If the user has no such component there is a heading but no content. Maybe we can hide the heading when no such service is present., manag servic page section client servic no long run process process user no compon head no content content mayb hide head no servic present present,0,0,0,0,0,0,0 
262,Arpit Gupta,site,0,Init Wizard: Advanced Config validation errors can be bypassed, init wizard wizard advanc config valid error bypass,Make the Naigos password (and re-type password) different so as you cause a validation error.This will let the user move on to the next screen by ignoring all other validation errors on this page., make naigo password type type password password differ caus valid error error let user move next screen ignor valid error page page,0,0,0,0,0,0,0 
264,Arpit Gupta,site,0,Nagios Admin Contact should be checked to ensure it is always an email address, nagio admin contact check ensur alway email address,,,0,0,0,0,0,0,0 
274,Ramya Sunil,null,0,Templeton data on hdfs needs to be readable by all users, templeton data hdf need readabl user,Content of /user/templeton dir-bash-3.2$ hadoop dfs -ls /user/templetonFound 4 items-rw-r--r-- 3 templeton hdfs 107373 2012-05-14 19:53 /user/templeton/hadoop-streaming.jar-rw------- 3 templeton hdfs 35352096 2012-05-14 19:53 /user/templeton/hive.tar.gz-rw------- 3 templeton hdfs 47909478 2012-05-14 19:53 /user/templeton/pig.tar.gz-rw------- 3 templeton hdfs 127652 2012-05-14 19:53 /user/templeton/ugi.jarOnly templeton user can use the jars, content user templeton user templeton dir bash dir bash hadoop df ls user templetonFound user templeton found item rw item rw templeton hdf user templeton hadoop stream jar rw user templeton hadoop stream jar rw templeton hdf user templeton hive tar gz rw user templeton hive tar gz rw templeton hdf user templeton pig tar gz rw user templeton pig tar gz rw templeton hdf user templeton ugi jarOnly user templeton ugi jar templeton user use jar,0,0,0,0,0,0,0 
276,Suresh Srinivas,site,0,Update HDFS parameter configuration description, updat HDFS paramet configur descript,Updating the short description and tooltip long description as follows:Changing the text that affects WebUI as follows: filesystem -&gt; file system HDFS Append Enabled -&gt; Append enabled HDFS WebHDFS Enabled -&gt; WebHDFS enabled Hadoop maximum Java heap size -&gt; Hadoop maximum Java heap size (MB)  Java Heap Size for slave daemons -&gt; Maximum Java heap size for daemons such as Balancer in MB (-Xmx)   NameNode maximum Java heap size -&gt; NameNode initial Java heap size (MB)  Java Heap Size for NameNode -&gt; Initial and minimum Java heap size for NameNode in MB (-Xms)   Hadoop Young Generation heap size -&gt; NameNode new generation size (MB)  Maximum size for New Generation for java heap size -&gt; Default size of Java new generation in MB for NameNode (-XX:NewSize)   DataNode Java heap size -&gt; DataNode maximum Java heap size (MB)  Java Heap Size for DataNode -&gt; Maximum Java heap size for DataNode in MB (-Xmx), updat short descript tooltip long descript follow chang follow chang text affect WebUI web UI follow follow filesystem gt gt file system HDFS append enabl gt gt append enabl HDFS WebHDFS web HDFS enabl gt gt WebHDFS web HDFS enabl hadoop maximum java heap size gt gt hadoop maximum java heap size MB MB java heap size slave daemon gt gt maximum java heap size daemon balanc MB xmx xmx NameNode name node maximum java heap size gt gt NameNode name node initi java heap size MB MB java heap size NameNode name node gt gt initi minimum java heap size NameNode name node MB xm xm hadoop young gener heap size gt gt NameNode name node new gener size MB MB maximum size new gener java heap size gt gt default size java new gener MB NameNode name node XX NewSize XX new size DataNode data node java heap size gt gt DataNode data node maximum java heap size MB MB java heap size DataNode data node gt gt maximum java heap size DataNode data node MB xmx xmx,0,0,0,0,0,0,0 
280,Vikram Dixit K,null,0,Cleanup of utilities, cleanup util,We need an api for the UI to figure out the status of the cluster., need api UI figur statu cluster cluster,0,0,0,0,0,0,0 
283,Vikram Dixit K,null,0,Fixup review and deploy rendering, fixup review deploy render,Currently render of the review and deploy page is messy., current render review deploy page messi messi,0,0,0,0,0,0,0 
287,Vikram Dixit K,ambari-server; ambari-web,0,Add link to uninstall on index page, add link uninstal index page,Uninstall link is now hooked into the index page., uninstal link hook index page page,0,0,0,0,0,0,0 
290,Jitendra Nath Pandey,ambari-server,0,Comment in addNodesWizardInit.js., comment addNodesWizardInit js add node wizard init js,Comment in addNodesWizardInit.js., comment addNodesWizardInit js add node wizard init js,0,0,0,0,0,0,0 
292,Jitendra Nath Pandey,ambari-web,0,HTML being spewed in the Review+Deploy page., HTML spew review deploy review deploy page page,HTML being spewed in the Review+Deploy page., HTML spew review deploy review deploy page page,0,0,0,0,0,0,0 
300,Yusaku Sako,null,0,Change the status message (success/error) location so that it shows below the page summary box  rather than above  more better visibility, chang statu messag success error success error locat show page summari box rather better visibl,,,0,0,0,0,0,0,0 
302,Ramya Sunil,null,0,regionservers config in the hbase only has localhost in it, regionserv config hbase localhost,/etc/hbase/conf/regionserver should correctly populate the slaves list, etc hbase conf regionserv etc hbase conf regionserv correctli popul slave list,0,0,0,0,0,0,0 
304,Vinod Kumar Vavilapalli,null,0,Upgrade to yui-3.5.1, upgrad yui yui,,,0,0,0,0,0,0,0 
310,Yusaku Sako,null,0,Externalize message resources for the welcome page.  Update styles on various pages., extern messag resourc welcom page page updat style variou page page,,,0,0,0,0,0,0,0 
312,Hitesh Shah,null,0,Uninstall's wipe flag should be correctly passed to puppet, uninstal uninstal wipe flag correctli pass puppet,,,0,0,0,0,0,0,0 
316,Vinod Kumar Vavilapalli,null,0,Grid mount points page doesn't let one pass with only a custom mount point, grid mount point page let one pass custom mount point,,,0,0,0,0,0,0,0 
319,Jitendra Nath Pandey,ambari-server,0,Scale puppet master to large number of nodes., scale puppet master larg number node node,Scale puppet master to large number of nodes., scale puppet master larg number node node,0,0,0,0,0,0,0 
323,Vikram Dixit K,ambari-server,0,During any process in the cluster initialization wizard  if the user goes back to the '1 Create Cluster' tab  the user is stuck., process cluster initi wizard user goe back creat cluster cluster tab user stuck stuck,,,0,0,0,0,0,0,0 
326,Jitendra Nath Pandey,ambari-server,0,Dependencies should be added only during install phase, depend ad instal phase,Host level dependencies are being set in running stage as well  which is redundant. It can be assumed that dependencies were installed at install stage., host level depend set run stage well redund redund assum depend instal instal stage stage,0,0,0,0,0,0,0 
330,Vinod Kumar Vavilapalli,null,0,Provide a way to resume if browser crashes/is closed during the deploy-in-progress, provid way resum browser crash crash close deploy progress deploy progress,Currently when the browser is closed one cannot view the install in progress. They will have to look at the logs on the hmc machine to figure out whats going on. It would be nice if we can provide a way to get back to the install progress., current browser close one cannot view instal progress progress look log hmc machin figur what go would nice provid way get back instal progress progress,0,0,0,0,0,0,0 
335,Ramya Sunil,null,0,Redundant downloads even though the artifacts are already installed, redund download even though artifact alreadi instal,Artifacts (such as mysql-connector.zip  hive.tar.gz  pig.tar.gz  ext.zip) are being downloaded even though they are previously installed leading to additional execution time., artifact mysql connector zip mysql connector zip hive tar gz hive tar gz pig tar gz pig tar gz ext zip ext zip download even though previous instal lead addit execut time time,0,0,0,0,0,0,0 
338,Vikram Dixit K,ambari-server,0,Cluster status update needs to happen for all stages of installation wizard., cluster statu updat need happen stage instal wizard wizard,Cluster status should be updated in db for each stage of the installation wizard. This is used to enable restart of browser and also showing status of the cluster on the index page., cluster statu updat db stage instal wizard wizard use enabl restart browser also show statu cluster index page page,0,0,0,0,0,0,0 
339,Vikram Dixit K,ambari-web,0,Making transitionToNextStage more robust, make transitionToNextStage transit next stage robust,If the currentStage is null  we should not proceed with a transition., currentStage current stage null not proceed transit transit,0,0,0,0,0,0,0 
349,Vikram Dixit K,ambari-server; ambari-web,0,Logging in case of error during uninstall needs to be fixed., log case error uninstal need fix fix,Logs disappear post uninstall because the transaction is also cleaned from the db., log disappear post uninstal transact also clean db db,0,0,0,0,0,0,0 
352,Yusaku Sako,null,0,Add flow control - force redirects to appropriate pages based on cluster configuration status for better usability, add flow control forc redirect appropri page base cluster configur statu better usabl,If no cluster has been set up yet  redirect to the welcome page.If a cluster is being configured (but has not gone thru deployment)  redirect to Step 1 of the cluster init wizard.If a cluster is being deployed  redirect to the deployment progress page.If a cluster has gone thru deployment but failed  redirect to the re-install page.If a cluster has gone thru deployment and succeed  do not perform any forced redirect., no cluster set yet redirect welcom page page cluster configur not gone thru deploy deploy redirect step cluster init wizard wizard cluster deploy redirect deploy progress page page cluster gone thru deploy fail redirect instal instal page page cluster gone thru deploy succeed not perform forc redirect redirect,0,0,0,0,0,0,0 
357,Yusaku Sako,null,0,Redesign master service assignment page so that it takes up less vertical space, redesign master servic assign page take less vertic space,,,0,0,0,0,0,0,0 
362,Vikram Dixit K,ambari-server,0,Create lock file as part of rpm install, creat lock file part rpm instal,Lock file is being created as part of create cluster. This is brittle and needs to be done as part of the rpm install., lock file creat part creat cluster cluster brittl need done part rpm instal instal,0,0,0,0,0,0,0 
366,Varun Kapoor,null,0,Package up the fonts/ subdirectory in the HMC RPM, packag font font subdirectori HMC RPM,The new fonts/ subdirectory used for the buttons on the ManageServices page isn't packaged up., new font font subdirectori use button ManageServices manag servic page packag,0,0,0,0,0,0,0 
369,Yusaku Sako,null,0,Improve Service Management page and general popup styling, improv servic manag page gener popup style,,,0,0,0,0,0,0,0 
371,Jitendra Nath Pandey,ambari-server,0,Mysql packages not being sent during install and uninstall, mysql packag not sent instal uninstal,Mysql packages not being sent during install and uninstall., mysql packag not sent instal uninstal uninstal,0,0,0,0,0,0,0 
377,Jitendra Nath Pandey,ambari-server,0,Uninstall does not handle component dependencies., uninstal not handl compon depend depend,Uninstall does not handle component dependencies., uninstal not handl compon depend depend,0,0,0,0,0,0,0 
386,Hitesh Shah,null,0,On Single Node install when install all the components the recommended num for Map/Reduce Tasks is too high, singl node instal instal compon recommend num map reduc map reduc task high,Use lower count of maps/reduce slots for a single node install., use lower count map reduc map reduc slot singl node instal instal,0,0,0,0,0,0,0 
393,Mahadev konar,null,0,ZooKeeper myid files not existent on ZK install., ZooKeeper zoo keeper myid file not exist ZK instal instal,ZooKeeper myid files not existent on ZK install., ZooKeeper zoo keeper myid file not exist ZK instal instal,0,0,0,0,0,0,0 
394,Vikram Dixit K,ambari-server,0,Add nodes fails to find node in db, add node fail find node db,Host not found in db error on assign nodes page, host not found db error assign node page,0,0,0,0,0,0,0 
399,Yusaku Sako,null,0,Cannot uninstall - the page hangs with the spinning icon, cannot uninstal page hang spin icon,,,0,0,0,0,0,0,0 
401,Jitendra Nath Pandey,ambari-server,0,Manual config changes for nn get reset on stop/start from hmc, manual config chang nn get reset stop start stop start hmc,Manual config changes for nn get reset on stop/start from hmc, manual config chang nn get reset stop start stop start hmc,0,0,0,0,0,0,0 
402,Vikram Dixit K,ambari-server,0,Completing successful add node takes one to initialize cluster page starting from scratch, complet success add node take one initi cluster page start scratch,,,0,0,0,0,0,0,0 
404,Yusaku Sako,null,0,Unify the top nav for both Monitoring and Cluster Management, unifi top nav monitor cluster manag,,,0,0,0,0,0,0,0 
414,Mahadev konar,null,0,Add rpm spec for hmc agent., add rpm spec hmc agent agent,Add rpm spec for hmc agent., add rpm spec hmc agent agent,0,0,0,0,0,0,0 
415,Hitesh Shah,null,0,Reset service back to original state after reconfiguration, reset servic back origin state reconfigur,,,0,0,0,0,0,0,0 
420,Yusaku Sako,null,0,Improve style on error log popups, improv style error log popup,,,0,0,0,0,0,0,0 
426,Ramya Sunil,null,0,Reinstall of cluster after failure to install results in failure, reinstal cluster failur instal result failur,According to Bikas:I tried to install a single node cluster. That failed for some random issue.I was presented an option to reinstall.I clicked on that option and it asked me to uninstall.I chose uninstall and wipe data option.Uninstall failed.This happened because the install did not complete in the first place.Thu May 24 17:45:28 -0400 2012 /Stage17/Hdp-oozie::Service/Hdp-oozie::Service::Createsymlinks/usr/lib/oozie/oozie-server/lib/mapred-site.xml/File/usr/lib/oozie/oozie-server/lib/mapred-site.xml/ensure (err): change from absent to present failed: Could not set 'present on ensure: No such file or directory - /usr/lib/oozie/oozie-server/lib/mapred-site.xml at /etc/puppet/agent/modules/hdp-oozie/manifests/service.pp:61, accord bika bika tri instal singl node cluster cluster fail random issu issu present option reinstal reinstal click option ask uninstal uninstal chose uninstal wipe data option uninstal option uninstal fail fail happen instal not complet first place thu place thu may stage hdp oozi servic hdp oozi servic createsymlink usr lib oozi oozi server lib mapr site xml file usr lib oozi oozi server lib mapr site xml ensur stage hdp oozi servic hdp oozi servic createsymlink usr lib oozi oozi server lib mapr site xml file usr lib oozi oozi server lib mapr site xml ensur err err chang absent present fail fail could not set present ensur ensur No file directori usr lib oozi oozi server lib mapr site xml usr lib oozi oozi server lib mapr site xml etc puppet agent modul hdp oozi manifest servic pp etc puppet agent modul hdp oozi manifest servic pp,0,0,0,0,0,0,0 
429,Mahadev konar,null,0,Fix bug with jmx parsing on HBase., fix bug jmx pars HBase base,Fix bug with jmx parsing on HBase., fix bug jmx pars HBase base,0,0,0,0,0,0,0 
433,Vikram Dixit K,ambari-server,0,Using service stop instead of killall for uninstall, use servic stop instead killal uninstal,,,0,0,0,0,0,0,0 
435,Vikram Dixit K,ambari-server,0,Uninstall needs to update status for failure., uninstal need updat statu failur failur,This is to enable the routing layer to redirect appropriately., enabl rout layer redirect appropri appropri,0,0,0,0,0,0,0 
442,Ramya Sunil,null,0,Duplicate definition: Class[Hdp-hbase::Regionserver::Enable-ganglia], duplic definit definit class hdp hbase regionserv enabl ganglia class hdp hbase regionserv enabl ganglia,Duplicate definition: Class&#91;Hdp-hbase::Regionserver::Enable-ganglia&#93; is already defined; cannot redefine at /etc/puppet/agent/modules/hdp-ganglia/manifests/monitor.pp:37 on node ip-10-64-19-248.ec2.internal, duplic definit definit class hdp hbase regionserv enabl ganglia class hdp hbase regionserv enabl ganglia alreadi defin defin cannot redefin etc puppet agent modul hdp ganglia manifest monitor pp etc puppet agent modul hdp ganglia manifest monitor pp node ip ec intern ip ec intern,0,0,0,0,0,0,0 
449,Yusaku Sako,null,0,Post cluster install/deploy the URL hmc/html/initializeCluster.php should be disabled, post cluster instal deploy instal deploy URL hmc html initializeCluster php hmc html initi cluster php disabl,Install a cluster. Then go to http://&lt;host&gt;/hmc/html/initializeCluster.php URL. You get a page enter cluster name. If you enter a cluster name  existing install is wiped out. We need to disable this URL on an installed cluster.Only way to enable this should be uninstall., instal cluster cluster go URL URL get page enter cluster name name enter cluster name exist instal wipe need disabl URL instal cluster cluster way enabl uninstal uninstal,0,0,0,0,0,0,0 
455,vitthal (Suhas) Gogate,null,0,nagios shows service status critical if hbase is not installed, nagio show servic statu critic hbase not instal,,,0,0,0,0,0,0,0 
466,Vikram Dixit K,ambari-server; ambari-web,0,Add nodes page alerts removed in case of adding duplicate nodes, add node page alert remov case ad duplic node,Alerts that are being shown needs to be changed to be compatible with current implementation of showing errors. A link now appears to 'Show the duplicate nodes' which shows the duplicate nodes., alert shown need chang compat current implement show error error link appear show show duplic node node show duplic node node,0,0,0,0,0,0,0 
467,Mahadev konar,null,0,Fix hive stop to escape $., fix hive stop escap,,,0,0,0,0,0,0,0 
468,Yusaku Sako,null,0,Post-Install Add Nodes - update progress title and success/error messages to reflect what it's actually doing/has done, post instal post instal add node updat progress titl success error success error messag reflect actual done,,,0,0,0,0,0,0,0 
475,Yusaku Sako,null,0,Add missing JS file for making post cluster install Add Nodes work, add miss JS file make post cluster instal add node work,,,0,0,0,0,0,0,0 
482,Yusaku Sako,null,0,Show the same welcome page to the user if the user starts configuring a cluster but has not started deploy yet, show welcom page user user start configur cluster not start deploy yet,,,0,0,0,0,0,0,0 
486,Yusaku Sako,null,0,Add Node installs MySQL Server for Hive, add node instal MySQL SQL server hive,Adding slave nodes post cluster install will install MySQL Server if Hive was selected as a service at the time of cluster installation., ad slave node post cluster instal instal MySQL SQL server hive select servic time cluster instal instal,0,0,0,0,0,0,0 
488,Yusaku Sako,null,0,Manage service needs a way to recover from terminated browser sessions, manag servic need way recov termin browser session,We need to block users from being able to start/stop services when we have a batch of start/stop activities are already in progress.Do something similar to deployment progress display and bring the user back to that modal status display which will end when we detect success/failure., need block user abl start stop start stop servic batch start stop start stop activ alreadi progress progress someth similar deploy progress display bring user back modal statu display end detect success failur success failur,0,0,0,0,0,0,0 
491,Yusaku Sako,null,0,Service Reconfiguration screens should respect the 'reconfigurable' attributes set in ConfigProperties table, servic reconfigur screen respect reconfigur reconfigur attribut set ConfigProperties config properti tabl,Some service config parameters are editable (can be customized on initial install)  but cannot be reconfigured post cluster install.This info is stored in ConfigProperties table  but the Service Reconfiguration screens are allowing these non-reconfigurable parameters to be changed., servic config paramet edit custom initi instal instal cannot reconfigur post cluster instal instal info store ConfigProperties config properti tabl servic reconfigur screen allow non reconfigur non reconfigur paramet chang chang,0,0,0,0,0,0,0 
492,Hitesh Shah,null,0,make support for os check a bit more robust, make support os check bit robust,,,0,0,0,0,0,0,0 
493,Hitesh Shah,null,0,Add rack_info as column in Hosts table, add rack_info column host tabl,,,0,0,0,0,0,0,0 
494,Mahadev konar,null,0,Fix node assignments not not allow slaves on master., fix node assign not not allow slave master master,,,0,0,0,0,0,0,0 
508,Varun Kapoor,null,0,Support Resume For Add Nodes, support resum add node,Just like for Manage Services + Deploy + Uninstall., like manag servic deploy uninstal uninstal,0,0,0,0,0,0,0 
510,Yusaku Sako,null,0,Modify the router to force redirection to 'Add Nodes Progress' popup, modifi router forc redirect add add node progress progress popup,,,0,0,0,0,0,0,0 
512,Mahadev konar,null,0,Fix puppet manifests for tarball downloads via rpms., fix puppet manifest tarbal download via rpm rpm,,,0,0,0,0,0,0,0 
519,Vikram Dixit K,ambari-server,0,update to fix the ganglia monitor_and_server anchor problem, updat fix ganglia monitor_and_server anchor problem,update to fix the ganglia monitor_and_server anchor problem, updat fix ganglia monitor_and_server anchor problem,0,0,0,0,0,0,0 
528,Ramya Sunil,null,0,Fix oozie smoke test failure, fix oozi smoke test failur,Oozie smoke test failing with 'Error: E0301 : E0301: Invalid resource &#91;usr/lib/oozie/conf&#93;', oozi smoke test fail error error invalid resourc usr lib oozi conf usr lib oozi conf,0,0,0,0,0,0,0 
529,Hitesh Shah,null,0,Fix Advanced Config: HDFS reserved space is in bytes. Too many bytes to count., fix advanc config config HDFS reserv space byte byte mani byte count count,Simplify user input., simplifi user input input,0,0,0,0,0,0,0 
539,Hitesh Shah,null,0,Create a spec file with less dependencies for HMC, creat spec file less depend HMC,Simplify process for users that want to use different dependencies for PHP and Ruby.e.g PHP-5.3  ruby-1.8.7, simplifi process user want use differ depend PHP rubi rubi PHP PHP rubi rubi,0,0,0,0,0,0,0 
543,Vikram Dixit K,infra,0,Rpm naming needs to be corrected., rpm name need correct correct,Rpm naming needs to be corrected., rpm name need correct correct,0,0,0,0,0,0,0 
544,Ramya Sunil,null,0,Templeton configs for pig archive not correct in HMC, templeton config pig archiv not correct HMC,From Arpit:The configs for pig in templeton are wrong.The deployed configs are&lt;property&gt; &lt;name&gt;templeton.pig.archive&lt;/name&gt; &lt;value&gt;hdfs:///apps/templeton/&lt;/value&gt; &lt;description&gt;The path to the Pig archive.&lt;/description&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;templeton.pig.path&lt;/name&gt; &lt;value&gt;/pig-0.9.2/bin/pig&lt;/value&gt; &lt;description&gt;The path to the Pig executable.&lt;/description&gt; &lt;/property&gt;They are missing the pig tar ball. For example they should be&lt;property&gt; &lt;name&gt;templeton.pig.archive&lt;/name&gt; &lt;value&gt;hdfs:///apps/templeton/pig.tar.gz&lt;/value&gt; &lt;description&gt;The path to the Pig archive.&lt;/description&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;templeton.pig.path&lt;/name&gt; &lt;value&gt;pig.tar.gz/pig-0.9.2/bin/pig&lt;/value&gt; &lt;description&gt;The path to the Pig executable.&lt;/description&gt; &lt;/property&gt;So both the properties are missing 'pig-0.9.2.tar.gz', arpit arpit config pig templeton wrong wrong deploy config lt properti gt lt properti gt lt name gt templeton pig archiv lt name gt lt name gt templeton pig archiv lt name gt lt valu gt hdf app templeton lt valu gt lt valu gt hdf app templeton lt valu gt lt descript gt lt descript gt path pig archiv lt descript gt archiv lt descript gt lt properti gt lt properti gt lt properti gt lt properti gt lt name gt templeton pig path lt name gt lt name gt templeton pig path lt name gt lt valu gt pig bin pig lt valu gt lt valu gt pig bin pig lt valu gt lt descript gt lt descript gt path pig execut lt descript gt execut lt descript gt lt properti gt lt properti gt miss pig tar ball ball exampl lt properti gt lt properti gt lt name gt templeton pig archiv lt name gt lt name gt templeton pig archiv lt name gt lt valu gt hdf app templeton pig tar gz lt valu gt lt valu gt hdf app templeton pig tar gz lt valu gt lt descript gt lt descript gt path pig archiv lt descript gt archiv lt descript gt lt properti gt lt properti gt lt properti gt lt properti gt lt name gt templeton pig path lt name gt lt name gt templeton pig path lt name gt lt valu gt pig tar gz pig bin pig lt valu gt lt valu gt pig tar gz pig bin pig lt valu gt lt descript gt lt descript gt path pig execut lt descript gt execut lt descript gt lt properti gt lt properti gt properti miss pig tar gz pig tar gz,0,0,0,0,0,0,0 
546,Hitesh Shah,null,0,Puppet fails to install 32-bit JDK properly on RHEL6, puppet fail instal bit JDK properli RHEL RHEL,mkdir -p /usr/jdk32 ; chmod +x /tmp/HDP-artifacts//jdk-6u31-linux-i586.bin; cd /usr/jdk32 ; echo A | /tmp/HDP-artifacts//jdk-6u31-linux-i586.bin -noregister 2&gt;&amp;1Unpacking...Checksumming...Extracting.../var/www/html/downloads/jdk-6u31-linux-i586.bin: ./install.sfx.1794: /lib/ld-linux.so.2: bad ELF interpreter: No such file or directoryFailed to extract the files. Please refer to the Troubleshooting section ofthe Installation Instructions on the download page for more information.Puppet should ensure glibc.i686 is installed before trying to install jdk., mkdir usr jdk usr jdk chmod tmp HDP artifact jdk linux bin tmp HDP artifact jdk linux bin cd usr jdk usr jdk echo tmp HDP artifact jdk linux bin tmp HDP artifact jdk linux bin noregist gt amp unpack checksum extract var www html download jdk linux bin gt amp unpack checksum extract var www html download jdk linux bin instal sfx instal sfx lib ld linux lib ld linux bad ELF interpret interpret No file directoryFailed directori fail extract file file pleas refer troubleshoot section ofth instal instruct download page inform puppet inform puppet ensur glibc glibc instal tri instal jdk jdk,0,0,0,0,0,0,0 
547,Hitesh Shah,null,0,Change os type check during node bootstrap to allow RHEL6 or CentOS6 nodes, chang os type check node bootstrap allow RHEL RHEL CentOS cent OS node,hmc/php/frontend/addNodes/verifyAndUpdateNodesInfo.php hardcodes checks to only allow rhel5 or centos5 nodes., hmc php frontend addNodes verifyAndUpdateNodesInfo php hmc php frontend add node verifi updat node info php hardcod check allow rhel rhel cento cento node node,0,0,0,0,0,0,0 
548,Hitesh Shah,null,0,Puppet agent install script should use correct epel repo, puppet agent instal script use correct epel repo,hmc/ShellScripts/puppet_agent_install.sh hardcodes to epel-release rpm for CentOS-5.4. Should be more intelligent to handle different OS types., hmc ShellScripts puppet_agent_install sh hmc shell script puppet_agent_install sh hardcod epel releas epel releas rpm CentOS cent OS intellig handl differ OS type type,0,0,0,0,0,0,0 
552,Vinod Kumar Vavilapalli,null,0,Update README to point to trunk, updat README point trunk,We need to fix the README to point to trunk after the merge of ambari-186 branch., need fix README point trunk merg ambari ambari branch branch,0,0,0,0,0,0,0 
565,Yusaku Sako,null,0,Remove YUI source files from SVN, remov YUI sourc file SVN,Currently YUI 3.5.1 source files are in SVN.We don't really need to have them checked into SVN as we don't track changes. We are pre-concatenating and minifying the YUI js files  so we don't need the files to run Ambari anyhow.We should just remove them from SVN and instead just checkin the tarball., current YUI sourc file SVN SVN realli need check SVN track chang chang pre concaten pre concaten minifi YUI js file need file run ambari anyhow anyhow remov SVN instead checkin tarbal tarbal,0,0,0,0,0,0,0 
566,Yusaku Sako,null,0,Update documentation, updat document,Modify pom.xml to create output files under ../site  rather than ./target.Make minor wording modifications., modifi pom xml pom xml creat output file site rather target make target make minor word modif modif,0,0,0,0,0,0,0 
569,Hitesh Shah,null,0,Nagios install fails on RHEL6, nagio instal fail RHEL RHEL,Puppet layer  when trying to install nagios  tries to install php-pecl-json when it is not needed and fails when trying to do so. On RHEL6  php-5.3 is default which has the json module built into it., puppet layer tri instal nagio tri instal php pecl json php pecl json not need fail tri RHEL RHEL php php default json modul built,0,0,0,0,0,0,0 
570,Yusaku Sako,null,0,Consolidate head tags for organization and combine CSS files for faster load, consolid head tag organ combin CSS file faster load,,,0,0,0,0,0,0,0 
573,Hitesh Shah,null,0,Puppet error: Cannot reassign variable zookeeper_hosts at modules/hdp/manifests/params.pp:47, puppet error error cannot reassign variabl zookeeper_hosts modul hdp manifest param pp modul hdp manifest param pp,Seems like a typo: $zookeeper_hosts = hdp_default('zookeeper_hosts')Should be $public_zookeeper_hosts, seem like typo typo zookeeper_hosts hdp_default zookeeper_hosts hdp_default zookeeper_hosts public_zookeeper_hosts,0,0,0,0,0,0,0 
576,Jaimin D Jetly,null,0,In Custom config for Nagios: emails with multiple periods before the '@' fails validation, custom config nagio nagio email multipl period fail valid,,,0,0,0,0,0,0,0 
578,Yusaku Sako,null,0,Custom Config page: don't allow form submission if there are client-side validation errors, custom config page page allow form submiss client side client side valid error,Currently the button looks disabled when there are client-side validation errors  but it is clickable. This is a problem because there is no server-side validation to make sure that the passwords match., current button look disabl client side client side valid error clickabl clickabl problem no server side server side valid make sure password match match,0,0,0,0,0,0,0 
581,Jaimin D Jetly,null,0,special characters in hosts files created on some common windows editors causes issues, special charact host file creat common window editor caus issu,,,0,0,0,0,0,0,0 
587,Vikram Dixit K,ambari-agent; ambari-server; ambari-web; documentation; infra; site; test,0,Rat compliance patch, rat complianc patch,Adding apache license to all the files within Ambari for rat tool compliance., ad apach licens file within ambari rat tool complianc complianc,0,0,0,0,0,0,0 
588,Yusaku Sako,null,0,Externalize the manager service name and point the Help link to a valid URL, extern manag servic name point help link valid URL,The master role assignment page (Step 5 of install) and the cluster topology summary page are referencing the manager service name as 'HMC Server'. This needs to be changed to 'Ambari' server.The post-install success message on a single-node install has the same issue.Currently  the Help link in the top nav launches a new tab and loads the page that the user is on. Instead  load the Help page on Ambari project website (for now  we'll point it to the Install Guide as a placeholder)., master role assign page step step instal instal cluster topolog summari page referenc manag servic name HMC HMC server server need chang ambari ambari server server post instal post instal success messag singl node singl node instal issu current issu current help link top nav launch new tab load page user instead load help page ambari project websit point instal guid placehold placehold,0,0,0,0,0,0,0 
591,Yusaku Sako,null,0,License header for PHP files should use PHP comments  not HTML comments, licens header PHP file use PHP comment not HTML comment,Some PHP files have the HTML-style comments. This is problematic sincethe license headers are becoming part of the HTML response. Worse yet  the headers are repeated multiple times in the response. This can also cause unexpected behavior., PHP file HTML style HTML style comment comment problemat sinceth licens header becom part HTML respons respons wors yet header repeat multipl time respons respons also caus unexpect behavior behavior,0,0,0,0,0,0,0 
592,Vinod Kumar Vavilapalli,null,0,Add a link to NOTICE file on every page, add link NOTICE file everi page,This is so that stuff with different compatible licenses can be attributed appropriately., stuff differ compat licens attribut appropri appropri,0,0,0,0,0,0,0 
597,Mahadev konar,null,0,Remove /usr/bin/php dependency from the rpm's, remov usr bin php usr bin php depend rpm rpm,,,0,0,0,0,0,0,0 
600,Hitesh Shah,null,0,Fix lzo installs to work correctly on RHEL6, fix lzo instal work correctli RHEL RHEL,,,0,0,0,0,0,0,0 
607,Hitesh Shah,null,0,Increase puppet timeouts to handle single-node installs timing out, increas puppet timeout handl singl node singl node instal time,,,0,0,0,0,0,0,0 
614,Yusaku Sako,null,0,The database set up script has a duplicate definition of AmbariConfig so install fails, databas set script duplic definit AmbariConfig ambari config instal fail,,,0,0,0,0,0,0,0 
615,Yusaku Sako,null,0,Eliminate redundant and unused definition for the columns in the table ConfigProperties, elimin redund unus definit column tabl ConfigProperties config properti,ConfigProperties table has a column named 'display_type'.There's also a JSON-encoded 'display_attributes' column.The 'display_attributes' column has the attributes 'isPassword'  'displayType'  and 'noDisplay'. This is duplicate information is already stored by the 'display_type' column so these attributes are not needed.Upon inspecting the code  these attributes are not used so changing them have no effect. We should simply get rid of these attributes., ConfigProperties config properti tabl column name display_type display_type also JSON encod JSON encod display_attributes display_attributes column column display_attributes display_attributes column attribut isPassword password displayType display type noDisplay no display duplic inform alreadi store display_type display_type column attribut not need upon need upon inspect code attribut not use chang no effect effect simpli get rid attribut attribut,0,0,0,0,0,0,0 
628,Ashish Singh,null,0,hdp-nagios and hdp-monitoring has wrong configuration file location  also owner:group permissions are wrong., hdp nagio hdp nagio hdp monitor hdp monitor wrong configur file locat also owner group owner group permiss wrong wrong,Suse environment has wrong configuration location for hdp-dashboard and hdp-nagios. Also  owner:group permissions were wrongly set to root:root instead of 'wwwrun' and group is 'www, suse environ wrong configur locat hdp dashboard hdp dashboard hdp nagio hdp nagio also owner group owner group permiss wrongli set root root root root instead wwwrun wwwrun group www,0,0,0,0,0,0,0 
633,Yusaku Sako,null,0,Fix invalid HTML markup on Monitoring Dashboard, fix invalid HTML markup monitor dashboard,,,0,0,0,0,0,0,0 
636,Yusaku Sako,null,0,Support for Hadoop Security (front-end changes), support hadoop secur front end front end chang chang,,,0,0,0,0,0,0,0 
638,Yusaku Sako,null,0,Weirdness with Custom Config page when the user goes back to previous stages, weird custom config page user goe back previou stage,Issue 1. Going back and forth between different stages in the Cluster Install Wizard  it is possible to get into a state where Custom Config form has the submit button disabled but no field errors are shown.Steps to replicate: Go up to Stage 6  but do not submit the form Go back to Stage 3 Go up to Stage 6 again. No field errors are shown when they should be.Issue 2. Custom Config stage is skipped once you get to 'Review and Deploy' and go back to a stage preceding Custom Config.Steps to replicate: Go thru the Cluster Install Wizard up to Stage 7 ('Review and Deploy')  but do not submit the form. Go back to Stage 4 or 5. Once you submit the form on Stage 5  Stage 6 is skipped and goes directly to Stage 7. If you go back to Stage 3 or earlier  then Stage 6 will not be skipped., issu go back forth differ stage cluster instal wizard possibl get state custom config form submit button disabl no field error shown step shown step replic replic Go stage not submit form Go back stage Go stage No field error shown issu issu custom config stage skip get review review deploy deploy go back stage preced custom config step config step replic replic Go thru cluster instal wizard stage review review deploy deploy not submit form form Go back stage submit form stage stage skip goe directli stage go back stage earlier stage not skip skip,0,0,0,0,0,0,0 
668,Hitesh Shah,null,0,Ambari should install yum priorities on all nodes to ensure main repo is picked first, ambari instal yum prioriti node ensur main repo pick first,Depending on which main hadoop repo is used to setup the cluster  sometimes  wrong packages may be pulled from add-on repos even if the main repo has a higher priority and has the same package. This can create problems by incompatible dependencies getting installed at times., depend main hadoop repo use setup cluster sometim wrong packag may pull add add repo even main repo higher prioriti packag packag creat problem incompat depend get instal time time,0,0,0,0,0,0,0 
675,Hitesh Shah,null,0,Make puppet generate more logs on command failures, make puppet gener log command failur,,,0,0,0,0,0,0,0 
689,Mahadev konar,null,0,Fix ambari agent init.d scripts and the bootstrapping., fix ambari agent init init script bootstrap bootstrap,,,0,0,0,0,0,0,0 
701,Hitesh Shah,null,0,Ambari does not handle a pre-setup user-supplied Hive Metastore, ambari not handl pre setup pre setup user suppli user suppli hive metastor,Ambari treats a Hive Metastore as something that it still needs to install and setup even though it may not have the necessary permissions to do so., ambari treat hive metastor someth still need instal setup even though may not necessari permiss,0,0,0,0,0,0,0 
1081,Srimanth Gunturi,ambari-web,0,HDFS disk capacity on dashboard is seen as negative number, HDFS disk capac dashboard seen neg number,Sometimes disk capacity calculations end up in negative numbers., sometim disk capac calcul end neg number number,0,0,0,0,0,0,1 
1085,Yusaku Sako,ambari-web,0,Remove files from ambari-web that were not meant to be checked in, remov file ambari web ambari web not meant check,ambari-web/node_modules  ambari-web/public  ambari-web/ambari.iml were not meant to be checked in. Must remove., ambari web node_modules ambari web node_modules ambari web public ambari web public ambari web ambari iml ambari web ambari iml not meant check must remov remov,0,0,0,0,0,0,0 
1092,Srimanth Gunturi,ambari-web,0,dashboard > Summary > capacity pie chart keeps changing colors, dashboard summari capac pie chart keep chang color,,,0,0,0,0,0,0,0 
1098,Srimanth Gunturi,ambari-web,0,Switching services does not update various UI elements, switch servic not updat variou UI element,When you switch services in the UI  sometimes alerts are mismatched compared to selected service. Also the highlights in left-bar are not working., switch servic UI sometim alert mismatch compar select servic servic also highlight left bar left bar not work work,0,0,0,0,0,0,1 
1102,ARUN KUMAR KANDREGULA,ambari-web,0,Error handling when errors are encountered during preparation for deploy, error handl error encount prepar deploy,Currently  if any errors are encountered during preparation for deploy  the user is taken to the deploy page and the hosts will be shown as 'Waiting' but nothing happens. This is bad UX.At a minimum  we should prevent the user from proceeding and display an appropriate error message if any error is encountered after 'Deploy' is clicked  but before we transition to Step 9.We should also think about how a user can recover from this situation.At this point  the deploy has not initiated  but certain API calls may have succeeded  so we may have incomplete info in the database. Currently there's no convenient way to 'rollback'.We can either ask the user to clean the slate by reinitializing the database and try again (should succeed if the original problem was temporary).We can also build more logic in the UI to retry  check if records already exist  etc..., current error encount prepar deploy user taken deploy page host shown wait wait noth happen happen bad UX UX minimum prevent user proceed display appropri error messag error encount deploy deploy click transit step also think user recov situat situat point deploy not initi certain API call may succeed may incomplet info databas databas current no conveni way rollback rollback either ask user clean slate reiniti databas tri succeed origin problem temporari temporari also build logic UI retri check record alreadi exist etc etc,0,0,0,0,0,0,1 
1103,ARUN KUMAR KANDREGULA,ambari-web,0,Need to be able to reliably recover from the case when the browser is closed during deploy (Step 8 post submission  Step 9) of the wizard, need abl reliabl recov case browser close deploy step step post submiss step wizard,Need to be able to reliably recover from the case when the browser is closed during deploy (Step 8 post submission  Step 9) of the wizard.Even after submitting  Step 10  its taking to Step 9 after browser restart. Ideally it should take to monitoring page., need abl reliabl recov case browser close deploy step step post submiss step wizard even wizard even submit step take step browser restart restart ideal take monitor page page,0,0,0,0,0,0,1 
1106,Jaimin D Jetly,ambari-web,0,User-specified custom configs (such as hdfs-site.xml overrides) should be persisted to maintain what the user specified, user specifi user specifi custom config hdf site xml hdf site xml overrid overrid persist maintain user specifi,,,0,0,0,0,0,0,0 
1113,ARUN KUMAR KANDREGULA,ambari-web,0,Install Wizard: Confirm host stuck at Preparing stage, instal wizard wizard confirm host stuck prepar stage,With the install wizard went to assign slaves page successfully  returned back to Welcome page  reentered data and then the UI got stuck at Confirm hosts page., instal wizard went assign slave page success return back welcom page reenter data UI got stuck confirm host page page,0,0,0,0,0,0,0 
1115,Srimanth Gunturi,ambari-web,0,Host component live status is broken, host compon live statu broken,When datanode is stopped on a host  its status keeps jumping., datanod stop host statu keep jump jump,0,0,0,0,0,0,0 
1123,Srimanth Gunturi,ambari-web,0,Ambari heatmaps and host information shows infinity for disk space used, ambari heatmap host inform show infin disk space use,When cluster is started after install  it has disk_total of null which results in Infinity., cluster start instal disk_total null result infin infin,0,0,0,0,0,0,1 
1125,Srimanth Gunturi,ambari-web,0,Graphs 'degrade' over time, graph degrad degrad time,Leave a page with graphs open for several minutes.The graphs become really coarse.It probably has something to do with the fact that Ganglia only provides 6-minute averages beyond the first 61 minutes (first 61 minutes  Ganglia keeps 15-second samples) and we may not be exactly querying for the last 60 minutes., leav page graph open sever minut minut graph becom realli coars coars probabl someth fact ganglia provid minut averag beyond first minut first minut ganglia keep second sampl sampl may not exactli queri last minut minut,0,0,0,0,0,0,0 
1142,ARUN KUMAR KANDREGULA,ambari-web,0,On Notification Popup  clicking 'go to nagios UI' doesn't load nagios UI, notif popup click go nagio UI UI load nagio UI,1) Cause notification to occur (for example  stop oozie)2) On dashboard  click notification icon3) On the notification popup  click 'go to nagios web UI'4) nothing happens.This issue is on IE9  Safari and Chrome. Works fine on Firefox., caus notif occur exampl stop oozi oozi dashboard click notif icon icon notif popup click go nagio web UI UI noth happen happen issu IE IE safari chrome chrome work fine firefox firefox,0,0,0,0,0,0,0 
1143,ARUN KUMAR KANDREGULA,ambari-web,0,tmpfs filesystem being added to the list in the dir used by Ambari, tmpf filesystem ad list dir use ambari,I saw this on a sles cluster. On EC2 they have a tmpfs mounted and Ambari picked it up.Not sure what the ideal solution is but i feel tmpfs should not be included in the available mount points.Also the tmpfs is being used in various directories that will have to change during the install.Attached screenshots., saw sle cluster cluster EC EC tmpf mount ambari pick not not sure ideal solut feel tmpf not includ avail mount point also point also tmpf use variou directori chang instal attach instal attach screenshot screenshot,0,0,0,0,0,0,0 
1150,Yusaku Sako,ambari-web,0,Installer Wizard - Retry feature in Deploy step (Step 9) is broken, instal wizard retri featur deploy step step step broken,,,0,0,0,0,0,0,0 
1151,Yusaku Sako,ambari-web,0,Reconfigure fails silently; it's not firing any API calls due to a JS error, reconfigur fail silent silent not fire API call due JS error,,,0,0,0,0,0,0,0 
1153,Yusaku Sako,ambari-web,0,Host jams in status 'Preparing' if host name is wrong, host jam statu prepar prepar host name wrong,,,0,0,0,0,0,0,0 
1164,Mahadev konar,null,0,Disk Info Metrics and memory usage sometimes do not show up for an hour or so., disk info metric memori usag sometim not show hour,Disk Info Metrics and memory usage sometimes do not show up for an hour or so., disk info metric memori usag sometim not show hour,0,0,0,0,0,0,0 
1184,Yusaku Sako,ambari-web,0,After adding hosts  the host count shown in the Dashboard is incorrect, ad host host count shown dashboard incorrect,,,0,0,0,0,0,0,0 
1190,Yusaku Sako,ambari-web,0,Detailed log view dialogs are not center-aligned, detail log view dialog not center align center align,,,0,0,0,0,0,0,0 
1207,Mahadev konar,null,0,Remove /hdp as the httpd conf for any of the nagios urls - should replace it with ambarinagios or something else., remov hdp httpd conf nagio url replac ambarinagio someth els els,Remove /hdp as the httpd conf for any of the nagios urls - should replace it with ambarinagios or something else., remov hdp httpd conf nagio url replac ambarinagio someth els els,0,0,0,0,0,0,0 
1210,Mahadev konar,null,0,Allow capacity scheduler to be attached to host role configs for CS configurability in the API's., allow capac schedul attach host role config CS configur API API,Allow capacity scheduler to be attached to host role configs for CS configurability in the API's., allow capac schedul attach host role config CS configur API API,0,0,0,0,0,0,0 
1231,Mahadev konar,null,0,Replace sudo with su in the ambari setup script since ambari server setup is already run as root., replac sudo su ambari setup script sinc ambari server setup alreadi run root root,Replace sudo with su in the ambari setup script since ambari server setup is already run as root., replac sudo su ambari setup script sinc ambari server setup alreadi run root root,0,0,0,0,0,0,0 
1233,Mahadev konar,null,0,Directory permissions on httpd /var/www/cgi-bin should not be touched by Ambari., directori permiss httpd var www cgi bin var www cgi bin not touch ambari ambari,Directory permissions on httpd /var/www/cgi-bin should not be touched by Ambari., directori permiss httpd var www cgi bin var www cgi bin not touch ambari ambari,0,0,0,0,0,0,0 
1259,Mahadev konar,null,0,Fix the host roles live status not go back to INSTALLED if it was in START_FAILED state., fix host role live statu not go back INSTALLED START_FAILED START FAILED state state,Fix the host roles live status not go back to INSTALLED if it was in START_FAILED state., fix host role live statu not go back INSTALLED START_FAILED START FAILED state state,0,0,0,0,0,0,0 
1264,Yusaku Sako,ambari-web,0,Service graphs refresh with spinners, servic graph refresh spinner,Service graphs are refreshing with spinners  rather than simply shifting to the left.See the attached movie clip., servic graph refresh spinner rather simpli shift left see left see attach movi clip clip,0,0,0,0,0,0,0 
1266,Mahadev konar,null,0,Agent checks packages as part of host check but doesn't tell which ones are needed or conflicting, agent check packag part host check tell one need conflict,Agent checks packages as part of host check but doesn't tell which ones are needed or conflicting, agent check packag part host check tell one need conflict,0,0,0,0,0,0,0 
1267,Mahadev konar,null,0,Store example Hive Queries somewhere in Ambari that's easily accessible for demo/test purposes, store exampl hive queri somewher ambari easili access demo test demo test purpos,Store example Hive Queries somewhere in Ambari that's easily accessible for demo/test purposes, store exampl hive queri somewher ambari easili access demo test demo test purpos,0,0,0,0,0,0,0 
1273,Srimanth Gunturi,ambari-web,0,Edit User: No error message is shown when the user does not enter the correct 'old password', edit user user No error messag shown user not enter correct old password password,No error message is shown when the user does not enter the correct 'old password' when editing an user., No error messag shown user not enter correct old password password edit user user,0,0,0,0,0,0,0 
1275,Srimanth Gunturi,ambari-web,0,Incorrect displaying 'Background operations' window after changing state of component, incorrect display background background oper oper window chang state compon,Steps:1. Change state (start/stop operations are preferable) for lot of components so that the number of background operations was approximately 20-30;2. Change size of browser (800-900 px);3. Go to down of page;4. Change state for next component;5. Confirm changing;Result:'Background operations' window was opened  but it 'OK' button is not visible.Expected result:'Background operations' window contains scroll bar for all background operations. 'OK' button is available for using., step step chang state start stop start stop oper prefer prefer lot compon number background oper approxim chang size browser px px Go page page chang state next compon compon confirm chang result background chang result background oper oper window open OK OK button not visibl expect visibl expect result background result background oper oper window contain scroll bar background oper oper OK OK button avail use use,0,0,0,0,0,0,0 
1277,Mahadev konar,null,0,Failing build due to url moved on Suse., fail build due url move suse suse,Failing build due to url moved on Suse. Looks like centos5 and 6 handle redirection all fine but doesnt look like the maven plugin handles that on SUSE., fail build due url move suse suse look like cento cento handl redirect fine doesnt look like maven plugin handl SUSE SUSE,0,0,0,0,0,0,0 
1299,Yusaku Sako,ambari-agent,0,Bootstrap can hang indefinitely, bootstrap hang indefinit,I was bootstrapping 4 nodes. One of them got stuck in 'Installing' phase and won't time out even after ~30 minutes.It seems like starting of ambari-agent was hanging., bootstrap node node one got stuck instal instal phase time even minut minut seem like start ambari agent ambari agent hang hang,0,0,0,0,0,0,0 
1300,Srimanth Gunturi,ambari-web,0,Service status / host component status can get stuck in the green blinking state if stop fails - no further operation can be performed, servic statu host compon statu get stuck green blink state stop fail no oper perform,This happens when a service/host component is running  but stop fails. This leaves the desired_state in the INSTALLED (i.e.  STOPPED) state  while the live state is STARTED.Currently  UI assumes when desired_state==INSTALLED and state==STARTED  it is STARTING. This was a trick to get around the problem of backend live state update lagging and to make UI more responsive., happen servic host servic host compon run stop fail fail leav desired_state INSTALLED STOPPED STOPPED state live state STARTED current STARTED current UI assum desired_state INSTALLED desired_state INSTALLED state STARTED state STARTED STARTING STARTING trick get around problem backend live state updat lag make UI respons respons,0,0,0,0,0,0,0 
1321,Srimanth Gunturi,ambari-web,0,Switching out of Jobs page does not launch popup anymore, switch job page not launch popup anymor,On the jobs page click on Job-X and see the popup with all the job information. Now switch to Services page and come back to the jobs page. Now clicking on Job-X will not launch popup., job page click job job see popup job inform inform switch servic page come back job page page click job job not launch popup popup,0,0,0,0,0,0,0 
1330,Mahadev konar,null,0,Cluster missing hosts after successful install and restart., cluster miss host success instal restart restart,Cluster missing hosts after successful install and restart. This bug got introduced due to my patch in AMBARI-1301., cluster miss host success instal restart restart bug got introduc due patch AMBARI AMBARI,0,0,0,0,0,0,0 
1343,Siddharth Wagle,ambari-agent,0,Service Check fails after secure install due to wrong kinit path, servic check fail secur instal due wrong kinit path,For manually installed kdc  the kinit path in the puppet script is /usr/kerberos/bin/kinitActual location:root@ip-10-38-13-250 data]# whereis kinitkinit: /usr/bin/kiniterr: /Stage&#91;2&#93;/Hdp-hbase::Hbase::Service_check/Hdp-hadoop::Exec-hadoop&#91;hbase::service_check::test&#93;/Hdp::Exec&#91;/usr/kerberos/bin/kinit -kt /etc/security/keytabs/hdfs.headless.keytab hdfs; hadoop --config /etc/hadoop/conf fs -test -e /apps/hbase/data/usertable&#93;/Exec&#91;/usr/kerberos/bin/kinit -kt /etc/security/keytabs/hdfs.headless.keytab hdfs; hadoop --config /etc/hadoop/conf fs -test -e /apps/hbase/data/usertable&#93;: Failed to call refresh: Could not find command '/usr/kerberos/bin/kinit', manual instal kdc kinit path puppet script usr kerbero bin kinitActual usr kerbero bin kinit actual locat root ip locat root ip data data wherei kinitkinit kinitkinit usr bin kiniterr usr bin kiniterr stage hdp hbase hbase Service_check hdp hadoop exec hadoop hbase service_check test hdp exec usr kerbero bin kinit stage hdp hbase hbase Service_check hdp hadoop exec hadoop hbase service_check test hdp exec usr kerbero bin kinit kt etc secur keytab hdf headless keytab etc secur keytab hdf headless keytab hdf hdf hadoop config etc hadoop conf etc hadoop conf fs test app hbase data usert exec usr kerbero bin kinit app hbase data usert exec usr kerbero bin kinit kt etc secur keytab hdf headless keytab etc secur keytab hdf headless keytab hdf hdf hadoop config etc hadoop conf etc hadoop conf fs test app hbase data usert app hbase data usert fail call refresh refresh could not find command usr kerbero bin kinit usr kerbero bin kinit,0,0,0,0,0,0,1 
1351,Jaimin D Jetly,ambari-web,0,Provide consistent ordering of hosts in heatmap, provid consist order host heatmap,,,0,0,0,0,0,0,0 
1354,Jaimin D Jetly,ambari-web,0,'No alerts' badge on the Host Detail page should be green  not red, No No alert alert badg host detail page green not red,,,0,0,0,0,0,0,0 
1359,Jaimin D Jetly,ambari-web,0,App Browser rows colours should alternate from dark grey to light grey and back, app browser row colour altern dark grey light grey back,,,0,0,0,0,0,0,0 
1360,Jaimin D Jetly,ambari-web,0,Mouse cursor hover behavior is strange on Job Browser, mous cursor hover behavior strang job browser,When hovering the mouse cursor around Show All  Filtered  the mouse cursor changes to the 'hand' icon as expected. To the right  the cursor turns into a hand even when hovering over areas where there's no link. Hovering over 'Clear filters'  the cursor does not turn into the 'hand'., hover mous cursor around show filter mous cursor chang hand hand icon expect expect right cursor turn hand even hover area no link link hover clear clear filter filter cursor not turn hand hand,0,0,0,0,0,0,0 
1376,Jaimin D Jetly,ambari-web,0,Wrong calculation of duration filter on apps page, wrong calcul durat filter app page,Wrong calculation for the duration filter if we enter just number  without h  m or s to specify the unit. By default we should take seconds as the default unit., wrong calcul durat filter enter number without specifi unit unit default take second default unit unit,0,0,0,0,0,0,0 
1432,Mahadev konar,null,0,Ambari Agent registration hangs due to Acceptor bug in Jetty for not reading through accepted connections., ambari agent registr hang due acceptor bug jetti not read accept connect connect,Ambari Agent registration hangs due to Acceptor bug in Jetty for not reading through accepted connections., ambari agent registr hang due acceptor bug jetti not read accept connect connect,0,0,0,0,0,0,0 
1441,Yusaku Sako,ambari-web,0,Validation for username used in service configs is broken, valid usernam use servic config broken,,,0,0,0,0,0,0,0 
1449,Jaimin D Jetly,ambari-web,0,Failure popup shown for reconfiguring HDFS when MapReduce is not installed, failur popup shown reconfigur HDFS MapReduce map reduc not instal,,,0,0,0,0,0,CHANGES.txt;ambari-web/app/controllers/main/service/info/configs.js;ambari-web/app/messages.js;,0 
1456,Yusaku Sako,ambari-web,0,Cannot proceed after bootstrapping in some cases due to a run-time error while running host checks, cannot proceed bootstrap case due run time run time error run host check,,,0,0,0,0,0,0,0 
1465,Siddharth Wagle,ambari-server,0,Minimize Read and Write locks for createHosts, minim read write lock createHosts creat host,Invocation count and exec time for ClustersImpl.mapHostToCluser very highorg.apache.ambari.server.state.cluster.ClustersImpl.mapHostToCluster(String  String) Time(ms): 252 925 Avg Time(ms): 5 269 Own Time(ms): 211Invocation Count: 48Each time host is mapped to cluster we refresh the entity manager. This results in the createHosts call taking excess of 10 minutes, invoc count exec time ClustersImpl mapHostToCluser cluster impl map host cluser highorg apach ambari server state cluster ClustersImpl mapHostToCluster string highorg apach ambari server state cluster cluster impl map host cluster string string string time ms time ms avg time ms time ms time ms time ms invoc invoc count count time host map cluster refresh entiti manag manag result createHosts creat host call take excess minut,0,0,0,0,0,0,1 
1473,Yusaku Sako,ambari-web,0,Further optimization of querying host information from the server, optim queri host inform server,Further work on optimizing query for getting host information on top of BUG-1460., work optim queri get host inform top BUG BUG,0,0,0,0,0,0,0 
1486,Mahadev konar,null,0,Fix TestHostName to take care of issues when gethostname and getfqdn do not match., fix TestHostName test host name take care issu gethostnam getfqdn not match match,Fix TestHostName to take care of issues when gethostname and getfqdn do not match., fix TestHostName test host name take care issu gethostnam getfqdn not match match,0,0,0,0,0,0,0 
1487,Mahadev konar,null,0,Fix alerts at host level if MapReduce is not selected not to alert for tasktrackers not running., fix alert host level MapReduce map reduc not select not alert tasktrack not run run,Fix alerts at host level if MapReduce is not selected not to alert for tasktrackers not running., fix alert host level MapReduce map reduc not select not alert tasktrack not run run,0,0,0,0,0,0,1 
1488,Mahadev konar,null,0,Nagios script causes unwanted  Datanode logs., nagio script caus unwant datanod log log,Nagios script causes unwanted Datanode logs., nagio script caus unwant datanod log log,0,0,0,0,0,0,1 
1489,Mahadev konar,null,0,Add hadoop-lzo to be one of the rpms to check for before installation., add hadoop lzo hadoop lzo one rpm check instal instal,Add hadoop-lzo to be one of the rpms to check for before installation., add hadoop lzo hadoop lzo one rpm check instal instal,0,0,0,0,0,0,0 
1496,Jaimin D Jetly,ambari-web,0,Make all service properties reconfigurable., make servic properti reconfigur reconfigur,,,0,0,0,0,0,0,0 
1497,Mahadev konar,null,0,Fix start up option for ambari-server where there is a missing space., fix start option ambari server ambari server miss space space,Fix start up option for ambari-server where there is a missing space., fix start option ambari server ambari server miss space space,0,0,0,0,0,0,0 
1499,Yusaku Sako,ambari-web,0,Add hosts is broken, add host broken,This is due to performance enhancements for querying hosts.Hosts/disk_info for the hosts being added is expected in the Add Hosts wizard  but it is now missing., due perform enhanc queri host host disk_info host host disk_info host ad expect add host wizard miss miss,0,0,0,0,0,0,0 
1519,Yusaku Sako,ambari-web,0,Ambari Web goes back and forth between frozen and usable state peridocially on a large cluster, ambari web goe back forth frozen usabl state peridoci larg cluster,The background polling to update the live status of services and host components runs every 6 seconds. When this happens  the whole UI freezes for several seconds periodically., background poll updat live statu servic host compon run everi second second happen whole UI freez sever second period period,0,0,0,0,0,0,0 
1520,Srimanth Gunturi,ambari-web,0,Alerts take around 20-30 seconds to show up everytime you refresh the dashboard., alert take around second show everytim refresh dashboard dashboard,Alerts take around 20-30 seconds to show up everytime you refresh the dashboard., alert take around second show everytim refresh dashboard dashboard,0,0,0,0,0,0,0 
1559,Steve Ratay,ambari-server,0,Jobs failed count always returns 0 in the jobtracker API metrics, job fail count alway return jobtrack API metric,See the attachments  but after running both successful and failed MapReduce jobs  the jobs submitted count includes all jobs  the jobs successful appears correct  but the jobs failed count is still 0., see attach run success fail MapReduce map reduc job job submit count includ job job success appear correct job fail count still,0,0,0,0,0,0,0 
1582,Siddharth Wagle,ambari-server,0,Cannot start hadoop services after hdfs re-configuration and amabri server restart., cannot start hadoop servic hdf configur configur amabri server restart restart,Cannot start hadoop services after several restarts since the agents., cannot start hadoop servic sever restart sinc agent agent,0,0,0,0,0,0,0 
1597,Siddharth Wagle,ambari-agent,0,Templeton smoke test fails for secure cluster, templeton smoke test fail secur cluster,Templeton start fails due to multiple errors.[0;36mnotice: /Stage&#91;2&#93;/Hdp-templeton::Copy-hdfs-directories/Hdp-hadoop::Hdfs::Copyfromlocal&#91;/usr/lib/hadoop/contrib/streaming/hadoop-streaming*.jar&#93;/Hdp-hadoop::Exec-hadoop&#91;fs -copyFromLocal /usr/lib/hadoop/contrib/streaming/hadoop-streaming*.jar /apps/webhcat/hadoop-streaming.jar&#93;/Hdp::Exec&#91;/usr/bin/kinit -kt /etc/security/keytabs/hcat.headless.keytab hcat; hadoop --config /etc/hadoop/conf fs -copyFromLocal /usr/lib/hadoop/contrib/streaming/hadoop-streaming*.jar /apps/webhcat/hadoop-streaming.jar&#93;/Exec&#91;/usr/bin/kinit -kt /etc/security/keytabs/hcat.headless.keytab hcat; hadoop --config /etc/hadoop/conf fs -copyFromLocal /usr/lib/hadoop/contrib/streaming/hadoop-streaming*.jar /apps/webhcat/hadoop-streaming.jar&#93;/returns: kinit: Client not found in Kerberos database while getting initial credentials^[[0m, templeton start fail due multipl error mnotic error mnotic stage hdp templeton copi hdf directori hdp hadoop hdf copyfromloc usr lib hadoop contrib stream hadoop stream jar hdp hadoop exec hadoop fs stage hdp templeton copi hdf directori hdp hadoop hdf copyfromloc usr lib hadoop contrib stream hadoop stream jar hdp hadoop exec hadoop fs copyFromLocal copi local usr lib hadoop contrib stream hadoop stream jar usr lib hadoop contrib stream hadoop stream jar app webhcat hadoop stream jar hdp exec usr bin kinit app webhcat hadoop stream jar hdp exec usr bin kinit kt etc secur keytab hcat headless keytab etc secur keytab hcat headless keytab hcat hcat hadoop config etc hadoop conf etc hadoop conf fs copyFromLocal copi local usr lib hadoop contrib stream hadoop stream jar usr lib hadoop contrib stream hadoop stream jar app webhcat hadoop stream jar exec usr bin kinit app webhcat hadoop stream jar exec usr bin kinit kt etc secur keytab hcat headless keytab etc secur keytab hcat headless keytab hcat hcat hadoop config etc hadoop conf etc hadoop conf fs copyFromLocal copi local usr lib hadoop contrib stream hadoop stream jar usr lib hadoop contrib stream hadoop stream jar app webhcat hadoop stream jar return app webhcat hadoop stream jar return kinit kinit client not found kerbero databas get initi credenti credenti,0,0,0,0,0,0,0 
1621,Yusaku Sako,ambari-web,0,Config/Reconfig UI should not allow certain configs to have host-level overrides, config reconfig config reconfig UI not allow certain config host level host level overrid,,,0,0,0,0,0,0,0 
1641,Steve Ratay,ambari-server,0,Some map and reduce task metrics are missing for the tasktrackers in the API, map reduc task metric miss tasktrack API,With Ambari 1.2.2  I can get the metrics.mapred object to show up for the tasktracker component. Our code is hitting the URL: http://sdll4474.labs.teradata.com:8080/api/v1/clusters/sdll4474.labs.teradata.com/services/MAPREDUCE/components/TASKTRACKER?fields=host_components/*. Here one of the objects in the host_components array. Note that the data in metrics.mapred.tasktracker is providing some data Ie never seen before. In previous versions we say properties such as reduces_running  reduceTaskSlots  maps_running  etc. in this object. { 'href' : 'http://aster39h1.td.teradata.com:8080/api/v1/clusters/aster39h1.td.teradata.com/hosts/byn001-17/host_components/TASKTRACKER'  'HostRoles' : { 'cluster_name' : 'aster39h1.td.teradata.com'  'desired_state' : 'STARTED'  'state' : 'STARTED'  'component_name' : 'TASKTRACKER'  'service_name' : 'MAPREDUCE'  'host_name' : 'byn001-17' }  'metrics' : { 'boottime' : 1.360089758E9  'process' : { 'proc_total' : 845.211111111  'proc_run' : 0.0 }  'rpc' : { 'rpcAuthorizationSuccesses' : 9  'SentBytes' : 6842  'rpcAuthorizationFailures' : 0  'ReceivedBytes' : 26187  'NumOpenConnections' : 0  'callQueueLen' : 0  'RpcQueueTime_num_ops' : 59  'rpcAuthenticationSuccesses' : 0  'RpcProcessingTime_num_ops' : 59  'rpcAuthenticationFailures' : 0  'RpcProcessingTime_avg_time' : 0.6666666666666666  'RpcQueueTime_avg_time' : 0.0 }  'mapred' : { 'shuffleOutput' : { 'shuffle_success_outputs' : 1  'shuffle_handler_busy_percent' : 0.0  'shuffle_output_bytes' : 1400  'shuffle_failed_outputs' : 0  'shuffle_exceptions_caught' : 0 }  'tasktracker' : { 'ConfigVersion' : 'default'  'HttpPort' : 50060  'TasksInfoJson' : '{/'running/':0 /'failed/':0 /'commit_pending/':0}'  'JobTrackerUrl' : 'aster39h1.td.teradata.com:50300'  'Healthy' : true  'Version' : '1.1.2.22  r'  'Hostname' : 'byn001-17'  'RpcPort' : 48526 } }  'ugi' : { 'loginFailure_num_ops' : 0  'loginSuccess_num_ops' : 0  'loginSuccess_avg_time' : 0.0  'loginFailure_avg_time' : 0.0 }  'disk' : { 'disk_total' : 36841.767  'disk_free' : 36776.9775333  'part_max_used' : 70.7 }  'cpu' : { 'cpu_speed' : 1999.0  'cpu_wio' : 0.0  'cpu_num' : 24.0  'cpu_idle' : 99.8886111111  'cpu_nice' : 0.0  'cpu_aidle' : 0.0  'cpu_system' : 0.1  'cpu_user' : 0.0227777777778 }  'rpcdetailed' : { 'getTask_avg_time' : 1.0  'ping_avg_time' : 0.0  'done_avg_time' : 1.0  'getProtocolVersion_avg_time' : 0.0  'getMapCompletionEvents_avg_time' : 0.0  'done_num_ops' : 9  'getMapCompletionEvents_num_ops' : 6  'canCommit_num_ops' : 6  'ping_num_ops' : 2  'commitPending_avg_time' : 1.0  'statusUpdate_num_ops' : 15  'statusUpdate_avg_time' : 1.0  'getTask_num_ops' : 9  'getProtocolVersion_num_ops' : 9  'commitPending_num_ops' : 3  'canCommit_avg_time' : 0.0 }  'load' : { 'load_fifteen' : 0.0  'load_one' : 0.0  'load_five' : 0.0 }  'jvm' : { 'memHeapCommittedM' : 100.4375  'NonHeapMemoryUsed' : 25214472  'logFatal' : 0  'threadsWaiting' : 17  'gcCount' : 122400  'threadsBlocked' : 0  'HeapMemoryUsed' : 77617416  'logWarn' : 0  'logError' : 0  'HeapMemoryMax' : 954466304  'memNonHeapCommittedM' : 26.125  'memNonHeapUsedM' : 24.046394  'gcTimeMillis' : 81352  'NonHeapMemoryMax' : 136314880  'logInfo' : 3  'memHeapUsedM' : 73.81818  'threadsNew' : 0  'threadsTerminated' : 0  'maxMemoryM' : 758.4375  'threadsTimedWaiting' : 10  'threadsRunnable' : 6 }  'network' : { 'pkts_out' : 111.684472222  'bytes_in' : 1428.83666667  'bytes_out' : 23201.8668056  'pkts_in' : 13.9853333333 }  'memory' : { 'mem_total' : 1.31854096E8  'swap_free' : 6291448.0  'mem_buffers' : 574794.711111  'mem_shared' : 0.0  'swap_total' : 6291448.0  'mem_cached' : 6061952.85556  'mem_free' : 1.23072573378E8 } }  'component' : [ { 'href' : 'http://aster39h1.td.teradata.com:8080/api/v1/clusters/aster39h1.td.teradata.com/services/MAPREDUCE/components/TASKTRACKER'  'ServiceComponentInfo' : { 'cluster_name' : 'aster39h1.td.teradata.com'  'component_name' : 'TASKTRACKER'  'service_name' : 'MAPREDUCE' } } ] }, ambari get metric mapr metric mapr object show tasktrack compon compon code hit URL URL one object host_components array array note data metric mapr tasktrack metric mapr tasktrack provid data never seen previou version say properti reduces_running reduceTaskSlots reduc task slot maps_running etc etc object object href href http aster td teradata com api cluster aster td teradata com host byn host_components TASKTRACKER http aster td teradata com api cluster aster td teradata com host byn host_components TASKTRACKER HostRoles host role cluster_name cluster_name aster td teradata com aster td teradata com desired_state desired_state STARTED STARTED state state STARTED STARTED component_name component_name TASKTRACKER TASKTRACKER service_name service_name MAPREDUCE MAPREDUCE host_name host_name byn byn metric metric boottim boottim process process proc_total proc_total proc_run proc_run rpc rpc rpcAuthorizationSuccesses rpc author success SentBytes sent byte rpcAuthorizationFailures rpc author failur ReceivedBytes receiv byte NumOpenConnections num open connect callQueueLen call queue len RpcQueueTime_num_ops rpc queue Time_num_ops rpcAuthenticationSuccesses rpc authent success RpcProcessingTime_num_ops rpc process Time_num_ops rpcAuthenticationFailures rpc authent failur RpcProcessingTime_avg_time rpc process Time_avg_time RpcQueueTime_avg_time rpc queue Time_avg_time mapr mapr shuffleOutput shuffl output shuffle_success_outputs shuffle_success_outputs shuffle_handler_busy_percent shuffle_handler_busy_percent shuffle_output_bytes shuffle_output_bytes shuffle_failed_outputs shuffle_failed_outputs shuffle_exceptions_caught shuffle_exceptions_caught tasktrack tasktrack ConfigVersion config version default default HttpPort http port TasksInfoJson task info json run run fail fail commit_pending commit_pending JobTrackerUrl job tracker url aster td teradata com aster td teradata com healthi healthi true version version hostnam hostnam byn byn RpcPort rpc port ugi ugi loginFailure_num_ops login Failure_num_ops loginSuccess_num_ops login Success_num_ops loginSuccess_avg_time login Success_avg_time loginFailure_avg_time login Failure_avg_time disk disk disk_total disk_total disk_free disk_free part_max_used part_max_used cpu cpu cpu_speed cpu_speed cpu_wio cpu_wio cpu_num cpu_num cpu_idle cpu_idle cpu_nice cpu_nice cpu_aidle cpu_aidle cpu_system cpu_system cpu_user cpu_user rpcdetail rpcdetail getTask_avg_time get Task_avg_time ping_avg_time ping_avg_time done_avg_time done_avg_time getProtocolVersion_avg_time get protocol Version_avg_time getMapCompletionEvents_avg_time get map complet Events_avg_time done_num_ops done_num_ops getMapCompletionEvents_num_ops get map complet Events_num_ops canCommit_num_ops Commit_num_ops ping_num_ops ping_num_ops commitPending_avg_time commit Pending_avg_time statusUpdate_num_ops statu Update_num_ops statusUpdate_avg_time statu Update_avg_time getTask_num_ops get Task_num_ops getProtocolVersion_num_ops get protocol Version_num_ops commitPending_num_ops commit Pending_num_ops canCommit_avg_time Commit_avg_time load load load_fifteen load_fifteen load_one load_one load_five load_five jvm jvm memHeapCommittedM mem heap commit NonHeapMemoryUsed non heap memori use logFatal log fatal threadsWaiting thread wait gcCount gc count threadsBlocked thread block HeapMemoryUsed heap memori use logWarn log warn logError log error HeapMemoryMax heap memori max memNonHeapCommittedM mem non heap commit memNonHeapUsedM mem non heap use gcTimeMillis gc time milli NonHeapMemoryMax non heap memori max logInfo log info memHeapUsedM mem heap use threadsNew thread new threadsTerminated thread termin maxMemoryM max memori threadsTimedWaiting thread time wait threadsRunnable thread runnabl network network pkts_out pkts_out bytes_in bytes_in bytes_out bytes_out pkts_in pkts_in memori memori mem_total mem_total swap_free swap_free mem_buffers mem_buffers mem_shared mem_shared swap_total swap_total mem_cached mem_cached mem_free mem_free compon compon href href http aster td teradata com api cluster aster td teradata com servic MAPREDUCE compon TASKTRACKER http aster td teradata com api cluster aster td teradata com servic MAPREDUCE compon TASKTRACKER ServiceComponentInfo servic compon info cluster_name cluster_name aster td teradata com aster td teradata com component_name component_name TASKTRACKER TASKTRACKER service_name service_name MAPREDUCE MAPREDUCE,0,0,0,0,0,CHANGES.txt;ambari-server/src/main/resources/jmx_properties.json;ambari-server/src/test/java/org/apache/ambari/server/controller/jmx/JMXPropertyProviderTest.java;ambari-server/src/test/resources/mapreduce_tasktracker_jmx.json;,0 
1645,Yusaku Sako,ambari-web,0,Undo should not be allowed on component hosts, undo not allow compon host,,,0,0,0,0,0,0,0 
1666,Siddharth Wagle,ambari-agent,0,Oozie properties for principal and keytab not read from oozie-site, oozi properti princip keytab not read oozi site oozi site,Oozie principal is create by the UI as oozie/${hostname}@realm.comPuppet script has a bug that does not read this property and uses default 'oozie' as the principal, oozi princip creat UI oozi hostnam realm comPuppet oozi hostnam realm com puppet script bug not read properti use default oozi oozi princip,0,0,0,0,0,0,0 
1667,Siddharth Wagle,ambari-agent,0,Starting all services fails on secure cluster (excluding HBase and ZooKeeper), start servic fail secur cluster exclud HBase base ZooKeeper zoo keeper,HDFS service check failure leads to this.After the failure of the 'HDFS service check' task  stage fails. But HDFS comes up.The Ambari server hostname for secure cluster: ec2-54-234-164-5.compute-1.amazonaws.com, HDFS servic check failur lead failur HDFS HDFS servic check check task stage fail fail HDFS come ambari server hostnam secur cluster cluster ec comput amazonaw com ec comput amazonaw com,0,0,0,0,0,0,0 
1702,Siddharth Wagle,ambari-server,0,Ambari/GSInstallers need to set the value of mapred.jobtracker.completeuserjobs.maximum, ambari GSInstallers ambari GS instal need set valu mapr jobtrack completeuserjob maximum mapr jobtrack completeuserjob maximum,mapred.jobtracker.completeuserjobs.maximum is currently set to 0. This causes issues with failed(/successful) jobs from pig and other job submitters because the references to the failed job is cleared up asap in jobtracker preventing one from accessing the failure reason. This value should be bumped up to about 100 according to the MapReduce team., mapr jobtrack completeuserjob maximum mapr jobtrack completeuserjob maximum current set caus issu fail success fail success job pig job submitt refer fail job clear asap jobtrack prevent one access failur reason reason valu bump accord MapReduce map reduc team team,0,0,0,0,0,0,0 
1724,Sumit Mohanty,null,0,Agent has it hard-coded that HDP repo file can only be downloaded once, agent hard code hard code HDP repo file download,Upgrade requires agents to download the repo file anytime., upgrad requir agent download repo file anytim anytim,0,0,0,0,0,0,0 
1726,Sumit Mohanty,null,0,It seems upgrades available at the FE is hard-coded to 1.3.0, seem upgrad avail FE hard code hard code,In order to test upgrade  I modified the available stack definitions to allow upgrade from 1.2.0 to 1.2.2 and removed upgrade to 1.3.0. However  the FE still says '(Upgrade available: HDP-1.3.0)'. However  http://server:8080/api/v1/stacks2/HDP/versions/1.3.0/ has min_upgrade_version as null.{ 'href' : 'http://server:8080/api/v1/stacks2/HDP/versions/1.3.0/'  'Versions' : { 'stack_version' : '1.3.0'  'stack_name' : 'HDP'  'min_upgrade_version' : null } ..., order test upgrad modifi avail stack definit allow upgrad remov upgrad howev FE still say upgrad upgrad avail avail HDP HDP howev min_upgrade_version null null href href http server api stack HDP version http server api stack HDP version version version stack_version stack_version stack_name stack_name HDP HDP min_upgrade_version min_upgrade_version null,0,0,0,0,0,0,0 
1739,Siddharth Wagle,ambari-agent,0,HBase and Zk failed to start on secure install, HBase base Zk fail start secur instal,Error during starting hbase and zookeeper during secure install.Incorrectly parsed Files:hbase-env.shzookeeper-env.sh, error start hbase zookeep secur instal incorrectli instal incorrectli pars file hbase env shzookeep env sh file hbase env shzookeep env sh,0,0,0,0,0,0,0 
1757,Sumit Mohanty,null,0,Add support for Stack 1.2.2 to Ambari, add support stack ambari,Add support for Stack 1.2.2 to Ambari., add support stack ambari ambari,0,0,0,0,0,0,1 
1764,Tom Beerbower,null,0,Unable to get all tasks from more than one request_id by one request, unabl get task one request_id one request,When trying to get tasks from more than one request_id returns tasks only for one.request 'api/v1/clusters/mycluster/requests?Requests/id=1|Requests/id=2'returns:{'href' : 'http://ec2-23-20-223-127.compute-1.amazonaws.com:8080/api/v1/clusters/mycluster/requests?Requests/id=1|Requests/id=2' 'items' : [{'href' : 'http://ec2-23-20-223-127.compute-1.amazonaws.com:8080/api/v1/clusters/mycluster/requests/2' 'Requests' :{ 'id' : 2  'cluster_name' : 'mycluster' }}]}, tri get task one request_id return task one request one request api cluster myclust request request id request id return href api cluster myclust request request id request id return href http ec comput amazonaw com api cluster myclust request request id request id http ec comput amazonaw com api cluster myclust request request id request id item item href href http ec comput amazonaw com api cluster myclust request http ec comput amazonaw com api cluster myclust request request request id id cluster_name cluster_name myclust myclust,0,0,0,0,0,CHANGES.txt;ambari-server/src/main/java/org/apache/ambari/server/controller/internal/RequestResourceProvider.java;ambari-server/src/test/java/org/apache/ambari/server/controller/internal/RequestResourceProviderTest.java;,0 
1770,Siddharth Wagle,ambari-agent,0,Hue installation fails due to manifest errors, hue instal fail due manifest error,Hue installation fails due to following errors:1. Change in the name of rpm bundle2. Empty values in the hue.ini sections, hue instal fail due follow error error chang name rpm bundl bundl empti valu hue ini hue ini section,0,0,0,0,0,0,1 
1775,Jaimin D Jetly,ambari-web,0,Security wizard - Javascript error is thrown when zooKeeper is included as a secure service., secur wizard javascript error thrown zooKeeper zoo keeper includ secur servic servic,,,0,0,0,0,0,0,0 
1789,Sumit Mohanty,null,0,Stopping and then Starting all services doesn't start NameNode, stop start servic start NameNode name node,Security wizard stops all services  applies configuration and then starts all services.Sometimes it has been noticed that the action to stop all service completes successfully but the action to start all services never sends the task to start NameNode., secur wizard stop servic appli configur start servic sometim servic sometim notic action stop servic complet success action start servic never send task start NameNode name node,0,0,0,0,0,0,1 
1791,Siddharth Wagle,ambari-agent,0,Can not specify request context for smoke test request, not specifi request context smoke test request,Regarding BUG-3509 when we send request to server likeapi/v1/clusters/cl1/services/HDFS/actions/HDFS_SERVICE_CHECKRequest Method:POST Form Data:{'RequestInfo':{'context':'Smoke Test'}}This request is not setting request_context., regard BUG BUG send request server likeapi cluster cl servic HDFS action HDFS_SERVICE_CHECKRequest likeapi cluster cl servic HDFS action HDFS SERVICE CHECK request method POST method POST form data RequestInfo context smoke data request info context smoke test test request not set request_context request_context,0,0,0,0,0,0,0 
1816,Jaimin D Jetly,ambari-web,0,Security wizard: Add missing secure configs to Hbase service and make 'zookeeper' as default primary name for zookeeper principal., secur wizard wizard add miss secur config hbase servic make zookeep zookeep default primari name zookeep princip princip,,,0,0,0,0,0,0,1 
1818,Siddharth Wagle,ambari-agent,0,HBase master shuts down immediately after start in a secure cluster., HBase base master shut immedi start secur cluster cluster,HBase master shuts down immediately after start in a secure cluster.Wrong settings in the hbase_master_jaas. Need to replace the 'HOST with actual fqdn, HBase base master shut immedi start secur cluster wrong cluster wrong set hbase_master_jaas hbase_master_jaas need replac HOST HOST actual fqdn,0,0,0,0,0,0,0 
1837,Jaimin D Jetly,ambari-web,0,Few core-site properties vanished after seemingly benign reconfiguration., core site core site properti vanish seemingli benign reconfigur reconfigur,UI metadata properties are not being reconfigured and retained on saving services., UI metadata properti not reconfigur retain save servic servic,0,0,0,0,0,0,1 
1838,Jaimin D Jetly,ambari-web,0,Cluster Management > Services > MapReduce > Config throws JS error and the page comes up blank, cluster manag servic MapReduce map reduc config throw JS error page come blank,,,0,0,0,0,0,0,1 
1849,Yusaku Sako,ambari-web,0,Cosmetic problems on HBase Dashboard, cosmet problem HBase base dashboard,,,0,0,0,0,0,0,0 
1859,Sumit Mohanty,null,0,Cannot load Nagios Alerts due to 400 Bad Request, cannot load nagio alert due bad request,Given the API call: http://dev.hortonworks.com:8080/api/v1/clusters/test403_2/host_components?HostRoles/component_name=NAGIOS_SERVER&amp;fields=HostRoles/nagios_alertsThe feedback is:{ 'status' : 400  'message' : 'The properties [HostRoles/nagios_alerts] specified in the request or predicate are not supported for the resource type HostComponent.' }, given API call call feedback statu statu messag messag properti HostRoles nagios_alerts host role nagios_alerts specifi request predic not support resourc type HostComponent host compon,0,0,0,0,0,0,1 
1860,Sumit Mohanty,null,0,Master broken - Cannot deploy services, master broken cannot deploy servic,Datanode install fails on multi-node clusters because the following configuration property:$ambari_db_rca_url= 'jdbc:postgresql://localhost/ambarirca'Ensure all of these variables are wired up:'ambari_db_rca_url''ambari_db_rca_driver''ambari_db_rca_username''ambari_db_rca_password', datanod instal fail multi node multi node cluster follow configur properti ambari_db_rca_url properti ambari_db_rca_url jdbc postgresql localhost ambarirca ensur jdbc postgresql localhost ambarirca ensur variabl wire ambari_db_rca_url ambari_db_rca_driver ambari_db_rca_username ambari_db_rca_password ambari_db_rca_url ambari_db_rca_driver ambari_db_rca_username ambari_db_rca_password,0,0,0,0,0,0,0 
1870,Matthew Farrellee,ambari-agent,0,ambari-agent RPM claims ownership of /usr/sbin, ambari agent ambari agent RPM claim ownership usr sbin usr sbin,This may impact other versions  only branch-1.2 was changed.The ambari-agent.spec (generated from rpm-maven-plugin) claims ownership of /usr/sbin $ grep sbin target/rpm/ambari-agent/SPECS/ambari-agent.spec | grep attr%attr(755 root root) /usr/sbinThis is a problem because the filesystem RPM owns /usr/sbin.According to rpm-maven-plugin documentation&#91;0&#93;  this is because the only file under /usr/sbin is ambari-agent and'directoryIncludedIf the value is true then the attribute string will be written for the directory if the sources identify all of the files in the directory (that is  no other mapping contributed files to the directory). This is the default behavior.'The 'no other mapping contributed files to the directory' bit is important.The solution is to add directoryInclude=false to the mapping.&#91;0&#93; http://mojo.codehaus.org/rpm-maven-plugin/map-params.html, may impact version branch branch chang chang ambari agent spec ambari agent spec gener rpm maven plugin rpm maven plugin claim ownership usr sbin usr sbin grep sbin target rpm ambari agent SPECS ambari agent spec target rpm ambari agent SPECS ambari agent spec grep attr attr attr attr root root root usr sbinThis usr sbin problem filesystem RPM own usr sbin accord usr sbin accord rpm maven plugin rpm maven plugin document document file usr sbin usr sbin ambari agent ambari agent directoryIncludedIf directori includ valu true attribut string written directori sourc identifi file directori no map contribut file directori directori default behavior behavior no map contribut file directori directori bit import import solut add directoryInclude fals directori includ fals map map,0,0,0,0,0,0,0 
1872,Jaimin D Jetly,ambari-web,0,Ambari FE is not setting proper value for fs.checkpoint.edits.dir, ambari FE not set proper valu fs checkpoint edit dir fs checkpoint edit dir,,,0,0,0,0,0,0,1 
1873,Yusaku Sako,ambari-web,0,HUE pid and log dir labels are flip flopped, HUE pid log dir label flip flop,,,0,0,0,0,0,0,0 
1880,Srimanth Gunturi,ambari-web,0,stacks2 API uses 'type' to refer to config tags and no longer exposes 'filename' as a property, stack stack API use type type refer config tag no longer expos filenam filenam properti,FE needs to be modified to not to use 'filename' in stacks API to get the config tags. The new property is 'type'., FE need modifi not use filenam filenam stack API get config tag tag new properti type type,0,0,0,0,0,0,1 
1881,Mahadev konar,null,0,API to map global properties to services is partially complete., API map global properti servic partial complet complet,API to map global properties to services is partially complete. The API gives 'global.xml' to approximately 47 properties. However the 'global' site has many more properties - so I dont know if some are fully missed., API map global properti servic partial complet complet API give global xml global xml approxim properti properti howev global global site mani properti dont know fulli miss miss,0,0,0,0,0,0,1 
1891,Srimanth Gunturi,ambari-web,0,Impossibility to scroll metric window after browser width changing, imposs scroll metric window browser width chang,Open detailed view of any metric diagram on Services page  for example 'Total Space Utilization'. After that change width of browser less than width of detailed view of metric diagram. Right arrow for graph time paging is invisible and we can't to resolve this problem using horizontal scrollbar., open detail view metric diagram servic page exampl total total space util util chang width browser less width detail view metric diagram diagram right arrow graph time page invis resolv problem use horizont scrollbar scrollbar,0,0,0,0,0,0,0 
1896,Srimanth Gunturi,ambari-web,0,Disable editing Capacity Scheduler on host configs, disabl edit capac schedul host config,Go to Configs tab of Host.Result: Queues in Capacity Scheduler category are editable.Expected: Queues in Capacity Scheduler category shouldn't be editable., Go config tab host result host result queue capac schedul categori edit expect edit expect queue capac schedul categori edit edit,0,0,0,0,0,0,1 
1912,Jaimin D Jetly,ambari-web,0,HBase master doesn't come up after disabling security., HBase base master come disabl secur secur,,,0,0,0,0,0,0,1 
1915,Siddharth Wagle,ambari-server,0,Client install tasks are shown twice in install progress popup, client instal task shown twice instal progress popup,Client is re-configured by re-installing all client only hosts. This results in multiple tasks for client install in the UI.API response:{ 'href' : 'http://ec2-50-17-99-21.compute-1.amazonaws.com:8080/api/v1/clusters/yusaku/requests/2'  'Requests' : { 'id' : 2  'cluster_name' : 'yusaku' }  'tasks' : [ { 'href' : 'http://ec2-50-17-99-21.compute-1.amazonaws.com:8080/api/v1/clusters/yusaku/requests/2/tasks/43'  'Tasks' : { 'exit_code' : 0  'stdout' : 'notice: /Stage[2]/Hdp-oozie/Configgenerator::Configfile[oozie-site]/File[/etc/oozie/conf/oozie-site.xml]/content: content changed '{md5}eaf59cc452c92e64b559071586150a08' to '{md5}cb15303aab1c384d19c102a6ce650ed2'/nnotice: Finished catalog run in 2.04 seconds'  'status' : 'COMPLETED'  'stderr' : 'none'  'host_name' : 'ip-10-40-19-235.ec2.internal'  'id' : 43  'cluster_name' : 'yusaku'  'attempt_cnt' : 1  'request_id' : 2  'command' : 'INSTALL'  'role' : 'OOZIE_CLIENT'  'start_time' : 1365743356709  'stage_id' : 1 } }  { 'href' : 'http://ec2-50-17-99-21.compute-1.amazonaws.com:8080/api/v1/clusters/yusaku/requests/2/tasks/51'  'Tasks' : { 'exit_code' : 999  'stdout' : ''  'status' : 'QUEUED'  'stderr' : ''  'host_name' : 'ip-10-40-19-235.ec2.internal'  'id' : 51  'cluster_name' : 'yusaku'  'attempt_cnt' : 1  'request_id' : 2  'command' : 'START'  'role' : 'GANGLIA_MONITOR'  'start_time' : 1365743407043  'stage_id' : 2 } }  { 'href' : 'http://ec2-50-17-99-21.compute-1.amazonaws.com:8080/api/v1/clusters/yusaku/requests/2/tasks/41'  'Tasks' : { 'exit_code' : 0  'stdout' : 'notice: Finished catalog run in 2.22 seconds'  'status' : 'COMPLETED'  'stderr' : 'none'  'host_name' : 'ip-10-40-19-235.ec2.internal'  'id' : 41  'cluster_name' : 'yusaku'  'attempt_cnt' : 1  'request_id' : 2  'command' : 'INSTALL'  'role' : 'HCAT'  'start_time' : 1365743356684  'stage_id' : 1 } }  { 'href' : 'http://ec2-50-17-99-21.compute-1.amazonaws.com:8080/api/v1/clusters/yusaku/requests/2/tasks/54'  'Tasks' : { 'exit_code' : 999  'stdout' : ''  'status' : 'QUEUED'  'stderr' : ''  'host_name' : 'ip-10-80-81-236.ec2.internal'  'id' : 54  'cluster_name' : 'yusaku'  'attempt_cnt' : 1  'request_id' : 2  'command' : 'START'  'role' : 'GANGLIA_SERVER'  'start_time' : 1365743407078  'stage_id' : 2 } }  { 'href' : 'http://ec2-50-17-99-21.compute-1.amazonaws.com:8080/api/v1/clusters/yusaku/requests/2/tasks/55'  'Tasks' : { 'exit_code' : 999  'stdout' : ''  'status' : 'QUEUED'  'stderr' : ''  'host_name' : 'ip-10-80-81-236.ec2.internal'  'id' : 55  'cluster_name' : 'yusaku'  'attempt_cnt' : 1  'request_id' : 2  'command' : 'START'  'role' : 'NAGIOS_SERVER'  'start_time' : 1365743407100  'stage_id' : 2 } }  { 'href' : 'http://ec2-50-17-99-21.compute-1.amazonaws.com:8080/api/v1/clusters/yusaku/requests/2/tasks/50'  'Tasks' : { 'exit_code' : 999  'stdout' : ''  'status' : 'QUEUED'  'stderr' : ''  'host_name' : 'ip-10-40-19-235.ec2.internal'  'id' : 50  'cluster_name' : 'yusaku'  'attempt_cnt' : 1  'request_id' : 2  'command' : 'START'  'role' : 'DATANODE'  'start_time' : 1365743407032  'stage_id' : 2 } }  { 'href' : 'http://ec2-50-17-99-21.compute-1.amazonaws.com:8080/api/v1/clusters/yusaku/requests/2/tasks/67'  'Tasks' : { 'exit_code' : 999  'stdout' : ''  'status' : 'PENDING'  'stderr' : ''  'host_name' : 'ip-10-40-19-235.ec2.internal'  'id' : 67  'cluster_name' : 'yusaku'  'attempt_cnt' : 0  'request_id' : 2  'command' : 'START'  'role' : 'HBASE_REGIONSERVER'  'start_time' : -1  'stage_id' : 4 } }  { 'href' : 'http://ec2-50-17-99-21.compute-1.amazonaws.com:8080/api/v1/clusters/yusaku/requests/2/tasks/47'  'Tasks' : { 'exit_code' : 0  'stdout' : 'warning: Dynamic lookup of $hadoop_heapsize is deprecated. Support will be removed in Puppet 2.8. Use a fully-qualified variable name (e.g.  $classname::variable) or parameterized classes./nnotice: /Stage[2]/Hdp-hive/Configgenerator::Configfile[hive-site]/File[/etc/hive/conf/hive-site.xml]/content: content changed '{md5}29d1def766d4aadfddbf38db13a2712e' to '{md5}2d26829fd012bf5f195e760fc8eeb7f9'/nnotice: Finished catalog run in 2.84 seconds'  'status' : 'COMPLETED'  'stderr' : 'none'  'host_name' : 'ip-10-80-81-236.ec2.internal'  'id' : 47  'cluster_name' : 'yusaku'  'attempt_cnt' : 1  'request_id' : 2  'command' : 'INSTALL'  'role' : 'HIVE_CLIENT'  'start_time' : 1365743356758  'stage_id' : 1 } }  { 'href' : 'http://ec2-50-17-99-21.compute-1.amazonaws.com:8080/api/v1/clusters/yusaku/requests/2/tasks/45'  'Tasks' : { 'exit_code' : 0  'stdout' : 'notice: Finished catalog run in 2.24 seconds'  'status' : 'COMPLETED'  'stderr' : 'none'  'host_name' : 'ip-10-40-19-235.ec2.internal'  'id' : 45  'cluster_name' : 'yusaku'  'attempt_cnt' : 1  'request_id' : 2  'command' : 'INSTALL'  'role' : 'SQOOP'  'start_time' : 1365743356733  'stage_id' : 1 } }  { 'href' : 'http://ec2-50-17-99-21.compute-1.amazonaws.com:8080/api/v1/clusters/yusaku/requests/2/tasks/44'  'Tasks' : { 'exit_code' : 0  'stdout' : 'notice: Finished catalog run in 2.13 seconds'  'status' : 'COMPLETED'  'stderr' : 'none'  'host_name' : 'ip-10-40-19-235.ec2.internal'  'id' : 44  'cluster_name' : 'yusaku'  'attempt_cnt' : 1  'request_id' : 2  'command' : 'INSTALL'  'role' : 'PIG'  'start_time' : 1365743356721  'stage_id' : 1 } }  { 'href' : 'http://ec2-50-17-99-21.compute-1.amazonaws.com:8080/api/v1/clusters/yusaku/requests/2/tasks/56'  'Tasks' : { 'exit_code' : 999  'stdout' : ''  'status' : 'QUEUED'  'stderr' : ''  'host_name' : 'ip-10-80-81-236.ec2.internal'  'id' : 56  'cluster_name' : 'yusaku'  'attempt_cnt' : 1  'request_id' : 2  'command' : 'START'  'role' : 'NAMENODE'  'start_time' : 1365743407109  'stage_id' : 2 } }  { 'href' : 'http://ec2-50-17-99-21.compute-1.amazonaws.com:8080/api/v1/clusters/yusaku/requests/2/tasks/52'  'Tasks' : { 'exit_code' : 999  'stdout' : ''  'status' : 'QUEUED'  'stderr' : ''  'host_name' : 'ip-10-40-19-235.ec2.internal'  'id' : 52  'cluster_name' : 'yusaku'  'attempt_cnt' : 1  'request_id' : 2  'command' : 'START'  'role' : 'ZOOKEEPER_SERVER'  'start_time' : 1365743407062  'stage_id' : 2 } }  { 'href' : 'http://ec2-50-17-99-21.compute-1.amazonaws.com:8080/api/v1/clusters/yusaku/requests/2/tasks/42'  'Tasks' : { 'exit_code' : 0  'stdout' : 'warning: Dynamic lookup of $hadoop_heapsize is deprecated. Support will be removed in Puppet 2.8. Use a fully-qualified variable name (e.g.  $classname::variable) or parameterized classes./nnotice: /Stage[2]/Hdp-hive/Configgenerator::Configfile[hive-site]/File[/etc/hive/conf/hive-site.xml]/content: content changed '{md5}27e517fec40f6157f75eb3116d5387bf' to '{md5}54ff14d0a6d9968e900f28853125b294'/nnotice: Finished catalog run in 2.28 seconds'  'status' : 'COMPLETED'  'stderr' : 'none'  'host_name' : 'ip-10-40-19-235.ec2.internal'  'id' : 42  'cluster_name' : 'yusaku'  'attempt_cnt' : 1  'request_id' : 2  'command' : 'INSTALL'  'role' : 'HIVE_CLIENT'  'start_time' : 1365743356697  'stage_id' : 1 } }  { 'href' : 'http://ec2-50-17-99-21.compute-1.amazonaws.com:8080/api/v1/clusters/yusaku/requests/2/tasks/63'  'Tasks' : { 'exit_code' : 999  'stdout' : ''  'status' : 'PENDING'  'stderr' : ''  'host_name' : 'ip-10-80-81-236.ec2.internal'  'id' : 63  'cluster_name' : 'yusaku'  'attempt_cnt' : 0  'request_id' : 2  'command' : 'START'  'role' : 'HBASE_MASTER'  'start_time' : -1  'stage_id' : 3 } }  { 'href' : 'http://ec2-50-17-99-21.compute-1.amazonaws.com:8080/api/v1/clusters/yusaku/requests/2/tasks/62'  'Tasks' : { 'exit_code' : 999  'stdout' : ''  'status' : 'PENDING'  'stderr' : ''  'host_name' : 'ip-10-40-19-235.ec2.internal'  'id' : 62  'cluster_name' : 'yusaku'  'attempt_cnt' : 0  'request_id' : 2  'command' : 'START'  'role' : 'TASKTRACKER'  'start_time' : -1  'stage_id' : 3 } }  { 'href' : 'http://ec2-50-17-99-21.compute-1.amazonaws.com:8080/api/v1/clusters/yusaku/requests/2/tasks/46'  'Tasks' : { 'exit_code' : 0  'stdout' : 'notice: Finished catalog run in 2.77 seconds'  'status' : 'COMPLETED'  'stderr' : 'none'  'host_name' : 'ip-10-80-81-236.ec2.internal'  'id' : 46  'cluster_name' : 'yusaku'  'attempt_cnt' : 1  'request_id' : 2  'command' : 'INSTALL'  'role' : 'HCAT'  'start_time' : 1365743356744  'stage_id' : 1 } }  { 'href' : 'http://ec2-50-17-99-21.compute-1.amazonaws.com:8080/api/v1/clusters/yusaku/requests/2/tasks/58'  'Tasks' : { 'exit_code' : 999  'stdout' : ''  'status' : 'QUEUED'  'stderr' : ''  'host_name' : 'ip-10-85-70-140.ec2.internal'  'id' : 58  'cluster_name' : 'yusaku'  'attempt_cnt' : 1  'request_id' : 2  'command' : 'START'  'role' : 'GANGLIA_MONITOR'  'start_time' : 1365743407125  'stage_id' : 2 } }  { 'href' : 'http://ec2-50-17-99-21.compute-1.amazonaws.com:8080/api/v1/clusters/yusaku/requests/2/tasks/60'  'Tasks' : { 'exit_code' : 999  'stdout' : ''  'status' : 'QUEUED'  'stderr' : ''  'host_name' : 'ip-10-85-70-140.ec2.internal'  'id' : 60  'cluster_name' : 'yusaku'  'attempt_cnt' : 1  'request_id' : 2  'command' : 'START'  'role' : 'ZOOKEEPER_SERVER'  'start_time' : 1365743407164  'stage_id' : 2 } }  { 'href' : 'http://ec2-50-17-99-21.compute-1.amazonaws.com:8080/api/v1/clusters/yusaku/requests/2/tasks/69'  'Tasks' : { 'exit_code' : 999  'stdout' : ''  'status' : 'PENDING'  'stderr' : ''  'host_name' : 'ip-10-85-70-140.ec2.internal'  'id' : 69  'cluster_name' : 'yusaku'  'attempt_cnt' : 0  'request_id' : 2  'command' : 'START'  'role' : 'OOZIE_SERVER'  'start_time' : -1  'stage_id' : 4 } }  { 'href' : 'http://ec2-50-17-99-21.compute-1.amazonaws.com:8080/api/v1/clusters/yusaku/requests/2/tasks/64'  'Tasks' : { 'exit_code' : 999  'stdout' : ''  'status' : 'PENDING'  'stderr' : ''  'host_name' : 'ip-10-85-70-140.ec2.internal'  'id' : 64  'cluster_name' : 'yusaku'  'attempt_cnt' : 0  'request_id' : 2  'command' : 'START'  'role' : 'HIVE_METASTORE'  'start_time' : -1  'stage_id' : 3 } }  { 'href' : 'http://ec2-50-17-99-21.compute-1.amazonaws.com:8080/api/v1/clusters/yusaku/requests/2/tasks/48'  'Tasks' : { 'exit_code' : 0  'stdout' : 'warning: Dynamic lookup of $service_state at /var/lib/ambari-agent/puppet/modules/hdp-hadoop/manifests/init.pp:213 is deprecated. Support will be removed in Puppet 2.8. Use a fully-qualified variable name (e.g.  $classname::variable) or parameterized classes./nwarning: Dynamic lookup of $tasktracker_port is deprecated. Support will be removed in Puppet 2.8. Use a fully-qualified variable name (e.g.  $classname::variable) or parameterized classes./nwarning: Dynamic lookup of $ambari_db_rca_url is deprecated. Support will be removed in Puppet 2.8. Use a fully-qualified variable name (e.g.  $classname::variable) or parameterized classes./nwarning: Dynamic lookup of $ambari_db_rca_driver is deprecated. Support will be removed in Puppet 2.8. Use a fully-qualified variable name (e.g.  $classname::variable) or parameterized classes./nwarning: Dynamic lookup of $ambari_db_rca_username is deprecated. Support will be removed in Puppet 2.8. Use a fully-qualified variable name (e.g.  $classname::variable) or parameterized classes./nwarning: Dynamic lookup of $ambari_db_rca_password is deprecated. Support will be removed in Puppet 2.8. Use a fully-qualified variable name (e.g.  $classname::variable) or parameterized classes./nnotice: /Stage[2]/Hdp-hadoop::Initialize/Configgenerator::Configfile[core-site]/File[/etc/hadoop/conf/core-site.xml]/content: content changed '{md5}95bdcddd064261ac3a00d8c0a7f79fee' to '{md5}d6f5b9646bf280e915e3b0d42ed622a9'/nnotice: /Stage[2]/Hdp-hadoop::Initialize/Configgenerator::Configfile[hdfs-site]/File[/etc/hadoop/conf/hdfs-site.xml]/content: content changed '{md5}5f83b57cbac46a0b7007ed94720a8c3b' to '{md5}e0e38c4dc10fc81b12637e34796ced70'/nnotice: /Stage[2]/Hdp-hadoop::Initialize/Configgenerator::Configfile[mapred-site]/File[/etc/hadoop/conf/mapred-site.xml]/content: content changed '{md5}42b54b8e096eafa7ba53c8f5b53bda3e' to '{md5}409f4680bc7871db2864afecbcefdb36'/nnotice: Finished catalog run in 3.67 seconds'  'status' : 'COMPLETED'  'stderr' : 'none'  'host_name' : 'ip-10-80-81-236.ec2.internal'  'id' : 48  'cluster_name' : 'yusaku'  'attempt_cnt' : 1  'request_id' : 2  'command' : 'INSTALL'  'role' : 'MAPREDUCE_CLIENT'  'start_time' : 1365743356769  'stage_id' : 1 } }  { 'href' : 'http://ec2-50-17-99-21.compute-1.amazonaws.com:8080/api/v1/clusters/yusaku/requests/2/tasks/70'  'Tasks' : { 'exit_code' : 999  'stdout' : ''  'status' : 'PENDING'  'stderr' : ''  'host_name' : 'ip-10-85-70-140.ec2.internal'  'id' : 70  'cluster_name' : 'yusaku'  'attempt_cnt' : 0  'request_id' : 2  'command' : 'START'  'role' : 'WEBHCAT_SERVER'  'start_time' : -1  'stage_id' : 5 } }  { 'href' : 'http://ec2-50-17-99-21.compute-1.amazonaws.com:8080/api/v1/clusters/yusaku/requests/2/tasks/61'  'Tasks' : { 'exit_code' : 999  'stdout' : ''  'status' : 'PENDING'  'stderr' : ''  'host_name' : 'ip-10-40-19-235.ec2.internal'  'id' : 61  'cluster_name' : 'yusaku'  'attempt_cnt' : 0  'request_id' : 2  'command' : 'START'  'role' : 'HBASE_MASTER'  'start_time' : -1  'stage_id' : 3 } }  { 'href' : 'http://ec2-50-17-99-21.compute-1.amazonaws.com:8080/api/v1/clusters/yusaku/requests/2/tasks/66'  'Tasks' : { 'exit_code' : 999  'stdout' : ''  'status' : 'PENDING'  'stderr' : ''  'host_name' : 'ip-10-85-70-140.ec2.internal'  'id' : 66  'cluster_name' : 'yusaku'  'attempt_cnt' : 0  'request_id' : 2  'command' : 'START'  'role' : 'SECONDARY_NAMENODE'  'start_time' : -1  'stage_id' : 3 } }  { 'href' : 'http://ec2-50-17-99-21.compute-1.amazonaws.com:8080/api/v1/clusters/yusaku/requests/2/tasks/49'  'Tasks' : { 'exit_code' : 0  'stdout' : 'notice: /Stage[2]/Hdp-oozie/Configgenerator::Configfile[oozie-site]/File[/etc/oozie/conf/oozie-site.xml]/content: content changed '{md5}001c4940080d2ea315a9720676f1bcad' to '{md5}282f1e354fe7f9da0f6de43425a40d40'/nnotice: Finished catalog run in 2.24 seconds'  'status' : 'COMPLETED'  'stderr' : 'none'  'host_name' : 'ip-10-80-81-236.ec2.internal'  'id' : 49  'cluster_name' : 'yusaku'  'attempt_cnt' : 1  'request_id' : 2  'command' : 'INSTALL'  'role' : 'OOZIE_CLIENT'  'start_time' : 1365743356796  'stage_id' : 1 } }  { 'href' : 'http://ec2-50-17-99-21.compute-1.amazonaws.com:8080/api/v1/clusters/yusaku/requests/2/tasks/53'  'Tasks' : { 'exit_code' : 999  'stdout' : ''  'status' : 'QUEUED'  'stderr' : ''  'host_name' : 'ip-10-80-81-236.ec2.internal'  'id' : 53  'cluster_name' : 'yusaku'  'attempt_cnt' : 1  'request_id' : 2  'command' : 'START'  'role' : 'GANGLIA_MONITOR'  'start_time' : 1365743407070  'stage_id' : 2 } }  { 'href' : 'http://ec2-50-17-99-21.compute-1.amazonaws.com:8080/api/v1/clusters/yusaku/requests/2/tasks/68'  'Tasks' : { 'exit_code' : 999  'stdout' : ''  'status' : 'PENDING'  'stderr' : ''  'host_name' : 'ip-10-85-70-140.ec2.internal'  'id' : 68  'cluster_name' : 'yusaku'  'attempt_cnt' : 0  'request_id' : 2  'command' : 'START'  'role' : 'HIVE_SERVER'  'start_time' : -1  'stage_id' : 4 } }  { 'href' : 'http://ec2-50-17-99-21.compute-1.amazonaws.com:8080/api/v1/clusters/yusaku/requests/2/tasks/65'  'Tasks' : { 'exit_code' : 999  'stdout' : ''  'status' : 'PENDING'  'stderr' : ''  'host_name' : 'ip-10-85-70-140.ec2.internal'  'id' : 65  'cluster_name' : 'yusaku'  'attempt_cnt' : 0  'request_id' : 2  'command' : 'START'  'role' : 'JOBTRACKER'  'start_time' : -1  'stage_id' : 3 } }  { 'href' : 'http://ec2-50-17-99-21.compute-1.amazonaws.com:8080/api/v1/clusters/yusaku/requests/2/tasks/57'  'Tasks' : { 'exit_code' : 999  'stdout' : ''  'status' : 'QUEUED'  'stderr' : ''  'host_name' : 'ip-10-80-81-236.ec2.internal'  'id' : 57  'cluster_name' : 'yusaku'  'attempt_cnt' : 1  'request_id' : 2  'command' : 'START'  'role' : 'ZOOKEEPER_SERVER'  'start_time' : 1365743407117  'stage_id' : 2 } }  { 'href' : 'http://ec2-50-17-99-21.compute-1.amazonaws.com:8080/api/v1/clusters/yusaku/requests/2/tasks/59'  'Tasks' : { 'exit_code' : 999  'stdout' : ''  'status' : 'QUEUED'  'stderr' : ''  'host_name' : 'ip-10-85-70-140.ec2.internal'  'id' : 59  'cluster_name' : 'yusaku'  'attempt_cnt' : 1  'request_id' : 2  'command' : 'START'  'role' : 'MYSQL_SERVER'  'start_time' : 1365743407156  'stage_id' : 2 } } ]}, client configur configur instal instal client host host result multipl task client instal UI API UI API respons respons href href http ec comput amazonaw com api cluster yusaku request http ec comput amazonaw com api cluster yusaku request request request id id cluster_name cluster_name yusaku yusaku task task href href http ec comput amazonaw com api cluster yusaku request task http ec comput amazonaw com api cluster yusaku request task task task exit_code exit_code stdout stdout notic notic stage hdp oozi configgener configfil oozi site file etc oozi conf oozi site xml content stage hdp oozi configgener configfil oozi site file etc oozi conf oozi site xml content content chang md eaf cc md eaf cc md cb aab ce ed nnotic md cb aab ce ed nnotic finish catalog run second second statu statu COMPLETED COMPLETED stderr stderr none none host_name host_name ip ec intern ip ec intern id id cluster_name cluster_name yusaku yusaku attempt_cnt attempt_cnt request_id request_id command command INSTALL INSTALL role role OOZIE_CLIENT OOZIE CLIENT start_time start_time stage_id stage_id href href http ec comput amazonaw com api cluster yusaku request task http ec comput amazonaw com api cluster yusaku request task task task exit_code exit_code stdout stdout statu statu QUEUED QUEUED stderr stderr host_name host_name ip ec intern ip ec intern id id cluster_name cluster_name yusaku yusaku attempt_cnt attempt_cnt request_id request_id command command START START role role GANGLIA_MONITOR GANGLIA MONITOR start_time start_time stage_id stage_id href href http ec comput amazonaw com api cluster yusaku request task http ec comput amazonaw com api cluster yusaku request task task task exit_code exit_code stdout stdout notic notic finish catalog run second second statu statu COMPLETED COMPLETED stderr stderr none none host_name host_name ip ec intern ip ec intern id id cluster_name cluster_name yusaku yusaku attempt_cnt attempt_cnt request_id request_id command command INSTALL INSTALL role role HCAT HCAT start_time start_time stage_id stage_id href href http ec comput amazonaw com api cluster yusaku request task http ec comput amazonaw com api cluster yusaku request task task task exit_code exit_code stdout stdout statu statu QUEUED QUEUED stderr stderr host_name host_name ip ec intern ip ec intern id id cluster_name cluster_name yusaku yusaku attempt_cnt attempt_cnt request_id request_id command command START START role role GANGLIA_SERVER GANGLIA SERVER start_time start_time stage_id stage_id href href http ec comput amazonaw com api cluster yusaku request task http ec comput amazonaw com api cluster yusaku request task task task exit_code exit_code stdout stdout statu statu QUEUED QUEUED stderr stderr host_name host_name ip ec intern ip ec intern id id cluster_name cluster_name yusaku yusaku attempt_cnt attempt_cnt request_id request_id command command START START role role NAGIOS_SERVER NAGIOS SERVER start_time start_time stage_id stage_id href href http ec comput amazonaw com api cluster yusaku request task http ec comput amazonaw com api cluster yusaku request task task task exit_code exit_code stdout stdout statu statu QUEUED QUEUED stderr stderr host_name host_name ip ec intern ip ec intern id id cluster_name cluster_name yusaku yusaku attempt_cnt attempt_cnt request_id request_id command command START START role role DATANODE DATANODE start_time start_time stage_id stage_id href href http ec comput amazonaw com api cluster yusaku request task http ec comput amazonaw com api cluster yusaku request task task task exit_code exit_code stdout stdout statu statu PENDING PENDING stderr stderr host_name host_name ip ec intern ip ec intern id id cluster_name cluster_name yusaku yusaku attempt_cnt attempt_cnt request_id request_id command command START START role role HBASE_REGIONSERVER HBASE REGIONSERVER start_time start_time stage_id stage_id href href http ec comput amazonaw com api cluster yusaku request task http ec comput amazonaw com api cluster yusaku request task task task exit_code exit_code stdout stdout warn warn dynam lookup hadoop_heapsize deprec deprec support remov puppet use fulli qualifi fulli qualifi variabl name classnam variabl classnam variabl parameter class nnotic class nnotic stage hdp hive configgener configfil hive site file etc hive conf hive site xml content stage hdp hive configgener configfil hive site file etc hive conf hive site xml content content chang md def aadfddbf db md def aadfddbf db md fd bf fc eeb nnotic md fd bf fc eeb nnotic finish catalog run second second statu statu COMPLETED COMPLETED stderr stderr none none host_name host_name ip ec intern ip ec intern id id cluster_name cluster_name yusaku yusaku attempt_cnt attempt_cnt request_id request_id command command INSTALL INSTALL role role HIVE_CLIENT HIVE CLIENT start_time start_time stage_id stage_id href href http ec comput amazonaw com api cluster yusaku request task http ec comput amazonaw com api cluster yusaku request task task task exit_code exit_code stdout stdout notic notic finish catalog run second second statu statu COMPLETED COMPLETED stderr stderr none none host_name host_name ip ec intern ip ec intern id id cluster_name cluster_name yusaku yusaku attempt_cnt attempt_cnt request_id request_id command command INSTALL INSTALL role role SQOOP SQOOP start_time start_time stage_id stage_id href href http ec comput amazonaw com api cluster yusaku request task http ec comput amazonaw com api cluster yusaku request task task task exit_code exit_code stdout stdout notic notic finish catalog run second second statu statu COMPLETED COMPLETED stderr stderr none none host_name host_name ip ec intern ip ec intern id id cluster_name cluster_name yusaku yusaku attempt_cnt attempt_cnt request_id request_id command command INSTALL INSTALL role role PIG PIG start_time start_time stage_id stage_id href href http ec comput amazonaw com api cluster yusaku request task http ec comput amazonaw com api cluster yusaku request task task task exit_code exit_code stdout stdout statu statu QUEUED QUEUED stderr stderr host_name host_name ip ec intern ip ec intern id id cluster_name cluster_name yusaku yusaku attempt_cnt attempt_cnt request_id request_id command command START START role role NAMENODE NAMENODE start_time start_time stage_id stage_id href href http ec comput amazonaw com api cluster yusaku request task http ec comput amazonaw com api cluster yusaku request task task task exit_code exit_code stdout stdout statu statu QUEUED QUEUED stderr stderr host_name host_name ip ec intern ip ec intern id id cluster_name cluster_name yusaku yusaku attempt_cnt attempt_cnt request_id request_id command command START START role role ZOOKEEPER_SERVER ZOOKEEPER SERVER start_time start_time stage_id stage_id href href http ec comput amazonaw com api cluster yusaku request task http ec comput amazonaw com api cluster yusaku request task task task exit_code exit_code stdout stdout warn warn dynam lookup hadoop_heapsize deprec deprec support remov puppet use fulli qualifi fulli qualifi variabl name classnam variabl classnam variabl parameter class nnotic class nnotic stage hdp hive configgener configfil hive site file etc hive conf hive site xml content stage hdp hive configgener configfil hive site file etc hive conf hive site xml content content chang md fec eb bf md fec eb bf md ff nnotic md ff nnotic finish catalog run second second statu statu COMPLETED COMPLETED stderr stderr none none host_name host_name ip ec intern ip ec intern id id cluster_name cluster_name yusaku yusaku attempt_cnt attempt_cnt request_id request_id command command INSTALL INSTALL role role HIVE_CLIENT HIVE CLIENT start_time start_time stage_id stage_id href href http ec comput amazonaw com api cluster yusaku request task http ec comput amazonaw com api cluster yusaku request task task task exit_code exit_code stdout stdout statu statu PENDING PENDING stderr stderr host_name host_name ip ec intern ip ec intern id id cluster_name cluster_name yusaku yusaku attempt_cnt attempt_cnt request_id request_id command command START START role role HBASE_MASTER HBASE MASTER start_time start_time stage_id stage_id href href http ec comput amazonaw com api cluster yusaku request task http ec comput amazonaw com api cluster yusaku request task task task exit_code exit_code stdout stdout statu statu PENDING PENDING stderr stderr host_name host_name ip ec intern ip ec intern id id cluster_name cluster_name yusaku yusaku attempt_cnt attempt_cnt request_id request_id command command START START role role TASKTRACKER TASKTRACKER start_time start_time stage_id stage_id href href http ec comput amazonaw com api cluster yusaku request task http ec comput amazonaw com api cluster yusaku request task task task exit_code exit_code stdout stdout notic notic finish catalog run second second statu statu COMPLETED COMPLETED stderr stderr none none host_name host_name ip ec intern ip ec intern id id cluster_name cluster_name yusaku yusaku attempt_cnt attempt_cnt request_id request_id command command INSTALL INSTALL role role HCAT HCAT start_time start_time stage_id stage_id href href http ec comput amazonaw com api cluster yusaku request task http ec comput amazonaw com api cluster yusaku request task task task exit_code exit_code stdout stdout statu statu QUEUED QUEUED stderr stderr host_name host_name ip ec intern ip ec intern id id cluster_name cluster_name yusaku yusaku attempt_cnt attempt_cnt request_id request_id command command START START role role GANGLIA_MONITOR GANGLIA MONITOR start_time start_time stage_id stage_id href href http ec comput amazonaw com api cluster yusaku request task http ec comput amazonaw com api cluster yusaku request task task task exit_code exit_code stdout stdout statu statu QUEUED QUEUED stderr stderr host_name host_name ip ec intern ip ec intern id id cluster_name cluster_name yusaku yusaku attempt_cnt attempt_cnt request_id request_id command command START START role role ZOOKEEPER_SERVER ZOOKEEPER SERVER start_time start_time stage_id stage_id href href http ec comput amazonaw com api cluster yusaku request task http ec comput amazonaw com api cluster yusaku request task task task exit_code exit_code stdout stdout statu statu PENDING PENDING stderr stderr host_name host_name ip ec intern ip ec intern id id cluster_name cluster_name yusaku yusaku attempt_cnt attempt_cnt request_id request_id command command START START role role OOZIE_SERVER OOZIE SERVER start_time start_time stage_id stage_id href href http ec comput amazonaw com api cluster yusaku request task http ec comput amazonaw com api cluster yusaku request task task task exit_code exit_code stdout stdout statu statu PENDING PENDING stderr stderr host_name host_name ip ec intern ip ec intern id id cluster_name cluster_name yusaku yusaku attempt_cnt attempt_cnt request_id request_id command command START START role role HIVE_METASTORE HIVE METASTORE start_time start_time stage_id stage_id href href http ec comput amazonaw com api cluster yusaku request task http ec comput amazonaw com api cluster yusaku request task task task exit_code exit_code stdout stdout warn warn dynam lookup service_state var lib ambari agent puppet modul hdp hadoop manifest init pp var lib ambari agent puppet modul hdp hadoop manifest init pp deprec deprec support remov puppet use fulli qualifi fulli qualifi variabl name classnam variabl classnam variabl parameter class nwarn class nwarn dynam lookup tasktracker_port deprec deprec support remov puppet use fulli qualifi fulli qualifi variabl name classnam variabl classnam variabl parameter class nwarn class nwarn dynam lookup ambari_db_rca_url deprec deprec support remov puppet use fulli qualifi fulli qualifi variabl name classnam variabl classnam variabl parameter class nwarn class nwarn dynam lookup ambari_db_rca_driver deprec deprec support remov puppet use fulli qualifi fulli qualifi variabl name classnam variabl classnam variabl parameter class nwarn class nwarn dynam lookup ambari_db_rca_username deprec deprec support remov puppet use fulli qualifi fulli qualifi variabl name classnam variabl classnam variabl parameter class nwarn class nwarn dynam lookup ambari_db_rca_password deprec deprec support remov puppet use fulli qualifi fulli qualifi variabl name classnam variabl classnam variabl parameter class nnotic class nnotic stage hdp hadoop initi configgener configfil core site file etc hadoop conf core site xml content stage hdp hadoop initi configgener configfil core site file etc hadoop conf core site xml content content chang md bdcddd ac fee md bdcddd ac fee md bf ed nnotic md bf ed nnotic stage hdp hadoop initi configgener configfil hdf site file etc hadoop conf hdf site xml content stage hdp hadoop initi configgener configfil hdf site file etc hadoop conf hdf site xml content content chang md cbac ed md cbac ed md dc fc ced nnotic md dc fc ced nnotic stage hdp hadoop initi configgener configfil mapr site file etc hadoop conf mapr site xml content stage hdp hadoop initi configgener configfil mapr site file etc hadoop conf mapr site xml content content chang md eafa ba bda md eafa ba bda md bc db afecbcefdb nnotic md bc db afecbcefdb nnotic finish catalog run second second statu statu COMPLETED COMPLETED stderr stderr none none host_name host_name ip ec intern ip ec intern id id cluster_name cluster_name yusaku yusaku attempt_cnt attempt_cnt request_id request_id command command INSTALL INSTALL role role MAPREDUCE_CLIENT MAPREDUCE CLIENT start_time start_time stage_id stage_id href href http ec comput amazonaw com api cluster yusaku request task http ec comput amazonaw com api cluster yusaku request task task task exit_code exit_code stdout stdout statu statu PENDING PENDING stderr stderr host_name host_name ip ec intern ip ec intern id id cluster_name cluster_name yusaku yusaku attempt_cnt attempt_cnt request_id request_id command command START START role role WEBHCAT_SERVER WEBHCAT SERVER start_time start_time stage_id stage_id href href http ec comput amazonaw com api cluster yusaku request task http ec comput amazonaw com api cluster yusaku request task task task exit_code exit_code stdout stdout statu statu PENDING PENDING stderr stderr host_name host_name ip ec intern ip ec intern id id cluster_name cluster_name yusaku yusaku attempt_cnt attempt_cnt request_id request_id command command START START role role HBASE_MASTER HBASE MASTER start_time start_time stage_id stage_id href href http ec comput amazonaw com api cluster yusaku request task http ec comput amazonaw com api cluster yusaku request task task task exit_code exit_code stdout stdout statu statu PENDING PENDING stderr stderr host_name host_name ip ec intern ip ec intern id id cluster_name cluster_name yusaku yusaku attempt_cnt attempt_cnt request_id request_id command command START START role role SECONDARY_NAMENODE SECONDARY NAMENODE start_time start_time stage_id stage_id href href http ec comput amazonaw com api cluster yusaku request task http ec comput amazonaw com api cluster yusaku request task task task exit_code exit_code stdout stdout notic notic stage hdp oozi configgener configfil oozi site file etc oozi conf oozi site xml content stage hdp oozi configgener configfil oozi site file etc oozi conf oozi site xml content content chang md ea bcad md ea bcad md fe da de nnotic md fe da de nnotic finish catalog run second second statu statu COMPLETED COMPLETED stderr stderr none none host_name host_name ip ec intern ip ec intern id id cluster_name cluster_name yusaku yusaku attempt_cnt attempt_cnt request_id request_id command command INSTALL INSTALL role role OOZIE_CLIENT OOZIE CLIENT start_time start_time stage_id stage_id href href http ec comput amazonaw com api cluster yusaku request task http ec comput amazonaw com api cluster yusaku request task task task exit_code exit_code stdout stdout statu statu QUEUED QUEUED stderr stderr host_name host_name ip ec intern ip ec intern id id cluster_name cluster_name yusaku yusaku attempt_cnt attempt_cnt request_id request_id command command START START role role GANGLIA_MONITOR GANGLIA MONITOR start_time start_time stage_id stage_id href href http ec comput amazonaw com api cluster yusaku request task http ec comput amazonaw com api cluster yusaku request task task task exit_code exit_code stdout stdout statu statu PENDING PENDING stderr stderr host_name host_name ip ec intern ip ec intern id id cluster_name cluster_name yusaku yusaku attempt_cnt attempt_cnt request_id request_id command command START START role role HIVE_SERVER HIVE SERVER start_time start_time stage_id stage_id href href http ec comput amazonaw com api cluster yusaku request task http ec comput amazonaw com api cluster yusaku request task task task exit_code exit_code stdout stdout statu statu PENDING PENDING stderr stderr host_name host_name ip ec intern ip ec intern id id cluster_name cluster_name yusaku yusaku attempt_cnt attempt_cnt request_id request_id command command START START role role JOBTRACKER JOBTRACKER start_time start_time stage_id stage_id href href http ec comput amazonaw com api cluster yusaku request task http ec comput amazonaw com api cluster yusaku request task task task exit_code exit_code stdout stdout statu statu QUEUED QUEUED stderr stderr host_name host_name ip ec intern ip ec intern id id cluster_name cluster_name yusaku yusaku attempt_cnt attempt_cnt request_id request_id command command START START role role ZOOKEEPER_SERVER ZOOKEEPER SERVER start_time start_time stage_id stage_id href href http ec comput amazonaw com api cluster yusaku request task http ec comput amazonaw com api cluster yusaku request task task task exit_code exit_code stdout stdout statu statu QUEUED QUEUED stderr stderr host_name host_name ip ec intern ip ec intern id id cluster_name cluster_name yusaku yusaku attempt_cnt attempt_cnt request_id request_id command command START START role role MYSQL_SERVER MYSQL SERVER start_time start_time stage_id stage_id,0,0,0,0,0,0,1 
1917,Jaimin D Jetly,null,0,Ambari Core-Site.xml Missing Property for LZO (enabled) - io.compression.codecs, ambari core site xml core site xml miss properti LZO enabl enabl io compress codec io compress codec,,,0,0,0,0,0,0,1 
1919,Sumit Mohanty,null,0,JobTracker History Server failed to come up on 1.3.0 stack and the request for service stall is stalled, JobTracker job tracker histori server fail come stack request servic stall stall,Attempted to install a cluster with 1.3.0 stack.Service install was all green  but JobTracker History Server failed to come up.The request for the service start is stalled  with no tasks in QUEUED or IN_PROGRESS state  but with some tasks in PENDING state., attempt instal cluster stack servic stack servic instal green JobTracker job tracker histori server fail come request servic start stall no task QUEUED IN_PROGRESS PROGRESS state task PENDING state state,0,0,0,0,0,0,0 
1924,Sumit Mohanty,null,0,Allow for users to customize Ganglia gmetad + gmond user accounts, allow user custom ganglia gmetad gmond user account,Allow customization of ganglia gmetad and gmond users.For reference: looks like this is available in gsInstaller so the pattern exists to follow for Ambari impl. Defaults to nobody/nobody, allow custom ganglia gmetad gmond user user refer refer look like avail gsInstaller gs instal pattern exist follow ambari impl impl default nobodi nobodi nobodi nobodi,0,0,0,0,0,0,1 
1933,Sumit Mohanty,null,0,Test failure : testCascadeDeleteStages, test failur testCascadeDeleteStages test cascad delet stage,mvn clean install produces the following failure ...testCascadeDeleteStages(org.apache.ambari.server.actionmanager.TestActionManager):Exception [EclipseLink-4002] (Eclipse Persistence Services -2.4.0.v20120608-r11652):org.eclipse.persistence.exceptions.DatabaseException(..), mvn clean instal produc follow failur testCascadeDeleteStages org apach ambari server actionmanag TestActionManager except test cascad delet stage org apach ambari server actionmanag test action manag except EclipseLink eclips link eclips eclips persist servic org eclips persist except DatabaseException org eclips persist except databas except,0,0,0,0,0,0,0 
1934,Sumit Mohanty,null,0,Security vulnerability with Ganglia and Nagios, secur vulner ganglia nagio,Ganglia Issue : Unspecified vulnerability in Ganglia Web before 3.5.1 allows remote attackers to execute arbitrary PHP code via unknown attack vectors. http://ganglia.info/?p=549 Ganglia Web 3.5.1 Release Security Advisory There is a security issue in Ganglia Web going back to at least 3.1.7 which can lead to arbitrary script being executed with web user privileges possibly leading to a machine compromise. Issue has been fixed in the latest version of Ganglia Web which can be downloaded from https://sourceforge.net/projects/ganglia/files/ganglia-web/3.5.1/ Solution: Need to get upgraded rpms with the Ganglia Web version 3.5.7 which has the fix for this vulnerability.Nagios: Multiple stack-based buffer overflows in the get_history function in history.cgi in Nagios Core before 3.4.4  and Icinga 1.6.x before 1.6.2  1.7.x before 1.7.4  and 1.8.x before 1.8.4  might allow remote attackers to execute arbitrary code via a long (1) host_name variable (host parameter) or (2) svc_description variable. http://www.nagios.org/projects/nagioscore/history/core-3x http://lists.grok.org.uk/pipermail/full-disclosure/2012-December/089125.html Vulnerable software and versions - nagios:nagios:3.4.3 and previous versions, ganglia issu unspecifi vulner ganglia web allow remot attack execut arbitrari PHP code via unknown attack vector vector ganglia web releas secur secur advisori secur issu ganglia web go back least lead arbitrari script execut web user privileg possibl lead machin compromis compromis issu fix latest version ganglia web download solut solut need get upgrad rpm ganglia web version fix vulner nagio vulner nagio multipl stack base stack base buffer overflow get_history function histori cgi histori cgi nagio core icinga might allow remot attack execut arbitrari code via long host_name variabl host paramet paramet svc_description variabl variabl vulner softwar version nagio nagio nagio nagio previou version,0,0,0,0,0,0,1 
1944,Siddharth Wagle,ambari-server,0,All Service Smoke tests fail when run with service start, servic smoke test fail run servic start,has_key(): expects the first argument to be a hash  got '' which is of type String at /var/lib/ambari-agent/puppet/modules/hdp/manifests/init.pp:38 on node ip-10-38-25-227.ec2.internalsite-pp#12.04.2013 03:16:38import '/var/lib/ambari-agent/puppet/modules/hdp/manifests/*.pp'import '/var/lib/ambari-agent/puppet/modules/hdp-hadoop/manifests/*.pp'import '/var/lib/ambari-agent/puppet/modules/hdp-hbase/manifests/*.pp'import '/var/lib/ambari-agent/puppet/modules/hdp-zookeeper/manifests/*.pp'import '/var/lib/ambari-agent/puppet/modules/hdp-oozie/manifests/*.pp'import '/var/lib/ambari-agent/puppet/modules/hdp-pig/manifests/*.pp'import '/var/lib/ambari-agent/puppet/modules/hdp-sqoop/manifests/*.pp'import '/var/lib/ambari-agent/puppet/modules/hdp-templeton/manifests/*.pp'import '/var/lib/ambari-agent/puppet/modules/hdp-hive/manifests/*.pp'import '/var/lib/ambari-agent/puppet/modules/hdp-hcat/manifests/*.pp'import '/var/lib/ambari-agent/puppet/modules/hdp-mysql/manifests/*.pp'import '/var/lib/ambari-agent/puppet/modules/hdp-monitor-webserver/manifests/*.pp'import '/var/lib/ambari-agent/puppet/modules/hdp-repos/manifests/*.pp'$ambari_db_rca_password= ['mapred']$nagios_server_host= ['ip-10-38-25-227.ec2.internal']$ambari_db_rca_url= ['jdbc:postgresql://ip-10-38-25-227.ec2.internal/ambarirca']$webhcat_server_host= ['ip-10-38-25-227.ec2.internal']$hbase_rs_hosts= ['ip-10-38-25-227.ec2.internal']$slave_hosts= ['ip-10-38-25-227.ec2.internal']$namenode_host= ['ip-10-38-25-227.ec2.internal']$ganglia_server_host= ['ip-10-38-25-227.ec2.internal']$hbase_master_hosts= ['ip-10-38-25-227.ec2.internal']$hive_mysql_host= ['ip-10-38-25-227.ec2.internal']$oozie_server= ['ip-10-38-25-227.ec2.internal']$ambari_db_rca_driver= ['org.postgresql.Driver']$zookeeper_hosts= ['ip-10-38-25-227.ec2.internal']$jtnode_host= ['ip-10-38-25-227.ec2.internal']$ambari_db_rca_username= ['mapred']$hive_server_host= ['ip-10-38-25-227.ec2.internal']node /default/ { stage{1 :} -&gt; stage{2 :}class {'hdp': stage =&gt; 1}class {'hdp-zookeeper::quorum::service_check': stage =&gt; 2}}, has_key has_key expect first argument hash got type string var lib ambari agent puppet modul hdp manifest init pp var lib ambari agent puppet modul hdp manifest init pp node ip ec internalsit pp ip ec internalsit pp import var lib ambari agent puppet modul hdp manifest pp import var lib ambari agent puppet modul hdp manifest pp import var lib ambari agent puppet modul hdp hadoop manifest pp import var lib ambari agent puppet modul hdp hadoop manifest pp import var lib ambari agent puppet modul hdp hbase manifest pp import var lib ambari agent puppet modul hdp hbase manifest pp import var lib ambari agent puppet modul hdp zookeep manifest pp import var lib ambari agent puppet modul hdp zookeep manifest pp import var lib ambari agent puppet modul hdp oozi manifest pp import var lib ambari agent puppet modul hdp oozi manifest pp import var lib ambari agent puppet modul hdp pig manifest pp import var lib ambari agent puppet modul hdp pig manifest pp import var lib ambari agent puppet modul hdp sqoop manifest pp import var lib ambari agent puppet modul hdp sqoop manifest pp import var lib ambari agent puppet modul hdp templeton manifest pp import var lib ambari agent puppet modul hdp templeton manifest pp import var lib ambari agent puppet modul hdp hive manifest pp import var lib ambari agent puppet modul hdp hive manifest pp import var lib ambari agent puppet modul hdp hcat manifest pp import var lib ambari agent puppet modul hdp hcat manifest pp import var lib ambari agent puppet modul hdp mysql manifest pp import var lib ambari agent puppet modul hdp mysql manifest pp import var lib ambari agent puppet modul hdp monitor webserv manifest pp import var lib ambari agent puppet modul hdp monitor webserv manifest pp import var lib ambari agent puppet modul hdp repo manifest pp ambari_db_rca_password var lib ambari agent puppet modul hdp repo manifest pp ambari_db_rca_password mapr nagios_server_host mapr nagios_server_host ip ec intern ambari_db_rca_url ip ec intern ambari_db_rca_url jdbc postgresql ip ec intern ambarirca webhcat_server_host jdbc postgresql ip ec intern ambarirca webhcat_server_host ip ec intern hbase_rs_hosts ip ec intern hbase_rs_hosts ip ec intern slave_hosts ip ec intern slave_hosts ip ec intern namenode_host ip ec intern namenode_host ip ec intern ganglia_server_host ip ec intern ganglia_server_host ip ec intern hbase_master_hosts ip ec intern hbase_master_hosts ip ec intern hive_mysql_host ip ec intern hive_mysql_host ip ec intern oozie_server ip ec intern oozie_server ip ec intern ambari_db_rca_driver ip ec intern ambari_db_rca_driver org postgresql driver zookeeper_hosts org postgresql driver zookeeper_hosts ip ec intern jtnode_host ip ec intern jtnode_host ip ec intern ambari_db_rca_username ip ec intern ambari_db_rca_username mapr hive_server_host mapr hive_server_host ip ec intern node ip ec intern node default default stage stage gt gt stage stage class hdp hdp stage gt gt class hdp zookeep quorum service_check hdp zookeep quorum service_check stage gt gt,0,0,0,0,0,0,0 
1947,Siddharth Wagle,ambari-agent,0,Oozie Smoke test fails with errors on the start services/install page., oozi smoke test fail error start servic instal servic instal page page,Ozzie smoke tests fail, ozzi smoke test fail,0,0,0,0,0,0,0 
1948,Siddharth Wagle,ambari-agent,0,System logs are not present on tasktracker, system log not present tasktrack,Run a mapreduce job.Find the attempt id and look for system logs on tasktracker.http://ec2-54-224-138-78.compute-1.amazonaws.com:50060/tasklog?attemptid=attempt_201304121816_0003_m_000000_0Actual result:The syslogs are not present here.Only stdout and stderr logs are present., run mapreduc job find job find attempt id look system log tasktrack http ec comput amazonaw com tasklog attemptid attempt   actual tasktrack http ec comput amazonaw com tasklog attemptid attempt   actual result result syslog not present stdout stderr log present present,0,0,0,0,0,0,1 
1952,Ashish Singh,infra,0,hadoop dependency version for ambari-log4j is hardcoded  making it regular expression based to pick latest from the repository., hadoop depend version ambari log ambari log hardcod make regular express base pick latest repositori repositori,Ambari-log4j has hardcoded hadoop-core and hadoop-tools dependency. Make it version as regular expression to pick from the range from 1.0 &lt;= x &lt; 2.0.Also  updating the repository url., ambari log ambari log hardcod hadoop core hadoop core hadoop tool hadoop tool depend depend make version regular express pick rang lt lt lt lt also also updat repositori url url,0,0,0,0,0,0,1 
1956,Yusaku Sako,ambari-web,0,Wrong install status shown in Add Service Wizard, wrong instal statu shown add servic wizard,Upon master component install failure  the host status becomes 'warning' instead of 'failed' for Add Service Wizard., upon master compon instal failur host statu becom warn warn instead fail fail add servic wizard wizard,0,0,0,0,0,0,1 
1957,Yusaku Sako,ambari-web,0,Hosts table: whether the alert filter is in effect or not is not clear, host tabl tabl whether alert filter effect not not clear,Currently  when the red badge inside the Hosts tab is clicked  it shows hosts that have at least one alert and no other hosts are displayed.The fact that the alert filter is in effect is not clear to the user and causes confusion., current red badg insid host tab click show host least one alert no host display display fact alert filter effect not clear user caus confus confus,0,0,0,0,0,0,0 
1966,Yusaku Sako,ambari-web,0,Client install tasks are shown twice in progress popup during start phase of install wizard (update API call to include params/reconfigure_client), client instal task shown twice progress popup start phase instal wizard updat API call includ param reconfigure_client param reconfigure_client,,,0,0,0,0,0,0,1 
1978,Siddharth Wagle,ambari-agent,0,Deploying HDP-1.3.0 results in several alerts - is it related to hard-coded port, deploy HDP HDP result sever alert relat hard code hard code port,TaskTracker  RegionServer  HBase master process down because check_tcp failure.Looks like the hadoop-services.cfg.erb has:check_command check_tcp!&lt;%=scope.function_hdp_template_var('jtnode_port')%&gt;!-w 1 -c 1and looks like the ports are not getting replaced and end up being empty., TaskTracker task tracker RegionServer region server HBase base master process check_tcp failur look failur look like hadoop servic cfg erb hadoop servic cfg erb check_command check_command check_tcp lt scope function_hdp_template_var jtnode_port gt check_tcp lt scope function_hdp_template_var jtnode_port gt look like port not get replac end empti empti,0,0,0,0,0,0,0 
1980,Nate Cole,null,0,When nagios is unavailable  return null instead of throwing an Exception, nagio unavail return null instead throw except,NAGIOS_SERVER alerts are retrieved from the nagios server when requesting the host_component. There is a SystemException thrown in the case of an IOException  which propagates as a 500 error for the entire request.In this case  set the nagios_alerts element to null instead of the 500 error., NAGIOS_SERVER NAGIOS SERVER alert retriev nagio server request host_component host_component SystemException system except thrown case IOException IO except propag error entir request request case set nagios_alerts element null instead error error,0,0,0,0,0,0,0 
1988,Yusaku Sako,ambari-web,0,Hostname pattern expression is broken, hostnam pattern express broken,dev[01-03].domain.com expanded to:dev1.domain.comdev2.domain.comdev3.domain.comShould be:dev01.domain.comdev02.domain.comdev03.domain.com, dev domain com dev domain com expand dev domain comdev domain comdev domain comShould dev domain comdev domain comdev domain com dev domain comdev domain comdev domain com dev domain comdev domain comdev domain com,0,0,0,0,0,0,0 
1997,Yusaku Sako,ambari-web,0,Filtered hosts get out of sync with the filter selection, filter host get sync filter select,1. Browse to Hosts2. Click one of the filters3. Browse to Services and back to Hosts4. The filter links show All as the current filter but the filter didn't reset and still shows a sub-set of hosts, brows host host click one filter filter brows servic back host host filter link show current filter filter reset still show sub set sub set host,0,0,0,0,0,0,0 
1998,Yusaku Sako,ambari-web,0,Action buttons on host details page not formatted properly on Firefox, action button host detail page not format properli firefox,,,0,0,0,0,0,0,0 
1999,Yusaku Sako,ambari-web,0,Clicking on Cancel on the Service Config page should not reload the entire app, click cancel servic config page not reload entir app,When Cancel is clicked on the Service Config page  simply reload the config (not the entire app)., cancel click servic config page simpli reload config not entir app app,0,0,0,0,0,0,1 
2001,Yusaku Sako,ambari-web,0,Filtering on Jobs table does not work under certain situations, filter job tabl not work certain situat,,,0,0,0,0,0,0,1 
2008,Sumit Mohanty,null,0,Using mixed OS overwrites ambari.repo during install, use mix OS overwrit ambari repo ambari repo instal,Performed install on mixed OS environment with 8 hosts.Ambari Server = RHEL6Three Hosts = RHEL6Four Hosts = RHEL5Performed manual ambari-agent bootstrap of the Four RHEL5 hosts. I was able to successfully register all hosts. When install started  the four RHEL5 hosts failed on installing their first component. Looking at the servers  looks like the right HDP.repo and HDP-epel.repo files are put in place.But looks like the ambari.repo file had been overwritten at some point during the install process  and now is point to the RHEL6 repos  causing failures., perform instal mix OS environ host ambari host ambari server RHEL three RHEL three host RHEL four RHEL four host RHEL perform RHEL perform manual ambari agent ambari agent bootstrap four RHEL RHEL host host abl success regist host host instal start four RHEL RHEL host fail instal first compon compon look server look like right HDP repo HDP repo HDP epel repo HDP epel repo file put place place look like ambari repo ambari repo file overwritten point instal process point RHEL RHEL repo caus failur failur,0,0,0,0,0,0,1 
2013,Nate Cole,null,0,Cannot delete cluster with components in UNKNOWN state, cannot delet cluster compon UNKNOWN state,When components are marked in an UNKNOWN state  it is not possible to delete the cluster - this should be possible., compon mark UNKNOWN state not possibl delet cluster possibl possibl,0,0,0,0,0,0,0 
2019,Siddharth Wagle,ambari-server,0,Cannot decommission data node (ensure recommission also works), cannot decommiss data node ensur recommiss also work work,stderr: $configuration&#91;hdfs-site&#93; is not an hash or array when accessing it with dfs.hosts.exclude at /var/lib/ambari-agent/puppet/modules/hdp-hadoop/manifests/hdfs/decommission.pp:24 on node ip-10-82-213-66.ec2.internal stdout:None, stderr stderr configur hdf site configur hdf site not hash array access df host exclud df host exclud var lib ambari agent puppet modul hdp hadoop manifest hdf decommiss pp var lib ambari agent puppet modul hdp hadoop manifest hdf decommiss pp node ip ec intern ip ec intern stdout none stdout none,0,0,0,0,0,0,0 
2024,Siddharth Wagle,ambari-server,0,Ambari Server becomes unresponsive after crashing on http reads on jersey., ambari server becom unrespons crash http read jersey jersey,The api's are being handled by a queuedthreadpool. The queuedthread pool size is 25.Somehow the http connections are being torn down from the UI side but the server still is hanging onto that socket and reading (most likely UI will also need to close http connections if its not using them - which might be an issue as well but doesnt have to addressed as urgent). The server has a read timeout of 0 which means it will just hang on to that socket for read. This causes all the threads to block at one time or the other. Simple solution is add read timeouts to all the SelectChannelConnector and SslSelectChannelConnector we use.Exception trace: SEVERE: The exception contained within MappableContainerException could not be mapped to a response  re-throwing to the HTTP containerorg.eclipse.jetty.io.EofException: early EOF at org.eclipse.jetty.server.HttpInput.read(HttpInput.java:65) at org.codehaus.jackson.impl.ByteSourceBootstrapper.ensureLoaded(ByteSourceBootstrapper.java:507) at org.codehaus.jackson.impl.ByteSourceBootstrapper.detectEncoding(ByteSourceBootstrapper.java:129) at org.codehaus.jackson.impl.ByteSourceBootstrapper.constructParser(ByteSourceBootstrapper.java:224) at org.codehaus.jackson.JsonFactory._createJsonParser(JsonFactory.java:785) at org.codehaus.jackson.JsonFactory.createJsonParser(JsonFactory.java:561) at org.codehaus.jackson.jaxrs.JacksonJsonProvider.readFrom(JacksonJsonProvider.java:414) at com.sun.jersey.json.impl.provider.entity.JacksonProviderProxy.readFrom(JacksonProviderProxy.java:139) at com.sun.jersey.spi.container.ContainerRequest.getEntity(ContainerRequest.java:474)Notice the API's is being called all the time - meaning they probalby had a browser up and running for a long time.There might be a possibilility that the browser might have some issues after running for a long time. Something to keep in mind when this happens again. Easy way to check that is to call Ambari server API's and also bring up a new browser window (new instance) and try hitting the browser UI., api api handl queuedthreadpool queuedthreadpool queuedthread pool size somehow somehow http connect torn UI side server still hang onto socket read like UI also need close http connect not use might issu well doesnt address urgent urgent server read timeout mean hang socket read read caus thread block one time simpl solut add read timeout SelectChannelConnector select channel connector SslSelectChannelConnector ssl select channel connector use except use except trace trace SEVERE SEVERE except contain within MappableContainerException mappabl contain except could not map respons throw throw HTTP containerorg eclips jetti io EofException containerorg eclips jetti io eof except earli EOF org eclips jetti server HttpInput read HttpInput java org eclips jetti server http input read http input java org codehau jackson impl ByteSourceBootstrapper ensureLoaded ByteSourceBootstrapper java org codehau jackson impl byte sourc bootstrapp ensur load byte sourc bootstrapp java org codehau jackson impl ByteSourceBootstrapper detectEncoding ByteSourceBootstrapper java org codehau jackson impl byte sourc bootstrapp detect encod byte sourc bootstrapp java org codehau jackson impl ByteSourceBootstrapper constructParser ByteSourceBootstrapper java org codehau jackson impl byte sourc bootstrapp construct parser byte sourc bootstrapp java org codehau jackson JsonFactory _createJsonParser JsonFactory java org codehau jackson json factori _create json parser json factori java org codehau jackson JsonFactory createJsonParser JsonFactory java org codehau jackson json factori creat json parser json factori java org codehau jackson jaxr JacksonJsonProvider readFrom JacksonJsonProvider java org codehau jackson jaxr jackson json provid read jackson json provid java com sun jersey json impl provid entiti JacksonProviderProxy readFrom JacksonProviderProxy java com sun jersey json impl provid entiti jackson provid proxi read jackson provid proxi java com sun jersey spi contain ContainerRequest getEntity ContainerRequest java notic com sun jersey spi contain contain request get entiti contain request java notic API API call time mean probalbi browser run long time time might possibilil browser might issu run long time time someth keep mind happen easi way check call ambari server API API also bring new browser window new instanc instanc tri hit browser UI UI,0,0,0,0,0,0,0 
2029,Yusaku Sako,ambari-web,0,Error when loading /main/services directly, error load main servic main servic directli,,,0,0,0,0,0,0,0 
2031,Giridharan Kesavan,infra,0,Add clover code coverage profile, add clover code coverag profil,mvn test -Pclover -Dclover.license=&lt;clover.coverage.license&gt; should run the unit tests and return html/xml code coverage reports, mvn test pclover pclover dclover licens lt clover coverag licens gt dclover licens lt clover coverag licens gt run unit test return html xml html xml code coverag report,0,0,0,0,0,0,0 
2034,Yusaku Sako,ambari-web,0,Disable 'Add Component' button in the Host Details page if the host is in UNKNOWN state or !isHeartbeating, disabl add add compon compon button host detail page host UNKNOWN state isHeartbeating heartbeat,,,0,0,0,0,0,0,0 
2035,Yusaku Sako,ambari-web,0,'Add local user' button is enabled but nothing happens upon clicking it under certain conditions, add add local user user button enabl noth happen upon click certain condit,Steps to reproduce1. Go to Admin tab2. Click on 'Add Local User' button3. Click on Admin tab again4. Clicking on 'Add Local User' button does nothing, step reproduc reproduc Go admin tab tab click add add local user user button button click admin tab click add add local user user button noth,0,0,0,0,0,0,0 
2038,Yusaku Sako,ambari-web,0,Services links on Dashboard connected to incorrect pages, servic link dashboard connect incorrect page,Click on any of the service links shown on the Dashboard page.It transitions to the service page and the content displayed is correct for the service chosen  but the URL indicates that it is another service and the side-menu shows a different service highlighted., click servic link shown dashboard page page transit servic page content display correct servic chosen URL indic anoth servic side menu side menu show differ servic highlight highlight,0,0,0,0,0,0,0 
2045,Siddharth Wagle,ambari-server,0,Add Unit test to verify  client re-install for install failed client, add unit test verifi client instal instal instal fail client,Add Unit test to verify  When INSTALL is schedules on client components it should also be scheduled on components that are in INSTALL_FAILED state, add unit test verifi INSTALL schedul client compon also schedul compon INSTALL_FAILED INSTALL FAILED state,0,0,0,0,0,0,0 
2054,Yusaku Sako,ambari-web,0,If 'Install from Local Repository' selected in install wizard  Add Host wizard not working, instal instal local repositori repositori select instal wizard add host wizard not work,,,0,0,0,0,0,0,0 
2058,Yusaku Sako,ambari-web,0,Host Detail page: if the host component is in INSTALL_FAILED state  we should let the user reinstall it, host detail page page host compon INSTALL_FAILED INSTALL FAILED state let user reinstal,,,0,0,0,0,0,0,0 
2065,Sumit Mohanty,null,0,Hadoop group customization does not take affect, hadoop group custom not take affect,To customize the hadoop group  when it was changed from 'hadoop' to 'hadoopgroup'  it didn't look like it worked.root@ip-10-85-135-237 hdfsuser# id hdfsuid=495(hdfs) gid=494(hdfs) groups=494(hdfs) 495(hadoop)And looking at the /etc/group filepuppet:x:497:hadoopgroup:x:500:rrdcached:x:496:apache:x:48:hadoop:x:495:mapred hdfs, custom hadoop group chang hadoop hadoop hadoopgroup hadoopgroup look like work root ip work root ip hdfsuser hdfsuser id hdfsuid hdf hdfsuid hdf gid hdf gid hdf group hdf group hdf hadoop hadoop look etc group etc group filepuppet hadoopgroup rrdcach apach hadoop mapr filepuppet hadoopgroup rrdcach apach hadoop mapr hdf,0,0,0,0,0,0,0 
2068,Yusaku Sako,ambari-web,0,'Preparing to install ' message needs spacing, prepar prepar instal messag need space,,,0,0,0,0,0,0,0 
2075,Yusaku Sako,ambari-web,0,Admin role can't be assigned to LDAP user, admin role assign LDAP user,,,0,0,0,0,0,0,0 
2081,Siddharth Wagle,ambari-agent,0,changeUid.sh failing during installation, changeUid sh chang uid sh fail instal,On SUSE  I received a puppet error on each agent that /tmp/changeUid.sh failed during installation. (Sorry I no longer have the error  I made puppet change and restarted to get by it). But in a nutshell  running the command manually gave:ip-10-82-233-26:/tmp # /tmp/changeUid.sh ambari-qa 1012 /tmp/ambari-qa /home/ambari-qa /var/spool/mail/ambari-qaChanging uid of ambari-qa from 1012 to 1012Changing directory permisions for /tmp/ambari-qa /home/ambari-qa /var/spool/mail/ambari-qausermod: UID 1012 is not unique.Note that the usermod is trying to change to an existing UID  so the command is failing everywhere, SUSE receiv puppet error agent tmp changeUid sh tmp chang uid sh fail instal instal sorri sorri no longer error made puppet chang restart get nutshel run command manual gave ip tmp gave ip tmp tmp changeUid sh tmp chang uid sh ambari qa ambari qa tmp ambari qa tmp ambari qa home ambari qa home ambari qa var spool mail ambari qaChanging var spool mail ambari qa chang uid ambari qa ambari qa chang chang directori permis tmp ambari qa tmp ambari qa home ambari qa home ambari qa var spool mail ambari qausermod var spool mail ambari qausermod UID not uniqu note uniqu note usermod tri chang exist UID command fail everywher,0,0,0,0,0,0,0 
2087,Sumit Mohanty,null,0,Tasks are not filtered by parent request id, task not filter parent request id,STEPS:1) Get tasks for first request  /api/v1/clusters/&lt;cluster&gt;/requests/&lt;firstRequest&gt;  i.e. task1 ... taskN12) Get tasks for second request by task from first requst  like /api/v1/clusters/&lt;cluster&gt;/requests/&lt;secondRequest&gt;/tasks/task1 (note task1 belongs to first request  not second)3) Notice that task from first request are present in second request., STEPS STEPS get task first request api cluster lt cluster gt request lt firstRequest gt api cluster lt cluster gt request lt first request gt task task taskN task get task second request task first requst like api cluster lt cluster gt request lt secondRequest gt task task api cluster lt cluster gt request lt second request gt task task note task task belong first request not second second notic task first request present second request request,0,0,0,0,0,0,0 
2089,Xi Wang,null,0,Post Ambari upgrade  Hive and Oozie fail to start after reconfigure, post ambari upgrad hive oozi fail start reconfigur,,,0,0,0,0,0,0,0 
2095,Jaimin D Jetly,ambari-web,0,It's possible to get into a state where install retry is not possible if the agent stops heartbeating, possibl get state instal retri not possibl agent stop heartbeat,This affects both Install and Add Host Wizards.Steps to reproduce:While installing components  stop the agent on one of the hosts.Waiting for a while puts the components on the host into the UNKNOWN state.Click Retry from the UI. This causes a server-side error and the UI gets confused (the hosts are shown with 'Waiting' message and no 'Retry' button is available).The user is not able to get out of this state., affect instal add host wizard step wizard step reproduc reproduc instal compon stop agent one host wait host wait put compon host UNKNOWN state click state click retri UI UI caus server side server side error UI get confus host shown wait wait messag no retri retri button avail avail user not abl get state state,0,0,0,0,0,0,0 
2101,Siddharth Wagle,ambari-agent,0,Hive service check (still) failing with file permissions, hive servic check still still fail file permiss,Stack upgrade testing is still showing this to be an issue.warning: Unrecognised escape sequence '/;' in file /var/lib/ambari-agent/puppet/modules/hdp-hive/manifests/hive/service_check.pp at line 32warning: Dynamic lookup of $configuration is deprecated. Support will be removed in Puppet 2.8. Use a fully-qualified variable name (e.g.  $classname::variable) or parameterized classes.notice: /Stage[1]/Hdp::Snappy::Package/Hdp::Snappy::Package::Ln[32]/Hdp::Exec[hdp::snappy::package::ln 32]/Exec[hdp::snappy::package::ln 32]/returns: executed successfullynotice: /Stage[2]/Hdp-hcat::Hcat::Service_check/Exec[hcatSmoke.sh prepare]/returns: ls: cannot access /usr/share/java/*oracle*: No such file or directorynotice: /Stage[2]/Hdp-hcat::Hcat::Service_check/Exec[hcatSmoke.sh prepare]/returns: 13/05/09 15:01:52 WARN conf.HiveConf: DEPRECATED: Configuration property hive.metastore.local no longer has any effect. Make sure to provide a valid value for hive.metastore.uris if you are connecting to a remote metastore.notice: /Stage[2]/Hdp-hcat::Hcat::Service_check/Exec[hcatSmoke.sh prepare]/returns: log4j:ERROR setFile(null true) call failed.notice: /Stage[2]/Hdp-hcat::Hcat::Service_check/Exec[hcatSmoke.sh prepare]/returns: java.io.FileNotFoundException: /tmp/ambari_qa/hive.log (Permission denied)notice: /Stage[2]/Hdp-hcat::Hcat::Service_check/Exec[hcatSmoke.sh prepare]/returns: at java.io.FileOutputStream.openAppend(Native Method)notice: /Stage[2]/Hdp-hcat::Hcat::Service_check/Exec[hcatSmoke.sh prepare]/returns: at java.io.FileOutputStream.&lt;init&gt;(FileOutputStream.java:192)notice: /Stage[2]/Hdp-hcat::Hcat::Service_check/Exec[hcatSmoke.sh prepare]/returns: at java.io.FileOutputStream.&lt;init&gt;(FileOutputStream.java:116)notice: /Stage[2]/Hdp-hcat::Hcat::Service_check/Exec[hcatSmoke.sh prepare]/returns: at org.apache.log4j.FileAppender.setFile(FileAppender.java:290)notice: /Stage[2]/Hdp-hcat::Hcat::Service_check/Exec[hcatSmoke.sh prepare]/returns: at org.apache.log4j.FileAppender.activateOptions(FileAppender.java:164)notice: /Stage[2]/Hdp-hcat::Hcat::Service_check/Exec[hcatSmoke.sh prepare]/returns: at org.apache.log4j.DailyRollingFileAppender.activateOptions(DailyRollingFileAppender.java:216)notice: /Stage[2]/Hdp-hcat::Hcat::Service_check/Exec[hcatSmoke.sh prepare]/returns: at org.apache.log4j.config.PropertySetter.activate(PropertySetter.java:257)notice: /Stage[2]/Hdp-hcat::Hcat::Service_check/Exec[hcatSmoke.sh prepare]/returns: at org.apache.log4j.config.PropertySetter.setProperties(PropertySetter.java:133)notice: /Stage[2]/Hdp-hcat::Hcat::Service_check/Exec[hcatSmoke.sh prepare]/returns: at org.apache.log4j.config.PropertySetter.setProperties(PropertySetter.java:97)notice: /Stage[2]/Hdp-hcat::Hcat::Service_check/Exec[hcatSmoke.sh prepare]/returns: at org.apache.log4j.PropertyConfigurator.parseAppender(PropertyConfigurator.java:689)notice: /Stage[2]/Hdp-hcat::Hcat::Service_check/Exec[hcatSmoke.sh prepare]/returns: at org.apache.log4j.PropertyConfigurator.parseCategory(PropertyConfigurator.java:647)notice: /Stage[2]/Hdp-hcat::Hcat::Service_check/Exec[hcatSmoke.sh prepare]/returns: at org.apache.log4j.PropertyConfigurator.configureRootCategory(PropertyConfigurator.java:544)notice: /Stage[2]/Hdp-hcat::Hcat::Service_check/Exec[hcatSmoke.sh prepare]/returns: at org.apache.log4j.PropertyConfigurator.doConfigure(PropertyConfigurator.java:440)notice: /Stage[2]/Hdp-hcat::Hcat::Service_check/Exec[hcatSmoke.sh prepare]/returns: at org.apache.log4j.PropertyConfigurator.doConfigure(PropertyConfigurator.java:476)notice: /Stage[2]/Hdp-hcat::Hcat::Service_check/Exec[hcatSmoke.sh prepare]/returns: at org.apache.log4j.PropertyConfigurator.configure(PropertyConfigurator.java:354)notice: /Stage[2]/Hdp-hcat::Hcat::Service_check/Exec[hcatSmoke.sh prepare]/returns: at org.apache.hadoop.hive.common.LogUtils.initHiveLog4jDefault(LogUtils.java:124)notice: /Stage[2]/Hdp-hcat::Hcat::Service_check/Exec[hcatSmoke.sh prepare]/returns: at org.apache.hadoop.hive.common.LogUtils.initHiveLog4jCommon(LogUtils.java:77)notice: /Stage[2]/Hdp-hcat::Hcat::Service_check/Exec[hcatSmoke.sh prepare]/returns: at org.apache.hadoop.hive.common.LogUtils.initHiveLog4j(LogUtils.java:58)notice: /Stage[2]/Hdp-hcat::Hcat::Service_check/Exec[hcatSmoke.sh prepare]/returns: at org.apache.hcatalog.cli.HCatCli.main(HCatCli.java:61)notice: /Stage[2]/Hdp-hcat::Hcat::Service_check/Exec[hcatSmoke.sh prepare]/returns: at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)notice: /Stage[2]/Hdp-hcat::Hcat::Service_check/Exec[hcatSmoke.sh prepare]/returns: at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)notice: /Stage[2]/Hdp-hcat::Hcat::Service_check/Exec[hcatSmoke.sh prepare]/returns: at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)notice: /Stage[2]/Hdp-hcat::Hcat::Service_check/Exec[hcatSmoke.sh prepare]/returns: at java.lang.reflect.Method.invoke(Method.java:597)notice: /Stage[2]/Hdp-hcat::Hcat::Service_check/Exec[hcatSmoke.sh prepare]/returns: at org.apache.hadoop.util.RunJar.main(RunJar.java:160)notice: /Stage[2]/Hdp-hcat::Hcat::Service_check/Exec[hcatSmoke.sh prepare]/returns: log4j:ERROR Either File or DatePattern options are not set for appender [DRFA].notice: /Stage[2]/Hdp-hcat::Hcat::Service_check/Exec[hcatSmoke.sh prepare]/returns: Exception in thread 'main' java.lang.RuntimeException: java.io.IOException: Permission deniednotice: /Stage[2]/Hdp-hcat::Hcat::Service_check/Exec[hcatSmoke.sh prepare]/returns: at org.apache.hadoop.hive.ql.session.SessionState.start(SessionState.java:272)notice: /Stage[2]/Hdp-hcat::Hcat::Service_check/Exec[hcatSmoke.sh prepare]/returns: at org.apache.hcatalog.cli.HCatCli.main(HCatCli.java:79)notice: /Stage[2]/Hdp-hcat::Hcat::Service_check/Exec[hcatSmoke.sh prepare]/returns: at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method), stack upgrad test still show issu warn issu warn unrecognis escap sequenc file var lib ambari agent puppet modul hdp hive manifest hive service_check pp var lib ambari agent puppet modul hdp hive manifest hive service_check pp line warn warn dynam lookup configur deprec deprec support remov puppet use fulli qualifi fulli qualifi variabl name classnam variabl classnam variabl parameter class notic class notic stage hdp snappi packag hdp snappi packag Ln hdp exec hdp snappi packag ln stage hdp snappi packag hdp snappi packag Ln hdp exec hdp snappi packag ln exec hdp snappi packag ln exec hdp snappi packag ln return return execut successfullynotic successfullynotic stage hdp hcat hcat Service_check exec hcatSmoke sh stage hdp hcat hcat Service_check exec hcat smoke sh prepar return prepar return ls ls cannot access usr share java oracl usr share java oracl No file directorynotic directorynotic stage hdp hcat hcat Service_check exec hcatSmoke sh stage hdp hcat hcat Service_check exec hcat smoke sh prepar return prepar return WARN conf HiveConf conf hive conf DEPRECATED DEPRECATED configur properti hive metastor local hive metastor local no longer effect effect make sure provid valid valu hive metastor uri hive metastor uri connect remot metastor notic metastor notic stage hdp hcat hcat Service_check exec hcatSmoke sh stage hdp hcat hcat Service_check exec hcat smoke sh prepar return prepar return log ERROR log ERROR setFile null set file null true true call fail notic fail notic stage hdp hcat hcat Service_check exec hcatSmoke sh stage hdp hcat hcat Service_check exec hcat smoke sh prepar return prepar return java io FileNotFoundException java io file not found except tmp ambari_qa hive log tmp ambari_qa hive log permiss permiss deni notic deni notic stage hdp hcat hcat Service_check exec hcatSmoke sh stage hdp hcat hcat Service_check exec hcat smoke sh prepar return prepar return java io FileOutputStream openAppend nativ java io file output stream open append nativ method notic method notic stage hdp hcat hcat Service_check exec hcatSmoke sh stage hdp hcat hcat Service_check exec hcat smoke sh prepar return prepar return java io FileOutputStream lt init gt FileOutputStream java notic java io file output stream lt init gt file output stream java notic stage hdp hcat hcat Service_check exec hcatSmoke sh stage hdp hcat hcat Service_check exec hcat smoke sh prepar return prepar return java io FileOutputStream lt init gt FileOutputStream java notic java io file output stream lt init gt file output stream java notic stage hdp hcat hcat Service_check exec hcatSmoke sh stage hdp hcat hcat Service_check exec hcat smoke sh prepar return prepar return org apach log FileAppender setFile FileAppender java notic org apach log file append set file file append java notic stage hdp hcat hcat Service_check exec hcatSmoke sh stage hdp hcat hcat Service_check exec hcat smoke sh prepar return prepar return org apach log FileAppender activateOptions FileAppender java notic org apach log file append activ option file append java notic stage hdp hcat hcat Service_check exec hcatSmoke sh stage hdp hcat hcat Service_check exec hcat smoke sh prepar return prepar return org apach log DailyRollingFileAppender activateOptions DailyRollingFileAppender java notic org apach log daili roll file append activ option daili roll file append java notic stage hdp hcat hcat Service_check exec hcatSmoke sh stage hdp hcat hcat Service_check exec hcat smoke sh prepar return prepar return org apach log config PropertySetter activ PropertySetter java notic org apach log config properti setter activ properti setter java notic stage hdp hcat hcat Service_check exec hcatSmoke sh stage hdp hcat hcat Service_check exec hcat smoke sh prepar return prepar return org apach log config PropertySetter setProperties PropertySetter java notic org apach log config properti setter set properti properti setter java notic stage hdp hcat hcat Service_check exec hcatSmoke sh stage hdp hcat hcat Service_check exec hcat smoke sh prepar return prepar return org apach log config PropertySetter setProperties PropertySetter java notic org apach log config properti setter set properti properti setter java notic stage hdp hcat hcat Service_check exec hcatSmoke sh stage hdp hcat hcat Service_check exec hcat smoke sh prepar return prepar return org apach log PropertyConfigurator parseAppender PropertyConfigurator java notic org apach log properti configur pars append properti configur java notic stage hdp hcat hcat Service_check exec hcatSmoke sh stage hdp hcat hcat Service_check exec hcat smoke sh prepar return prepar return org apach log PropertyConfigurator parseCategory PropertyConfigurator java notic org apach log properti configur pars categori properti configur java notic stage hdp hcat hcat Service_check exec hcatSmoke sh stage hdp hcat hcat Service_check exec hcat smoke sh prepar return prepar return org apach log PropertyConfigurator configureRootCategory PropertyConfigurator java notic org apach log properti configur configur root categori properti configur java notic stage hdp hcat hcat Service_check exec hcatSmoke sh stage hdp hcat hcat Service_check exec hcat smoke sh prepar return prepar return org apach log PropertyConfigurator doConfigure PropertyConfigurator java notic org apach log properti configur configur properti configur java notic stage hdp hcat hcat Service_check exec hcatSmoke sh stage hdp hcat hcat Service_check exec hcat smoke sh prepar return prepar return org apach log PropertyConfigurator doConfigure PropertyConfigurator java notic org apach log properti configur configur properti configur java notic stage hdp hcat hcat Service_check exec hcatSmoke sh stage hdp hcat hcat Service_check exec hcat smoke sh prepar return prepar return org apach log PropertyConfigurator configur PropertyConfigurator java notic org apach log properti configur configur properti configur java notic stage hdp hcat hcat Service_check exec hcatSmoke sh stage hdp hcat hcat Service_check exec hcat smoke sh prepar return prepar return org apach hadoop hive common LogUtils initHiveLog jDefault LogUtils java notic org apach hadoop hive common log util init hive log default log util java notic stage hdp hcat hcat Service_check exec hcatSmoke sh stage hdp hcat hcat Service_check exec hcat smoke sh prepar return prepar return org apach hadoop hive common LogUtils initHiveLog jCommon LogUtils java notic org apach hadoop hive common log util init hive log common log util java notic stage hdp hcat hcat Service_check exec hcatSmoke sh stage hdp hcat hcat Service_check exec hcat smoke sh prepar return prepar return org apach hadoop hive common LogUtils initHiveLog LogUtils java notic org apach hadoop hive common log util init hive log log util java notic stage hdp hcat hcat Service_check exec hcatSmoke sh stage hdp hcat hcat Service_check exec hcat smoke sh prepar return prepar return org apach hcatalog cli HCatCli main HCatCli java notic org apach hcatalog cli cat cli main cat cli java notic stage hdp hcat hcat Service_check exec hcatSmoke sh stage hdp hcat hcat Service_check exec hcat smoke sh prepar return prepar return sun reflect NativeMethodAccessorImpl invok nativ sun reflect nativ method accessor impl invok nativ method notic method notic stage hdp hcat hcat Service_check exec hcatSmoke sh stage hdp hcat hcat Service_check exec hcat smoke sh prepar return prepar return sun reflect NativeMethodAccessorImpl invok NativeMethodAccessorImpl java notic sun reflect nativ method accessor impl invok nativ method accessor impl java notic stage hdp hcat hcat Service_check exec hcatSmoke sh stage hdp hcat hcat Service_check exec hcat smoke sh prepar return prepar return sun reflect DelegatingMethodAccessorImpl invok DelegatingMethodAccessorImpl java notic sun reflect deleg method accessor impl invok deleg method accessor impl java notic stage hdp hcat hcat Service_check exec hcatSmoke sh stage hdp hcat hcat Service_check exec hcat smoke sh prepar return prepar return java lang reflect method invok method java notic java lang reflect method invok method java notic stage hdp hcat hcat Service_check exec hcatSmoke sh stage hdp hcat hcat Service_check exec hcat smoke sh prepar return prepar return org apach hadoop util RunJar main RunJar java notic org apach hadoop util run jar main run jar java notic stage hdp hcat hcat Service_check exec hcatSmoke sh stage hdp hcat hcat Service_check exec hcat smoke sh prepar return prepar return log ERROR log ERROR either file DatePattern date pattern option not set append DRFA notic DRFA notic stage hdp hcat hcat Service_check exec hcatSmoke sh stage hdp hcat hcat Service_check exec hcat smoke sh prepar return prepar return except thread main main java lang RuntimeException java lang runtim except java io IOException java io IO except permiss deniednotic deniednotic stage hdp hcat hcat Service_check exec hcatSmoke sh stage hdp hcat hcat Service_check exec hcat smoke sh prepar return prepar return org apach hadoop hive ql session SessionState start SessionState java notic org apach hadoop hive ql session session state start session state java notic stage hdp hcat hcat Service_check exec hcatSmoke sh stage hdp hcat hcat Service_check exec hcat smoke sh prepar return prepar return org apach hcatalog cli HCatCli main HCatCli java notic org apach hcatalog cli cat cli main cat cli java notic stage hdp hcat hcat Service_check exec hcatSmoke sh stage hdp hcat hcat Service_check exec hcat smoke sh prepar return prepar return sun reflect NativeMethodAccessorImpl invok nativ sun reflect nativ method accessor impl invok nativ method method,0,0,0,0,0,0,0 
2134,Jaimin D Jetly,ambari-server,0,Set default value of oozie property 'oozie.service.AuthorizationService.authorization.enabled' to true., set default valu oozi properti oozi servic AuthorizationService author enabl oozi servic author servic author enabl true true,,,0,0,0,0,0,0,0 
2136,Mahadev konar,null,0,Home paths are not set correctly in /etc/sqoop/conf/sqoop-env.sh, home path not set correctli etc sqoop conf sqoop env sh etc sqoop conf sqoop env sh,Ambari sets the followings:#Set path to where bin/hadoop is availableexport HADOOP_HOME=${HADOOP_HOME:-/usr}#set the path to where bin/hbase is availableexport HBASE_HOME=${HBASE_HOME:-/usr}#Set the path to where bin/hive is availableexport HIVE_HOME=${HIVE_HOME:-/usr}# add libthrift in hive to sqoop class path first so hive imports workexport SQOOP_USER_CLASSPATH=''ls ${HIVE_HOME}/lib/libthrift-*.jar 2&gt; /dev/null':${SQOOP_USER_CLASSPATH}'#Set the path for where zookeper config dir isexport ZOOCFGDIR=${ZOOCFGDIR:-/etc/zookeeper/conf}It should be the followings (also screenshot is available):#Set path to where bin/hadoop is availableexport HADOOP_HOME=${HADOOP_HOME:-/usr/lib/hadoop}#set the path to where bin/hbase is availableexport HBASE_HOME=${HBASE_HOME:-/usr/lib/hbase}#Set the path to where bin/hive is availableexport HIVE_HOME=${HIVE_HOME:-/usr/lib/hive}#Set the path for where zookeper config dir isexport ZOOCFGDIR=${ZOOCFGDIR:-/etc/zookeeper/conf}# add libthrift in hive to sqoop class path first so hive imports workexport SQOOP_USER_CLASSPATH=''ls ${HIVE_HOME}/lib/libthrift-*.jar 2&gt; /dev/null':${SQOOP_USER_CLASSPATH}, ambari set follow set follow set path bin hadoop bin hadoop availableexport HADOOP_HOME HADOOP_HOME usr set HADOOP HOME HADOOP HOME usr set path bin hbase bin hbase availableexport HBASE_HOME HBASE_HOME usr set HBASE HOME HBASE HOME usr set path bin hive bin hive availableexport HIVE_HOME HIVE_HOME usr HIVE HOME HIVE HOME usr add libthrift hive sqoop class path first hive import workexport SQOOP_USER_CLASSPATH ls SQOOP USER CLASSPATH ls HIVE_HOME lib libthrift jar HIVE HOME lib libthrift jar gt gt dev null SQOOP_USER_CLASSPATH set dev null SQOOP USER CLASSPATH set path zookep config dir isexport ZOOCFGDIR ZOOCFGDIR etc zookeep conf ZOOCFGDIR ZOOCFGDIR etc zookeep conf follow also screenshot avail set avail set path bin hadoop bin hadoop availableexport HADOOP_HOME HADOOP_HOME usr lib hadoop set HADOOP HOME HADOOP HOME usr lib hadoop set path bin hbase bin hbase availableexport HBASE_HOME HBASE_HOME usr lib hbase set HBASE HOME HBASE HOME usr lib hbase set path bin hive bin hive availableexport HIVE_HOME HIVE_HOME usr lib hive set HIVE HOME HIVE HOME usr lib hive set path zookep config dir isexport ZOOCFGDIR ZOOCFGDIR etc zookeep conf ZOOCFGDIR ZOOCFGDIR etc zookeep conf add libthrift hive sqoop class path first hive import workexport SQOOP_USER_CLASSPATH ls SQOOP USER CLASSPATH ls HIVE_HOME lib libthrift jar HIVE HOME lib libthrift jar gt gt dev null SQOOP_USER_CLASSPATH dev null SQOOP USER CLASSPATH,0,0,0,0,0,0,0 
2143,Sumit Mohanty,null,0,HBASE fails to start on master, HBASE fail start master,HBASE master fails to start on master. From log:2013-05-14 21:06:43 487 FATAL org.apache.hadoop.hbase.master.HMaster: Unhandled exception. Starting shutdown.org.apache.hadoop.security.AccessControlException: org.apache.hadoop.security.AccessControlException: Permission denied: user=hbase  access=EXECUTE  inode='/apps/hbase/data':hdfs:hdfs:drwx------ at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:39) at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:27) at java.lang.reflect.Constructor.newInstance(Constructor.java:513) at org.apache.hadoop.ipc.RemoteException.instantiateException(RemoteException.java:95) at org.apache.hadoop.ipc.RemoteException.unwrapRemoteException(RemoteException.java:57) at org.apache.hadoop.hdfs.DFSClient.getFileInfo(DFSClient.java:1134) at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:556) at org.apache.hadoop.fs.FileSystem.exists(FileSystem.java:779) at org.apache.hadoop.hbase.util.FSUtils.getVersion(FSUtils.java:287) at org.apache.hadoop.hbase.util.FSUtils.checkVersion(FSUtils.java:329) at org.apache.hadoop.hbase.master.MasterFileSystem.checkRootDir(MasterFileSystem.java:434) at org.apache.hadoop.hbase.master.MasterFileSystem.createInitialFileSystemLayout(MasterFileSystem.java:146) at org.apache.hadoop.hbase.master.MasterFileSystem.&lt;init&gt;(MasterFileSystem.java:131) at org.apache.hadoop.hbase.master.HMaster.finishInitialization(HMaster.java:532) at org.apache.hadoop.hbase.master.HMaster.run(HMaster.java:391) at java.lang.Thread.run(Thread.java:662), HBASE master fail start master master log log FATAL org apach hadoop hbase master HMaster org apach hadoop hbase master master unhandl except except start shutdown org apach hadoop secur AccessControlException shutdown org apach hadoop secur access control except org apach hadoop secur AccessControlException org apach hadoop secur access control except permiss deni deni user hbase user hbase access EXECUTE access EXECUTE inod app hbase data hdf hdf drwx inod app hbase data hdf hdf drwx sun reflect NativeConstructorAccessorImpl newInstance nativ sun reflect nativ constructor accessor impl new instanc nativ method method sun reflect NativeConstructorAccessorImpl newInstance NativeConstructorAccessorImpl java sun reflect nativ constructor accessor impl new instanc nativ constructor accessor impl java sun reflect DelegatingConstructorAccessorImpl newInstance DelegatingConstructorAccessorImpl java sun reflect deleg constructor accessor impl new instanc deleg constructor accessor impl java java lang reflect constructor newInstance constructor java java lang reflect constructor new instanc constructor java org apach hadoop ipc RemoteException instantiateException RemoteException java org apach hadoop ipc remot except instanti except remot except java org apach hadoop ipc RemoteException unwrapRemoteException RemoteException java org apach hadoop ipc remot except unwrap remot except remot except java org apach hadoop hdf DFSClient getFileInfo DFSClient java org apach hadoop hdf DFS client get file info DFS client java org apach hadoop hdf DistributedFileSystem getFileStatus DistributedFileSystem java org apach hadoop hdf distribut file system get file statu distribut file system java org apach hadoop fs FileSystem exist FileSystem java org apach hadoop fs file system exist file system java org apach hadoop hbase util FSUtils getVersion FSUtils java org apach hadoop hbase util FS util get version FS util java org apach hadoop hbase util FSUtils checkVersion FSUtils java org apach hadoop hbase util FS util check version FS util java org apach hadoop hbase master MasterFileSystem checkRootDir MasterFileSystem java org apach hadoop hbase master master file system check root dir master file system java org apach hadoop hbase master MasterFileSystem createInitialFileSystemLayout MasterFileSystem java org apach hadoop hbase master master file system creat initi file system layout master file system java org apach hadoop hbase master MasterFileSystem lt init gt MasterFileSystem java org apach hadoop hbase master master file system lt init gt master file system java org apach hadoop hbase master HMaster finishInitialization HMaster java org apach hadoop hbase master master finish initi master java org apach hadoop hbase master HMaster run HMaster java org apach hadoop hbase master master run master java java lang thread run thread java java lang thread run thread java,0,0,0,0,0,0,0 
2144,Siddharth Wagle,ambari-agent,0,Installation with existing Oracle DB fails, instal exist oracl DB fail,On Step8 'Customize Services' for HIVE and OOZIE we can use option 'Existing Oracle DB'.But after Cluster install HIVE and OOZIE didn't start (with option 'Existing Oracle DB').In the logs I found such:/var/log/hive/hive.logCaused by: org.datanucleus.exceptions.NucleusException: Attempt to invoke the 'DBCP' plugin to create a ConnectionPool gave an error : The specified datastore driver ('oracle.jdbc.driver.OracleDriver') was not found in the CLASSPATH. Please check your CLASSPATH specification  and the name of the driver./var/log/oozie/oozie.log013-05-14 11:25:59 618 FATAL Services:533 - USER[-] GROUP[-] TOKEN[-] APP[-] JOB[-] ACTION[-] E0103: Could not load service classes  Cannot load JDBC driver class 'oracle.jdbc.driver.OracleDriver'org.apache.oozie.service.ServiceException: E0103: Could not load service classes  Cannot load JDBC driver class 'oracle.jdbc.driver.OracleDriver', step step custom custom servic servic HIVE OOZIE use option exist exist oracl DB DB cluster instal HIVE OOZIE start option exist exist oracl DB DB log found var log hive hive logCaused var log hive hive log caus org datanucleu except NucleusException org datanucleu except nucleu except attempt invok DBCP DBCP plugin creat ConnectionPool connect pool gave error specifi datastor driver oracl jdbc driver OracleDriver oracl jdbc driver oracl driver not found CLASSPATH CLASSPATH pleas check CLASSPATH specif name driver var log oozi oozi log driver var log oozi oozi log FATAL servic servic USER USER GROUP GROUP TOKEN TOKEN APP APP JOB JOB ACTION ACTION could not load servic class cannot load JDBC driver class oracl jdbc driver OracleDriver org apach oozi servic ServiceException oracl jdbc driver oracl driver org apach oozi servic servic except could not load servic class cannot load JDBC driver class oracl jdbc driver OracleDriver oracl jdbc driver oracl driver,0,0,0,0,0,0,0 
2146,Sumit Mohanty,null,0,When hive and oozie users have been changed after upgrade hive metastore and oozie cannot start properly, hive oozi user chang upgrad hive metastor oozi cannot start properli,Oozie start failure:^[[0;36mnotice: /Stage[2]/Hdp-oozie::Service/Hdp::Exec[exec su - ooziexx -c 'cd /var/tmp/oozie &amp;&amp; /usr/lib/oozie/bin/oozie-start.sh']/Exec[exec su - ooziexx -c 'cd /var/tmp/oozie &amp;&amp; /usr/lib/oozie/bin/oozie-start.sh']/returns: Setting OOZIE_BASE_URL: http://ip-10-212-166-111.ec2.internal:11000/oozie^[[0m^[[0;36mnotice: /Stage[2]/Hdp-oozie::Service/Hdp::Exec[exec su - ooziexx -c 'cd /var/tmp/oozie &amp;&amp; /usr/lib/oozie/bin/oozie-start.sh']/Exec[exec su - ooziexx -c 'cd /var/tmp/oozie &amp;&amp; /usr/lib/oozie/bin/oozie-start.sh']/returns: Using CATALINA_BASE: /var/lib/oozie/oozie-server^[[0m^[[0;36mnotice: /Stage[2]/Hdp-oozie::Service/Hdp::Exec[exec su - ooziexx -c 'cd /var/tmp/oozie &amp;&amp; /usr/lib/oozie/bin/oozie-start.sh']/Exec[exec su - ooziexx -c 'cd /var/tmp/oozie &amp;&amp; /usr/lib/oozie/bin/oozie-start.sh']/returns: Setting OOZIE_HTTPS_KEYSTORE_FILE: /home/ooziexx/.keystore^[[0m^[[0;36mnotice: /Stage[2]/Hdp-oozie::Service/Hdp::Exec[exec su - ooziexx -c 'cd /var/tmp/oozie &amp;&amp; /usr/lib/oozie/bin/oozie-start.sh']/Exec[exec su - ooziexx -c 'cd /var/tmp/oozie &amp;&amp; /usr/lib/oozie/bin/oozie-start.sh']/returns: Setting OOZIE_HTTPS_KEYSTORE_PASS: password^[[0m^[[0;36mnotice: /Stage[2]/Hdp-oozie::Service/Hdp::Exec[exec su - ooziexx -c 'cd /var/tmp/oozie &amp;&amp; /usr/lib/oozie/bin/oozie-start.sh']/Exec[exec su - ooziexx -c 'cd /var/tmp/oozie &amp;&amp; /usr/lib/oozie/bin/oozie-start.sh']/returns: Setting CATALINA_OUT: /var/log/oozie//catalina.out^[[0m^[[0;36mnotice: /Stage[2]/Hdp-oozie::Service/Hdp::Exec[exec su - ooziexx -c 'cd /var/tmp/oozie &amp;&amp; /usr/lib/oozie/bin/oozie-start.sh']/Exec[exec su - ooziexx -c 'cd /var/tmp/oozie &amp;&amp; /usr/lib/oozie/bin/oozie-start.sh']/returns: Using CATALINA_PID: /var/run/oozie/oozie.pid^[[0m^[[0;36mnotice: /Stage[2]/Hdp-oozie::Service/Hdp::Exec[exec su - ooziexx -c 'cd /var/tmp/oozie &amp;&amp; /usr/lib/oozie/bin/oozie-start.sh']/Exec[exec su - ooziexx -c 'cd /var/tmp/oozie &amp;&amp; /usr/lib/oozie/bin/oozie-start.sh']/returns: ^[[0m^[[0;36mnotice: /Stage[2]/Hdp-oozie::Service/Hdp::Exec[exec su - ooziexx -c 'cd /var/tmp/oozie &amp;&amp; /usr/lib/oozie/bin/oozie-start.sh']/Exec[exec su - ooziexx -c 'cd /var/tmp/oozie &amp;&amp; /usr/lib/oozie/bin/oozie-start.sh']/returns: Using CATALINA_OPTS: -Dderby.stream.error.file=/var/log/oozie//derby.log^[[0m^[[0;36mnotice: /Stage[2]/Hdp-oozie::Service/Hdp::Exec[exec su - ooziexx -c 'cd /var/tmp/oozie &amp;&amp; /usr/lib/oozie/bin/oozie-start.sh']/Exec[exec su - ooziexx -c 'cd /var/tmp/oozie &amp;&amp; /usr/lib/oozie/bin/oozie-start.sh']/returns: Adding to CATALINA_OPTS: -Doozie.home.dir=/usr/lib/oozie -Doozie.config.dir=/etc/oozie/conf -Doozie.log.dir=/var/log/oozie/ -Doozie.data.dir=/grid/0/hadoop/oozie/data/ -Doozie.config.file=oozie-site.xml -Doozie.log4j.file=oozie-log4j.properties -Doozie.log4j.reload=10 -Doozie.http.hostname=ip-10-212-166-111.ec2.internal -Doozie.admin.port=11001 -Doozie.http.port=11000 -Doozie.https.port=11443 -Doozie.base.url=http://ip-10-212-166-111.ec2.internal:11000/oozie -Doozie.https.keystore.file=/home/ooziexx/.keystore -Doozie.https.keystore.pass=password -Djava.library.path=/usr/lib/hadoop/lib/native/Linux-amd64-64^[[0m^[[0;36mnotice: /Stage[2]/Hdp-oozie::Service/Hdp::Exec[exec su - ooziexx -c 'cd /var/tmp/oozie &amp;&amp; /usr/lib/oozie/bin/oozie-start.sh']/Exec[exec su - ooziexx -c 'cd /var/tmp/oozie &amp;&amp; /usr/lib/oozie/bin/oozie-start.sh']/returns: ^[[0m^[[0;36mnotice: /Stage[2]/Hdp-oozie::Service/Hdp::Exec[exec su - ooziexx -c 'cd /var/tmp/oozie &amp;&amp; /usr/lib/oozie/bin/oozie-start.sh']/Exec[exec su - ooziexx -c 'cd /var/tmp/oozie &amp;&amp; /usr/lib/oozie/bin/oozie-start.sh']/returns: /usr/lib/oozie/oozie-server/bin/catalina.sh: line 386: /var/run/oozie/oozie.pid: Permission denied^[[0m^[[1;35merr: /Stage[2]/Hdp-oozie::Service/Hdp::Exec[exec su - ooziexx -c 'cd /var/tmp/oozie &amp;&amp; /usr/lib/oozie/bin/oozie-start.sh']/Exec[exec su - ooziexx -c 'cd /var/tmp/oozie &amp;&amp; /usr/lib/oozie/bin/oozie-start.sh']/returns: change from notrun to 0 failed: su - ooziexx -c 'cd /var/tmp/oozie &amp;&amp; /usr/lib/oozie/bin/oozie-start.sh' returned 1 instead of one of [0] at /var/lib/ambari-agent/puppet/modules/hdp/manifests/init.pp:340^[[0m^[[0;36mnotice: /Stage[2]/Hdp-oozie::Service/Hdp::Exec[exec su - ooziexx -c 'cd /var/tmp/oozie &amp;&amp; /usr/lib/oozie/bin/oozie-start.sh']/Anchor[hdp::exec::exec su - ooziexx -c 'cd /var/tmp/oozie &amp;&amp; /usr/lib/oozie/bin/oozie-start.sh'::end]: Dependency Exec[exec su - ooziexx -c 'cd /var/tmp/oozie &amp;&amp; /usr/lib/oozie/bin/oozie-start.sh'] has failures: true^[[0m^[[0;33mwarning: /Stage[2]/Hdp-oozie::Service/Hdp::Exec[exec su - ooziexx -c 'cd /var/tmp/oozie &amp;&amp; /usr/lib/oozie/bin/oozie-start.sh']/Anchor[hdp::exec::exec su - ooziexx -c 'cd /var/tmp/oozie &amp;&amp; /usr/lib/oozie/bin/oozie-start.sh'::end]: Skipping because of failed dependencies^[[0m^[[0;36mnotice: /Stage[2]/Hdp-oozie::Service/Hdp-oozie::Service::Directory[/var/log/oozie]/Hdp::Directory_recursive_create[/var/log/oozie]/Hdp::Directory[/var/log/oozie]/File[/var/log/oozie]/owner: owner changed 'oozie' to 'ooziexx'^[[0m^[[0;36mnotice: /Stage[2]/Hdp-oozie::Service/Hdp-oozie::Service::Directory[/var/log/oozie]/Hdp::Directory_recursive_create[/var/log/oozie]/Hdp::Directory[/var/log/oozie]/File[/var/log/oozie]/group: group changed 'oozie' to 'hadoopxx'^[[0m^[[0;36mnotice: /Stage[2]/Hdp-oozie::Service/Hdp-oozie::Service::Directory[/var/run/oozie]/Hdp::Directory_recursive_create[/var/run/oozie]/Hdp::Directory[/var/run/oozie]/File[/var/run/oozie]/owner: owner changed 'oozie' to 'ooziexx'^[[0m^[[0;36mnotice: /Stage[2]/Hdp-oozie::Service/Hdp-oozie::Service::Directory[/var/run/oozie]/Hdp::Directory_recursive_create[/var/run/oozie]/Hdp::Directory[/var/run/oozie]/File[/var/run/oozie]/group: group changed 'oozie' to 'hadoopxx'^[[0m^[[0;36mnotice: Finished catalog run in 9.36 seconds^[[0m, oozi start failur mnotic failur mnotic stage hdp oozi servic hdp exec exec stage hdp oozi servic hdp exec exec su ooziexx cd var tmp oozi var tmp oozi amp amp amp amp usr lib oozi bin oozi start sh exec exec usr lib oozi bin oozi start sh exec exec su ooziexx cd var tmp oozi var tmp oozi amp amp amp amp usr lib oozi bin oozi start sh return usr lib oozi bin oozi start sh return set OOZIE_BASE_URL OOZIE BASE URL stage hdp oozi servic hdp exec exec stage hdp oozi servic hdp exec exec su ooziexx cd var tmp oozi var tmp oozi amp amp amp amp usr lib oozi bin oozi start sh exec exec usr lib oozi bin oozi start sh exec exec su ooziexx cd var tmp oozi var tmp oozi amp amp amp amp usr lib oozi bin oozi start sh return usr lib oozi bin oozi start sh return use CATALINA_BASE CATALINA BASE var lib oozi oozi server mnotic var lib oozi oozi server mnotic stage hdp oozi servic hdp exec exec stage hdp oozi servic hdp exec exec su ooziexx cd var tmp oozi var tmp oozi amp amp amp amp usr lib oozi bin oozi start sh exec exec usr lib oozi bin oozi start sh exec exec su ooziexx cd var tmp oozi var tmp oozi amp amp amp amp usr lib oozi bin oozi start sh return usr lib oozi bin oozi start sh return set OOZIE_HTTPS_KEYSTORE_FILE OOZIE HTTPS KEYSTORE FILE home ooziexx keystor mnotic home ooziexx keystor mnotic stage hdp oozi servic hdp exec exec stage hdp oozi servic hdp exec exec su ooziexx cd var tmp oozi var tmp oozi amp amp amp amp usr lib oozi bin oozi start sh exec exec usr lib oozi bin oozi start sh exec exec su ooziexx cd var tmp oozi var tmp oozi amp amp amp amp usr lib oozi bin oozi start sh return usr lib oozi bin oozi start sh return set OOZIE_HTTPS_KEYSTORE_PASS OOZIE HTTPS KEYSTORE PASS password mnotic password mnotic stage hdp oozi servic hdp exec exec stage hdp oozi servic hdp exec exec su ooziexx cd var tmp oozi var tmp oozi amp amp amp amp usr lib oozi bin oozi start sh exec exec usr lib oozi bin oozi start sh exec exec su ooziexx cd var tmp oozi var tmp oozi amp amp amp amp usr lib oozi bin oozi start sh return usr lib oozi bin oozi start sh return set CATALINA_OUT CATALINA var log oozi catalina mnotic var log oozi catalina mnotic stage hdp oozi servic hdp exec exec stage hdp oozi servic hdp exec exec su ooziexx cd var tmp oozi var tmp oozi amp amp amp amp usr lib oozi bin oozi start sh exec exec usr lib oozi bin oozi start sh exec exec su ooziexx cd var tmp oozi var tmp oozi amp amp amp amp usr lib oozi bin oozi start sh return usr lib oozi bin oozi start sh return use CATALINA_PID CATALINA PID var run oozi oozi pid mnotic var run oozi oozi pid mnotic stage hdp oozi servic hdp exec exec stage hdp oozi servic hdp exec exec su ooziexx cd var tmp oozi var tmp oozi amp amp amp amp usr lib oozi bin oozi start sh exec exec usr lib oozi bin oozi start sh exec exec su ooziexx cd var tmp oozi var tmp oozi amp amp amp amp usr lib oozi bin oozi start sh return usr lib oozi bin oozi start sh return mnotic mnotic stage hdp oozi servic hdp exec exec stage hdp oozi servic hdp exec exec su ooziexx cd var tmp oozi var tmp oozi amp amp amp amp usr lib oozi bin oozi start sh exec exec usr lib oozi bin oozi start sh exec exec su ooziexx cd var tmp oozi var tmp oozi amp amp amp amp usr lib oozi bin oozi start sh return usr lib oozi bin oozi start sh return use CATALINA_OPTS CATALINA OPTS dderbi stream error file var log oozi derbi log mnotic dderbi stream error file var log oozi derbi log mnotic stage hdp oozi servic hdp exec exec stage hdp oozi servic hdp exec exec su ooziexx cd var tmp oozi var tmp oozi amp amp amp amp usr lib oozi bin oozi start sh exec exec usr lib oozi bin oozi start sh exec exec su ooziexx cd var tmp oozi var tmp oozi amp amp amp amp usr lib oozi bin oozi start sh return usr lib oozi bin oozi start sh return ad CATALINA_OPTS CATALINA OPTS doozi home dir usr lib oozi doozi home dir usr lib oozi doozi config dir etc oozi conf doozi config dir etc oozi conf doozi log dir var log oozi doozi log dir var log oozi doozi data dir grid hadoop oozi data doozi data dir grid hadoop oozi data doozi config file oozi site xml doozi config file oozi site xml doozi log file oozi log properti doozi log file oozi log properti doozi log reload doozi log reload doozi http hostnam ip ec intern doozi http hostnam ip ec intern doozi admin port doozi admin port doozi http port doozi http port doozi http port doozi http port doozi base url http ip ec intern oozi doozi base url http ip ec intern oozi doozi http keystor file home ooziexx keystor doozi http keystor file home ooziexx keystor doozi http keystor pass password doozi http keystor pass password djava librari path usr lib hadoop lib nativ linux amd mnotic djava librari path usr lib hadoop lib nativ linux amd mnotic stage hdp oozi servic hdp exec exec stage hdp oozi servic hdp exec exec su ooziexx cd var tmp oozi var tmp oozi amp amp amp amp usr lib oozi bin oozi start sh exec exec usr lib oozi bin oozi start sh exec exec su ooziexx cd var tmp oozi var tmp oozi amp amp amp amp usr lib oozi bin oozi start sh return usr lib oozi bin oozi start sh return mnotic mnotic stage hdp oozi servic hdp exec exec stage hdp oozi servic hdp exec exec su ooziexx cd var tmp oozi var tmp oozi amp amp amp amp usr lib oozi bin oozi start sh exec exec usr lib oozi bin oozi start sh exec exec su ooziexx cd var tmp oozi var tmp oozi amp amp amp amp usr lib oozi bin oozi start sh return usr lib oozi bin oozi start sh return usr lib oozi oozi server bin catalina sh usr lib oozi oozi server bin catalina sh line var run oozi oozi pid var run oozi oozi pid permiss deni merr deni merr stage hdp oozi servic hdp exec exec stage hdp oozi servic hdp exec exec su ooziexx cd var tmp oozi var tmp oozi amp amp amp amp usr lib oozi bin oozi start sh exec exec usr lib oozi bin oozi start sh exec exec su ooziexx cd var tmp oozi var tmp oozi amp amp amp amp usr lib oozi bin oozi start sh return usr lib oozi bin oozi start sh return chang notrun fail fail su ooziexx cd var tmp oozi var tmp oozi amp amp amp amp usr lib oozi bin oozi start sh usr lib oozi bin oozi start sh return instead one var lib ambari agent puppet modul hdp manifest init pp mnotic var lib ambari agent puppet modul hdp manifest init pp mnotic stage hdp oozi servic hdp exec exec stage hdp oozi servic hdp exec exec su ooziexx cd var tmp oozi var tmp oozi amp amp amp amp usr lib oozi bin oozi start sh anchor hdp exec exec usr lib oozi bin oozi start sh anchor hdp exec exec su ooziexx cd var tmp oozi var tmp oozi amp amp amp amp usr lib oozi bin oozi start sh end usr lib oozi bin oozi start sh end depend exec exec exec exec su ooziexx cd var tmp oozi var tmp oozi amp amp amp amp usr lib oozi bin oozi start sh usr lib oozi bin oozi start sh failur failur true mwarn true mwarn stage hdp oozi servic hdp exec exec stage hdp oozi servic hdp exec exec su ooziexx cd var tmp oozi var tmp oozi amp amp amp amp usr lib oozi bin oozi start sh anchor hdp exec exec usr lib oozi bin oozi start sh anchor hdp exec exec su ooziexx cd var tmp oozi var tmp oozi amp amp amp amp usr lib oozi bin oozi start sh end usr lib oozi bin oozi start sh end skip fail depend mnotic depend mnotic stage hdp oozi servic hdp oozi servic directori var log oozi hdp Directory_recursive_create var log oozi hdp directori var log oozi file var log oozi owner stage hdp oozi servic hdp oozi servic directori var log oozi hdp Directory_recursive_create var log oozi hdp directori var log oozi file var log oozi owner owner chang oozi oozi ooziexx mnotic ooziexx mnotic stage hdp oozi servic hdp oozi servic directori var log oozi hdp Directory_recursive_create var log oozi hdp directori var log oozi file var log oozi group stage hdp oozi servic hdp oozi servic directori var log oozi hdp Directory_recursive_create var log oozi hdp directori var log oozi file var log oozi group group chang oozi oozi hadoopxx mnotic hadoopxx mnotic stage hdp oozi servic hdp oozi servic directori var run oozi hdp Directory_recursive_create var run oozi hdp directori var run oozi file var run oozi owner stage hdp oozi servic hdp oozi servic directori var run oozi hdp Directory_recursive_create var run oozi hdp directori var run oozi file var run oozi owner owner chang oozi oozi ooziexx mnotic ooziexx mnotic stage hdp oozi servic hdp oozi servic directori var run oozi hdp Directory_recursive_create var run oozi hdp directori var run oozi file var run oozi group stage hdp oozi servic hdp oozi servic directori var run oozi hdp Directory_recursive_create var run oozi hdp directori var run oozi file var run oozi group group chang oozi oozi hadoopxx mnotic hadoopxx mnotic finish catalog run second second,0,0,0,0,0,0,0 
2147,Nate Cole,null,0,Capture user for auditing config changes, captur user audit config chang,Add the ability to capture username and save in the table for config mappings. This applies to cluster and host level, add abil captur usernam save tabl config map map appli cluster host level,0,0,0,0,0,0,0 
2149,Mahadev konar,null,0,Ambari needs to set right path for GC log directory of Hbase process., ambari need set right path GC log directori hbase process process,Ambari needs to set right path for GC log directory of Hbase process., ambari need set right path GC log directori hbase process process,0,0,0,0,0,0,0 
2152,Yusaku Sako,ambari-web,0,Sometimes stale host / host component indicators are shown, sometim stale host host compon indic shown,,,0,0,0,0,0,0,0 
2159,Mahadev konar,null,0,After upgrading ambari from 1.2.2.5 to 1.2.3.6 the server throws 500 error when starting/stopping any service, upgrad ambari server throw error start stop start stop servic,After upgrading ambari from 1.2.2.5 to 1.2.3.6 the server throws 500 error when starting/stopping any service, upgrad ambari server throw error start stop start stop servic,0,0,0,0,0,0,0 
2161,Jaimin D Jetly,ambari-agent,0,Datanode Start fails in secure cluster., datanod start fail secur cluster cluster,,,0,0,0,0,0,0,0 
2171,Yusaku Sako,ambari-web,0,Host status filter not restored on Hosts page when navigating back, host statu filter not restor host page navig back,,,0,0,0,0,0,0,0 
2172,Yusaku Sako,ambari-web,0,Fix unit tests for Ambari Web, fix unit test ambari web,Fix currently failing unit tests., fix current fail unit test test,0,0,0,0,0,0,0 
2173,Sumit Mohanty,null,0,TEST BROKEN : FAIL: test_upgradeCommand_executeCommand (TestActionQueue.TestActionQueue), TEST BROKEN FAIL FAIL test_upgradeCommand_executeCommand test_upgrade Command_execute command TestActionQueue TestActionQueue test action queue test action queue,TEST BROKEN : FAIL: test_upgradeCommand_executeCommand (TestActionQueue.TestActionQueue), TEST BROKEN FAIL FAIL test_upgradeCommand_executeCommand test_upgrade Command_execute command TestActionQueue TestActionQueue test action queue test action queue,0,0,0,0,0,0,0 
2180,Mahadev konar,null,0,Remove '0.1' stack definition since its never been used and is redundant., remov stack definit sinc never use redund redund,Remove '0.1' stack definition since its never been used and is redundant., remov stack definit sinc never use redund redund,0,0,0,0,0,0,0 
2187,Srimanth Gunturi,ambari-web,0,Hadoop2 Monitoring: Jobs page should be hidden when HDP 2.0.x stack is installed, hadoop hadoop monitor monitor job page hidden HDP stack instal,When a HDP 2.0.x stack is installed  the Jobs page should be hidden., HDP stack instal job page hidden hidden,0,0,0,0,0,0,0 
2188,Srimanth Gunturi,ambari-web,0,Update mock json data for Test mode, updat mock json data test mode,,,0,0,0,0,0,0,0 
2195,Vikram Dixit K,null,0,Ambari has a deadlock when re-installing after reboot of cluster nodes, ambari deadlock instal instal reboot cluster node,Java stack information for the threads listed above:==================================================='Thread-2': at org.apache.ambari.server.state.ServiceImpl.getDesiredConfigs(ServiceImpl.java:240) waiting to lock &lt;0x000000077b356dd0&gt; (a org.apache.ambari.server.state.ServiceImpl$$EnhancerByGuice$$9e2acafa) at org.apache.ambari.server.state.ServiceComponentImpl.getDesiredConfigs(ServiceComponentImpl.java:292) locked &lt;0x000000077b39bce8&gt; (a org.apache.ambari.server.state.ServiceComponentImpl$$EnhancerByGuice$$af7a745c) at org.apache.ambari.server.state.svccomphost.ServiceComponentHostImpl.getDesiredConfigs(ServiceComponentHostImpl.java:1057) at org.apache.ambari.server.agent.HeartbeatMonitor.generateStatusCommands(HeartbeatMonitor.java:166) at org.apache.ambari.server.agent.HeartbeatMonitor.doWork(HeartbeatMonitor.java:137) at org.apache.ambari.server.agent.HeartbeatMonitor.run(HeartbeatMonitor.java:85) at java.lang.Thread.run(Thread.java:662)'main': at org.apache.ambari.server.state.ServiceComponentImpl.debugDump(ServiceComponentImpl.java:376) waiting to lock &lt;0x000000077b39bce8&gt; (a org.apache.ambari.server.state.ServiceComponentImpl$$EnhancerByGuice$$af7a745c) at org.apache.ambari.server.state.ServiceImpl.debugDump(ServiceImpl.java:354) locked &lt;0x000000077b356dd0&gt; (a org.apache.ambari.server.state.ServiceImpl$$EnhancerByGuice$$9e2acafa) at org.apache.ambari.server.state.cluster.ClusterImpl.debugDump(ClusterImpl.java:693) at org.apache.ambari.server.state.cluster.ClustersImpl.debugDump(ClustersImpl.java:517) at org.apache.ambari.server.controller.AmbariServer.run(AmbariServer.java:320) at org.apache.ambari.server.controller.AmbariServer.main(AmbariServer.java:432)Found 1 deadlock., java stack inform thread list thread thread org apach ambari server state ServiceImpl getDesiredConfigs ServiceImpl java org apach ambari server state servic impl get desir config servic impl java wait lock lt dd gt lt dd gt org apach ambari server state ServiceImpl EnhancerByGuice acafa org apach ambari server state servic impl enhanc guic acafa org apach ambari server state ServiceComponentImpl getDesiredConfigs ServiceComponentImpl java org apach ambari server state servic compon impl get desir config servic compon impl java lock lt bce gt lt bce gt org apach ambari server state ServiceComponentImpl EnhancerByGuice af org apach ambari server state servic compon impl enhanc guic af org apach ambari server state svccomphost ServiceComponentHostImpl getDesiredConfigs ServiceComponentHostImpl java org apach ambari server state svccomphost servic compon host impl get desir config servic compon host impl java org apach ambari server agent HeartbeatMonitor generateStatusCommands HeartbeatMonitor java org apach ambari server agent heartbeat monitor gener statu command heartbeat monitor java org apach ambari server agent HeartbeatMonitor doWork HeartbeatMonitor java org apach ambari server agent heartbeat monitor work heartbeat monitor java org apach ambari server agent HeartbeatMonitor run HeartbeatMonitor java org apach ambari server agent heartbeat monitor run heartbeat monitor java java lang thread run thread java main java lang thread run thread java main org apach ambari server state ServiceComponentImpl debugDump ServiceComponentImpl java org apach ambari server state servic compon impl debug dump servic compon impl java wait lock lt bce gt lt bce gt org apach ambari server state ServiceComponentImpl EnhancerByGuice af org apach ambari server state servic compon impl enhanc guic af org apach ambari server state ServiceImpl debugDump ServiceImpl java org apach ambari server state servic impl debug dump servic impl java lock lt dd gt lt dd gt org apach ambari server state ServiceImpl EnhancerByGuice acafa org apach ambari server state servic impl enhanc guic acafa org apach ambari server state cluster ClusterImpl debugDump ClusterImpl java org apach ambari server state cluster cluster impl debug dump cluster impl java org apach ambari server state cluster ClustersImpl debugDump ClustersImpl java org apach ambari server state cluster cluster impl debug dump cluster impl java org apach ambari server control AmbariServer run AmbariServer java org apach ambari server control ambari server run ambari server java org apach ambari server control AmbariServer main AmbariServer java found org apach ambari server control ambari server main ambari server java found deadlock deadlock,0,0,0,0,0,0,0 
2200,Chad Roberts,ambari-server,0,ambari-server start script (ambari-server.py) will never use SERVER_START_CMD_DEBUG, ambari server ambari server start script ambari server py ambari server py never use SERVER_START_CMD_DEBUG SERVER START CMD DEBUG,The ambari-server.py start script has a command defined for starting the ambari-server in debug mode (SERVER_START_CMD_DEBUG  which turns on remote debugging)  but there is currently no option supported that will force the script to use the debug start commaand. I propose adding a --debug option so that you can run 'ambari-server start --debug' to activate remote debugging., ambari server py ambari server py start script command defin start ambari server ambari server debug mode SERVER_START_CMD_DEBUG SERVER START CMD DEBUG turn remot debug debug current no option support forc script use debug start commaand commaand propos ad debug option run ambari server ambari server start debug debug activ remot debug debug,0,0,0,0,0,0,0 
2203,Yusaku Sako,ambari-web,0,Background operations popup does not automatically refresh the task log, background oper popup not automat refresh task log,,,0,0,0,0,0,0,0 
2208,Yusaku Sako,ambari-web,0,Reassign Master Wizard: refreshing page on step 2  3 or 4 breaks wizard, reassign master wizard wizard refresh page step break wizard,,,0,0,0,0,0,0,0 
2217,Sumit Mohanty,null,0,Increase ambari-agent test coverage, increas ambari agent ambari agent test coverag,ActionQueue.py missing 'Unrecognized command' testcase (L. 173) /src/test/python/TestActionQueue.py:42 unused test_RetryAction stub (retry is implemented in another way) /src/main/python/ambari_agent/ActionQueue.py:221 not covered case if commandresult&#91;&#39;exitcode&#39;&#93; != 0: /src/main/python/ambari_agent/ActionQueue.py:247 not covered case if command.has_key('roleCommand') and command&#91;&#39;roleCommand&#39;&#93; == 'START':PuppetExecutor.py configureEnviron/generate_repo_manifests/run_manifest/runCommand are not covered.PythonExecutor.py isSuccessfull is not testedRepoInstaller.py prepareReposInfo/generateFiles are not coveredshell.py is not covered, ActionQueue py action queue py miss unrecogn unrecogn command command testcas src test python TestActionQueue py src test python test action queue py unus test_RetryAction test retri action stub retri implement anoth way way src main python ambari_agent ActionQueue py src main python ambari_agent action queue py not cover case commandresult exitcod commandresult exitcod src main python ambari_agent ActionQueue py src main python ambari_agent action queue py not cover case command has_key roleCommand command has_key role command command roleCommand command role command START PuppetExecutor py START puppet executor py configureEnviron generate_repo_manifests run_manifest runCommand configur environ generate_repo_manifests run_manifest run command not cover PythonExecutor py cover python executor py isSuccessfull successful not testedRepoInstaller py test repo instal py prepareReposInfo generateFiles prepar repo info gener file not coveredshel py coveredshel py not cover,0,0,0,0,0,0,0 
2223,Siddharth Wagle,ambari-agent,0,Using an external MySQL / Oracle database for Oozie does not work, use extern MySQL SQL oracl databas oozi not work,When setting up Oozie with an external database  the following commands are run:cd /var/tmp/oozie &amp;&amp; /usr/lib/oozie/bin/oozie-setup.sh -hadoop 0.20.200 /usr/lib/hadoop/ -extjs /usr/share/HDP-oozie/ext.zip -jars /usr/lib/hadoop/lib/hadoop-lzo-0.5.0.jar:/usr/share/java/mysql-connector-java.jarThe above command succeeds.However  the next command fails:cd /var/tmp/oozie &amp;&amp; /usr/lib/oozie/bin/ooziedb.sh create -sqlfile oozie.sql -run setting OOZIE_CONFIG=${OOZIE_CONFIG:-/etc/oozie/conf} setting OOZIE_DATA=${OOZIE_DATA:-/var/lib/oozie} setting OOZIE_LOG=${OOZIE_LOG:-/var/log/oozie} setting CATALINA_BASE=${CATALINA_BASE:-/var/lib/oozie/oozie-server} setting CATALINA_TMPDIR=${CATALINA_TMPDIR:-/var/tmp/oozie} setting CATALINA_PID=${CATALINA_PID:-/var/run/oozie/oozie.pid} setting JAVA_HOME=/usr/jdk/jdk1.6.0_31 setting OOZIE_LOG=/var/log/oozie/ setting CATALINA_PID=/var/run/oozie/oozie.pid setting OOZIE_DATA=/grid/0/hadoop/oozie/data/ setting JAVA_LIBRARY_PATH=/usr/lib/hadoop/lib/native/Linux-amd64-64Validate DB ConnectionError: Could not connect to the database: java.lang.ClassNotFoundException: com.mysql.jdbc.DriverStack trace for the error was (for debug purposes):--------------------------------------java.lang.Exception: Could not connect to the database: java.lang.ClassNotFoundException: com.mysql.jdbc.Driver at org.apache.oozie.tools.OozieDBCLI.validateConnection(OozieDBCLI.java:358) at org.apache.oozie.tools.OozieDBCLI.createDB(OozieDBCLI.java:168) at org.apache.oozie.tools.OozieDBCLI.run(OozieDBCLI.java:112) at org.apache.oozie.tools.OozieDBCLI.main(OozieDBCLI.java:63)Caused by: java.lang.ClassNotFoundException: com.mysql.jdbc.Driver at java.net.URLClassLoader$1.run(URLClassLoader.java:202) at java.security.AccessController.doPrivileged(Native Method) at java.net.URLClassLoader.findClass(URLClassLoader.java:190) at java.lang.ClassLoader.loadClass(ClassLoader.java:306) at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:301) at java.lang.ClassLoader.loadClass(ClassLoader.java:247) at java.lang.Class.forName0(Native Method) at java.lang.Class.forName(Class.java:169) at org.apache.oozie.tools.OozieDBCLI.createConnection(OozieDBCLI.java:347) at org.apache.oozie.tools.OozieDBCLI.validateConnection(OozieDBCLI.java:354) ... 3 more--------------------------------------, set oozi extern databas follow command run cd run cd var tmp oozi var tmp oozi amp amp amp amp usr lib oozi bin oozi setup sh usr lib oozi bin oozi setup sh hadoop usr lib hadoop usr lib hadoop extj usr share HDP oozi ext zip usr share HDP oozi ext zip jar usr lib hadoop lib hadoop lzo jar usr share java mysql connector java jarThe usr lib hadoop lib hadoop lzo jar usr share java mysql connector java jar command succe howev succe howev next command fail cd fail cd var tmp oozi var tmp oozi amp amp amp amp usr lib oozi bin ooziedb sh usr lib oozi bin ooziedb sh creat sqlfile oozi sql oozi sql run set OOZIE_CONFIG OOZIE_CONFIG etc oozi conf OOZIE CONFIG OOZIE CONFIG etc oozi conf set OOZIE_DATA OOZIE_DATA var lib oozi OOZIE DATA OOZIE DATA var lib oozi set OOZIE_LOG OOZIE_LOG var log oozi OOZIE LOG OOZIE LOG var log oozi set CATALINA_BASE CATALINA_BASE var lib oozi oozi server CATALINA BASE CATALINA BASE var lib oozi oozi server set CATALINA_TMPDIR CATALINA_TMPDIR var tmp oozi CATALINA TMPDIR CATALINA TMPDIR var tmp oozi set CATALINA_PID CATALINA_PID var run oozi oozi pid CATALINA PID CATALINA PID var run oozi oozi pid set JAVA_HOME usr jdk jdk  JAVA HOME usr jdk jdk  set OOZIE_LOG var log oozi OOZIE LOG var log oozi set CATALINA_PID var run oozi oozi pid CATALINA PID var run oozi oozi pid set OOZIE_DATA grid hadoop oozi data OOZIE DATA grid hadoop oozi data set JAVA_LIBRARY_PATH usr lib hadoop lib nativ linux amd valid JAVA LIBRARY PATH usr lib hadoop lib nativ linux amd valid DB ConnectionError connect error could not connect databas databas java lang ClassNotFoundException java lang class not found except com mysql jdbc DriverStack com mysql jdbc driver stack trace error debug purpos java lang except purpos java lang except could not connect databas databas java lang ClassNotFoundException java lang class not found except com mysql jdbc driver com mysql jdbc driver org apach oozi tool OozieDBCLI validateConnection OozieDBCLI java org apach oozi tool oozi DBCLI valid connect oozi DBCLI java org apach oozi tool OozieDBCLI createDB OozieDBCLI java org apach oozi tool oozi DBCLI creat DB oozi DBCLI java org apach oozi tool OozieDBCLI run OozieDBCLI java org apach oozi tool oozi DBCLI run oozi DBCLI java org apach oozi tool OozieDBCLI main OozieDBCLI java caus org apach oozi tool oozi DBCLI main oozi DBCLI java caus java lang ClassNotFoundException java lang class not found except com mysql jdbc driver com mysql jdbc driver java net URLClassLoader run URLClassLoader java java net URL class loader run URL class loader java java secur AccessController doPrivileged nativ java secur access control privileg nativ method method java net URLClassLoader findClass URLClassLoader java java net URL class loader find class URL class loader java java lang ClassLoader loadClass ClassLoader java java lang class loader load class class loader java sun misc launcher AppClassLoader loadClass launcher java sun misc launcher app class loader load class launcher java java lang ClassLoader loadClass ClassLoader java java lang class loader load class class loader java java lang class forName nativ java lang class name nativ method method java lang class forName class java java lang class name class java org apach oozi tool OozieDBCLI createConnection OozieDBCLI java org apach oozi tool oozi DBCLI creat connect oozi DBCLI java org apach oozi tool OozieDBCLI validateConnection OozieDBCLI java org apach oozi tool oozi DBCLI valid connect oozi DBCLI java,0,0,0,0,0,0,0 
2228,Sumit Mohanty,null,0,Fix MySQL and Oracle DDL scripts according to last DB changes, fix MySQL SQL oracl DDL script accord last DB chang,user_name column was added to clusterconfigmapping and hostconfigmapping tables. This changes should be made to DDL scripts for Oracle and MySQL also., user_name column ad clusterconfigmap hostconfigmap tabl tabl chang made DDL script oracl MySQL SQL also also,0,0,0,0,0,0,0 
2233,Sumit Mohanty,null,0,Ensure version values are used appropriately throughout Ambari, ensur version valu use appropri throughout ambari,The current version of Ambari build is being used in several scenarios: Ensure Ambari Server installs the correct version of Ambari Agent Ensure that Ambari Server only accepts registration from correct version of Ambari Agent Ensure that DB version is compatible with Ambari Server  The DB version itself will be used to control DB upgrades  Towards this end the following open issues remain: Get the build version be automatically embedded in the version file Use the above for deploying agent as well as allowing agents to register Regarding DB version there are two possible paths:  Separate out DB version and have it be modified manually as needed Have the build version be used as DB version - this may make writing upgrade scripts little complicated as build version may change due to some proj mgmt decision, current version ambari build use sever scenario scenario ensur ambari server instal correct version ambari agent ensur ambari server accept registr correct version ambari agent ensur DB version compat ambari server DB version use control DB upgrad toward end follow open issu remain remain get build version automat embed version file use deploy agent well allow agent regist regard DB version two possibl path path separ DB version modifi manual need build version use DB version may make write upgrad script littl complic build version may chang due proj mgmt decis,0,0,0,0,0,0,1 
2240,Jaimin D Jetly,ambari-web,0,Allow Security related configs to be modified via custom settings, allow secur relat config modifi via custom set,,,0,0,0,0,0,ambari-web/app/data/HDP2/config_mapping.js;ambari-web/app/data/HDP2/config_properties.js;ambari-web/app/data/config_mapping.js;ambari-web/app/data/config_properties.js;,0 
2259,Oleg Nechiporenko,null,0,Start/Stop button may stay enabled for 30-40 seconds after it has been clicked, start stop start stop button may stay enabl second click,Start/Stop button stays enabled for atleast 30-40 seconds after its been clicked already., start stop start stop button stay enabl atleast second click alreadi alreadi,0,0,0,0,0,0,1 
2260,Tom Beerbower,null,0,Bad hosts query example in API docs, bad host queri exampl API doc,The example ...'hosts' : [ { 'href' : 'http://your.ambari.server/api/v1/clusters/c1/hosts/host1'  'Hosts' : { 'cluster_name' : 'c1'  'host_name' : 'some.cluster.host' } }  { 'href' : 'http://your.ambari.server/api/v1/clusters/c1/hosts/host2'  'Hosts' : { 'cluster_name' : 'c1'  'host_name' : 'another.cluster.host' } ]... should read ... 'hosts' : [ { 'href' : 'http://your.ambari.server/api/v1/clusters/c1/hosts/some.host'  'Hosts' : { 'cluster_name' : 'c1'  'host_name' : 'some.host' } }  { 'href' : 'http://your.ambari.server/api/v1/clusters/c1/hosts/another.host'  'Hosts' : { 'cluster_name' : 'c1'  'host_name' : 'another.host' } } ], exampl host host href href http ambari server api cluster host host http ambari server api cluster host host host host cluster_name cluster_name host_name host_name cluster host cluster host href href http ambari server api cluster host host http ambari server api cluster host host host host cluster_name cluster_name host_name host_name anoth cluster host anoth cluster host read host host href href http ambari server api cluster host host http ambari server api cluster host host host host cluster_name cluster_name host_name host_name host host href href http ambari server api cluster host anoth host http ambari server api cluster host anoth host host host cluster_name cluster_name host_name host_name anoth host anoth host,0,0,0,0,0,ambari-server/docs/api/v1/clusters-cluster.md;ambari-server/docs/api/v1/index.md;ambari-server/docs/api/v1/index.md;,0 
2262,Andrii Tkach,ambari-web,0,On 'install Options' page  when selecting 'Perform manual registration on hosts and do not use SSH' is setting 'Path to 64-bit JDK' disabled, instal option option page select perform perform manual registr host not use SSH SSH set path path bit JDK JDK disabl,On 'install Options' page  when selecting 'Perform manual registration on hosts and do not use SSH' is setting 'Path to 64-bit JDK' disabled(Screen Shot 2013-06-03 at 10.54.49 AM.png).Also path to 64-bit JDK JAVA_HOME' input field is enabled with unchecked check box(unchecked.png).Steps:1. Go to 'Install Options' page.Result:'Path to 64-bit JDK JAVA_HOME' input field is available for editing when check box is unchecked., instal option option page select perform perform manual registr host not use SSH SSH set path path bit JDK JDK disabl screen disabl screen shot png also png also path bit JDK JAVA_HOME JAVA HOME input field enabl uncheck check box uncheck png step box uncheck png step Go instal instal option option page result path page result path bit JDK JAVA_HOME JAVA HOME input field avail edit check box uncheck uncheck,0,0,0,0,0,0,0 
2279,Jaimin D Jetly,ambari-web,0,Configuration mapping metadata on ambari-web should be computed as per the stack selection., configur map metadata ambari web ambari web comput per stack select select,,,0,0,0,0,0,ambari-web/app/controllers/main/service/info/configs.js;ambari-web/app/controllers/wizard/step8_controller.js;,0 
2290,Dmytro Sen,ambari-server,0,Ambari Upgrade prcoess should preserve the old configs and add the new config options to the old config files., ambari upgrad prcoess preserv old config add new config option old config file file,The Ambari Upgrade process should preserve the old configs and add the new config options to the old config files.Currently we have it the other way around  that we copy the needed 3 properties from the old config files - this is wrong. We need to use the older config file and add the new options to the old config file. This is because the older config file can have all kinds of config option that the user might have used. We have to really really keep in mind usability of the product when fixing issues., ambari upgrad process preserv old config add new config option old config file current file current way around copi need properti old config file wrong wrong need use older config file add new option old config file file older config file kind config option user might use use realli realli keep mind usabl product fix issu issu,0,0,0,0,0,0,1 
2300,Dmitry Lysnichenko,ambari-server,0,500 Exception creating service component during install, except creat servic compon instal,I was installing a new cluster in my VM when the progress blocked on step 12. Looking on browser log  the PUTs for clusters desired_configs succeeded  but the very next call to create service component failed.&#91;POST&#93; http://dev.hortonworks.com:8080/api/v1/clusters/vmc/services?ServiceInfo/service_name=HDFSStatus Code:500 Invalid arguments  clustername and componentname should be non-null and non-empty when trying to create a componentData uploaded:{'components':[{'ServiceComponentInfo':{'component_name':'NAMENODE'}} {'ServiceComponentInfo':{'component_name':'SECONDARY_NAMENODE'}} {'ServiceComponentInfo':{'component_name':'DATANODE'}} {'ServiceComponentInfo':{'component_name':'HDFS_CLIENT'}}]}:Exception on server console:Mar 21  2013 11:25:09 AM com.sun.jersey.spi.container.ContainerResponse mapMappableContainerExceptionSEVERE: The RuntimeException could not be mapped to a response  re-throwing to the HTTP containerjava.lang.IllegalArgumentException: Invalid arguments  clustername and componentname should be non-null and non-empty when trying to create a component at org.apache.ambari.server.controller.AmbariManagementControllerImpl.createComponents(AmbariManagementControllerImpl.java:387) at org.apache.ambari.server.controller.internal.ComponentResourceProvider$1.invoke(ComponentResourceProvider.java:88) at org.apache.ambari.server.controller.internal.ComponentResourceProvider$1.invoke(ComponentResourceProvider.java:85) at org.apache.ambari.server.controller.internal.AbstractResourceProvider.createResources(AbstractResourceProvider.java:229) at org.apache.ambari.server.controller.internal.ComponentResourceProvider.createResources(ComponentResourceProvider.java:85) at org.apache.ambari.server.controller.internal.ClusterControllerImpl.createResources(ClusterControllerImpl.java:131) at org.apache.ambari.server.api.services.persistence.PersistenceManagerImpl.create(PersistenceManagerImpl.java:75) at org.apache.ambari.server.api.handlers.QueryCreateHandler.persist(QueryCreateHandler.java:163) at org.apache.ambari.server.api.handlers.QueryCreateHandler.handleRequest(QueryCreateHandler.java:68) at org.apache.ambari.server.api.services.BaseRequest.process(BaseRequest.java:98) at org.apache.ambari.server.api.services.BaseService.handleRequest(BaseService.java:73) at org.apache.ambari.server.api.services.ServiceService.createServices(ServiceService.java:114) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25) at java.lang.reflect.Method.invoke(Method.java:597), instal new cluster VM progress block step look browser log PUTs PU Ts cluster desired_configs succeed next call creat servic compon fail POST fail POST code code invalid argument clusternam componentnam non null non null non empti non empti tri creat componentData compon data upload compon ServiceComponentInfo component_name NAMENODE upload compon servic compon info component_name NAMENODE ServiceComponentInfo component_name SECONDARY_NAMENODE servic compon info component_name SECONDARY NAMENODE ServiceComponentInfo component_name DATANODE servic compon info component_name DATANODE ServiceComponentInfo component_name HDFS_CLIENT except servic compon info component_name HDFS CLIENT except server consol mar consol mar com sun jersey spi contain ContainerResponse com sun jersey spi contain contain respons mapMappableContainerExceptionSEVERE map mappabl contain except SEVERE RuntimeException runtim except could not map respons throw throw HTTP containerjava lang IllegalArgumentException containerjava lang illeg argument except invalid argument clusternam componentnam non null non null non empti non empti tri creat compon org apach ambari server control AmbariManagementControllerImpl createComponents AmbariManagementControllerImpl java org apach ambari server control ambari manag control impl creat compon ambari manag control impl java org apach ambari server control intern ComponentResourceProvider invok ComponentResourceProvider java org apach ambari server control intern compon resourc provid invok compon resourc provid java org apach ambari server control intern ComponentResourceProvider invok ComponentResourceProvider java org apach ambari server control intern compon resourc provid invok compon resourc provid java org apach ambari server control intern AbstractResourceProvider createResources AbstractResourceProvider java org apach ambari server control intern abstract resourc provid creat resourc abstract resourc provid java org apach ambari server control intern ComponentResourceProvider createResources ComponentResourceProvider java org apach ambari server control intern compon resourc provid creat resourc compon resourc provid java org apach ambari server control intern ClusterControllerImpl createResources ClusterControllerImpl java org apach ambari server control intern cluster control impl creat resourc cluster control impl java org apach ambari server api servic persist PersistenceManagerImpl creat PersistenceManagerImpl java org apach ambari server api servic persist persist manag impl creat persist manag impl java org apach ambari server api handler QueryCreateHandler persist QueryCreateHandler java org apach ambari server api handler queri creat handler persist queri creat handler java org apach ambari server api handler QueryCreateHandler handleRequest QueryCreateHandler java org apach ambari server api handler queri creat handler handl request queri creat handler java org apach ambari server api servic BaseRequest process BaseRequest java org apach ambari server api servic base request process base request java org apach ambari server api servic BaseService handleRequest BaseService java org apach ambari server api servic base servic handl request base servic java org apach ambari server api servic ServiceService createServices ServiceService java org apach ambari server api servic servic servic creat servic servic servic java sun reflect NativeMethodAccessorImpl invok nativ sun reflect nativ method accessor impl invok nativ method method sun reflect NativeMethodAccessorImpl invok NativeMethodAccessorImpl java sun reflect nativ method accessor impl invok nativ method accessor impl java sun reflect DelegatingMethodAccessorImpl invok DelegatingMethodAccessorImpl java sun reflect deleg method accessor impl invok deleg method accessor impl java java lang reflect method invok method java java lang reflect method invok method java,0,0,0,0,0,0,1 
2313,Oleg Nechiporenko,null,0,UI allows adding already existing properties to custom core-site.xml /hdfs-site.xml settings and creates confusion, UI allow ad alreadi exist properti custom core site xml core site xml hdf site xml hdf site xml set creat confus,Steps:1. Go to 'Services' page.2. Select 'HDFS' service.3. Select 'Configs' tab.4. Open 'Custom core-site.xml' panel.5. Add property with name 'ipc.client.idlethreshold' to this panel.Result:Property with name 'ipc.client.idlethreshold' was added to 'Custom core-site.xml' panel. But there is already presented property with same name in 'core-site.xml' file. After saving added property was disappeared from UI  and after service starting value of the old was changed to new (on UI and in 'core-site.xml' file).Expected result:UI should not allow to add property with existing name in specified file., step step Go servic servic page page select HDFS HDFS servic servic select config config tab tab open custom custom core site xml core site xml panel panel add properti name ipc client idlethreshold ipc client idlethreshold panel result properti panel result properti name ipc client idlethreshold ipc client idlethreshold ad custom custom core site xml core site xml panel panel alreadi present properti name core site xml core site xml file file save ad properti disappear UI servic start valu old chang new UI core site xml core site xml file expect file expect result UI result UI not allow add properti exist name specifi file file,0,0,0,0,0,0,0 
2337,Jaimin D Jetly,ambari-web,0,Security Wizard: navigation not locked down  causes artifacts  and other unwanted side effects, secur wizard wizard navig not lock caus artifact unwant side effect,,,0,0,0,0,0,0,1 
2346,Yusaku Sako,ambari-web,0,API call to get 'metrics/cpu' does not work for NameNode and JobTracker host components, API call get metric cpu metric cpu not work NameNode name node JobTracker job tracker host compon,1. http://ambari:8080/api/v1/clusters/cluster/services?fields=components/host_components/metricsincludes all metrics for NameNode and JobTracker  including cpu metrics.2. http://ambari:8080/api/v1/clusters/cluster/services?fields=components/host_components/metrics/cpudoes not return cpu metrics for NameNode and JobTracker, metric NameNode name node JobTracker job tracker includ cpu metric metric not return cpu metric NameNode name node JobTracker job tracker,0,0,0,0,0,ambari-agent/src/main/puppet/modules/hdp-ganglia/files/rrd.py;,1 
2349,Oleksandr Diachenko,ambari-server,0,Enhance processing of ojdbc.jar before starting ambari server, enhanc process ojdbc jar ojdbc jar start ambari server,Enhancements: Read RESOURCE_DIR from the ambari.properties Ask user twice to place drivers to /usr/share/java, enhanc enhanc read RESOURCE_DIR RESOURCE DIR ambari properti ambari properti ask user twice place driver usr share java usr share java,0,0,0,0,0,0,1 
2363,Dmitry Lysnichenko,ambari-server,0,Intermittent test failure with HBase port Scanner test., intermitt test failur HBase base port scanner test test,This test fails sometimes and is not very reliable., test fail sometim not reliabl reliabl,0,0,0,0,0,0,1 
2371,Jaimin D Jetly,ambari-web,0,Security Wizard: webhcat Server start fails on enabling security, secur wizard wizard webhcat server start fail enabl secur,This happens when templeton.kerberos.principal property is set to HTTP/_HOST@&lt;realm name&gt; instead of HTTP/&lt;internal host name&gt;@&lt;realm name&gt;, happen templeton kerbero princip templeton kerbero princip properti set HTTP _HOST lt realm HTTP  HOST lt realm name gt name gt instead HTTP lt intern HTTP lt intern host name gt lt realm name gt lt realm name gt name gt,0,0,0,0,0,ambari-web/app/controllers/main/admin/security/add/step3.js;ambari-web/app/controllers/main/admin/security/disable.js;,1 
2383,Siddharth Wagle,ambari-server,0,Add unit tests for ambari-server python changes, add unit test ambari server ambari server python chang,AMBARI-2174 - Add missing unit tests for the code changes, AMBARI AMBARI add miss unit test code chang,0,0,0,0,0,ambari-web/app/utils/host_progress_popup.js;,1 
2391,Oleksandr Diachenko,ambari-server,0,Bootstrap is broken for ambari web with RHEL-5.8, bootstrap broken ambari web RHEL RHEL,Steps:1. Install ambari-server.2. Go to 'Install Options' page.3. Set the hosts list and ssh-key  click 'Next' button.Result:Ambari Web is blocked in 'Confirm Hosts'. Confirming was not ended after not less than 40 minutes., step step instal ambari server ambari server Go instal instal option option page page set host list ssh key ssh key click next next button result ambari button result ambari web block confirm confirm host host confirm not end not less minut minut,0,0,0,0,0,0,1 
2394,Siddharth Wagle,ambari-server,0,ambari-server setup borken in trunk, ambari server ambari server setup borken trunk,install_jce_manually() in the download_jdk() result in fatal exception.Checking JDK...INFO: Loading properties from /etc/ambari-server/conf/ambari.propertiesERROR: Error getting ambari propertiesERROR: Exiting with exit code -1. Reason: Downloading or installing JDK failed: 'Fatal exception: Error getting ambari properties  exit code -1'. Exiting., install_jce_manually install_jce_manually download_jdk download_jdk result fatal except check except check JDK INFO JDK INFO load properti etc ambari server conf ambari propertiesERROR etc ambari server conf ambari properti ERROR error get ambari propertiesERROR properti ERROR exit exit code reason reason download instal JDK fail fail fatal fatal except except error get ambari properti exit code exit exit,0,0,0,0,0,0,1 
2403,Dmitry Lysnichenko,ambari-server,0,ambari-server setup should allow user to change database password, ambari server ambari server setup allow user chang databas password,If we run setup second time. Amabri should allow user to change the DB password for the ambari-user.Currently  the executed script should allow for this.command: &#91;&#39;su&#39;  &#39;-&#39;  &#39;postgres&#39;  &#39;--command=psql -f /var/lib/ambari-server/resources/Ambari-DDL-Postgres-CREATE.sql -v username=/&#39;&quot;ambari-server&quot;/&#39; -v password=&quot;/&#39;/&#39;&quot;&#39;&#93;, run setup second time time amabri allow user chang DB password ambari user current ambari user current execut script allow command command su su postgr postgr command psql command psql var lib ambari server resourc ambari DDL postgr CREATE sql var lib ambari server resourc ambari DDL postgr CREATE sql usernam quot ambari server quot usernam quot ambari server quot password quot quot password quot quot,0,0,0,0,0,0,0 
2408,Jaimin D Jetly,ambari-web,0,Kerberos globals are shown in HDFS config page during install, kerbero global shown HDFS config page instal,,,0,0,0,0,0,0,1 
2413,Andrii Tkach,ambari-web,0,Installer Wizard step-6: NameNode and SNameNode should not be co-hosted by default on multinode cluster., instal wizard step step NameNode name node SNameNode name node not co host co host default multinod cluster cluster,,,0,0,0,0,0,0,0 
2414,Oleg Nechiporenko,ambari-web,0,HDFS Config page is broken in testMode on trunk, HDFS config page broken testMode test mode trunk,HDFS Config page (post-install) does not load when App.testMode = true, HDFS config page post instal post instal not load app testMode app test mode true,0,0,0,0,0,0,0 
2433,Dmitry Lysnichenko,ambari-server,0,Bootstrap failed on rhel 5.6, bootstrap fail rhel,STDOUTTraceback (most recent call last):File '/tmp/setupAgent.py'  line 192  in ?main(sys.argv)File '/tmp/setupAgent.py'  line 188  in mainsys.exit(runAgent(passPhrase  expected_hostname))File '/tmp/setupAgent.py'  line 80  in runAgentagent_retcode = subprocess.call('/usr/sbin/ambari-agent start --expected-hostname={0}'.format(expected_hostname)  shell=True)AttributeError: 'str' object has no attribute 'format'Error seems to be caused by python 2.4 version., STDOUTTraceback STDOUT traceback recent call last file last file tmp setupAgent py tmp setup agent py line main sy argv file main sy argv file tmp setupAgent py tmp setup agent py line mainsi exit runAgent passPhrase mainsi exit run agent pass phrase expected_hostname file expected_hostname file tmp setupAgent py tmp setup agent py line runAgentagent_retcode run Agentagent_retcode subprocess call usr sbin ambari agent subprocess call usr sbin ambari agent start expect hostnam format expected_hostname expect hostnam format expected_hostname shell true AttributeError shell true attribut error str str object no attribut format error format error seem caus python version version,0,0,0,0,0,0,1 
2441,Dmitry Lysnichenko,ambari-server,0,Ambari server start fails with reconfigured user, ambari server start fail reconfigur user,STR:1) Run ambari-server setup.2) Choose custom user  user1.3) Delete ambari.user from ambari.properties.4) Run ambari-server setup.5) Choose custom user  different from choosen in step 2  user2.6) Run ambari-server start.Got error:ambari-server startUsing python /usr/bin/python2.6Starting ambari-serverHave root privileges.Checking iptables...iptables is disabled nowRunning server: &#91;&#39;/bin/su&#39;  &#39;user2&#39;  &#39;-s&#39;  &#39;/bin/sh&#39;  &#39;-c&#39;  &#39;/usr/jdk64/jdk1.6.0_31/bin/java -server -XX:NewRatio=3 -XX:+UseConcMarkSweepGC -XX:-UseGCOverheadLimit -XX:CMSInitiatingOccupancyFraction=60 -Xms512m -Xmx2048m -cp /etc/ambari-server/conf:/usr/lib/ambari-server/*:/usr/lib64/qt-3.3/bin:/usr/local/sbin:/usr/local/bin:/sbin:/bin:/usr/sbin:/usr/bin:/root/bin:/usr/lib/ambari-server/* org.apache.ambari.server.controller.AmbariServer &gt;/var/log/ambari-server/ambari-server.out 2&gt;&amp;1 &amp; echo $! &gt; /var/run/ambari-server/ambari-server.pid&#39;&#93;done.sh: /var/run/ambari-server/ambari-server.pid: Permission deniedsh: /var/log/ambari-server/ambari-server.out: Permission denied, STR STR run ambari server ambari server setup setup choos custom user user user delet ambari user ambari user ambari properti ambari properti run ambari server ambari server setup setup choos custom user differ choosen step user user run ambari server ambari server start got start got error ambari server error ambari server startUsing start use python usr bin python start usr bin python start ambari serverHave ambari server root privileg check privileg check iptabl iptabl iptabl iptabl disabl nowRunning run server server bin su bin su user user bin sh bin sh usr jdk jdk  bin java usr jdk jdk  bin java server XX NewRatio XX new ratio XX UseConcMarkSweepGC XX use conc mark sweep GC XX UseGCOverheadLimit XX use GC overhead limit XX CMSInitiatingOccupancyFraction XX CMS initi occup fraction xm xm xmx xmx cp etc ambari server conf usr lib ambari server usr lib qt bin usr local sbin usr local bin sbin bin usr sbin usr bin root bin usr lib ambari server etc ambari server conf usr lib ambari server usr lib qt bin usr local sbin usr local bin sbin bin usr sbin usr bin root bin usr lib ambari server org apach ambari server control AmbariServer org apach ambari server control ambari server gt var log ambari server ambari server gt var log ambari server ambari server gt amp gt amp amp amp echo gt gt var run ambari server ambari server pid done sh var run ambari server ambari server pid done sh var run ambari server ambari server pid var run ambari server ambari server pid permiss deniedsh deniedsh var log ambari server ambari server var log ambari server ambari server permiss deni,0,0,0,0,0,0,1 
2443,Jaimin D Jetly,ambari-agent; ambari-web,0,Security wizard: smoke test for services fails with customized service user names., secur wizard wizard smoke test servic fail custom servic user name name,,,0,0,0,0,0,0,1 
2447,Dmitry Lysnichenko,ambari-server,0,Upgrade from 1.2.2/1.2.3.7 to 1.2.5 fails because the ddl script does not work - metainfo version change is broken., upgrad fail ddl script not work metainfo version chang broken broken,Upgrade from 1.2.2/1.2.3.7 to 1.2.5 fails because the ddl script does not work - metainfo version change is broken.Again we need thorugh testing around this. Please make sure we have tested 1.2.2 and 1.2.3  1.2.4 upgrade to 1.2.5., upgrad fail ddl script not work metainfo version chang broken broken need thorugh test around pleas make sure test upgrad,0,0,0,0,0,0,0 
2461,Dmitry Lysnichenko,ambari-server,0,Add unit tests for bootstrap and setupAgent python scripts for the server., add unit test bootstrap setupAgent setup agent python script server server,Add unit tests for bootstrap and setupAgent python scripts for the server.We need to find gaps on the bootstrap and setupagent script and add unit tests for them., add unit test bootstrap setupAgent setup agent python script server server need find gap bootstrap setupag script add unit test,0,0,0,0,0,0,1 
2466,Yusaku Sako,ambari-web,0,Hive/Oozie database settings should accept custom JDBC URLs, hive oozi hive oozi databas set accept custom JDBC URLs UR Ls,Ran into issues setting up Hive and Oozie with an Oracle database.1. We are hard-coding port 1521 for the JDBC URL. 2. There are two types of JDBC URLs for Oracle: jdbc:oracle:thin:@&#91;HOST&#93;&#91;:PORT&#93;:SID jdbc:oracle:thin:@//&#91;HOST&#93;&#91;:PORT&#93;/SERVICEWe are making the assumption that it is the latter  but this may not work depending on how Oracle is set up.3. We prompt for the 'Database Name'. In Oracle context  this could be the SID or SERVICE NAME  but it's not clear what this is.As a solution to all of the above  we will construct the JDBC URL based on the database type  host  and name for Hive/Oozie and present it to the user as an editable text field during install.Post-install  the JDBC URL remains editable  but does not change automatically as changes other database-related parameters., ran issu set hive oozi oracl databas databas hard code hard code port JDBC URL URL two type JDBC URLs UR Ls oracl oracl jdbc oracl thin HOST PORT SID jdbc oracl thin HOST PORT SID jdbc oracl thin HOST PORT SERVICEWe jdbc oracl thin HOST PORT SERVICE make assumpt latter may not work depend oracl set prompt databas databas name name oracl context could SID SERVICE NAME not clear solut construct JDBC URL base databas type host name hive oozi hive oozi present user edit text field instal post instal instal post instal JDBC URL remain edit not chang automat chang databas relat databas relat paramet paramet,0,0,0,0,0,0,1 
2471,Mahadev konar,null,0,Remove unnecessary check for hostnames/ service name which is wrong., remov unnecessari check hostnam hostnam servic name wrong wrong,Remove unnecessary check for hostnames/ service name which is wrong., remov unnecessari check hostnam hostnam servic name wrong wrong,0,0,0,0,0,0,1 
2475,Ximo Guanter,null,0,Ambari bootstrap actions report success even if a failure happened, ambari bootstrap action report success even failur happen,Sometimes  bootstrap actions reports success even if it has failed host tasks:&lt;bootStrapRequest&gt; &lt;status&gt;SUCCESS&lt;/status&gt; &lt;hostsStatus&gt; &lt;hostName&gt;andromeda54.hi.inet&lt;/hostName&gt; &lt;status&gt;FAILED&lt;/status&gt; &lt;statusCode&gt;1&lt;/statusCode&gt; &lt;log&gt; [...] &lt;/log&gt; &lt;/hostsStatus&gt; &lt;hostsStatus&gt; &lt;hostName&gt;andromeda55.hi.inet&lt;/hostName&gt; &lt;status&gt;FAILED&lt;/status&gt; &lt;statusCode&gt;1&lt;/statusCode&gt; &lt;log&gt; [...] &lt;/log&gt; &lt;/hostsStatus&gt; &lt;log&gt; [...] &lt;/log&gt;&lt;/bootStrapRequest&gt;, sometim bootstrap action report success even fail host task lt bootStrapRequest gt task lt boot strap request gt lt statu gt SUCCESS lt statu gt lt statu gt SUCCESS lt statu gt lt hostsStatus gt lt host statu gt lt hostName gt andromeda hi inet lt hostName gt lt host name gt andromeda hi inet lt host name gt lt statu gt FAILED lt statu gt lt statu gt FAILED lt statu gt lt statusCode gt lt statusCode gt lt statu code gt lt statu code gt lt log gt lt log gt lt log gt lt log gt lt hostsStatus gt lt host statu gt lt hostsStatus gt lt host statu gt lt hostName gt andromeda hi inet lt hostName gt lt host name gt andromeda hi inet lt host name gt lt statu gt FAILED lt statu gt lt statu gt FAILED lt statu gt lt statusCode gt lt statusCode gt lt statu code gt lt statu code gt lt log gt lt log gt lt log gt lt log gt lt hostsStatus gt lt host statu gt lt log gt lt log gt lt log gt lt bootStrapRequest gt lt log gt lt boot strap request gt,0,0,0,0,0,0,1 
2480,Xi Wang,ambari-web,0,Dashboard page has a lot of footer padding, dashboard page lot footer pad,This ticket solved:1. Dashboard page has padding space under footer.2. When a widget got deleted  the page scroll to top.(page should stay in place), ticket solv solv dashboard page pad space footer footer widget got delet page scroll top page top page stay place place,0,0,0,0,0,0,1 
2486,Dmitry Lysnichenko,ambari-agent,0,shell.killprocessgrp is not working in a reliable way, shell killprocessgrp shell killprocessgrp not work reliabl way,We have noticed an issue where shell.killprocessgrp is not working correctly. We have seen a scenario where namenode start takes a long time when on a secure cluster the jce policy is unavailable. After 10 minutes when the agent tries to kill the puppet process it invariably fails.We need to run some experiment (perhaps using long running puppet processes) to ensure that shell.killprocessgrp works as expected.Also  we need to verify that the behavior is as expected on both RHEL and Suse., notic issu shell killprocessgrp shell killprocessgrp not work correctli correctli seen scenario namenod start take long time secur cluster jce polici unavail unavail minut agent tri kill puppet process invari fail fail need run experi perhap use long run puppet process process ensur shell killprocessgrp shell killprocessgrp work expect also expect also need verifi behavior expect RHEL suse suse,0,0,0,0,0,0,1 
2490,Siddharth Wagle,ambari-server,0,Issues with setup ldap, issu setup ldap,I got this blow-up (when bind anon was either false or I just pressed returnBind anonymously true/false (false):====================Review Settings====================authentication.ldap.primaryUrl: my.ldap:389authentication.ldap.secondaryUrl: asdauthentication.ldap.useSSL: falseauthentication.ldap.usernameAttribute: uidauthentication.ldap.baseDn: basednauthorization.userRoleName: userauthorization.adminRoleName: adminauthentication.ldap.bindAnonymously: falseTraceback (most recent call last):File '/usr/sbin/ambari-server.py'  line 3047  in &lt;module&gt;main()File '/usr/sbin/ambari-server.py'  line 2891  in mainsetup_ldap()File '/usr/sbin/ambari-server.py'  line 2353  in setup_ldapprint('%s: %s' % (property  ldap_property_value_mapproperty))KeyError: 'authentication.ldap.managerDn', got blow blow bind anon either fals press returnBind return bind anonym true fals true fals fals review fals review set authent ldap primaryUrl set authent ldap primari url ldap authent ldap secondaryUrl ldap authent ldap secondari url asdauthent ldap useSSL asdauthent ldap use SSL falseauthent ldap usernameAttribute falseauthent ldap usernam attribut uidauthent ldap baseDn uidauthent ldap base Dn basednauthor userRoleName basednauthor user role name userauthor adminRoleName userauthor admin role name adminauthent ldap bindAnonymously adminauthent ldap bind anonym falseTraceback fals traceback recent call last file last file usr sbin ambari server py usr sbin ambari server py line lt modul gt main file lt modul gt main file usr sbin ambari server py usr sbin ambari server py line mainsetup_ldap file mainsetup_ldap file usr sbin ambari server py usr sbin ambari server py line setup_ldapprint setup_ldapprint properti ldap_property_value_mapproperty KeyError ldap_property_value_mapproperty key error authent ldap managerDn authent ldap manag Dn,0,0,0,0,0,0,1 
2498,Oleksandr Diachenko,ambari-server,0,Cleanup setup https flow, cleanup setup http flow,Expected flow:[root@localhost ~]# ambari-server setup-httpsUsing python /usr/bin/python2.6Setting up HTTPS properties...Do you want to configure HTTPS [y/n] (y)?SSL port (8443) ? Please enter path to Certificate: /some/path/on/my/host/server.crtPlease enter path to Private Key: /some/path/on/my/host/server.keyPlease enter password for Private Key:Importing and saving certificate...done.NOTE: Reset Ambari Server to apply changes ('ambari-server restart|stop|start')Ambari Server 'HTTPS setup' completed successfully. Exiting., expect flow root localhost flow root localhost ambari server ambari server setup httpsUsing setup http use python usr bin python set usr bin python set HTTPS properti properti want configur HTTPS SSL SSL port pleas enter path certif certif path host server crtPlease path host server crt pleas enter path privat key key path host server keyPlease path host server key pleas enter password privat key import key import save certif done NOTE certif done NOTE reset ambari server appli chang ambari server ambari server restart stop start ambari restart stop start ambari server HTTPS HTTPS setup setup complet success success exit exit,0,0,0,0,0,0,1 
2515,Jaimin D Jetly,ambari-web,0,Cannot add property mapred.task.tracker.task-controller, cannot add properti mapr task tracker task control mapr task tracker task control,,,0,0,0,0,0,0,0 
2517,Siddharth Wagle,ambari-agent,0,Decommission data node not working in secure mode, decommiss data node not work secur mode,Decommission datanode does not do kinit before refresh., decommiss datanod not kinit refresh refresh,0,0,0,0,0,0,1 
2522,Siddharth Wagle,ambari-agent,0,Zookeeper smoke test failing in secure cluster, zookeep smoke test fail secur cluster,Zookeeper smoke test failing in secure cluster, zookeep smoke test fail secur cluster,0,0,0,0,0,0,1 
2525,Dmitry Lysnichenko,ambari-server,0,Add helpful message when not able to download jdk with setup options for the user to be able to specify the jdk., add help messag not abl download jdk setup option user abl specifi jdk jdk,Add helpful message when not able to download jdk with setup options for the user to be able to specify the jdk., add help messag not abl download jdk setup option user abl specifi jdk jdk,0,0,0,0,0,0,0 
2532,Siddharth Wagle,ambari-agent,0,Incorrect permission on taskcontroller.cfg, incorrect permiss taskcontrol cfg taskcontrol cfg,/etc/conf/hadoop/taskcontroller.cfgIn secure mode permissions are set to '400'., etc conf hadoop taskcontrol cfgIn etc conf hadoop taskcontrol cfg secur mode permiss set,0,0,0,0,0,0,0 
2534,Sumit Mohanty,ambari-server,0,Some memory configs are set to -1 in Ambari, memori config set ambari,Some memory configs are set to -1 in ambari-mapred.cluster.reduce.memory.mb-mapred.jobtracker.maxtasks.per.job-mapred.cluster.max.reduce.memory.mb-mapred.cluster.map.memory.mb-mapred.job.map.memory.mb-mapred.job.reduce.memory.mb-mapred.cluster.max.map.memory.mbModify the stack definition to put default values as appropriate., memori config set ambari mapr cluster reduc memori mb mapr jobtrack maxtask per job mapr cluster max reduc memori mb mapr cluster map memori mb mapr job map memori mb mapr job reduc memori mb mapr cluster max map memori mbModify ambari mapr cluster reduc memori mb mapr jobtrack maxtask per job mapr cluster max reduc memori mb mapr cluster map memori mb mapr job map memori mb mapr job reduc memori mb mapr cluster max map memori mb modifi stack definit put default valu appropri appropri,0,0,0,0,0,0,0 
2542,Nate Cole,ambari-server,0,Custom Repo URL cannot be set when non-root, custom repo URL cannot set non root non root,The first iteration for creating custom repo URL persisted the new URL to disk. This poses a problem when running Ambari as non-root because the file system is owned by root. Change the implementation to save the override in the metainfo table., first iter creat custom repo URL persist new URL disk disk pose problem run ambari non root non root file system own root root chang implement save overrid metainfo tabl tabl,0,0,0,0,0,0,0 
2545,Dmitry Lysnichenko,ambari-agent,0,Regression: Agent external hostname is not verified during bootstrap with no warnings, regress regress agent extern hostnam not verifi bootstrap no warn,When confirming hosts using external addresses bootstrapping should be failed immediately and a warning should be logged. Right now this functionality is broken  neither warning in log nor failing immediately present, confirm host use extern address bootstrap fail immedi warn log log right function broken neither warn log nor fail immedi present,0,0,0,0,0,0,0 
2556,Dmitry Lysnichenko,ambari-server,0,Ctrl+C during ambari-server setup prints out a python stack trace, ctrl ctrl ambari server ambari server setup print python stack trace,We should be able to catch KeyBoardInterrupt in ambari-server main and print a useful message like:'Aborting ... Keyboard Interrupt.' and avoid the stack trace for the user., abl catch KeyBoardInterrupt key board interrupt ambari server ambari server main print use messag like abort like abort keyboard interrupt interrupt avoid stack trace user user,0,0,0,0,0,0,0 
2568,Dmitry Lysnichenko,ambari-agent,0,Setup LDAP does not validate true/false response, setup LDAP not valid true fals true fals respons,Garbage responses to true/false questions just pass thru. Notice below  just put in garbage for Use SSL and that's what it would have written.Need validation to confirm they enter either 1) return to accept default or 2) the word true or 3) the word false. Else  inform the user'Property must be 'true' or 'false'.' and ask again.Secondary URL :Use SS &#91;true/false&#93; (false): asdUser name attribute* (uid):Base DN* :Property cannot be blank.Base DN* : asdBind anonymously* true/false (false):Manager DN* :asdEnter Manager Password*:Re-enter password:Passwords do not matchEnter Manager Password*:Re-enter password:====================Review Settings====================authentication.ldap.primaryUrl: my.url:849authentication.ldap.useSSL: asdauthentication.ldap.usernameAttribute: uid, garbag respons true fals true fals question pass thru thru notic put garbag use SSL would written need written need valid confirm enter either return accept default word true word fals fals els inform user properti user properti must true true fals fals ask secondari secondari URL use use SS true fals true fals fals fals asdUser asd user name attribut attribut uid base uid base DN DN properti properti cannot blank base blank base DN DN asdBind asd bind anonym anonym true fals true fals fals manag fals manag DN DN asdEnter asd enter manag password enter password enter password password password password not matchEnter match enter manag password enter password enter password review password review set authent ldap primaryUrl set authent ldap primari url url authent ldap useSSL url authent ldap use SSL asdauthent ldap usernameAttribute asdauthent ldap usernam attribut uid,0,0,0,0,0,0,0 
2578,Dmitry Lysnichenko,ambari-server,0,Using another user for ambari server user create a local group for the ambari server user with same name., use anoth user ambari server user creat local group ambari server user name name,Using an ambari-qa user (that is a ldap user and he has hadoop set up as a primary ldap group) [root@va21 ldap]# id ambari-qauid=524(ambari-qa) gid=522(hadoop) groups=522(hadoop)causes ambari-server setup to create an ambari-qa local group (at /etc/group). ambari-qa:x:601:ambari-qa[root@va21 ldap]# id ambari-qauid=524(ambari-qa) gid=522(hadoop) groups=522(hadoop) 601(ambari-qa)Ldap users and groups are transparent for ambari-server  it starts well.The problem is that additional group is created., use ambari qa ambari qa user ldap user hadoop set primari ldap group group root va root va ldap ldap id ambari qauid ambari qa ambari qauid ambari qa gid hadoop gid hadoop group hadoop caus group hadoop caus ambari server ambari server setup creat ambari qa ambari qa local group etc group etc group ambari qa ambari qa root va ambari qa ambari qa root va ldap ldap id ambari qauid ambari qa ambari qauid ambari qa gid hadoop gid hadoop group hadoop group hadoop ambari qa ldap ambari qa ldap user group transpar ambari server ambari server start well well problem addit group creat creat,0,0,0,0,0,0,0 
2585,Aleksandr Kovalenko,ambari-web,0,Host Check report show hosts without issues, host check report show host without issu,Report contains hosts  which don't have issues  but should show 'A space delimited list of hosts which have issues'., report contain host issu show space delimit list host issu issu,0,0,0,0,0,0,0 
2590,Xi Wang,null,0,JS Error when deleting a widget after sorting it on remove/edit sign, JS error delet widget sort remov edit remov edit sign,,,0,0,0,0,0,0,0 
2594,Siddharth Wagle,ambari-agent,0,HDP installation fails due to puppet syntax error, HDP instal fail due puppet syntax error,namenode_host is not an hash or array when accessing it with 0 at /var/lib/ambari-agent/puppet/modules/hdp/manifests/params.pp:70 on node host1., namenode_host not hash array access var lib ambari agent puppet modul hdp manifest param pp var lib ambari agent puppet modul hdp manifest param pp node host host,0,0,0,0,0,0,0 
2595,Andrii Tkach,ambari-web,0,Properties of the same name cannot be added to different custom site.xml's, properti name cannot ad differ custom site xml site xml,Steps (Installer Wizard):Go to 'Customize Services' page.Select 'HDFS' tab.Add custom property 'xxx' to 'Custom core-site.xml' panel.Try add custom property 'xxx' to 'Custom hdfs-site.xml' panel.Result:Custom property can not be added to 'Custom hdfs-site.xml' panel (see attachment).Steps (Ambari monitoring UI):Go to 'Customize Services' page.Select 'HDFS' tab.Add custom property to 'Custom core-site.xml' panel (for example  'install-test-core-site').Continue and end hadoop installation.Go to 'Services' page.Select 'MapReduce' tab.Try add custom property 'install-test-core-site' to 'Custom mapred-site.xml' panel.Result:Custom property can not be added to 'Custom mapred-site.xml' panel (see attachment)., step instal instal wizard Go wizard Go custom custom servic servic page select page select HDFS HDFS tab add tab add custom properti xxx xxx custom custom core site xml core site xml panel tri panel tri add custom properti xxx xxx custom custom hdf site xml hdf site xml panel result custom panel result custom properti not ad custom custom hdf site xml hdf site xml panel see attach step attach step ambari ambari monitor UI Go UI Go custom custom servic servic page select page select HDFS HDFS tab add tab add custom properti custom custom core site xml core site xml panel exampl instal test core site continu instal test core site continu end hadoop instal Go instal Go servic servic page select page select MapReduce map reduc tab tri tab tri add custom properti instal test core site instal test core site custom custom mapr site xml mapr site xml panel result custom panel result custom properti not ad custom custom mapr site xml mapr site xml panel see attach attach,0,0,0,0,0,ambari-web/app/views/common/configs/services_config.js;,0 
2600,Antonenko Alexander,ambari-web,0,Add Quick Links (Web UI) for Oozie  Hue  Nagios  Ganglia, add quick link web web UI UI oozi hue nagio ganglia,There are no quick links for Oozie. Similarly  some other services also are missing the quick links., no quick link oozi oozi similarli servic also miss quick link link,0,0,0,0,0,0,0 
2605,Siddharth Wagle,ambari-agent,0,'kdestroy' not required for zookeeper smoke test, kdestroy kdestroy not requir zookeep smoke test,zookeeper smoke test passes without having to 'kdestroy' on the user running the smoke test., zookeep smoke test pass without kdestroy kdestroy user run smoke test test,0,0,0,0,0,0,0 
2608,Sumit Mohanty,ambari-server,0,WebHCat and Oozie services does not start on RHEL5 with enabled security because of 'CRITICAL: Error doing kinit for nagios', WebHCat web cat oozi servic not start RHEL RHEL enabl secur CRITICAL CRITICAL error kinit nagio nagio,FE only has support to provide single path for kinit. As Ambari supports mixed OS deployment it cannot be guaranteed that kinit exists at the same path on all nodes. FE should allow providing a set of look-up paths for kinit as well as the BE should support a set of default lookup paths., FE support provid singl path kinit kinit ambari support mix OS deploy cannot guarante kinit exist path node node FE allow provid set look look path kinit well support set default lookup path path,0,0,0,0,0,0,1 
2612,Dmytro Shkvyra,ambari-agent; ambari-server,0,Rename agent.fqdn property in ambari.props to server.fqdn, renam agent fqdn agent fqdn properti ambari prop ambari prop server fqdn server fqdn,lets just rename agent -&gt; server, let renam agent gt gt server,0,0,0,0,0,0,0 
2613,Aleksandr Kovalenko,ambari-web,0,Host Checks: truncation on checked processes makes it difficult to know the actual processes in conflict, host check check truncat check process make difficult know actual process conflict,Processes are truncated too short and can't really tell what's in conflict. Since there is a lot of space on the right (in fact  the hostname column is too far to the left compared to other sections)  we should display more characters (with hover tooltip showing full text)., process truncat short realli tell conflict conflict sinc lot space right fact hostnam column far left compar section section display charact hover tooltip show full text text,0,0,0,0,0,0,0 
2614,Andrii Tkach,ambari-web,0,Popover with config name goes beyond the container, popov config name goe beyond contain,See attachecd screenshot., see attachecd screenshot screenshot,0,0,0,0,0,0,0 
2619,Antonenko Alexander,ambari-web,0,Wrong info on Services > Summary tab for DataNodes Live  TaskTrackers Live  RegionServers live, wrong info servic summari tab DataNodes data node live TaskTrackers task tracker live RegionServers region server live,1. Install cluster2. On the host with SNameNode  we also have a region server3. Stop snamenode component on that host4. Services &gt; hbase &gt; summary shows region server is not liveAlso after stopping DataNode or TaskTracker  component status changes are not reflected on Services &gt; summary tab, instal cluster cluster host SNameNode name node also region server server stop snamenod compon host host servic gt gt hbase gt gt summari show region server not liveAlso live also stop DataNode data node TaskTracker task tracker compon statu chang not reflect servic gt gt summari tab,0,0,0,0,0,0,1 
2631,Oleksandr Diachenko,ambari-server,0,Host cleanup left two packages(ambari-log4j  libconfuse), host cleanup left two packag ambari log packag ambari log libconfus libconfus,,,0,0,0,0,0,0,1 
2632,Xi Wang,null,0,Dashboard Widgets: 'hover to show details' experience is jarring, dashboard widget widget hover show detail detail experi jar,,,0,0,0,0,0,0,1 
2633,Sumit Mohanty,null,0,Reset the latest stack version for 1.2.5, reset latest stack version,Reset the latest stack version for 1.2.5, reset latest stack version,0,0,0,0,0,0,1 
2635,Srimanth Gunturi,ambari-web,0,Perf: Service summary view inefficiently binds to host components, perf perf servic summari view ineffici bind host compon,In ambari-web/app/views/main/service/info/summary.js#hostComponentsUpd()  is called per each hostComponent's host and master property change. On a 150 node cluster  we get like 300 calls just for this method.Due to this  service_mapper  which usually maps in 600ms  takes now 5.8s., ambari web app view main servic info summari js hostComponentsUpd ambari web app view main servic info summari js host compon upd call per hostComponent host compon host master properti chang chang node cluster get like call method due method due service_mapper usual map ms take,0,0,0,0,0,0,1 
2636,Xi Wang,null,0,Dashboard Metrics legend size increased unexpectedly on mouseover from line space, dashboard metric legend size increas unexpectedli mouseov line space,This happened in a very specific situation.1. Put mouse on the line space around a metric widget.2. hover on the widget with mouse down.Result:The legend show up as a strange bigger size., happen specif situat situat put mous line space around metric widget widget hover widget mous result result legend show strang bigger size size,0,0,0,0,0,0,0 
2640,Aleksandr Kovalenko,ambari-web,0,Going back to Customize Services page from the Install page resets certain directory values, go back custom servic page instal page reset certain directori valu,Steps to reproduce: Install using non-default directories Upon install failure  go back to Customize Services page from the left nav. Certain directories (NN dirs  SNN dir  DN dirs  Oozie Data Dir  ZK Dir  etc) are reverted back to the default. Other parameters are not reverted back., step reproduc reproduc instal use non default non default directori upon instal failur go back custom servic page left nav nav certain directori NN NN dir SNN dir DN dir oozi data dir ZK dir etc etc revert back default default paramet not revert back back,0,0,0,0,0,0,1 
2644,Siddharth Wagle,ambari-server,0,Ambari-server can not find password for remote database with password encryption enabled, ambari server ambari server not find password remot databas password encrypt enabl,Performed cluster setup as proposed at E2E test scenario. ambari-server setupambari-server setup-ldapambari-server encrypt-passwordsambari-server setup-httpsambari-server startServer does not start. It complains about missing password file / db password alias19:03:36 249 INFO Configuration:300 - Generation of file with password19:03:37 320 INFO CredentialProvider:146 - action =&gt; PUT  alias =&gt; ambari.db.password19:03:37 885 INFO Configuration:313 - Reading password from existing file19:03:38 838 INFO CredentialProvider:146 - action =&gt; PUT  alias =&gt; ambari.ldap.manager.password19:12:02 925 INFO Configuration:313 - Reading password from existing file19:12:02 946 INFO Configuration:324 - API SSL Authentication is turned on.19:12:02 946 INFO Configuration:329 - Reading password from existing file19:12:02 948 INFO Configuration:481 - Hosts Mapping File null19:12:02 951 INFO HostsMap:60 - Using hostsmap file null19:12:04 467 INFO MasterKeyServiceImpl:209 - Loading from persistent master: #1.0# Fri  Jul 12 2013 19:03:34.71719:12:06 016 INFO AmbariServer:446 - Getting the controller19:12:11 146 INFO CertificateManager:68 - Initialization of root certificate19:12:11 147 INFO CertificateManager:70 - Certificate exists:false19:12:11 147 INFO CertificateManager:137 - Generation of server certificate19:12:16 383 INFO ShellCommandUtil:43 - Command openssl genrsa -des3 -passout pass:n15KV1q6aWRZIP86XAjpTdbTaKo0HHWIsTuaOPZQdxycChECKG -out /var/lib/ambari-server/keys/ca.key 4096 was finished with exit code: 0 - the operation was completely successfully.19:12:16 431 INFO ShellCommandUtil:43 - Command openssl req -passin pass:n15KV1q6aWRZIP86XAjpTdbTaKo0HHWIsTuaOPZQdxycChECKG -new -key /var/lib/ambari-server/keys/ca.key -out /var/lib/ambari-server/keys/ca.crt -batch was finished with exit code: 0 - the operation was completely successfully.19:12:16 483 INFO ShellCommandUtil:43 - Command openssl x509 -passin pass:n15KV1q6aWRZIP86XAjpTdbTaKo0HHWIsTuaOPZQdxycChECKG -req -days 365 -in /var/lib/ambari-server/keys/ca.crt -signkey /var/lib/ambari-server/keys/ca.key -out /var/lib/ambari-server/keys/ca.crt was finished with exit code: 0 - the operation was completely successfully.19:12:16 496 INFO ShellCommandUtil:43 - Command openssl pkcs12 -export -in /var/lib/ambari-server/keys/ca.crt -inkey /var/lib/ambari-server/keys/ca.key -certfile /var/lib/ambari-server/keys/ca.crt -out /var/lib/ambari-server/keys/keystore.p12 -password pass:n15KV1q6aWRZIP86XAjpTdbTaKo0HHWIsTuaOPZQdxycChECKG -passin pass:n15KV1q6aWRZIP86XAjpTdbTaKo0HHWIsTuaOPZQdxycChECKG was finished with exit code: 0 - the operation was completely successfully.19:12:16 883 INFO AmbariServer:123 - ********* Meta Info initialized **********19:12:16 896 INFO ClustersImpl:88 - Initializing the ClustersImpl19:12:17 115 ERROR Configuration:610 - Error reading from credential store.19:12:17 116 ERROR Configuration:616 - Cannot read password for alias = /etc/ambari-server/conf/password.dat19:12:17 117 ERROR AmbariServer:455 - Failed to run the Ambari Serverjava.lang.RuntimeException: Unable to read database password at org.apache.ambari.server.configuration.Configuration.readPasswordFromFile(Configuration.java:596) at org.apache.ambari.server.configuration.Configuration.getRcaDatabasePassword(Configuration.java:583) at org.apache.ambari.eventdb.webservice.WorkflowJsonService.setDBProperties(WorkflowJsonService.java:95) at org.apache.ambari.server.controller.AmbariServer.performStaticInjection(AmbariServer.java:437) at org.apache.ambari.server.controller.AmbariServer.run(AmbariServer.java:125) at org.apache.ambari.server.controller.AmbariServer.main(AmbariServer.java:452)Caused by: java.io.FileNotFoundException: File '/etc/ambari-server/conf/password.dat' does not exist at org.apache.commons.io.FileUtils.openInputStream(FileUtils.java:265) at org.apache.commons.io.FileUtils.readFileToString(FileUtils.java:1457) at org.apache.commons.io.FileUtils.readFileToString(FileUtils.java:1475) at org.apache.ambari.server.configuration.Configuration.readPasswordFromFile(Configuration.java:594) ... 5 more19:12:17 118 ERROR AmbariServer:420 - Error stopping the serverjava.lang.NullPointerException at org.apache.ambari.server.controller.AmbariServer.stop(AmbariServer.java:418) at org.apache.ambari.server.controller.AmbariServer.main(AmbariServer.java:457)Content of ambari.properties:server.jdbc.rca.driver=oracle.jdbc.driver.OracleDriverauthentication.ldap.managerDn=uid=hdfs ou=people ou=dev dc=apache dc=orgauthentication.ldap.primaryUrl=localhost:389server.jdbc.rca.url=jdbc:oracle:thin:@ip-10-34-79-165.ec2.internal:1521/XEserver.connection.max.idle.millis=900000server.jdbc.port=1521server.version.file=/var/lib/ambari-server/resources/versionserver.jdbc.rca.user.passwd=/etc/ambari-server/conf/password.datapi.authenticate=truejce_policy.url=http://public-repo-1.hortonworks.com/ARTIFACTS/jce_policy-6.zipserver.persistence.type=remoteclient.api.ssl.key_name=https.keyauthentication.ldap.useSSL=falseambari-server.user=ambar-serverclient.api.ssl.port=8443authentication.ldap.usernameAttribute=uidserver.jdbc.user.name=ambariserver.jdbc.schema=XEjava.home=/usr/jdk64/jdk1.6.0_31server.os_type=redhat6api.ssl=truebootstrap.script=/usr/lib/python2.6/site-packages/ambari_server/bootstrap.pyclient.api.ssl.cert_name=https.crtauthentication.ldap.bindAnonymously=falseclient.security=ldapserver.jdbc.hostname=ip-10-34-79-165.ec2.internalresources.dir=/var/lib/ambari-server/resourcessecurity.passwords.encryption.enabled=truebootstrap.setup_agent.script=/usr/lib/python2.6/site-packages/ambari_server/setupAgent.pyserver.jdbc.driver=oracle.jdbc.driver.OracleDriverjdk.url=http://public-repo-1.hortonworks.com/ARTIFACTS/jdk-6u31-linux-x64.binsecurity.server.keys_dir=/var/lib/ambari-server/keysserver.jdbc.rca.user.name=ambariwebapp.dir=/usr/lib/ambari-server/webmetadata.path=/var/lib/ambari-server/resources/stacksserver.jdbc.url=jdbc:oracle:thin:@ip-10-34-79-165.ec2.internal:1521/XEserver.fqdn.service.url=http://169.254.169.254/latest/meta-data/public-hostnamebootstrap.dir=/var/run/ambari-server/bootstrapauthentication.ldap.baseDn=dc=apache dc=orgserver.jdbc.user.passwd=${alias=ambari.db.password}authentication.ldap.managerPassword=${alias=ambari.ldap.manager.password}server.jdbc.database=oraclesecurity.server.two_way_ssl=trueFile /etc/ambari-server/conf/password.dat is missingSetup flow:[root@ip-10-116-65-200 kerb]# ambari-server setupUsing python /usr/bin/python2.6Initializing...Setup ambari-serverChecking SELinux...SELinux status is 'enabled'SELinux mode is 'enforcing'Temporarily disabling SELinuxWARNING: SELinux is set to 'permissive' mode and temporarily disabled.OK to continue [y/n] (y)? yCustomize user account for ambari-server daemon [y/n] (n)? yEnter user account for ambari-server daemon (root):ambar-serverAdjusting ambari-server permissions and ownership...Checking iptables...iptables is disabled now. please reenable later.Checking JDK...Downloading JDK from http://public-repo-1.hortonworks.com/ARTIFACTS/jdk-6u31-linux-x64.bin to /var/lib/ambari-server/resources/jdk-6u31-linux-x64.binJDK distribution size is 85581913 bytesjdk-6u31-linux-x64.bin... 100% (81.6 MB of 81.6 MB)Successfully downloaded JDK distribution to /var/lib/ambari-server/resources/jdk-6u31-linux-x64.binTo install the Oracle JDK you must accept the license terms found at http://www.oracle.com/technetwork/java/javase/downloads/jdk-6u21-license-159167.txt. Not accepting will cancel the Ambari Server setup.Do you accept the Oracle Binary Code License Agreement [y/n] (y)? Installing JDK to /usr/jdk64Successfully installed JDK to /usr/jdk64/jdk1.6.0_31Downloading JCE Policy archive from http://public-repo-1.hortonworks.com/ARTIFACTS/jce_policy-6.zip to /var/lib/ambari-server/resources/jce_policy-6.zipSuccessfully downloaded JCE Policy archive to /var/lib/ambari-server/resources/jce_policy-6.zipCompleting setup...Configuring database...Enter advanced database configuration [y/n] (n)? ySelect database:1 - PostgreSQL (Embedded)2 - Oracle[1]:2Hostname [localhost]:ip-10-34-79-165.ec2.internalPort [1521]:Select Oracle identifier type:1 - Service Name2 - SID[1]:XEInvalid number.Select Oracle identifier type:1 - Service Name2 - SID[1]:1Service Name [ambari]:XEUsername [ambari]: Enter Database Password [bigdata]: WARNING: Before starting Ambari Server  you must copy the Oracle JDBC driver JAR file to /usr/share/java.Press &lt;enter&gt; to continue.Copying JDBC drivers to server resources...Configuring remote database connection properties...WARNING: Cannot find oracle sqlplus client in the path to load the Ambari Server schema. Before starting Ambari Server  you must run the following DDL against the database to create the schema sqlplus ambari/bigdata &lt; /var/lib/ambari-server/resources/Ambari-DDL-Oracle-CREATE.sql Press &lt;enter&gt; to continue.WARNING: The cli was not foundAmbari Server 'setup' completed with warnings.[root@ip-10-116-65-200 kerb]# less /etc/passwd, perform cluster setup propos test scenario scenario ambari server ambari server setupambari server setupambari server setup ldapambari server setup ldapambari server encrypt passwordsambari server encrypt passwordsambari server setup httpsambari server setup httpsambari server startServer start server not start start complain miss password file db password alia alia INFO configur configur gener file password password INFO CredentialProvider credenti provid action gt gt PUT alia gt gt ambari db password ambari db password INFO configur configur read password exist file file INFO CredentialProvider credenti provid action gt gt PUT alia gt gt ambari ldap manag password ambari ldap manag password INFO configur configur read password exist file file INFO configur configur API SSL authent turn INFO configur configur read password exist file file INFO configur configur host map file null null INFO HostsMap host map use hostsmap file null null INFO MasterKeyServiceImpl master key servic impl load persist master master fri jul INFO AmbariServer ambari server get control control INFO CertificateManager certif manag initi root certif certif INFO CertificateManager certif manag certif exist fals exist fals INFO CertificateManager certif manag gener server certif certif INFO ShellCommandUtil shell command util command openssl genrsa de de passout pass KV aWRZIP XAjpTdbTaKo HHWIsTuaOPZQdxycChECKG pass KV WRZIP ajp tdb Ta Ko HHW tua OPZ qdxyc Ch ECKG var lib ambari server key ca key var lib ambari server key ca key finish exit code code oper complet success success INFO ShellCommandUtil shell command util command openssl req passin pass KV aWRZIP XAjpTdbTaKo HHWIsTuaOPZQdxycChECKG pass KV WRZIP ajp tdb Ta Ko HHW tua OPZ qdxyc Ch ECKG new key var lib ambari server key ca key var lib ambari server key ca key var lib ambari server key ca crt var lib ambari server key ca crt batch finish exit code code oper complet success success INFO ShellCommandUtil shell command util command openssl passin pass KV aWRZIP XAjpTdbTaKo HHWIsTuaOPZQdxycChECKG pass KV WRZIP ajp tdb Ta Ko HHW tua OPZ qdxyc Ch ECKG req day var lib ambari server key ca crt var lib ambari server key ca crt signkey var lib ambari server key ca key var lib ambari server key ca key var lib ambari server key ca crt var lib ambari server key ca crt finish exit code code oper complet success success INFO ShellCommandUtil shell command util command openssl pkc pkc export var lib ambari server key ca crt var lib ambari server key ca crt inkey var lib ambari server key ca key var lib ambari server key ca key certfil var lib ambari server key ca crt var lib ambari server key ca crt var lib ambari server key keystor var lib ambari server key keystor password pass KV aWRZIP XAjpTdbTaKo HHWIsTuaOPZQdxycChECKG pass KV WRZIP ajp tdb Ta Ko HHW tua OPZ qdxyc Ch ECKG passin pass KV aWRZIP XAjpTdbTaKo HHWIsTuaOPZQdxycChECKG pass KV WRZIP ajp tdb Ta Ko HHW tua OPZ qdxyc Ch ECKG finish exit code code oper complet success success INFO AmbariServer ambari server meta info initi INFO ClustersImpl cluster impl initi ClustersImpl cluster impl ERROR configur configur error read credenti store store ERROR configur configur cannot read password alia etc ambari server conf password dat etc ambari server conf password dat ERROR AmbariServer ambari server fail run ambari serverjava lang RuntimeException serverjava lang runtim except unabl read databas password org apach ambari server configur configur readPasswordFromFile configur java org apach ambari server configur configur read password file configur java org apach ambari server configur configur getRcaDatabasePassword configur java org apach ambari server configur configur get rca databas password configur java org apach ambari eventdb webservic WorkflowJsonService setDBProperties WorkflowJsonService java org apach ambari eventdb webservic workflow json servic set DB properti workflow json servic java org apach ambari server control AmbariServer performStaticInjection AmbariServer java org apach ambari server control ambari server perform static inject ambari server java org apach ambari server control AmbariServer run AmbariServer java org apach ambari server control ambari server run ambari server java org apach ambari server control AmbariServer main AmbariServer java caus org apach ambari server control ambari server main ambari server java caus java io FileNotFoundException java io file not found except file etc ambari server conf password dat etc ambari server conf password dat not exist org apach common io FileUtils openInputStream FileUtils java org apach common io file util open input stream file util java org apach common io FileUtils readFileToString FileUtils java org apach common io file util read file string file util java org apach common io FileUtils readFileToString FileUtils java org apach common io file util read file string file util java org apach ambari server configur configur readPasswordFromFile configur java org apach ambari server configur configur read password file configur java ERROR AmbariServer ambari server error stop serverjava lang NullPointerException serverjava lang null pointer except org apach ambari server control AmbariServer stop AmbariServer java org apach ambari server control ambari server stop ambari server java org apach ambari server control AmbariServer main AmbariServer java content org apach ambari server control ambari server main ambari server java content ambari properti server jdbc rca driver oracl jdbc driver OracleDriverauthentication ldap managerDn uid hdf ambari properti server jdbc rca driver oracl jdbc driver oracl driverauthent ldap manag Dn uid hdf ou peopl ou peopl ou dev ou dev dc apach dc apach dc orgauthent ldap primaryUrl localhost server jdbc rca url jdbc oracl thin ip ec intern XEserver connect max idl milli server jdbc port server version file var lib ambari server resourc versionserv jdbc rca user passwd etc ambari server conf password datapi authent truejce_policy url http public repo hortonwork com ARTIFACTS jce_policy zipserv persist type remotecli api ssl key_name http keyauthent ldap useSSL falseambari server user ambar servercli api ssl port authent ldap usernameAttribute uidserv jdbc user name ambariserv jdbc schema XEjava home usr jdk jdk  server os_type redhat api ssl truebootstrap script usr lib python site packag ambari_server bootstrap pyclient api ssl cert_name http crtauthent ldap bindAnonymously falsecli secur ldapserv jdbc hostnam ip ec internalresourc dir var lib ambari server resourcessecur password encrypt enabl truebootstrap setup_agent script usr lib python site packag ambari_server setupAgent pyserv jdbc driver oracl jdbc driver OracleDriverjdk url http public repo hortonwork com ARTIFACTS jdk linux binsecur server keys_dir var lib ambari server keysserv jdbc rca user name ambariwebapp dir usr lib ambari server webmetadata path var lib ambari server resourc stacksserv jdbc url jdbc oracl thin ip ec intern XEserver fqdn servic url http latest meta data public hostnamebootstrap dir var run ambari server bootstrapauthent ldap baseDn dc apach dc orgauthent ldap primari url localhost server jdbc rca url jdbc oracl thin ip ec intern eserv connect max idl milli server jdbc port server version file var lib ambari server resourc versionserv jdbc rca user passwd etc ambari server conf password datapi authent truejce_policy url http public repo hortonwork com ARTIFACTS jce_policy zipserv persist type remotecli api ssl key_name http keyauthent ldap use SSL falseambari server user ambar servercli api ssl port authent ldap usernam attribut uidserv jdbc user name ambariserv jdbc schema ejava home usr jdk jdk  server os_type redhat api ssl truebootstrap script usr lib python site packag ambari_server bootstrap pyclient api ssl cert_name http crtauthent ldap bind anonym falsecli secur ldapserv jdbc hostnam ip ec internalresourc dir var lib ambari server resourcessecur password encrypt enabl truebootstrap setup_agent script usr lib python site packag ambari_server setup agent pyserv jdbc driver oracl jdbc driver oracl driverjdk url http public repo hortonwork com ARTIFACTS jdk linux binsecur server keys_dir var lib ambari server keysserv jdbc rca user name ambariwebapp dir usr lib ambari server webmetadata path var lib ambari server resourc stacksserv jdbc url jdbc oracl thin ip ec intern eserv fqdn servic url http latest meta data public hostnamebootstrap dir var run ambari server bootstrapauthent ldap base Dn dc apach dc orgserv jdbc user passwd alia ambari db password authent ldap managerPassword alia ambari ldap manag password server jdbc databas oraclesecur server two_way_ssl trueFile dc orgserv jdbc user passwd alia ambari db password authent ldap manag password alia ambari ldap manag password server jdbc databas oraclesecur server two_way_ssl true file etc ambari server conf password dat etc ambari server conf password dat missingSetup miss setup flow root ip flow root ip kerb kerb ambari server ambari server setupUsing setup use python usr bin python initi setup usr bin python initi setup ambari serverChecking ambari server check SELinux SELinux SE linux SE linux statu enabl SELinux enabl SE linux mode enforc temporarili enforc temporarili disabl SELinuxWARNING SE linux WARNING SELinux SE linux set permiss permiss mode temporarili disabl OK disabl OK continu yCustomize custom user account ambari server ambari server daemon yEnter enter user account ambari server ambari server daemon root ambar serverAdjusting root ambar server adjust ambari server ambari server permiss ownership check ownership check iptabl iptabl iptabl iptabl disabl pleas reenabl later check later check JDK download JDK download JDK var lib ambari server resourc jdk linux binJDK var lib ambari server resourc jdk linux bin JDK distribut size bytesjdk linux bin bytesjdk linux bin MB MB success MB success download JDK distribut var lib ambari server resourc jdk linux binTo var lib ambari server resourc jdk linux bin instal oracl JDK must accept licens term found not accept cancel ambari server setup setup accept oracl binari code licens agreement instal JDK usr jdk success usr jdk success instal JDK usr jdk jdk  download usr jdk jdk  download JCE polici archiv var lib ambari server resourc jce_policy zipSuccessfully var lib ambari server resourc jce_policy zip success download JCE polici archiv var lib ambari server resourc jce_policy zipCompleting var lib ambari server resourc jce_policy zip complet setup configur setup configur databas enter databas enter advanc databas configur ySelect select databas databas PostgreSQL postgr SQL embed embed oracl hostnam oracl hostnam localhost ip ec internalPort localhost ip ec intern port select select oracl identifi type type servic name name SID XEInvalid SID XE invalid number select number select oracl identifi type type servic name name SID servic SID servic name ambari XEUsername ambari XE usernam ambari ambari enter databas password bigdata bigdata WARNING WARNING start ambari server must copi oracl JDBC driver JAR file usr share java press usr share java press lt enter gt lt enter gt continu copi continu copi JDBC driver server resourc configur resourc configur remot databas connect properti WARNING properti WARNING cannot find oracl sqlplu client path load ambari server schema schema start ambari server must run follow DDL databas creat schema sqlplu ambari bigdata ambari bigdata lt lt var lib ambari server resourc ambari DDL oracl CREATE sql var lib ambari server resourc ambari DDL oracl CREATE sql press lt enter gt lt enter gt continu WARNING continu WARNING cli not foundAmbari found ambari server setup setup complet warn root ip warn root ip kerb kerb less etc passwd etc passwd,0,0,0,0,0,0,0 
2653,Dmytro Shkvyra,ambari-agent; ambari-server,0,Add umask checks for host checks - we should alert if umask is not 022., add umask check host check alert umask not,Add umask checks for host checks - we should alert if umask is not 022., add umask check host check alert umask not,0,0,0,0,0,0,1 
2660,Srimanth Gunturi,ambari-web,0,Host checks say pass when all hosts failed to register, host check say pass host fail regist,When all hosts fail to register  there are no warnings  and hence we show OK for host checks., host fail regist no warn henc show OK host check check,0,0,0,0,0,0,1 
2661,Jaimin D Jetly,ambari-web,0,Security wizard: Relogin while on step3 without quitting the wizard throws JS error., secur wizard wizard relogin step step without quit wizard throw JS error error,Steps to reproduce: Go to step-3 (Generate principals and keytabs) of Enable security wizard. Restart Amabri server. Refresh on step-3. ui will take you to login page. Entering correct credentials  user will be navigated again to step-3 of security wizard. At this point JS error is encountered., step reproduc reproduc Go step step gener gener princip keytab keytab enabl secur wizard wizard restart amabri server server refresh step step ui take login page page enter correct credenti user navig step step secur wizard wizard point JS error encount encount,0,0,0,0,0,ambari-web/app/routes/main.js;,1 
2670,Antonenko Alexander,ambari-web,0,Start button not available for various components within 10 sec after stop operation finishes, start button not avail variou compon within sec stop oper finish,Steps to reproduce: 1. Stop a component. 2. Wait for the corresponding BG operation to finish. Result: 'Start' button isn't available for the component within 10 seconds since stop operation finished in UI. It appears later.This happens cuz of update interval  it is set to 15 seconds (App.contentUpdateInterval)  that's why in some moments it can take up to 15 sec to update components status  after request is done.Solution: Create a seperate update interval specialy for updating host components. In config.js we even have App.componentsUpdateInterval = 6000; But this value was not used anywhere in code till now., step reproduc reproduc stop compon compon wait correspond BG oper finish finish result result start start button avail compon within second sinc stop oper finish UI UI appear later later happen cuz updat interv set second app contentUpdateInterval app content updat interv moment take sec updat compon statu request done solut done solut creat seper updat interv speciali updat host compon compon config js config js even app componentsUpdateInterval app compon updat interv valu not use anywher code till,0,0,0,0,0,0,1 
2681,Sumit Mohanty,ambari-server,0,setup ldap does not validate secondary url, setup ldap not valid secondari url,setup ldap does not validate secondary url. It should validate the input (when entered) the same way as the primary., setup ldap not valid secondari url url valid input enter enter way primari primari,0,0,0,0,0,0,0 
2688,Artem Baranchuk,ambari-server,0,Error messages printed to log, error messag print log,Notice in the ambari-server snippet below a lot of these messages:ERROR Configuration:616 - Cannot read password for alias = nullSteps to reproduce:Setup serverSetup encrypt passwords  don't persist the keySetup httpsStart the server  provided master keyDo cluster install, notic ambari server ambari server snippet lot messag ERROR messag ERROR configur configur cannot read password alia nullSteps null step reproduc setup reproduc setup serverSetup server setup encrypt password persist keySetup key setup httpsStart http start server provid master keyDo key cluster instal,0,0,0,0,0,0,0 
2689,Jaimin D Jetly,ambari-web,0,Enable Security Wizard stops on step '2. Save Configurations' and doesn't let the user leave the wizard, enabl secur wizard stop step save configur configur let user leav wizard,,,0,0,0,0,0,ambari-web/app/controllers/main/admin/security/add/step4.js;ambari-web/app/controllers/main/admin/security/disable.js;ambari-web/app/messages.js;ambari-web/app/models/cluster_states.js;,0 
2690,Xi Wang,ambari-web,0,Datanode Live widget displays 0 dead when no datanode is live on a cluster., datanod live widget display dead no datanod live cluster cluster,,,0,0,0,0,0,0,1 
2697,Jaimin D Jetly,ambari-web,0,Disable security not working in web-ui testMode., disabl secur not work web ui web ui testMode test mode,,,0,0,0,0,0,ambari-web/app/controllers/main/admin/security/disable.js;,0 
2698,Aleksandr Kovalenko,ambari-web,0,Host specific progress bar for a task has some inconsistencies, host specif progress bar task inconsist,See the attached images. The third image added is a summary of what was going on., see attach imag imag third imag ad summari go,0,0,0,0,0,0,1 
2701,Dmytro Sen,null,0,Implement a cleanup thread that removes files in ambari-agent data directory that are older than a configurable amount of time, implement cleanup thread remov file ambari agent ambari agent data directori older configur amount time,Implement a cleanup thread that removes files in ambari-agent data directory that are older than a month or so(must be configurable).It's required  because the directory will grow unbounded if it's not cleaned up., implement cleanup thread remov file ambari agent ambari agent data directori older month must must configur configur requir directori grow unbound not clean,0,0,0,0,0,0,1 
2707,Oleg Nechiporenko,ambari-web,0,Fix JS Unit tests after merge 1.4.0 to trunk, fix JS unit test merg trunk,,,0,0,0,0,0,0,1 
2708,Antonenko Alexander,ambari-web,0,Make ambari web testMode work for installer wizard with HDP stack-2 selection., make ambari web testMode test mode work instal wizard HDP stack stack select select,Installer wizard with HDP stack-2 selection in test mode, instal wizard HDP stack stack select test mode,0,0,0,0,0,0,0 
2723,Artem Baranchuk,ambari-agent,0,hbase super user cannot submit jobs since Ambari creates hbase super user with uid<1000, hbase super user cannot submit job sinc ambari creat hbase super user uid uid,Copytable jobs need to be submitted as the hbase super user however the uid for hbase super user created by Ambari has uid &lt; 1000, copyt job need submit hbase super user howev uid hbase super user creat ambari uid lt lt,0,0,0,0,0,0,1 
2727,Oleg Nechiporenko,ambari-web,0,Disallow actions upon host components on hosts that stopped heartbeating, disallow action upon host compon host stop heartbeat,On a host that stopped heartbeating  the UI shows actions to perform on host components. However  upon executing an action  the backend does not create any tasks and returns 200. The UI doesn't do anything in this case. Instead  the UI should disable action buttons in this case., host stop heartbeat UI show action perform host compon compon howev upon execut action backend not creat task return UI anyth case case instead UI disabl action button case case,0,0,0,0,0,0,1 
2729,Andrii Babiichuk,ambari-web,0,While a host component is being installed (INSTALLING state)  it does not show up in the Host Detail page, host compon instal INSTALLING INSTALLING state state not show host detail page,Say Add Hosts wizard fails to add a host and the host components are in INSTALL_FAILED state. In this case  the UI displays the host component with a red gear and shows the action menu with the current state 'Install Failed' and the action 'Re-Install'. Once you invoke 'Re-Install'  the host component disappears from the UI. Once the host component finishes installing  it magically appears again., say add host wizard fail add host host compon INSTALL_FAILED INSTALL FAILED state state case UI display host compon red gear show action menu current state instal instal fail fail action instal instal invok instal instal host compon disappear UI UI host compon finish instal magic appear,0,0,0,0,0,0,1 
2733,Oleg Nechiporenko,ambari-web,0,Hosts and Host Details page UI tweaks, host host detail page UI tweak,1. Hosts &gt; Design around full hostname being displayed. Consider being able to show 40 characters and then truncate &gt; 40 chars 2. Hosts &gt; Show # control should persist when navigating around app  and after logout/login3. Hosts &gt; Make Components list an expand/collapse control instead of a list with abbreviations4. Host Details &gt; Move Components area above Summary area since the Component Controls are used very often (much more often than viewing the Summary area info)., host gt gt design around full hostnam display display consid abl show charact truncat gt gt char host gt gt show control persist navig around app logout login logout login host gt gt make compon list expand collaps expand collaps control instead list abbrevi abbrevi host detail gt gt move compon area summari area sinc compon control use often much often view summari area info info,0,0,0,0,0,0,1 
2748,Sumit Mohanty,ambari-server,0,Misc logging changes, misc log chang,Additional logs:  When a task is timed-out/failed API requests to update component and component hosts   Remove logs  Do not log ganglia population time when its less than 5 second, addit log log task time fail time fail API request updat compon compon host remov log not log ganglia popul time less second,0,0,0,0,0,0,1 
2753,Antonenko Alexander,ambari-web,0,Security Wizard step 4: no hosts shown when clicking on the 'Start Services'/'Stop Services' link, secur wizard step no host shown click start start servic stop servic stop servic servic link,Proceed to step 4 of security wizard  click on 'Start Services' or 'Stop Services' link.Result: popup window is shown with empty contentThis bug was happening due to js error 'Uncaught TypeError: Cannot call method 'filterProperty' of null' in setBackgroundOperationHeader: functionAfter background operation (host popup) popup was optimized for better peformace on large cluster this error showed up. New function on setting popup header  did not account that this popup (HostPopup) is used not only in BG operations  but also in security wizard., proce step secur wizard click start start servic servic stop stop servic servic link result link result popup window shown empti contentThis content bug happen due js error uncaught uncaught TypeError type error cannot call method filterProperty filter properti null null setBackgroundOperationHeader set background oper header functionAfter function background oper host popup popup popup optim better peformac larg cluster error show new function set popup header not account popup HostPopup host popup use not BG oper also secur wizard wizard,0,0,0,0,0,0,1 
2758,Andrii Babiichuk,ambari-web,0,Jobs page: table is not striped and pagination is not disabled, job page page tabl not stripe pagin not disabl,To reproduce go to the Jobs page from top menu (do not open .../main/apps directly). Table is not striped and pagination buttons are enabled even if there is only one page., reproduc go job page top menu not open main app main app directli directli tabl not stripe pagin button enabl even one page page,0,0,0,0,0,0,1 
2760,Srimanth Gunturi,ambari-web,0,Stack 2.0.3  Hive Check execute fail, stack hive check execut fail,When installing Hadoop 2 stack  Hive service check fails to run., instal hadoop stack hive servic check fail run run,0,0,0,0,0,0,1 
2761,Antonenko Alexander,ambari-web,0,Customize Services page - Misc tab: incorrect behavior of popup window for changing user names, custom servic page misc tab tab incorrect behavior popup window chang user name,In firefoxSteps:Go to 'Customize Services' page.Select 'Misc' tab.Change username for HDFS  HBase or Group (do not move focus to other elements).Click 'Next' button.Result:Browser was switched to 'Review' page.Was opened popup window for changing properties depended with user names. User must to refresh the page for popup menu disappearing., firefoxSteps Go firefox step Go custom custom servic servic page select page select misc misc tab chang tab chang usernam HDFS HBase base group not move focu element click element click next next button result browser button result browser switch review review page page open popup window chang properti depend user name name user must refresh page popup menu disappear disappear,0,0,0,0,0,0,1 
2763,Siddharth Wagle,ambari-server,0,Ozzie does not work with local FS user, ozzi not work local FS user,Running jobs as a local FS user does not work work 2.0.* stack because of permissions on /tmp/hadoop-yarn/staging  which is the default staging dir., run job local FS user not work work stack permiss tmp hadoop yarn stage tmp hadoop yarn stage default stage dir dir,0,0,0,0,0,0,1 
2768,Oleg Nechiporenko,ambari-web,0,Host Checks > Show Report is showing bogus information for FILES AND FOLDERS, host check show report show bogu inform FILES FOLDERS,Host Checks popup is showing that /usr/lib/hadoop already exists.When I clicked on 'Show Reports'  it is showing '/usr/lib/hadoop/ /folder'. This doesn't make much sense. FILES AND FOLDERS/usr/lib/hadoop/ /folderThe API is showing: 'stackFoldersAndFiles' : [ { 'name' : '/usr/lib/hadoop'  'type' : 'directory' }, host check popup show usr lib hadoop usr lib hadoop alreadi exist exist click show show report report show usr lib hadoop usr lib hadoop folder folder make much sens sens FILES FOLDERS usr lib hadoop FOLDERS usr lib hadoop folderThe folder API show show stackFoldersAndFiles stack folder file name name usr lib hadoop usr lib hadoop type type directori directori,0,0,0,0,0,0,0 
2777,Yusaku Sako,ambari-web,0,Cannot save HDFS configs with SNN in MAINTENANCE mode, cannot save HDFS config SNN MAINTENANCE mode,,,0,0,0,0,0,0,1 
2782,Oleg Nechiporenko,ambari-web,0,Hadoop2 stack install should merge YARN MR2 options, hadoop hadoop stack instal merg YARN MR MR option,YARN in current Hadoop 2 stack has only MR2 as application. Since it does not make sense to install YARN without a default application  and MR2 cannot be installed by itself  we should combine both into a single install option (see screenshot)., YARN current hadoop stack MR MR applic applic sinc not make sens instal YARN without default applic MR MR cannot instal combin singl instal option see screenshot screenshot,0,0,0,0,0,0,1 
2786,Andrew Onischuk,ambari-server,0,YARN time series data needed for NodeManager statuses, YARN time seri data need NodeManager node manag status,We need API call for a graph which will show NodeManager status counts. NodeManagers can be in the following states: active  lost  unhealthy  rebooted  and decommissioned., need API call graph show NodeManager node manag statu count count NodeManagers node manag follow state state activ lost unhealthi reboot decommiss decommiss,0,0,0,0,0,0,1 
2799,Oleg Nechiporenko,ambari-web,0,YARN service summary additional information, YARN servic summari addit inform,We need to show below 2 additional information Across cluster memory - used/reserved/total Queues information if available, need show addit inform across cluster memori use reserv total use reserv total queue inform avail,0,0,0,0,0,0,1 
2808,Dmytro Shkvyra,ambari-web,0,Can't add from UI some queues in capacity-scheduler.xml, add UI queue capac schedul xml capac schedul xml,Properties of capacity-scheduler.xml are truncated by ' '. It make impossible to create multiple queues  please see http://hadoop.apache.org/docs/current/hadoop-yarn/hadoop-yarn-site/CapacityScheduler.html, properti capac schedul xml capac schedul xml truncat make imposs creat multipl queue pleas see,0,0,0,0,0,0,1 
2816,Oleg Nechiporenko,ambari-web,0,Customize Services: directories are shown in comma-delimited format when revisiting, custom servic servic directori shown comma delimit comma delimit format revisit,In the Install Wizard  Customize Services page shows multiple directories delimited by newlines.However  when revisiting the page (go back to Customize Services from the Review page  for example)  the directories are shown in comma-delimited format. We should always show the directories in newline-delimited format. Note that when we actually store the value  the directories are comma-delimited (which is correct)., instal wizard custom servic page show multipl directori delimit newlin howev newlin howev revisit page go back custom servic review page exampl exampl directori shown comma delimit comma delimit format format alway show directori newlin delimit newlin delimit format format note actual store valu directori comma delimit comma delimit correct correct,0,0,0,0,0,0,1 
2834,Jaimin D Jetly,ambari-server,0,Utility script to generate keytabs is broken, util script gener keytab broken,keytab Tar for each host is packaged including hostname. Untaring it on a host creates path starting with &lt;hostanme&gt;/&lt;actual path&gt;. Fix is to package the content inside the hostname directory excluding the hostname directory itself., keytab tar host packag includ hostnam hostnam untar host creat path start lt hostanm gt lt actual lt hostanm gt lt actual path gt path gt fix packag content insid hostnam directori exclud hostnam directori,0,0,0,0,0,0,0 
2836,Andrew Onischuk,ambari-web,0,HBase 0.95.2 - Logger doesn't work, HBase base logger work,Installing 0.95.2 from internal repo 2.0.5. hbase-daemon.sh defines a default logger of INFO RFA{{  when log4j.properties uses {{INFO DRFA. They should match  as startup generates an error and does not continue.We should stop over writing the log4j properties for hbase. This will allow for hbase log4j properties to be in sync with those that come with the rpms., instal intern repo hbase daemon sh hbase daemon sh defin default logger INFO RFA RFA log properti log properti use INFO INFO DRFA DRFA match startup gener error not continu continu stop write log log properti hbase hbase allow hbase log log properti sync come rpm rpm,0,0,0,0,0,0,1 
2838,Sumit Mohanty,ambari-server,0,Running Requests are not visibile on the UI since the API is not returning the running requests., run request not visibil UI sinc API not return run request request,The issue is the following:getRequestsByTaskStatus behaves correctly and returns the latest N requests. Note that the N requests have M (M &gt;&gt; N) tasks.Then the call to findByRequestIds gets oldest N tasks where the requestId for tasks belong to the list returned by the first call. So instead of getting M tasks we only get N tasks that too N oldest tasks which are returned. As a result the call never returns that latest request/tasks. The fix is to drop the filter done by the calls findByRequestIds and findByRequestAndTaskIds. Filter should only be applied on the number of requests to be returned., issu follow getRequestsByTaskStatus follow get request task statu behav correctli return latest request request note request gt gt gt gt task task call findByRequestIds find request id get oldest task requestId request Id task belong list return first call call instead get task get task oldest task return return result call never return latest request task request task fix drop filter done call findByRequestIds find request id findByRequestAndTaskIds find request task id filter appli number request return return,0,0,0,0,0,0,0 
2840,Andrii Tkach,ambari-web,0,YARN and ZK data directory names have ' ' at end, YARN ZK data directori name end,Installed the Hadoop2 stack and upon finishing the zk_data_dir in global  and yarn.nodemanager.local-dirs in yarn-site have the folder names suffixed with ' ' in API. Consequently  the folder names on system end up with a ' ' at end. Ex: /hadoop/yarn  and /hadoop/zookeeper ., instal hadoop hadoop stack upon finish zk_data_dir global yarn nodemanag local dir yarn nodemanag local dir yarn site yarn site folder name suffix API API consequ folder name system end end end Ex Ex hadoop yarn hadoop yarn hadoop zookeep hadoop zookeep,0,0,0,0,0,ambari-web/app/controllers/wizard.js;ambari-web/app/controllers/wizard/step7_controller.js;ambari-web/app/controllers/wizard/step8_controller.js;,1 
2847,Siddharth Wagle,ambari-agent,0,Restart service component fails if pid is reallocated, restart servic compon fail pid realloc,1. Stop secondary namenode.2. Edit the pid file  default location = /var/run/hadoop/hdfs/hadoop-hdfs-secondarynamenode.pid3. Change the pid to any other process pid that is currently running.4. Start secondary namenode.Outcome:Secondary namenode start command succeeds but secondary namenode does not start. (indicated by live status of the component)., stop secondari namenod namenod edit pid file default locat var run hadoop hdf hadoop hdf secondarynamenod pid var run hadoop hdf hadoop hdf secondarynamenod pid chang pid process pid current run run start secondari namenod outcom secondari namenod outcom secondari namenod start command succe secondari namenod not start start indic live statu compon compon,0,0,0,0,0,0,1 
2864,Siddharth Wagle,ambari-agent,0,Host registration fails, host registr fail,Host registration fails with:INFO 2013-08-10 01:50:49 923 Controller.py:99 - Unable to connect to: https://c6401.ambari.apache.org:8441/agent/v1/register/c6403.ambari.apache.orgTraceback (most recent call last): File '/usr/lib/python2.6/site-packages/ambari_agent/Controller.py'  line 80  in registerWithServer ret = json.loads(response) File '/usr/lib64/python2.6/json/__init__.py'  line 307  in loads return _default_decoder.decode(s) File '/usr/lib64/python2.6/json/decoder.py'  line 319  in decode obj  end = self.raw_decode(s  idx=_w(s  0).end()) File '/usr/lib64/python2.6/json/decoder.py'  line 338  in raw_decode raise ValueError('No JSON object could be decoded')ValueError: No JSON object could be decodedambari-server.log is showing:01:55:22 732 WARN [qtp967966535-50] ServletHandler:514 - /agent/v1/register/c6401.ambari.apache.orgcom.google.gson.JsonSyntaxException: java.lang.IllegalStateException: Expected a string but was BEGIN_OBJECT at line 1 column 3680 at com.google.gson.internal.bind.ReflectiveTypeAdapterFactory$Adapter.read(ReflectiveTypeAdapterFactory.java:176) at com.google.gson.internal.bind.TypeAdapterRuntimeTypeWrapper.read(TypeAdapterRuntimeTypeWrapper.java:40) at com.google.gson.internal.bind.ArrayTypeAdapter.read(ArrayTypeAdapter.java:72) at com.google.gson.internal.bind.ReflectiveTypeAdapterFactory$1.read(ReflectiveTypeAdapterFactory.java:93) at com.google.gson.internal.bind.ReflectiveTypeAdapterFactory$Adapter.read(ReflectiveTypeAdapterFactory.java:172) at com.google.gson.internal.bind.ReflectiveTypeAdapterFactory$1.read(ReflectiveTypeAdapterFactory.java:93) at com.google.gson.internal.bind.ReflectiveTypeAdapterFactory$Adapter.read(ReflectiveTypeAdapterFactory.java:172) at com.google.gson.internal.bind.ReflectiveTypeAdapterFactory$1.read(ReflectiveTypeAdapterFactory.java:93) at com.google.gson.internal.bind.ReflectiveTypeAdapterFactory$Adapter.read(ReflectiveTypeAdapterFactory.java:172) at com.google.gson.Gson.fromJson(Gson.java:795) at com.google.gson.Gson.fromJson(Gson.java:761) at org.apache.ambari.server.api.GsonJsonProvider.readFrom(GsonJsonProvider.java:60) at com.sun.jersey.spi.container.ContainerRequest.getEntity(ContainerRequest.java:474) at com.sun.jersey.server.impl.model.method.dispatch.EntityParamDispatchProvider$EntityInjectable.getValue(EntityParamDispatchProvider.java:123) at com.sun.jersey.server.impl.inject.InjectableValuesProvider.getInjectableValues(InjectableValuesProvider.java:46) at com.sun.jersey.server.impl.model.method.dispatch.AbstractResourceMethodDispatchProvider$EntityParamInInvoker.getParams(AbstractResourceMethodDispatchProvider.java:153) at com.sun.jersey.server.impl.model.method.dispatch.AbstractResourceMethodDispatchProvider$TypeOutInvoker._dispatch(AbstractResourceMethodDispatchProvider.java:183) at com.sun.jersey.server.impl.model.method.dispatch.ResourceJavaMethodDispatcher.dispatch(ResourceJavaMethodDispatcher.java:75) at com.sun.jersey.server.impl.uri.rules.HttpMethodRule.accept(HttpMethodRule.java:288) at com.sun.jersey.server.impl.uri.rules.RightHandPathRule.accept(RightHandPathRule.java:147) at com.sun.jersey.server.impl.uri.rules.ResourceClassRule.accept(ResourceClassRule.java:108) at com.sun.jersey.server.impl.uri.rules.RightHandPathRule.accept(RightHandPathRule.java:147) at com.sun.jersey.server.impl.uri.rules.RootResourceClassesRule.accept(RootResourceClassesRule.java:84) at com.sun.jersey.server.impl.application.WebApplicationImpl._handleRequest(WebApplicationImpl.java:1469), host registr fail INFO INFO control py control py unabl connect recent call last last file usr lib python site packag ambari_agent control py usr lib python site packag ambari_agent control py line registerWithServer regist server ret json load respons json load respons file usr lib python json init py usr lib python json init py line load return _default_decoder decod _default_decoder decod file usr lib python json decod py usr lib python json decod py line decod obj end self raw_decode self raw_decode idx _w idx _w end end file usr lib python json decod py usr lib python json decod py line raw_decode rais ValueError No valu error No JSON object could decod ValueError decod valu error No JSON object could decodedambari server log decodedambari server log show show WARN qtp qtp ServletHandler servlet handler agent regist ambari apach orgcom googl gson JsonSyntaxException agent regist ambari apach orgcom googl gson json syntax except java lang IllegalStateException java lang illeg state except expect string BEGIN_OBJECT BEGIN OBJECT line column com googl gson intern bind ReflectiveTypeAdapterFactory adapt read ReflectiveTypeAdapterFactory java com googl gson intern bind reflect type adapt factori adapt read reflect type adapt factori java com googl gson intern bind TypeAdapterRuntimeTypeWrapper read TypeAdapterRuntimeTypeWrapper java com googl gson intern bind type adapt runtim type wrapper read type adapt runtim type wrapper java com googl gson intern bind ArrayTypeAdapter read ArrayTypeAdapter java com googl gson intern bind array type adapt read array type adapt java com googl gson intern bind ReflectiveTypeAdapterFactory read ReflectiveTypeAdapterFactory java com googl gson intern bind reflect type adapt factori read reflect type adapt factori java com googl gson intern bind ReflectiveTypeAdapterFactory adapt read ReflectiveTypeAdapterFactory java com googl gson intern bind reflect type adapt factori adapt read reflect type adapt factori java com googl gson intern bind ReflectiveTypeAdapterFactory read ReflectiveTypeAdapterFactory java com googl gson intern bind reflect type adapt factori read reflect type adapt factori java com googl gson intern bind ReflectiveTypeAdapterFactory adapt read ReflectiveTypeAdapterFactory java com googl gson intern bind reflect type adapt factori adapt read reflect type adapt factori java com googl gson intern bind ReflectiveTypeAdapterFactory read ReflectiveTypeAdapterFactory java com googl gson intern bind reflect type adapt factori read reflect type adapt factori java com googl gson intern bind ReflectiveTypeAdapterFactory adapt read ReflectiveTypeAdapterFactory java com googl gson intern bind reflect type adapt factori adapt read reflect type adapt factori java com googl gson gson fromJson gson java com googl gson gson json gson java com googl gson gson fromJson gson java com googl gson gson json gson java org apach ambari server api GsonJsonProvider readFrom GsonJsonProvider java org apach ambari server api gson json provid read gson json provid java com sun jersey spi contain ContainerRequest getEntity ContainerRequest java com sun jersey spi contain contain request get entiti contain request java com sun jersey server impl model method dispatch EntityParamDispatchProvider EntityInjectable getValue EntityParamDispatchProvider java com sun jersey server impl model method dispatch entiti param dispatch provid entiti inject get valu entiti param dispatch provid java com sun jersey server impl inject InjectableValuesProvider getInjectableValues InjectableValuesProvider java com sun jersey server impl inject inject valu provid get inject valu inject valu provid java com sun jersey server impl model method dispatch AbstractResourceMethodDispatchProvider EntityParamInInvoker getParams AbstractResourceMethodDispatchProvider java com sun jersey server impl model method dispatch abstract resourc method dispatch provid entiti param invok get param abstract resourc method dispatch provid java com sun jersey server impl model method dispatch AbstractResourceMethodDispatchProvider TypeOutInvoker _dispatch AbstractResourceMethodDispatchProvider java com sun jersey server impl model method dispatch abstract resourc method dispatch provid type invok _dispatch abstract resourc method dispatch provid java com sun jersey server impl model method dispatch ResourceJavaMethodDispatcher dispatch ResourceJavaMethodDispatcher java com sun jersey server impl model method dispatch resourc java method dispatch dispatch resourc java method dispatch java com sun jersey server impl uri rule HttpMethodRule accept HttpMethodRule java com sun jersey server impl uri rule http method rule accept http method rule java com sun jersey server impl uri rule RightHandPathRule accept RightHandPathRule java com sun jersey server impl uri rule right hand path rule accept right hand path rule java com sun jersey server impl uri rule ResourceClassRule accept ResourceClassRule java com sun jersey server impl uri rule resourc class rule accept resourc class rule java com sun jersey server impl uri rule RightHandPathRule accept RightHandPathRule java com sun jersey server impl uri rule right hand path rule accept right hand path rule java com sun jersey server impl uri rule RootResourceClassesRule accept RootResourceClassesRule java com sun jersey server impl uri rule root resourc class rule accept root resourc class rule java com sun jersey server impl applic WebApplicationImpl _handleRequest WebApplicationImpl java com sun jersey server impl applic web applic impl _handle request web applic impl java,0,0,0,0,0,0,0 
2865,Sumit Mohanty,ambari-agent,0,Nagios server fails to start with invalid configuration error, nagio server fail start invalid configur error,Nagios fails to start with invalid configuration error. (This is likely intermittent).Error: Configuration validation failed - when Nagios is started./usr/sbin/nagios -v /etc/nagios/nagios.cfgCopyright (c) 1999-2009 Ethan GalstadLast Modified: 03-15-2013License: GPLWebsite: http://www.nagios.orgReading configuration data... Read main config file okay...Processing object config file '/etc/nagios/objects/commands.cfg'...Processing object config file '/etc/nagios/objects/contacts.cfg'...Processing object config file '/etc/nagios/objects/timeperiods.cfg'...Processing object config file '/etc/nagios/objects/templates.cfg'...Processing object config file '/etc/nagios/objects/hadoop-hosts.cfg'...Processing object config file '/etc/nagios/objects/hadoop-hostgroups.cfg'...Processing object config file '/etc/nagios/objects/hadoop-servicegroups.cfg'...Processing object config file '/etc/nagios/objects/hadoop-services.cfg'...Processing object config file '/etc/nagios/objects/hadoop-commands.cfg'...Error: Could not find any hostgroup matching 'resourcemanager' (config file '/etc/nagios/objects/hadoop-services.cfg'  starting on line 292) Error processing object config files!***&gt; One or more problems was encountered while processing the config files... Check your configuration file(s) to ensure that they contain valid directives and data defintions. If you are upgrading from a previous version of Nagios  you should be aware that some variables/definitions may have been removed or modified in this version. Make sure to read the HTML documentation regarding the config files  as well as the 'Whats New' section to find out what has changed., nagio fail start invalid configur error error like intermitt error intermitt error configur valid fail nagio start usr sbin nagio start usr sbin nagio etc nagio nagio cfgCopyright etc nagio nagio cfg copyright ethan GalstadLast galstad last modifi modifi licens licens GPLWebsite GPL websit configur data data read main config file okay process okay process object config file etc nagio object command cfg process etc nagio object command cfg process object config file etc nagio object contact cfg process etc nagio object contact cfg process object config file etc nagio object timeperiod cfg process etc nagio object timeperiod cfg process object config file etc nagio object templat cfg process etc nagio object templat cfg process object config file etc nagio object hadoop host cfg process etc nagio object hadoop host cfg process object config file etc nagio object hadoop hostgroup cfg process etc nagio object hadoop hostgroup cfg process object config file etc nagio object hadoop servicegroup cfg process etc nagio object hadoop servicegroup cfg process object config file etc nagio object hadoop servic cfg process etc nagio object hadoop servic cfg process object config file etc nagio object hadoop command cfg error etc nagio object hadoop command cfg error could not find hostgroup match resourcemanag resourcemanag config file etc nagio object hadoop servic cfg etc nagio object hadoop servic cfg start line error process object config file gt file gt one problem encount process config file file check configur file file ensur contain valid direct data defint defint upgrad previou version nagio awar variabl definit variabl definit may remov modifi version version make sure read HTML document regard config file well what what new new section find chang chang,0,0,0,0,0,0,0 
2866,Oleksandr Diachenko,ambari-server,0,API JMX mapping needs to be updated due to property name changes, API JMX map need updat due properti name chang,In Ambari UI  we show properties like NameNode RPC Time.We used to get this metric by querying the NameNode component for 'RpcQueueTime_avg_time'.However  in Hadoop 2  it looks like this property name changed to 'RpcQueueTimeAvgTime'  so the Ambari API no longer contains these metrics. Other properties related to NameNode RPC may have changed. We need to update the mapping accordingly., ambari UI show properti like NameNode name node RPC time time use get metric queri NameNode name node compon RpcQueueTime_avg_time howev rpc queue Time_avg_time howev hadoop look like properti name chang RpcQueueTimeAvgTime rpc queue time avg time ambari API no longer contain metric metric properti relat NameNode name node RPC may chang chang need updat map accordingli accordingli,0,0,0,0,0,0,0 
2871,Oleksandr Diachenko,ambari-agent,0,Nagios start fails due to invalid configs, nagio start fail due invalid config,Steps to reproduce:1) Deploy HDP-2.0.5 cluster with Nagios.2) Start of Nagios failed  puppet log:notice: /Stage[1]/Hdp::Snappy::Package/Hdp::Snappy::Package::Ln[32]/Hdp::Exec[hdp::snappy::package::ln 32]/Exec[hdp::snappy::package::ln 32]/returns: executed successfullynotice: /Stage[2]/Hdp-nagios::Server::Enable_snmp/Exec[enable_snmp]/returns: executed successfullynotice: /Stage[2]/Hdp-nagios::Server::Config/Hdp-nagios::Server::Configfile[hadoop-hostgroups.cfg]/Hdp::Configfile[/etc/nagios/objects/hadoop-hostgroups.cfg]/File[/etc/nagios/objects/hadoop-hostgroups.cfg]/content: content changed '{md5}873d2be7b9f78137e0740223944d93af' to '{md5}780117e3c2407e9d02b37eab93159149'notice: /Stage[2]/Hdp-nagios::Server::Config/Hdp-nagios::Server::Configfile[nagios]/Hdp::Configfile[/etc/init.d//nagios]/File[/etc/init.d//nagios]/content: content changed '{md5}3990694abc37617c79e2ea5276d71089' to '{md5}c4c4454911c0c6c1ba29d9d0dc2aa28c'notice: /Stage[2]/Hdp-nagios::Server::Config/Hdp-nagios::Server::Configfile[hadoop-hosts.cfg]/Hdp::Configfile[/etc/nagios/objects/hadoop-hosts.cfg]/File[/etc/nagios/objects/hadoop-hosts.cfg]/content: content changed '{md5}7979396ff0b495e40901acdd2ecc457c' to '{md5}fa5ec3a93a4827cc6a691e0b8e22b4f6'notice: /Stage[2]/Hdp-nagios::Server::Config/Hdp-nagios::Server::Configfile[hadoop-services.cfg]/Hdp::Configfile[/etc/nagios/objects/hadoop-services.cfg]/File[/etc/nagios/objects/hadoop-services.cfg]/content: content changed '{md5}06c9d0bb0aa3b1e7b30b19fb1bb30b5a' to '{md5}934241156b5489483dab8018f9cecd22'notice: /Stage[2]/Hdp-nagios::Server::Web_permisssions/Hdp::Exec[htpasswd -c -b /etc/nagios/htpasswd.users nagiosadmin p]/Exec[htpasswd -c -b /etc/nagios/htpasswd.users nagiosadmin p]/returns: executed successfullynotice: /Stage[2]/Hdp-nagios::Server::Web_permisssions/Hdp::Exec[apache_permissions_htpasswd.users]/Exec[apache_permissions_htpasswd.users]/returns: executed successfullynotice: /Stage[2]/Hdp-nagios::Server::Services/Exec[nagios]/returns: nagios is stoppednotice: /Stage[2]/Hdp-nagios::Server::Services/Exec[nagios]/returns: Configuration validation failed[FAILED]err: /Stage[2]/Hdp-nagios::Server::Services/Exec[nagios]/returns: change from notrun to 0 failed: service nagios start returned 1 instead of one of [0] at /var/lib/ambari-agent/puppet/modules/hdp-nagios/manifests/server.pp:284notice: /Stage[2]/Hdp-nagios::Server::Services/Exec[nagios]/returns: nagios is stoppednotice: /Stage[2]/Hdp-nagios::Server::Services/Exec[nagios]/returns: Configuration validation failed[FAILED]err: /Stage[2]/Hdp-nagios::Server::Services/Exec[nagios]: Failed to call refresh: service nagios start returned 1 instead of one of [0] at /var/lib/ambari-agent/puppet/modules/hdp-nagios/manifests/server.pp:284notice: /Stage[2]/Hdp-nagios::Server::Services/Anchor[hdp-nagios::server::services::end]: Dependency Exec[nagios] has failures: truewarning: /Stage[2]/Hdp-nagios::Server::Services/Anchor[hdp-nagios::server::services::end]: Skipping because of failed dependenciesnotice: /Stage[2]/Hdp-monitor-webserver/Hdp::Package[httpd]/Hdp::Package::Process_pkg[httpd]/Anchor[hdp::package::httpd::begin]: Dependency Exec[nagios] has failures: truewarning: /Stage[2]/Hdp-monitor-webserver/Hdp::Package[httpd]/Hdp::Package::Process_pkg[httpd]/Anchor[hdp::package::httpd::begin]: Skipping because of failed dependenciesnotice: /Stage[2]/Hdp-monitor-webserver/Hdp::Package[httpd]/Hdp::Package::Process_pkg[httpd]/Package[httpd]: Dependency Exec[nagios] has failures: truewarning: /Stage[2]/Hdp-monitor-webserver/Hdp::Package[httpd]/Hdp::Package::Process_pkg[httpd]/Package[httpd]: Skipping because of failed dependenciesnotice: /Stage[2]/Hdp-monitor-webserver/Hdp::Package[httpd]/Hdp::Package::Process_pkg[httpd]/Hdp::Java::Package[httpd]/Anchor[hdp::java::package::httpd::begin]: Dependency Exec[nagios] has failures: truewarning: /Stage[2]/Hdp-monitor-webserver/Hdp::Package[httpd]/Hdp::Package::Process_pkg[httpd]/Hdp::Java::Package[httpd]/Anchor[hdp::java::package::httpd::begin]: Skipping because of failed dependenciesnotice: /Stage[2]/Hdp-monitor-webserver/Hdp::Package[httpd]/Hdp::Package::Process_pkg[httpd]/Hdp::Java::Package[httpd]/Exec[mkdir -p /tmp/HDP-artifacts/ ; curl -kf --retry 10 http://dev01.hortonworks.com:8080/resources//jdk-6u31-linux-x64.bin -o /tmp/HDP-artifacts//jdk-6u31-linux-x64.bin httpd]: Dependency Exec[nagios] has failures: truewarning: /Stage[2]/Hdp-monitor-webserver/Hdp::Package[httpd]/Hdp::Package::Process_pkg[httpd]/Hdp::Java::Package[httpd]/Exec[mkdir -p /tmp/HDP-artifacts/ ; curl -kf --retry 10 http://dev01.hortonworks.com:8080/resources//jdk-6u31-linux-x64.bin -o /tmp/HDP-artifacts//jdk-6u31-linux-x64.bin httpd]: Skipping because of failed dependenciesnotice: /Stage[2]/Hdp-monitor-webserver/Hdp::Package[httpd]/Hdp::Package::Process_pkg[httpd]/Hdp::Java::Package[httpd]/Exec[mkdir -p /usr/jdk ; chmod +x /tmp/HDP-artifacts//jdk-6u31-linux-x64.bin; cd /usr/jdk ; echo A | /tmp/HDP-artifacts//jdk-6u31-linux-x64.bin -noregister &gt; /dev/null 2&gt;&amp;1 httpd]: Dependency Exec[nagios] has failures: truewarning: /Stage[2]/Hdp-monitor-webserver/Hdp::Package[httpd]/Hdp::Package::Process_pkg[httpd]/Hdp::Java::Package[httpd]/Exec[mkdir -p /usr/jdk ; chmod +x /tmp/HDP-artifacts//jdk-6u31-linux-x64.bin; cd /usr/jdk ; echo A | /tmp/HDP-artifacts//jdk-6u31-linux-x64.bin -noregister &gt; /dev/null 2&gt;&amp;1 httpd]: Skipping because of failed dependenciesnotice: /Stage[2]/Hdp-monitor-webserver/Hdp::Package[httpd]/Hdp::Package::Process_pkg[httpd]/Hdp::Java::Package[httpd]/File[/usr/jdk/jdk1.6.0_31/bin/java httpd]: Dependency Exec[nagios] has failures: truewarning: /Stage[2]/Hdp-monitor-webserver/Hdp::Package[httpd]/Hdp::Package::Process_pkg[httpd]/Hdp::Java::Package[httpd]/File[/usr/jdk/jdk1.6.0_31/bin/java httpd]: Skipping because of failed dependenciesnotice: /Stage[2]/Hdp-monitor-webserver/Hdp::Package[httpd]/Hdp::Package::Process_pkg[httpd]/Hdp::Java::Package[httpd]/Anchor[hdp::java::package::httpd::end]: Dependency Exec[nagios] has failures: truewarning: /Stage[2]/Hdp-monitor-webserver/Hdp::Package[httpd]/Hdp::Package::Process_pkg[httpd]/Hdp::Java::Package[httpd]/Anchor[hdp::java::package::httpd::end]: Skipping because of failed dependenciesnotice: /Stage[2]/Hdp-monitor-webserver/Hdp::Package[httpd]/Hdp::Package::Process_pkg[httpd]/Anchor[hdp::package::httpd::end]: Dependency Exec[nagios] has failures: truewarning: /Stage[2]/Hdp-monitor-webserver/Hdp::Package[httpd]/Hdp::Package::Process_pkg[httpd]/Anchor[hdp::package::httpd::end]: Skipping because of failed dependenciesnotice: /Stage[2]/Hdp-monitor-webserver/Hdp::Exec[monitor webserver restart]/Anchor[hdp::exec::monitor webserver restart::begin]: Dependency Exec[nagios] has failures: truewarning: /Stage[2]/Hdp-monitor-webserver/Hdp::Exec[monitor webserver restart]/Anchor[hdp::exec::monitor webserver restart::begin]: Skipping because of failed dependenciesnotice: /Stage[2]/Hdp-monitor-webserver/Hdp::Exec[monitor webserver restart]/Exec[monitor webserver restart]: Dependency Exec[nagios] has failures: truewarning: /Stage[2]/Hdp-monitor-webserver/Hdp::Exec[monitor webserver restart]/Exec[monitor webserver restart]: Skipping because of failed dependenciesnotice: /Stage[2]/Hdp-monitor-webserver/Hdp::Exec[monitor webserver restart]/Anchor[hdp::exec::monitor webserver restart::end]: Dependency Exec[nagios] has failures: truewarning: /Stage[2]/Hdp-monitor-webserver/Hdp::Exec[monitor webserver restart]/Anchor[hdp::exec::monitor webserver restart::end]: Skipping because of failed dependencies3) Run checkconfig:[root@dev02 ~]# /usr/sbin/nagios -v /etc/nagios/nagios.cfg Nagios Core 3.5.0Copyright (c) 2009-2011 Nagios Core Development Team and Community ContributorsCopyright (c) 1999-2009 Ethan GalstadLast Modified: 03-15-2013License: GPLWebsite: http://www.nagios.orgReading configuration data... Read main config file okay...Processing object config file '/etc/nagios/objects/commands.cfg'...Processing object config file '/etc/nagios/objects/contacts.cfg'...Processing object config file '/etc/nagios/objects/timeperiods.cfg'...Processing object config file '/etc/nagios/objects/templates.cfg'...Processing object config file '/etc/nagios/objects/hadoop-hosts.cfg'...Processing object config file '/etc/nagios/objects/hadoop-hostgroups.cfg'...Processing object config file '/etc/nagios/objects/hadoop-servicegroups.cfg'...Processing object config file '/etc/nagios/objects/hadoop-services.cfg'...Processing object config file '/etc/nagios/objects/hadoop-commands.cfg'...Error: Could not find any servicegroup matching 'MAPREDUCE' (config file '/etc/nagios/objects/hadoop-services.cfg'  starting on line 67) Error processing object config files!***&gt; One or more problems was encountered while processing the config files... Check your configuration file(s) to ensure that they contain valid directives and data defintions. If you are upgrading from a previous version of Nagios  you should be aware that some variables/definitions may have been removed or modified in this version. Make sure to read the HTML documentation regarding the config files  as well as the 'Whats New' section to find out what has changed.[root@dev02 ~]# It seems we have invalid condition for generation of MAPREDUCE Nagios checks., step reproduc reproduc deploy HDP HDP cluster nagio nagio start nagio fail puppet log notic log notic stage hdp snappi packag hdp snappi packag Ln hdp exec hdp snappi packag ln stage hdp snappi packag hdp snappi packag Ln hdp exec hdp snappi packag ln exec hdp snappi packag ln exec hdp snappi packag ln return return execut successfullynotic successfullynotic stage hdp nagio server Enable_snmp exec enable_snmp return stage hdp nagio server Enable_snmp exec enable_snmp return execut successfullynotic successfullynotic stage hdp nagio server config hdp nagio server configfil hadoop hostgroup cfg hdp configfil etc nagio object hadoop hostgroup cfg file etc nagio object hadoop hostgroup cfg content stage hdp nagio server config hdp nagio server configfil hadoop hostgroup cfg hdp configfil etc nagio object hadoop hostgroup cfg file etc nagio object hadoop hostgroup cfg content content chang md af md af md eab notic md eab notic stage hdp nagio server config hdp nagio server configfil nagio hdp configfil etc init nagio file etc init nagio content stage hdp nagio server config hdp nagio server configfil nagio hdp configfil etc init nagio file etc init nagio content content chang md abc ea md abc ea md ba dc aa notic md ba dc aa notic stage hdp nagio server config hdp nagio server configfil hadoop host cfg hdp configfil etc nagio object hadoop host cfg file etc nagio object hadoop host cfg content stage hdp nagio server config hdp nagio server configfil hadoop host cfg hdp configfil etc nagio object hadoop host cfg file etc nagio object hadoop host cfg content content chang md ff acdd ecc md ff acdd ecc md fa ec cc notic md fa ec cc notic stage hdp nagio server config hdp nagio server configfil hadoop servic cfg hdp configfil etc nagio object hadoop servic cfg file etc nagio object hadoop servic cfg content stage hdp nagio server config hdp nagio server configfil hadoop servic cfg hdp configfil etc nagio object hadoop servic cfg file etc nagio object hadoop servic cfg content content chang md bb aa fb bb md bb aa fb bb md dab cecd notic md dab cecd notic stage hdp nagio server Web_permisssions hdp exec htpasswd stage hdp nagio server Web_permisssions hdp exec htpasswd etc nagio htpasswd user etc nagio htpasswd user nagiosadmin exec htpasswd exec htpasswd etc nagio htpasswd user etc nagio htpasswd user nagiosadmin return return execut successfullynotic successfullynotic stage hdp nagio server Web_permisssions hdp exec apache_permissions_htpasswd user exec apache_permissions_htpasswd user return stage hdp nagio server Web_permisssions hdp exec apache_permissions_htpasswd user exec apache_permissions_htpasswd user return execut successfullynotic successfullynotic stage hdp nagio server servic exec nagio return stage hdp nagio server servic exec nagio return nagio stoppednotic stoppednotic stage hdp nagio server servic exec nagio return stage hdp nagio server servic exec nagio return configur valid fail FAILED err fail FAILED err stage hdp nagio server servic exec nagio return stage hdp nagio server servic exec nagio return chang notrun fail fail servic nagio start return instead one var lib ambari agent puppet modul hdp nagio manifest server pp notic var lib ambari agent puppet modul hdp nagio manifest server pp notic stage hdp nagio server servic exec nagio return stage hdp nagio server servic exec nagio return nagio stoppednotic stoppednotic stage hdp nagio server servic exec nagio return stage hdp nagio server servic exec nagio return configur valid fail FAILED err fail FAILED err stage hdp nagio server servic exec nagio stage hdp nagio server servic exec nagio fail call refresh refresh servic nagio start return instead one var lib ambari agent puppet modul hdp nagio manifest server pp notic var lib ambari agent puppet modul hdp nagio manifest server pp notic stage hdp nagio server servic anchor hdp nagio server servic end stage hdp nagio server servic anchor hdp nagio server servic end depend exec nagio exec nagio failur failur truewarn truewarn stage hdp nagio server servic anchor hdp nagio server servic end stage hdp nagio server servic anchor hdp nagio server servic end skip fail dependenciesnotic dependenciesnotic stage hdp monitor webserv hdp packag httpd hdp packag Process_pkg httpd anchor hdp packag httpd begin stage hdp monitor webserv hdp packag httpd hdp packag Process_pkg httpd anchor hdp packag httpd begin depend exec nagio exec nagio failur failur truewarn truewarn stage hdp monitor webserv hdp packag httpd hdp packag Process_pkg httpd anchor hdp packag httpd begin stage hdp monitor webserv hdp packag httpd hdp packag Process_pkg httpd anchor hdp packag httpd begin skip fail dependenciesnotic dependenciesnotic stage hdp monitor webserv hdp packag httpd hdp packag Process_pkg httpd packag httpd stage hdp monitor webserv hdp packag httpd hdp packag Process_pkg httpd packag httpd depend exec nagio exec nagio failur failur truewarn truewarn stage hdp monitor webserv hdp packag httpd hdp packag Process_pkg httpd packag httpd stage hdp monitor webserv hdp packag httpd hdp packag Process_pkg httpd packag httpd skip fail dependenciesnotic dependenciesnotic stage hdp monitor webserv hdp packag httpd hdp packag Process_pkg httpd hdp java packag httpd anchor hdp java packag httpd begin stage hdp monitor webserv hdp packag httpd hdp packag Process_pkg httpd hdp java packag httpd anchor hdp java packag httpd begin depend exec nagio exec nagio failur failur truewarn truewarn stage hdp monitor webserv hdp packag httpd hdp packag Process_pkg httpd hdp java packag httpd anchor hdp java packag httpd begin stage hdp monitor webserv hdp packag httpd hdp packag Process_pkg httpd hdp java packag httpd anchor hdp java packag httpd begin skip fail dependenciesnotic dependenciesnotic stage hdp monitor webserv hdp packag httpd hdp packag Process_pkg httpd hdp java packag httpd exec mkdir stage hdp monitor webserv hdp packag httpd hdp packag Process_pkg httpd hdp java packag httpd exec mkdir tmp HDP artifact tmp HDP artifact curl kf retri tmp HDP artifact jdk linux bin tmp HDP artifact jdk linux bin httpd httpd depend exec nagio exec nagio failur failur truewarn truewarn stage hdp monitor webserv hdp packag httpd hdp packag Process_pkg httpd hdp java packag httpd exec mkdir stage hdp monitor webserv hdp packag httpd hdp packag Process_pkg httpd hdp java packag httpd exec mkdir tmp HDP artifact tmp HDP artifact curl kf retri tmp HDP artifact jdk linux bin tmp HDP artifact jdk linux bin httpd httpd skip fail dependenciesnotic dependenciesnotic stage hdp monitor webserv hdp packag httpd hdp packag Process_pkg httpd hdp java packag httpd exec mkdir stage hdp monitor webserv hdp packag httpd hdp packag Process_pkg httpd hdp java packag httpd exec mkdir usr jdk usr jdk chmod tmp HDP artifact jdk linux bin tmp HDP artifact jdk linux bin cd usr jdk usr jdk echo tmp HDP artifact jdk linux bin tmp HDP artifact jdk linux bin noregist gt gt dev null dev null gt amp gt amp httpd httpd depend exec nagio exec nagio failur failur truewarn truewarn stage hdp monitor webserv hdp packag httpd hdp packag Process_pkg httpd hdp java packag httpd exec mkdir stage hdp monitor webserv hdp packag httpd hdp packag Process_pkg httpd hdp java packag httpd exec mkdir usr jdk usr jdk chmod tmp HDP artifact jdk linux bin tmp HDP artifact jdk linux bin cd usr jdk usr jdk echo tmp HDP artifact jdk linux bin tmp HDP artifact jdk linux bin noregist gt gt dev null dev null gt amp gt amp httpd httpd skip fail dependenciesnotic dependenciesnotic stage hdp monitor webserv hdp packag httpd hdp packag Process_pkg httpd hdp java packag httpd file usr jdk jdk  bin java stage hdp monitor webserv hdp packag httpd hdp packag Process_pkg httpd hdp java packag httpd file usr jdk jdk  bin java httpd httpd depend exec nagio exec nagio failur failur truewarn truewarn stage hdp monitor webserv hdp packag httpd hdp packag Process_pkg httpd hdp java packag httpd file usr jdk jdk  bin java stage hdp monitor webserv hdp packag httpd hdp packag Process_pkg httpd hdp java packag httpd file usr jdk jdk  bin java httpd httpd skip fail dependenciesnotic dependenciesnotic stage hdp monitor webserv hdp packag httpd hdp packag Process_pkg httpd hdp java packag httpd anchor hdp java packag httpd end stage hdp monitor webserv hdp packag httpd hdp packag Process_pkg httpd hdp java packag httpd anchor hdp java packag httpd end depend exec nagio exec nagio failur failur truewarn truewarn stage hdp monitor webserv hdp packag httpd hdp packag Process_pkg httpd hdp java packag httpd anchor hdp java packag httpd end stage hdp monitor webserv hdp packag httpd hdp packag Process_pkg httpd hdp java packag httpd anchor hdp java packag httpd end skip fail dependenciesnotic dependenciesnotic stage hdp monitor webserv hdp packag httpd hdp packag Process_pkg httpd anchor hdp packag httpd end stage hdp monitor webserv hdp packag httpd hdp packag Process_pkg httpd anchor hdp packag httpd end depend exec nagio exec nagio failur failur truewarn truewarn stage hdp monitor webserv hdp packag httpd hdp packag Process_pkg httpd anchor hdp packag httpd end stage hdp monitor webserv hdp packag httpd hdp packag Process_pkg httpd anchor hdp packag httpd end skip fail dependenciesnotic dependenciesnotic stage hdp monitor webserv hdp exec monitor stage hdp monitor webserv hdp exec monitor webserv restart anchor hdp exec monitor restart anchor hdp exec monitor webserv restart begin restart begin depend exec nagio exec nagio failur failur truewarn truewarn stage hdp monitor webserv hdp exec monitor stage hdp monitor webserv hdp exec monitor webserv restart anchor hdp exec monitor restart anchor hdp exec monitor webserv restart begin restart begin skip fail dependenciesnotic dependenciesnotic stage hdp monitor webserv hdp exec monitor stage hdp monitor webserv hdp exec monitor webserv restart exec monitor restart exec monitor webserv restart restart depend exec nagio exec nagio failur failur truewarn truewarn stage hdp monitor webserv hdp exec monitor stage hdp monitor webserv hdp exec monitor webserv restart exec monitor restart exec monitor webserv restart restart skip fail dependenciesnotic dependenciesnotic stage hdp monitor webserv hdp exec monitor stage hdp monitor webserv hdp exec monitor webserv restart anchor hdp exec monitor restart anchor hdp exec monitor webserv restart end restart end depend exec nagio exec nagio failur failur truewarn truewarn stage hdp monitor webserv hdp exec monitor stage hdp monitor webserv hdp exec monitor webserv restart anchor hdp exec monitor restart anchor hdp exec monitor webserv restart end restart end skip fail depend depend run checkconfig root dev checkconfig root dev usr sbin nagio usr sbin nagio etc nagio nagio cfg etc nagio nagio cfg nagio core copyright copyright nagio core develop team commun ContributorsCopyright contributor copyright ethan GalstadLast galstad last modifi modifi licens licens GPLWebsite GPL websit configur data data read main config file okay process okay process object config file etc nagio object command cfg process etc nagio object command cfg process object config file etc nagio object contact cfg process etc nagio object contact cfg process object config file etc nagio object timeperiod cfg process etc nagio object timeperiod cfg process object config file etc nagio object templat cfg process etc nagio object templat cfg process object config file etc nagio object hadoop host cfg process etc nagio object hadoop host cfg process object config file etc nagio object hadoop hostgroup cfg process etc nagio object hadoop hostgroup cfg process object config file etc nagio object hadoop servicegroup cfg process etc nagio object hadoop servicegroup cfg process object config file etc nagio object hadoop servic cfg process etc nagio object hadoop servic cfg process object config file etc nagio object hadoop command cfg error etc nagio object hadoop command cfg error could not find servicegroup match MAPREDUCE MAPREDUCE config file etc nagio object hadoop servic cfg etc nagio object hadoop servic cfg start line error process object config file gt file gt one problem encount process config file file check configur file file ensur contain valid direct data defint defint upgrad previou version nagio awar variabl definit variabl definit may remov modifi version version make sure read HTML document regard config file well what what new new section find chang root dev chang root dev seem invalid condit gener MAPREDUCE nagio check check,0,0,0,0,0,0,0 
2876,Sumit Mohanty,ambari-server,0,Puppet script syntax issues result in hive deployment with custom DB and oozie service check failures, puppet script syntax issu result hive deploy custom DB oozi servic check failur,Few puppet variables are missing in jdbc-connector and oozie service-check puppet scripts., puppet variabl miss jdbc connector jdbc connector oozi servic check servic check puppet script script,0,0,0,0,0,0,0 
2879,Siddharth Wagle,ambari-agent,0,Oozie failed at smoke test in secured cluster, oozi fail smoke test secur cluster,stderr:None stdout:notice: /Stage[1]/Hdp::Snappy::Package/Hdp::Snappy::Package::Ln[32]/Hdp::Exec[hdp::snappy::package::ln 32]/Exec[hdp::snappy::package::ln 32]/returns: executed successfullynotice: /Stage[1]/Hdp::Snmp/Hdp::Package[snmp]/Hdp::Package::Process_pkg[snmp]/Hdp::Java::Package[snmp]/Hdp::Java::Jce::Package[snmp]/Exec[jce-install snmp]/returns: executed successfullynotice: /Stage[2]/Hdp-oozie::Oozie::Service_check/Hdp-oozie::Smoke_shell_file[oozieSmoke.sh]/Exec[/tmp/oozieSmoke.sh]/returns: Moved to trash: hdfs://domU-12-31-39-07-D5-91.compute-1.internal:8020/user/ambari-qa/examplesnotice: /Stage[2]/Hdp-oozie::Oozie::Service_check/Hdp-oozie::Smoke_shell_file[oozieSmoke.sh]/Exec[/tmp/oozieSmoke.sh]/returns: Moved to trash: hdfs://domU-12-31-39-07-D5-91.compute-1.internal:8020/user/ambari-qa/input-datanotice: /Stage[2]/Hdp-oozie::Oozie::Service_check/Hdp-oozie::Smoke_shell_file[oozieSmoke.sh]/Exec[/tmp/oozieSmoke.sh]/returns: Error: AUTHENTICATION : Could not authenticate  GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - UNKNOWN_SERVER)notice: /Stage[2]/Hdp-oozie::Oozie::Service_check/Hdp-oozie::Smoke_shell_file[oozieSmoke.sh]/Exec[/tmp/oozieSmoke.sh]/returns: Invalid sub-command: Missing argument for option: infonotice: /Stage[2]/Hdp-oozie::Oozie::Service_check/Hdp-oozie::Smoke_shell_file[oozieSmoke.sh]/Exec[/tmp/oozieSmoke.sh]/returns:notice: /Stage[2]/Hdp-oozie::Oozie::Service_check/Hdp-oozie::Smoke_shell_file[oozieSmoke.sh]/Exec[/tmp/oozieSmoke.sh]/returns: use 'help [sub-command]' for help detailsnotice: /Stage[2]/Hdp-oozie::Oozie::Service_check/Hdp-oozie::Smoke_shell_file[oozieSmoke.sh]/Exec[/tmp/oozieSmoke.sh]/returns: Invalid sub-command: Missing argument for option: infonotice: /Stage[2]/Hdp-oozie::Oozie::Service_check/Hdp-oozie::Smoke_shell_file[oozieSmoke.sh]/Exec[/tmp/oozieSmoke.sh]/returns:notice: /Stage[2]/Hdp-oozie::Oozie::Service_check/Hdp-oozie::Smoke_shell_file[oozieSmoke.sh]/Exec[/tmp/oozieSmoke.sh]/returns: use 'help [sub-command]' for help detailsnotice: /Stage[2]/Hdp-oozie::Oozie::Service_check/Hdp-oozie::Smoke_shell_file[oozieSmoke.sh]/Exec[/tmp/oozieSmoke.sh]/returns:notice: /Stage[2]/Hdp-oozie::Oozie::Service_check/Hdp-oozie::Smoke_shell_file[oozieSmoke.sh]/Exec[/tmp/oozieSmoke.sh]/returns: workflow_status=err: /Stage[2]/Hdp-oozie::Oozie::Service_check/Hdp-oozie::Smoke_shell_file[oozieSmoke.sh]/Exec[/tmp/oozieSmoke.sh]/returns: change from notrun to 0 failed: sh /tmp/oozieSmoke.sh /etc/oozie/conf /etc/hadoop/conf ambari-qa true /etc/security/keytabs/smokeuser.headless.keytab EXAMPLE.COM jt/domu-12-31-39-07-d5-91.compute-1.internal@EXAMPLE.COM nn/domu-12-31-39-07-d5-91.compute-1.internal@EXAMPLE.COM /usr/bin/kinit returned 1 instead of one of [0] at /var/lib/ambari-agent/puppet/modules/hdp-oozie/manifests/oozie/service_check.pp:63notice: Finished catalog run in 51.05 seconds, stderr none stderr none stdout notic stdout notic stage hdp snappi packag hdp snappi packag Ln hdp exec hdp snappi packag ln stage hdp snappi packag hdp snappi packag Ln hdp exec hdp snappi packag ln exec hdp snappi packag ln exec hdp snappi packag ln return return execut successfullynotic successfullynotic stage hdp snmp hdp packag snmp hdp packag Process_pkg snmp hdp java packag snmp hdp java jce packag snmp exec jce instal stage hdp snmp hdp packag snmp hdp packag Process_pkg snmp hdp java packag snmp hdp java jce packag snmp exec jce instal snmp return snmp return execut successfullynotic successfullynotic stage hdp oozi oozi Service_check hdp oozi Smoke_shell_file oozieSmoke sh exec tmp oozieSmoke sh return stage hdp oozi oozi Service_check hdp oozi Smoke_shell_file oozi smoke sh exec tmp oozi smoke sh return move trash trash hdf domU comput intern user ambari qa examplesnotic hdf dom comput intern user ambari qa examplesnotic stage hdp oozi oozi Service_check hdp oozi Smoke_shell_file oozieSmoke sh exec tmp oozieSmoke sh return stage hdp oozi oozi Service_check hdp oozi Smoke_shell_file oozi smoke sh exec tmp oozi smoke sh return move trash trash hdf domU comput intern user ambari qa input datanotic hdf dom comput intern user ambari qa input datanotic stage hdp oozi oozi Service_check hdp oozi Smoke_shell_file oozieSmoke sh exec tmp oozieSmoke sh return stage hdp oozi oozi Service_check hdp oozi Smoke_shell_file oozi smoke sh exec tmp oozi smoke sh return error error AUTHENTICATION could not authent GSSException GSS except No valid credenti provid mechan mechan level level server not found kerbero databas UNKNOWN_SERVER notic UNKNOWN SERVER notic stage hdp oozi oozi Service_check hdp oozi Smoke_shell_file oozieSmoke sh exec tmp oozieSmoke sh return stage hdp oozi oozi Service_check hdp oozi Smoke_shell_file oozi smoke sh exec tmp oozi smoke sh return invalid sub command sub command miss argument option option infonotic infonotic stage hdp oozi oozi Service_check hdp oozi Smoke_shell_file oozieSmoke sh exec tmp oozieSmoke sh return notic stage hdp oozi oozi Service_check hdp oozi Smoke_shell_file oozi smoke sh exec tmp oozi smoke sh return notic stage hdp oozi oozi Service_check hdp oozi Smoke_shell_file oozieSmoke sh exec tmp oozieSmoke sh return stage hdp oozi oozi Service_check hdp oozi Smoke_shell_file oozi smoke sh exec tmp oozi smoke sh return use help sub command sub command help detailsnotic detailsnotic stage hdp oozi oozi Service_check hdp oozi Smoke_shell_file oozieSmoke sh exec tmp oozieSmoke sh return stage hdp oozi oozi Service_check hdp oozi Smoke_shell_file oozi smoke sh exec tmp oozi smoke sh return invalid sub command sub command miss argument option option infonotic infonotic stage hdp oozi oozi Service_check hdp oozi Smoke_shell_file oozieSmoke sh exec tmp oozieSmoke sh return notic stage hdp oozi oozi Service_check hdp oozi Smoke_shell_file oozi smoke sh exec tmp oozi smoke sh return notic stage hdp oozi oozi Service_check hdp oozi Smoke_shell_file oozieSmoke sh exec tmp oozieSmoke sh return stage hdp oozi oozi Service_check hdp oozi Smoke_shell_file oozi smoke sh exec tmp oozi smoke sh return use help sub command sub command help detailsnotic detailsnotic stage hdp oozi oozi Service_check hdp oozi Smoke_shell_file oozieSmoke sh exec tmp oozieSmoke sh return notic stage hdp oozi oozi Service_check hdp oozi Smoke_shell_file oozi smoke sh exec tmp oozi smoke sh return notic stage hdp oozi oozi Service_check hdp oozi Smoke_shell_file oozieSmoke sh exec tmp oozieSmoke sh return stage hdp oozi oozi Service_check hdp oozi Smoke_shell_file oozi smoke sh exec tmp oozi smoke sh return workflow_status err workflow_status err stage hdp oozi oozi Service_check hdp oozi Smoke_shell_file oozieSmoke sh exec tmp oozieSmoke sh return stage hdp oozi oozi Service_check hdp oozi Smoke_shell_file oozi smoke sh exec tmp oozi smoke sh return chang notrun fail fail sh tmp oozieSmoke sh tmp oozi smoke sh etc oozi conf etc oozi conf etc hadoop conf etc hadoop conf ambari qa ambari qa true etc secur keytab smokeus headless keytab etc secur keytab smokeus headless keytab EXAMPLE COM EXAMPLE COM jt domu comput intern EXAMPLE COM jt domu comput intern EXAMPLE COM nn domu comput intern EXAMPLE COM nn domu comput intern EXAMPLE COM usr bin kinit usr bin kinit return instead one var lib ambari agent puppet modul hdp oozi manifest oozi service_check pp notic var lib ambari agent puppet modul hdp oozi manifest oozi service_check pp notic finish catalog run second,0,0,0,0,0,0,0 
2884,Andrii Tkach,ambari-web,0,Oozie start fails - likely due to 'failed install', oozi start fail like due fail instal instal,Oozie start failed with following in the log: hadoop dfs -chmod -R 755 /user/oozie/share' returned 1 instead of one of 0On the node: chmod: '/user/oozie/share': No such file or directoryoozie@c6402 ~$ hadoop dfs -ls /user/ DEPRECATED: Use of this script to execute hdfs command is deprecated.Instead use the hdfs command for it.Found 3 itemsdrwxrwx--- - ambari-qa hdfs 0 2013-08-02 02:40 /user/ambari-qadrwx------ - hive hdfs 0 2013-08-02 02:41 /user/hivedrwxrwxr-x - hdfs hdfs 0 2013-08-02 02:42 /user/oozieoozie@c6402 ~$ hadoop dfs -ls /user/oozieDEPRECATED: Use of this script to execute hdfs command is deprecated.Instead use the hdfs command for it.oozie@c6402 ~$The reason  the oozie smoke is failing to run an oozie job with more than one node in the cluster  due to bad settings in /etc/hadoop/core-site.xml:&lt;property&gt; &lt;name&gt;hadoop.proxyuser.oozie.hosts&lt;/name&gt; &lt;value&gt;host1&lt;/value&gt;&lt;/property&gt;host1  in my case is host on which oozie is not installed. After changing this to host2 (where oozie server is installed)  oozie smoke succeeded., oozi start fail follow log log hadoop df chmod user oozi share user oozi share return instead one node node chmod chmod user oozi share user oozi share No file directoryoozi directoryoozi hadoop df ls user user DEPRECATED DEPRECATED use script execut hdf command deprec instead deprec instead use hdf command found found itemsdrwxrwx itemsdrwxrwx ambari qa ambari qa hdf user ambari qadrwx user ambari qadrwx hive hdf user hivedrwxrwxr user hivedrwxrwxr hdf hdf user oozieoozi user oozieoozi hadoop df ls user oozieDEPRECATED user oozi DEPRECATED use script execut hdf command deprec instead deprec instead use hdf command oozi oozi reason oozi smoke fail run oozi job one node cluster due bad set etc hadoop core site xml lt properti gt etc hadoop core site xml lt properti gt lt name gt hadoop proxyus oozi host lt name gt lt name gt hadoop proxyus oozi host lt name gt lt valu gt host lt valu gt lt properti gt host lt valu gt host lt valu gt lt properti gt host case host oozi not instal instal chang host host oozi server instal instal oozi smoke succeed succeed,0,0,0,0,0,ambari-web/app/controllers/wizard/step8_controller.js;,0 
2891,Sumit Mohanty,ambari-server,0,hadoop-env.sh and core-site are missing on hosts that have only yarn components deployed, hadoop env sh hadoop env sh core site core site miss host yarn compon deploy,Yarn component need hadoop-env.sh and core-site.xml. These files should be deployed on hosts on which only yarn components are deployed., yarn compon need hadoop env sh hadoop env sh core site xml core site xml file deploy host yarn compon deploy deploy,0,0,0,0,0,0,0 
2903,Mahadev konar,null,0,Add HBase 96 metrics changes to jmx in a backwards compatible way., add HBase base metric chang jmx backward compat way way,Add HBase 96 metrics changes to jmx in a backwards compatible way., add HBase base metric chang jmx backward compat way way,0,0,0,0,0,0,0 
2905,Siddharth Wagle,ambari-server,0,SNAMENODE should not start after transition to Maintenance mode, SNAMENODE not start transit mainten mode,Currently  in HA NN cluster  starting HDFS service at services tab  tries to start SNAMENODE as well (through it is in Maintainance state because of executing curl -u admin:admin -i -X PUT -d '{'RequestInfo':{'context':'SNN maintenance'} 'Body':{'HostRoles':{'state':'MAINTENANCE'}}}' http://$SERVER:8080/api/v1/clusters/$CLUSTER/hosts/$SNN_HOST/host_components/SECONDARY_NAMENODE command ), current HA NN cluster start HDFS servic servic tab tri start SNAMENODE well maintain state execut curl admin admin admin admin PUT RequestInfo context SNN request info context SNN mainten mainten bodi HostRoles state MAINTENANCE bodi host role state MAINTENANCE command,0,0,0,0,0,0,0 
2927,Srimanth Gunturi,ambari-web,0,ResourceManager's RPC and NodeManager counts missing from time-series, ResourceManager resourc manag RPC NodeManager node manag count miss time seri time seri,ResourceManager's rpc.rpc.RpcQueueTimeAvgTime and yarn.ClusterMetrics.NumActiveNMs are not being provided accurately due to changes introduced in AMBARI-2910 to YARN configuration to collect more metrics.We need to narrow down the scope of metric collection to keep getting these previous metrics., ResourceManager resourc manag rpc rpc RpcQueueTimeAvgTime rpc rpc rpc queue time avg time yarn ClusterMetrics NumActiveNMs yarn cluster metric num activ Ms not provid accur due chang introduc AMBARI AMBARI YARN configur collect metric metric need narrow scope metric collect keep get previou metric metric,0,0,0,0,0,0,0 
2931,Andrii Tkach,ambari-web,0,Popover stuck after routing to another page, popov stuck rout anoth page,Steps to reporduce:1. Go to Installer-&gt;Welcome step2. Focus on cluster name textfield3. Hover on 'learn more' label4. Press Enter to route to the next pageResult:Popover remains visible on other pages, step reporduc reporduc Go instal gt welcom instal gt welcom step step focu cluster name textfield textfield hover learn label label press enter rout next pageResult popov page result popov remain visibl page,0,0,0,0,0,0,0 
2938,Sumit Mohanty,ambari-server,0,Update stack definition for MAPREDUCE2, updat stack definit MAPREDUCE MAPREDUCE,Update stack definition for MAPREDUCE2 and the default site xml files., updat stack definit MAPREDUCE MAPREDUCE default site xml file file,0,0,0,0,0,0,0 
2939,Sumit Mohanty,ambari-server,0,Update 1.3.2 stack definition for repo url, updat stack definit repo url,Update 1.3.2 stack definition for repo url, updat stack definit repo url,0,0,0,0,0,0,0 
2943,Mahadev konar,null,0,Oozie smoke tests fail on Ambari with NPE in Oozie Server., oozi smoke test fail ambari NPE oozi server server,Oozie smoke tests fail on Ambari with NPE in Oozie Server., oozi smoke test fail ambari NPE oozi server server,0,0,0,0,0,0,0 
2947,Mahadev konar,null,0,Use a specific build number for the stck builds., use specif build number stck build build,Use a specific build number for the stck builds., use specif build number stck build build,0,0,0,0,0,0,0 
2948,Siddharth Wagle,ambari-agent,0,Mapreduce pid directory cutomization fails, mapreduc pid directori cutom fail,Changing mapreduce log directory prefix results in Live status showing history server not started., chang mapreduc log directori prefix result live statu show histori server not start start,0,0,0,0,0,0,0 
2973,Vladimir Tkhir,ambari-agent; ambari-server,0,Ambari server and agent are not stopped during package uninstall, ambari server agent not stop packag uninstal,When ambari-agent and ambari-server packages are uninstalled  uninstall scriplets don't stop running services. That's why processes remain running even after package removal. That may cause issues during upgrade (if administrator misses the 'stop services' step)[root@host01 ~]$ ambari-server statusUsing python /usr/bin/python2.6Ambari-server statusAmbari Server runningFound Ambari Server PID: '7850 at: /var/run/ambari-server/ambari-server.pid[root@host01]# ambari-agent statusFound ambari-agent PID: 3521ambari-agent running.Agent PID at: /var/run/ambari-agent/ambari-agent.pidAgent out at: /var/log/ambari-agent/ambari-agent.outAgent log at: /var/log/ambari-agent/ambari-agent.log[root@host01]# rpm -e ambari-server[root@host01]# rpm -e ambari-agent[root@host01]# ps aux | grep ambari | grep -v grep | grep -v postgresroot 7850 2.1 13.2 3031480 254212 ? Sl 20:51 0:36 /usr/jdk64/jdk1.6.0_31/bin/java -server -XX:NewRatio=3 -XX:+UseConcMarkSweepGC -XX:-UseGCOverheadLimit -XX:CMSInitiatingOccupancyFraction=60 -Xms512m -Xmx2048m -cp /etc/ambari-server/conf:/usr/lib/ambari-server/*:/sbin:/bin:/usr/sbin:/usr/bin:/usr/lib/ambari-server/* org.apache.ambari.server.controller.AmbariServerroot 3521 0.7 1.1 499760 22544 ? Sl 20:53 0:12 /usr/bin/python2.6 /usr/lib/python2.6/site-packages/ambari_agent/main.py start restart --expected-hostname=host01, ambari agent ambari agent ambari server ambari server packag uninstal uninstal scriplet stop run servic servic process remain run even packag remov remov may caus issu upgrad administr miss stop servic servic step root host step root host ambari server ambari server statusUsing statu use python usr bin python ambari server usr bin python ambari server statusAmbari statu ambari server runningFound run found ambari server PID PID var run ambari server ambari server pid root host var run ambari server ambari server pid root host ambari agent ambari agent statusFound statu found ambari agent ambari agent PID PID ambari agent ambari agent run agent run agent PID var run ambari agent ambari agent pidAgent var run ambari agent ambari agent pid agent var log ambari agent ambari agent outAgent var log ambari agent ambari agent agent log var log ambari agent ambari agent log root host var log ambari agent ambari agent log root host rpm ambari server root host ambari server root host rpm ambari agent root host ambari agent root host ps aux grep ambari grep grep grep postgresroot Sl usr jdk jdk  bin java usr jdk jdk  bin java server XX NewRatio XX new ratio XX UseConcMarkSweepGC XX use conc mark sweep GC XX UseGCOverheadLimit XX use GC overhead limit XX CMSInitiatingOccupancyFraction XX CMS initi occup fraction xm xm xmx xmx cp etc ambari server conf usr lib ambari server sbin bin usr sbin usr bin usr lib ambari server etc ambari server conf usr lib ambari server sbin bin usr sbin usr bin usr lib ambari server org apach ambari server control AmbariServerroot org apach ambari server control ambari serverroot Sl usr bin python usr bin python usr lib python site packag ambari_agent main py usr lib python site packag ambari_agent main py start restart expect hostnam host expect hostnam host,0,0,0,0,0,0,0 
2986,Mahadev konar,null,0,Should turn on predicate pushdown by default., turn predic pushdown default default,Should turn on predicate pushdown by default., turn predic pushdown default default,0,0,0,0,0,0,0 
3019,Siddharth Wagle,ambari-server,0,Ambari should always point to latest repo, ambari alway point latest repo,Ambari should always point to latest repo., ambari alway point latest repo repo,0,0,0,0,0,0,0 
3021,Jaimin D Jetly,ambari-web,0,Customize Services page->Misc tab: Popup with related properties does not opened after 'Group User' value changing, custom servic page misc page misc tab tab popup relat properti not open group group user user valu chang,,,0,0,0,0,0,ambari-server/src/main/resources/stacks/HDP/2.0.5/services/YARN/configuration/yarn-site.xml;ambari-server/src/main/resources/stacks/HDPLocal/2.0.5/services/YARN/configuration/yarn-site.xml;,0 
3024,Mahadev konar,null,0,Oozie oozie-site.xml misssing two xsd values causing shell and sla workflows to fail, oozi oozi site xml oozi site xml misss two xsd valu caus shell sla workflow fail,Following two values need to be added to oozie-site.xml in order to get sla and shell workflows to run successfully.shell-action-0.2.xsdoozie-sla-0.1.xsd oozie-sla-0.2.xsdFollowing is the property name&lt;property&gt;&lt;name&gt;oozie.service.SchemaService.wf.ext.schemas&lt;/name&gt;&lt;value&gt;shell-action-0.1.xsd email-action-0.1.xsd hive-action-0.2.xsd sqoop-action-0.2.xsd ssh-action-0.1.xsd distcp-action-0.1.xsd&lt;/value&gt;&lt;/property&gt;, follow two valu need ad oozi site xml oozi site xml order get sla shell workflow run success shell action xsdoozi sla xsd success shell action xsdoozi sla xsd oozi sla xsdFollowing oozi sla xsd follow properti name lt properti gt lt name gt oozi servic SchemaService wf ext schema lt name gt lt valu gt shell action xsd name lt properti gt lt name gt oozi servic schema servic wf ext schema lt name gt lt valu gt shell action xsd email action xsd email action xsd hive action xsd hive action xsd sqoop action xsd sqoop action xsd ssh action xsd ssh action xsd distcp action xsd lt valu gt lt properti gt distcp action xsd lt valu gt lt properti gt,0,0,0,0,0,0,0 
3026,Siddharth Wagle,ambari-server,0,Ambari server setup with silent option prints error statement for the first time, ambari server setup silent option print error statement first time,command: ambari-server setup -sCompleting setup...Configuring database...Enter advanced database configuration [y/n] &#40;n&#41;? ERROR: Connection properties not set in config file.Default properties detected. Using built-in database.Checking PostgreSQL...Running initdb: This may take upto a minute.About to start PostgreSQLConfiguring local database...Configuring PostgreSQL...Restarting PostgreSQLAmbari Server 'setup' completed successfully.Running ambari-server setup command again doesn't reproduce the error statement., command command ambari server ambari server setup sCompleting complet setup configur setup configur databas enter databas enter advanc databas configur ERROR ERROR connect properti not set config file default file default properti detect detect use built built databas check databas check PostgreSQL run postgr SQL run initdb initdb may take upto minut minut start PostgreSQLConfiguring postgr SQL configur local databas configur databas configur PostgreSQL restart postgr SQL restart PostgreSQLAmbari postgr SQL ambari server setup setup complet success run success run ambari server ambari server setup command reproduc error statement statement,0,0,0,0,0,0,1 
3047,Sumit Mohanty,ambari-server,0,Enhance host clean up to handle tmp files and folders, enhanc host clean handl tmp file folder,Host cleanup should: remove files and folders in tmp folder based on what users are being cleaned remove default hadoop group, host cleanup remov file folder tmp folder base user clean remov default hadoop group,0,0,0,0,0,0,1 
3056,Andrii Tkach,ambari-web,0,Advanced config orders should be consistent in Install Wizard > Customize Services and Monitoring > Services > Config, advanc config order consist instal wizard custom servic monitor servic config,Compare the config parameter ordering in Install Wizard &gt; Customize Services service configs and Monitoring &gt; Services &gt; Config; they are different.We should use the same parameter ordering that we use in Install Wizard &gt; Customize Services for Monitoring &gt; Services &gt; Config., compar config paramet order instal wizard gt gt custom servic servic config monitor gt gt servic gt gt config config differ differ use paramet order use instal wizard gt gt custom servic monitor gt gt servic gt gt config config,0,0,0,0,0,ambari-web/app/controllers/main/service/info/configs.js;ambari-web/app/data/HDP2/global_properties.js;ambari-web/app/utils/config.js;,1 
3061,Dmytro Sen,ambari-agent,0,Do not use regex to determine folder name by full path for dfs_domain_socket_path, not use regex determin folder name full path dfs_domain_socket_path,The point is to use custom puppet function instead of regex for line$dfs_domain_socket_path_dir = regsubst($hdp-hadoop::params::dfs_domain_socket_path  '/[^//]+$'  '').It could be implemented with ruby:File.split('/path/to/file') # =&gt; ['/path/to'  'file'], point use custom puppet function instead regex line dfs_domain_socket_path_dir line dfs_domain_socket_path_dir regsubst hdp hadoop param dfs_domain_socket_path regsubst hdp hadoop param dfs_domain_socket_path could implement rubi file split path file rubi file split path file gt gt path path file file,0,0,0,0,0,0,1 
3068,Artem Baranchuk,ambari-agent,0,Warning messages not cleared when task fails, warn messag not clear task fail,Installed a cluster  namenode start fails  install exits with warnings.If i go an look at the specific task that fails  the puppet warnings are still present. Seems like those puppet warnings didn't get cleared.In a task failure case  having the warnings clear is when it's most important., instal cluster namenod start fail instal exit warn warn go look specif task fail puppet warn still present present seem like puppet warn get clear clear task failur case warn clear import import,0,0,0,0,0,0,1 
3069,Oleg Nechiporenko,ambari-web,0,Fix Unit tests, fix unit test,,,0,0,0,0,0,0,1 
3074,Siddharth Wagle,ambari-agent,0,Ambari wont start NodeManager because one of multiple folders not created, ambari wont start NodeManager node manag one multipl folder not creat,yarn-site having:'yarn.nodemanager.local-dirs' : '/grid/0/hadoop/yarn /grid/1/hadoop/yarn /grid/2/hadoop/yarn /grid/3/hadoop/yarn /grid/4/hadoop/yarn /grid/5/hadoop/yarn' 'yarn.nodemanager.log-dirs' : '/grid/0/hadoop/yarn /grid/1/hadoop/yarn /grid/2/hadoop/yarn /grid/3/hadoop/yarn /grid/4/hadoop/yarn /grid/5/hadoop/yarn' Now /grid/3 was mounted as read-only due to some disk errors. Though other folders got successfully created  Ambari will not start the NodeManager process.notice: /Stage[1]/Hdp::Snappy::Package/Hdp::Snappy::Package::Ln[32]/Hdp::Exec[hdp::snappy::package::ln 32]/Exec[hdp::snappy::package::ln 32]/returns: executed successfullynotice: /Stage[2]/Hdp-yarn::Nodemanager/Hdp-yarn::Nodemanager::Create_nm_dirs[/grid/3/hadoop/yarn]/Hdp::Directory_recursive_create[/grid/3/hadoop/yarn]/Hdp::Exec[mkdir -p /grid/3/hadoop/yarn]/Exec[mkdir -p /grid/3/hadoop/yarn]/returns: mkdir: cannot create directory '/grid/3/hadoop': Read-only file systemerr: /Stage[2]/Hdp-yarn::Nodemanager/Hdp-yarn::Nodemanager::Create_nm_dirs[/grid/3/hadoop/yarn]/Hdp::Directory_recursive_create[/grid/3/hadoop/yarn]/Hdp::Exec[mkdir -p /grid/3/hadoop/yarn]/Exec[mkdir -p /grid/3/hadoop/yarn]/returns: change from notrun to 0 failed: mkdir -p /grid/3/hadoop/yarn returned 1 instead of one of [0] at /var/lib/ambari-agent/puppet/modules/hdp/manifests/init.pp:479notice: /Stage[2]/Hdp-yarn::Nodemanager/Hdp-yarn::Nodemanager::Create_nm_dirs[/grid/3/hadoop/yarn]/Hdp::Directory_recursive_create[/grid/3/hadoop/yarn]/Hdp::Exec[mkdir -p /grid/3/hadoop/yarn]/Anchor[hdp::exec::mkdir -p /grid/3/hadoop/yarn::end]: Dependency Exec[mkdir -p /grid/3/hadoop/yarn] has failures: truewarning: /Stage[2]/Hdp-yarn::Nodemanager/Hdp-yarn::Nodemanager::Create_nm_dirs[/grid/3/hadoop/yarn]/Hdp::Directory_recursive_create[/grid/3/hadoop/yarn]/Hdp::Exec[mkdir -p /grid/3/hadoop/yarn]/Anchor[hdp::exec::mkdir -p /grid/3/hadoop/yarn::end]: Skipping because of failed dependenciesnotice: /Stage[2]/Hdp-yarn::Nodemanager/Hdp-yarn::Nodemanager::Create_nm_dirs[/grid/3/hadoop/yarn]/Hdp::Directory_recursive_create[/grid/3/hadoop/yarn]/Hdp::Directory[/grid/3/hadoop/yarn]/File[/grid/3/hadoop/yarn]: Dependency Exec[mkdir -p /grid/3/hadoop/yarn] has failures: truewarning: /Stage[2]/Hdp-yarn::Nodemanager/Hdp-yarn::Nodemanager::Create_nm_dirs[/grid/3/hadoop/yarn]/Hdp::Directory_recursive_create[/grid/3/hadoop/yarn]/Hdp::Directory[/grid/3/hadoop/yarn]/File[/grid/3/hadoop/yarn]: Skipping because of failed dependenciesnotice: /Stage[2]/Hdp-yarn::Initialize/Hdp-yarn::Generate_common_configs[yarn-common-configs]/Configgenerator::Configfile[capacity-scheduler]/File[/etc/hadoop/conf/capacity-scheduler.xml]/content: content changed '{md5}e5d17c21c7a5e1db9f3af35cba71df0a' to '{md5}2ca1d267a46f1aecac726caabaa16774'notice: /Stage[2]/Hdp-yarn::Initialize/Hdp-yarn::Generate_common_configs[yarn-common-configs]/Configgenerator::Configfile[capacity-scheduler]/File[/etc/hadoop/conf/capacity-scheduler.xml]/owner: owner changed 'hdfs' to 'yarn'notice: /Stage[2]/Hdp-yarn::Initialize/Hdp-yarn::Generate_common_configs[yarn-common-configs]/Configgenerator::Configfile[core-site]/File[/etc/hadoop/conf/core-site.xml]/content: content changed '{md5}86d742a780d59a957ea0a283dec03784' to '{md5}8506e4402ba8140ea4f9fed97b6f94e2'notice: /Stage[2]/Hdp-yarn::Initialize/Hdp-yarn::Generate_common_configs[yarn-common-configs]/Configgenerator::Configfile[yarn-site]/File[/etc/hadoop/conf/yarn-site.xml]/content: content changed '{md5}d84a967ce47a6b77734ed8f53d817c6e' to '{md5}42940cca6e8f64ae5de50524fb131274'notice: /Stage[2]/Hdp-yarn::Nodemanager/Hdp-yarn::Service[nodemanager]/Anchor[hdp-yarn::service::nodemanager::begin]: Dependency Exec[mkdir -p /grid/3/hadoop/yarn] has failures: truewarning: /Stage[2]/Hdp-yarn::Nodemanager/Hdp-yarn::Service[nodemanager]/Anchor[hdp-yarn::service::nodemanager::begin]: Skipping because of failed dependenciesnotice: /Stage[2]/Hdp-yarn::Nodemanager/Hdp-yarn::Service[nodemanager]/Hdp::Directory_recursive_create[/var/log/hadoop-yarn]/Hdp::Exec[mkdir -p /var/log/hadoop-yarn]/Anchor[hdp::exec::mkdir -p /var/log/hadoop-yarn::begin]: Dependency Exec[mkdir -p /grid/3/hadoop/yarn] has failures: truewarning: /Stage[2]/Hdp-yarn::Nodemanager/Hdp-yarn::Service[nodemanager]/Hdp::Directory_recursive_create[/var/log/hadoop-yarn]/Hdp::Exec[mkdir -p /var/log/hadoop-yarn]/Anchor[hdp::exec::mkdir -p /var/log/hadoop-yarn::begin]: Skipping because of failed dependenciesnotice: /Stage[2]/Hdp-yarn::Nodemanager/Hdp-yarn::Service[nodemanager]/Hdp::Directory_recursive_create[/var/log/hadoop-yarn]/Hdp::Exec[mkdir -p /var/log/hadoop-yarn]/Exec[mkdir -p /var/log/hadoop-yarn]: Dependency Exec[mkdir -p /grid/3/hadoop/yarn] has failures: truewarning: /Stage[2]/Hdp-yarn::Nodemanager/Hdp-yarn::Service[nodemanager]/Hdp::Directory_recursive_create[/var/log/hadoop-yarn]/Hdp::Exec[mkdir -p /var/log/hadoop-yarn]/Exec[mkdir -p /var/log/hadoop-yarn]: Skipping because of failed dependenciesnotice: /Stage[2]/Hdp-yarn::Nodemanager/Hdp-yarn::Service[nodemanager]/Hdp::Directory_recursive_create[/var/log/hadoop-yarn]/Hdp::Exec[mkdir -p /var/log/hadoop-yarn]/Anchor[hdp::exec::mkdir -p /var/log/hadoop-yarn::end]: Dependency Exec[mkdir -p /grid/3/hadoop/yarn] has failures: truewarning: /Stage[2]/Hdp-yarn::Nodemanager/Hdp-yarn::Service[nodemanager]/Hdp::Directory_recursive_create[/var/log/hadoop-yarn]/Hdp::Exec[mkdir -p /var/log/hadoop-yarn]/Anchor[hdp::exec::mkdir -p /var/log/hadoop-yarn::end]: Skipping because of failed dependenciesnotice: /Stage[2]/Hdp-yarn::Nodemanager/Hdp-yarn::Service[nodemanager]/Hdp::Directory_recursive_create[/var/log/hadoop-yarn]/Hdp::Directory[/var/log/hadoop-yarn]/File[/var/log/hadoop-yarn]: Dependency Exec[mkdir -p /grid/3/hadoop/yarn] has failures: truewarning: /Stage[2]/Hdp-yarn::Nodemanager/Hdp-yarn::Service[nodemanager]/Hdp::Directory_recursive_create[/var/log/hadoop-yarn]/Hdp::Directory[/var/log/hadoop-yarn]/File[/var/log/hadoop-yarn]: Skipping because of failed dependenciesnotice: /Stage[2]/Hdp-yarn::Nodemanager/Hdp-yarn::Service[nodemanager]/Hdp::Directory_recursive_create[/var/run/hadoop-yarn/yarn]/Hdp::Exec[mkdir -p /var/run/hadoop-yarn/yarn]/Anchor[hdp::exec::mkdir -p /var/run/hadoop-yarn/yarn::begin]: Dependency Exec[mkdir -p /grid/3/hadoop/yarn] has failures: truewarning: /Stage[2]/Hdp-yarn::Nodemanager/Hdp-yarn::Service[nodemanager]/Hdp::Directory_recursive_create[/var/run/hadoop-yarn/yarn]/Hdp::Exec[mkdir -p /var/run/hadoop-yarn/yarn]/Anchor[hdp::exec::mkdir -p /var/run/hadoop-yarn/yarn::begin]: Skipping because of failed dependenciesnotice: /Stage[2]/Hdp-yarn::Nodemanager/Hdp-yarn::Service[nodemanager]/Hdp::Directory_recursive_create[/var/run/hadoop-yarn/yarn]/Hdp::Exec[mkdir -p /var/run/hadoop-yarn/yarn]/Exec[mkdir -p /var/run/hadoop-yarn/yarn]: Dependency Exec[mkdir -p /grid/3/hadoop/yarn] has failures: truewarning: /Stage[2]/Hdp-yarn::Nodemanager/Hdp-yarn::Service[nodemanager]/Hdp::Directory_recursive_create[/var/run/hadoop-yarn/yarn]/Hdp::Exec[mkdir -p /var/run/hadoop-yarn/yarn]/Exec[mkdir -p /var/run/hadoop-yarn/yarn]: Skipping because of failed dependenciesnotice: /Stage[2]/Hdp-yarn::Nodemanager/Hdp-yarn::Service[nodemanager]/Hdp::Directory_recursive_create[/var/run/hadoop-yarn/yarn]/Hdp::Exec[mkdir -p /var/run/hadoop-yarn/yarn]/Anchor[hdp::exec::mkdir -p /var/run/hadoop-yarn/yarn::end]: Dependency Exec[mkdir -p /grid/3/hadoop/yarn] has failures: truewarning: /Stage[2]/Hdp-yarn::Nodemanager/Hdp-yarn::Service[nodemanager]/Hdp::Directory_recursive_create[/var/run/hadoop-yarn/yarn]/Hdp::Exec[mkdir -p /var/run/hadoop-yarn/yarn]/Anchor[hdp::exec::mkdir -p /var/run/hadoop-yarn/yarn::end]: Skipping because of failed dependenciesnotice: /Stage[2]/Hdp-yarn::Nodemanager/Hdp-yarn::Service[nodemanager]/Hdp::Directory_recursive_create[/var/run/hadoop-yarn/yarn]/Hdp::Directory[/var/run/hadoop-yarn/yarn]/File[/var/run/hadoop-yarn/yarn]: Dependency Exec[mkdir -p /grid/3/hadoop/yarn] has failures: truewarning: /Stage[2]/Hdp-yarn::Nodemanager/Hdp-yarn::Service[nodemanager]/Hdp::Directory_recursive_create[/var/run/hadoop-yarn/yarn]/Hdp::Directory[/var/run/hadoop-yarn/yarn]/File[/var/run/hadoop-yarn/yarn]: Skipping because of failed dependenciesnotice: /Stage[2]/Hdp-yarn::Nodemanager/Hdp-yarn::Service[nodemanager]/Hdp::Exec[su - yarn -c 'export HADOOP_LIBEXEC_DIR=/usr/lib/hadoop/libexec &amp;&amp; /usr/lib/hadoop-yarn/sbin/yarn-daemon.sh --config /etc/hadoop/conf start nodemanager']/Anchor[hdp::exec::su - yarn -c 'export HADOOP_LIBEXEC_DIR=/usr/lib/hadoop/libexec &amp;&amp; /usr/lib/hadoop-yarn/sbin/yarn-daemon.sh --config /etc/hadoop/conf start nodemanager'::begin]: Dependency Exec[mkdir -p /grid/3/hadoop/yarn] has failures: truewarning: /Stage[2]/Hdp-yarn::Nodemanager/Hdp-yarn::Service[nodemanager]/Hdp::Exec[su - yarn -c 'export HADOOP_LIBEXEC_DIR=/usr/lib/hadoop/libexec &amp;&amp; /usr/lib/hadoop-yarn/sbin/yarn-daemon.sh --config /etc/hadoop/conf start nodemanager']/Anchor[hdp::exec::su - yarn -c 'export HADOOP_LIBEXEC_DIR=/usr/lib/hadoop/libexec &amp;&amp; /usr/lib/hadoop-yarn/sbin/yarn-daemon.sh --config /etc/hadoop/conf start nodemanager'::begin]: Skipping because of failed dependenciesnotice: /Stage[2]/Hdp-yarn::Nodemanager/Hdp-yarn::Service[nodemanager]/Hdp::Exec[su - yarn -c 'export HADOOP_LIBEXEC_DIR=/usr/lib/hadoop/libexec &amp;&amp; /usr/lib/hadoop-yarn/sbin/yarn-daemon.sh --config /etc/hadoop/conf start nodemanager']/Exec[su - yarn -c 'export HADOOP_LIBEXEC_DIR=/usr/lib/hadoop/libexec &amp;&amp; /usr/lib/hadoop-yarn/sbin/yarn-daemon.sh --config /etc/hadoop/conf start nodemanager']: Dependency Exec[mkdir -p /grid/3/hadoop/yarn] has failures: truewarning: /Stage[2]/Hdp-yarn::Nodemanager/Hdp-yarn::Service[nodemanager]/Hdp::Exec[su - yarn -c 'export HADOOP_LIBEXEC_DIR=/usr/lib/hadoop/libexec &amp;&amp; /usr/lib/hadoop-yarn/sbin/yarn-daemon.sh --config /etc/hadoop/conf start nodemanager']/Exec[su - yarn -c 'export HADOOP_LIBEXEC_DIR=/usr/lib/hadoop/libexec &amp;&amp; /usr/lib/hadoop-yarn/sbin/yarn-daemon.sh --config /etc/hadoop/conf start nodemanager']: Skipping because of failed dependenciesnotice: /Stage[2]/Hdp-yarn::Nodemanager/Hdp-yarn::Service[nodemanager]/Hdp::Exec[su - yarn -c 'export HADOOP_LIBEXEC_DIR=/usr/lib/hadoop/libexec &amp;&amp; /usr/lib/hadoop-yarn/sbin/yarn-daemon.sh --config /etc/hadoop/conf start nodemanager']/Anchor[hdp::exec::su - yarn -c 'export HADOOP_LIBEXEC_DIR=/usr/lib/hadoop/libexec &amp;&amp; /usr/lib/hadoop-yarn/sbin/yarn-daemon.sh --config /etc/hadoop/conf start nodemanager'::end]: Dependency Exec[mkdir -p /grid/3/hadoop/yarn] has failures: truewarning: /Stage[2]/Hdp-yarn::Nodemanager/Hdp-yarn::Service[nodemanager]/Hdp::Exec[su - yarn -c 'export HADOOP_LIBEXEC_DIR=/usr/lib/hadoop/libexec &amp;&amp; /usr/lib/hadoop-yarn/sbin/yarn-daemon.sh --config /etc/hadoop/conf start nodemanager']/Anchor[hdp::exec::su - yarn -c 'export HADOOP_LIBEXEC_DIR=/usr/lib/hadoop/libexec &amp;&amp; /usr/lib/hadoop-yarn/sbin/yarn-daemon.sh --config /etc/hadoop/conf start nodemanager'::end]: Skipping because of failed dependenciesnotice: /Stage[2]/Hdp-yarn::Nodemanager/Hdp-yarn::Service[nodemanager]/Hdp::Exec[sleep 5; ls /var/run/hadoop-yarn/yarn/yarn-yarn-nodemanager.pid &gt;/dev/null 2&gt;&amp;1 &amp;&amp; ps 'cat /var/run/hadoop-yarn/yarn/yarn-yarn-nodemanager.pid' &gt;/dev/null 2&gt;&amp;1]/Anchor[hdp::exec::sleep 5; ls /var/run/hadoop-yarn/yarn/yarn-yarn-nodemanager.pid &gt;/dev/null 2&gt;&amp;1 &amp;&amp; ps 'cat /var/run/hadoop-yarn/yarn/yarn-yarn-nodemanager.pid' &gt;/dev/null 2&gt;&amp;1::begin]: Dependency Exec[mkdir -p /grid/3/hadoop/yarn] has failures: truewarning: /Stage[2]/Hdp-yarn::Nodemanager/Hdp-yarn::Service[nodemanager]/Hdp::Exec[sleep 5; ls /var/run/hadoop-yarn/yarn/yarn-yarn-nodemanager.pid &gt;/dev/null 2&gt;&amp;1 &amp;&amp; ps 'cat /var/run/hadoop-yarn/yarn/yarn-yarn-nodemanager.pid' &gt;/dev/null 2&gt;&amp;1]/Anchor[hdp::exec::sleep 5; ls /var/run/hadoop-yarn/yarn/yarn-yarn-nodemanager.pid &gt;/dev/null 2&gt;&amp;1 &amp;&amp; ps 'cat /var/run/hadoop-yarn/yarn/yarn-yarn-nodemanager.pid' &gt;/dev/null 2&gt;&amp;1::begin]: Skipping because of failed dependenciesnotice: /Stage[2]/Hdp-yarn::Nodemanager/Hdp-yarn::Service[nodemanager]/Hdp::Exec[sleep 5; ls /var/run/hadoop-yarn/yarn/yarn-yarn-nodemanager.pid &gt;/dev/null 2&gt;&amp;1 &amp;&amp; ps 'cat /var/run/hadoop-yarn/yarn/yarn-yarn-nodemanager.pid' &gt;/dev/null 2&gt;&amp;1]/Exec[sleep 5; ls /var/run/hadoop-yarn/yarn/yarn-yarn-nodemanager.pid &gt;/dev/null 2&gt;&amp;1 &amp;&amp; ps 'cat /var/run/hadoop-yarn/yarn/yarn-yarn-nodemanager.pid' &gt;/dev/null 2&gt;&amp;1]: Dependency Exec[mkdir -p /grid/3/hadoop/yarn] has failures: truewarning: /Stage[2]/Hdp-yarn::Nodemanager/Hdp-yarn::Service[nodemanager]/Hdp::Exec[sleep 5; ls /var/run/hadoop-yarn/yarn/yarn-yarn-nodemanager.pid &gt;/dev/null 2&gt;&amp;1 &amp;&amp; ps 'cat /var/run/hadoop-yarn/yarn/yarn-yarn-nodemanager.pid' &gt;/dev/null 2&gt;&amp;1]/Exec[sleep 5; ls /var/run/hadoop-yarn/yarn/yarn-yarn-nodemanager.pid &gt;/dev/null 2&gt;&amp;1 &amp;&amp; ps 'cat /var/run/hadoop-yarn/yarn/yarn-yarn-nodemanager.pid' &gt;/dev/null 2&gt;&amp;1]: Skipping because of failed dependenciesnotice: /Stage[2]/Hdp-yarn::Nodemanager/Hdp-yarn::Service[nodemanager]/Hdp::Exec[sleep 5; ls /var/run/hadoop-yarn/yarn/yarn-yarn-nodemanager.pid &gt;/dev/null 2&gt;&amp;1 &amp;&amp; ps 'cat /var/run/hadoop-yarn/yarn/yarn-yarn-nodemanager.pid' &gt;/dev/null 2&gt;&amp;1]/Anchor[hdp::exec::sleep 5; ls /var/run/hadoop-yarn/yarn/yarn-yarn-nodemanager.pid &gt;/dev/null 2&gt;&amp;1 &amp;&amp; ps 'cat /var/run/hadoop-yarn/yarn/yarn-yarn-nodemanager.pid' &gt;/dev/null 2&gt;&amp;1::end]: Dependency Exec[mkdir -p /grid/3/hadoop/yarn] has failures: truewarning: /Stage[2]/Hdp-yarn::Nodemanager/Hdp-yarn::Service[nodemanager]/Hdp::Exec[sleep 5; ls /var/run/hadoop-yarn/yarn/yarn-yarn-nodemanager.pid &gt;/dev/null 2&gt;&amp;1 &amp;&amp; ps 'cat /var/run/hadoop-yarn/yarn/yarn-yarn-nodemanager.pid' &gt;/dev/null 2&gt;&amp;1]/Anchor[hdp::exec::sleep 5; ls /var/run/hadoop-yarn/yarn/yarn-yarn-nodemanager.pid &gt;/dev/null 2&gt;&amp;1 &amp;&amp; ps 'cat /var/run/hadoop-yarn/yarn/yarn-yarn-nodemanager.pid' &gt;/dev/null 2&gt;&amp;1::end]: Skipping because of failed dependenciesnotice: /Stage[2]/Hdp-yarn::Nodemanager/Hdp-yarn::Service[nodemanager]/Anchor[hdp-yarn::service::nodemanager::end]: Dependency Exec[mkdir -p /grid/3/hadoop/yarn] has failures: truewarning: /Stage[2]/Hdp-yarn::Nodemanager/Hdp-yarn::Service[nodemanager]/Anchor[hdp-yarn::service::nodemanager::end]: Skipping because of failed dependenciesnotice: /Stage[2]/Hdp-yarn::Nodemanager/Anchor[hdp-yarn::nodemanager::end]: Dependency Exec[mkdir -p /grid/3/hadoop/yarn] has failures: truewarning: /Stage[2]/Hdp-yarn::Nodemanager/Anchor[hdp-yarn::nodemanager::end]: Skipping because of failed dependenciesnotice: /Stage[2]/Hdp-yarn::Initialize/Hdp-yarn::Generate_common_configs[yarn-common-configs]/Configgenerator::Configfile[mapred-site]/File[/etc/hadoop/conf/mapred-site.xml]/content: content changed '{md5}093cb1899b3c3b9dc4a7c1c93729c18b' to '{md5}4c462999cc47e6f6ba0e6381d71d81ba'notice: /Stage[2]/Hdp-yarn::Initialize/Hdp-yarn::Generate_common_configs[yarn-common-configs]/Configgenerator::Configfile[mapred-site]/File[/etc/hadoop/conf/mapred-site.xml]/owner: owner changed 'mapred' to 'yarn'notice: Finished catalog run in 2.39 seconds, yarn site yarn site yarn nodemanag local dir yarn nodemanag local dir grid hadoop yarn grid hadoop yarn grid hadoop yarn grid hadoop yarn grid hadoop yarn grid hadoop yarn grid hadoop yarn grid hadoop yarn grid hadoop yarn grid hadoop yarn grid hadoop yarn grid hadoop yarn yarn nodemanag log dir yarn nodemanag log dir grid hadoop yarn grid hadoop yarn grid hadoop yarn grid hadoop yarn grid hadoop yarn grid hadoop yarn grid hadoop yarn grid hadoop yarn grid hadoop yarn grid hadoop yarn grid hadoop yarn grid hadoop yarn grid grid mount read read due disk error error though folder got success creat ambari not start NodeManager node manag process notic process notic stage hdp snappi packag hdp snappi packag Ln hdp exec hdp snappi packag ln stage hdp snappi packag hdp snappi packag Ln hdp exec hdp snappi packag ln exec hdp snappi packag ln exec hdp snappi packag ln return return execut successfullynotic successfullynotic stage hdp yarn nodemanag hdp yarn nodemanag Create_nm_dirs grid hadoop yarn hdp Directory_recursive_create grid hadoop yarn hdp exec mkdir stage hdp yarn nodemanag hdp yarn nodemanag Create_nm_dirs grid hadoop yarn hdp Directory_recursive_create grid hadoop yarn hdp exec mkdir grid hadoop yarn exec mkdir grid hadoop yarn exec mkdir grid hadoop yarn return grid hadoop yarn return mkdir mkdir cannot creat directori grid hadoop grid hadoop read read file systemerr systemerr stage hdp yarn nodemanag hdp yarn nodemanag Create_nm_dirs grid hadoop yarn hdp Directory_recursive_create grid hadoop yarn hdp exec mkdir stage hdp yarn nodemanag hdp yarn nodemanag Create_nm_dirs grid hadoop yarn hdp Directory_recursive_create grid hadoop yarn hdp exec mkdir grid hadoop yarn exec mkdir grid hadoop yarn exec mkdir grid hadoop yarn return grid hadoop yarn return chang notrun fail fail mkdir grid hadoop yarn grid hadoop yarn return instead one var lib ambari agent puppet modul hdp manifest init pp notic var lib ambari agent puppet modul hdp manifest init pp notic stage hdp yarn nodemanag hdp yarn nodemanag Create_nm_dirs grid hadoop yarn hdp Directory_recursive_create grid hadoop yarn hdp exec mkdir stage hdp yarn nodemanag hdp yarn nodemanag Create_nm_dirs grid hadoop yarn hdp Directory_recursive_create grid hadoop yarn hdp exec mkdir grid hadoop yarn anchor hdp exec mkdir grid hadoop yarn anchor hdp exec mkdir grid hadoop yarn end grid hadoop yarn end depend exec mkdir exec mkdir grid hadoop yarn grid hadoop yarn failur failur truewarn truewarn stage hdp yarn nodemanag hdp yarn nodemanag Create_nm_dirs grid hadoop yarn hdp Directory_recursive_create grid hadoop yarn hdp exec mkdir stage hdp yarn nodemanag hdp yarn nodemanag Create_nm_dirs grid hadoop yarn hdp Directory_recursive_create grid hadoop yarn hdp exec mkdir grid hadoop yarn anchor hdp exec mkdir grid hadoop yarn anchor hdp exec mkdir grid hadoop yarn end grid hadoop yarn end skip fail dependenciesnotic dependenciesnotic stage hdp yarn nodemanag hdp yarn nodemanag Create_nm_dirs grid hadoop yarn hdp Directory_recursive_create grid hadoop yarn hdp directori grid hadoop yarn file grid hadoop yarn stage hdp yarn nodemanag hdp yarn nodemanag Create_nm_dirs grid hadoop yarn hdp Directory_recursive_create grid hadoop yarn hdp directori grid hadoop yarn file grid hadoop yarn depend exec mkdir exec mkdir grid hadoop yarn grid hadoop yarn failur failur truewarn truewarn stage hdp yarn nodemanag hdp yarn nodemanag Create_nm_dirs grid hadoop yarn hdp Directory_recursive_create grid hadoop yarn hdp directori grid hadoop yarn file grid hadoop yarn stage hdp yarn nodemanag hdp yarn nodemanag Create_nm_dirs grid hadoop yarn hdp Directory_recursive_create grid hadoop yarn hdp directori grid hadoop yarn file grid hadoop yarn skip fail dependenciesnotic dependenciesnotic stage hdp yarn initi hdp yarn Generate_common_configs yarn common config configgener configfil capac schedul file etc hadoop conf capac schedul xml content stage hdp yarn initi hdp yarn Generate_common_configs yarn common config configgener configfil capac schedul file etc hadoop conf capac schedul xml content content chang md db af cba df md db af cba df md ca aecac caabaa notic md ca aecac caabaa notic stage hdp yarn initi hdp yarn Generate_common_configs yarn common config configgener configfil capac schedul file etc hadoop conf capac schedul xml owner stage hdp yarn initi hdp yarn Generate_common_configs yarn common config configgener configfil capac schedul file etc hadoop conf capac schedul xml owner owner chang hdf hdf yarn notic yarn notic stage hdp yarn initi hdp yarn Generate_common_configs yarn common config configgener configfil core site file etc hadoop conf core site xml content stage hdp yarn initi hdp yarn Generate_common_configs yarn common config configgener configfil core site file etc hadoop conf core site xml content content chang md ea dec md ea dec md ba ea fed notic md ba ea fed notic stage hdp yarn initi hdp yarn Generate_common_configs yarn common config configgener configfil yarn site file etc hadoop conf yarn site xml content stage hdp yarn initi hdp yarn Generate_common_configs yarn common config configgener configfil yarn site file etc hadoop conf yarn site xml content content chang md ce ed md ce ed md cca ae de fb notic md cca ae de fb notic stage hdp yarn nodemanag hdp yarn servic nodemanag anchor hdp yarn servic nodemanag begin stage hdp yarn nodemanag hdp yarn servic nodemanag anchor hdp yarn servic nodemanag begin depend exec mkdir exec mkdir grid hadoop yarn grid hadoop yarn failur failur truewarn truewarn stage hdp yarn nodemanag hdp yarn servic nodemanag anchor hdp yarn servic nodemanag begin stage hdp yarn nodemanag hdp yarn servic nodemanag anchor hdp yarn servic nodemanag begin skip fail dependenciesnotic dependenciesnotic stage hdp yarn nodemanag hdp yarn servic nodemanag hdp Directory_recursive_create var log hadoop yarn hdp exec mkdir stage hdp yarn nodemanag hdp yarn servic nodemanag hdp Directory_recursive_create var log hadoop yarn hdp exec mkdir var log hadoop yarn anchor hdp exec mkdir var log hadoop yarn anchor hdp exec mkdir var log hadoop yarn begin var log hadoop yarn begin depend exec mkdir exec mkdir grid hadoop yarn grid hadoop yarn failur failur truewarn truewarn stage hdp yarn nodemanag hdp yarn servic nodemanag hdp Directory_recursive_create var log hadoop yarn hdp exec mkdir stage hdp yarn nodemanag hdp yarn servic nodemanag hdp Directory_recursive_create var log hadoop yarn hdp exec mkdir var log hadoop yarn anchor hdp exec mkdir var log hadoop yarn anchor hdp exec mkdir var log hadoop yarn begin var log hadoop yarn begin skip fail dependenciesnotic dependenciesnotic stage hdp yarn nodemanag hdp yarn servic nodemanag hdp Directory_recursive_create var log hadoop yarn hdp exec mkdir stage hdp yarn nodemanag hdp yarn servic nodemanag hdp Directory_recursive_create var log hadoop yarn hdp exec mkdir var log hadoop yarn exec mkdir var log hadoop yarn exec mkdir var log hadoop yarn var log hadoop yarn depend exec mkdir exec mkdir grid hadoop yarn grid hadoop yarn failur failur truewarn truewarn stage hdp yarn nodemanag hdp yarn servic nodemanag hdp Directory_recursive_create var log hadoop yarn hdp exec mkdir stage hdp yarn nodemanag hdp yarn servic nodemanag hdp Directory_recursive_create var log hadoop yarn hdp exec mkdir var log hadoop yarn exec mkdir var log hadoop yarn exec mkdir var log hadoop yarn var log hadoop yarn skip fail dependenciesnotic dependenciesnotic stage hdp yarn nodemanag hdp yarn servic nodemanag hdp Directory_recursive_create var log hadoop yarn hdp exec mkdir stage hdp yarn nodemanag hdp yarn servic nodemanag hdp Directory_recursive_create var log hadoop yarn hdp exec mkdir var log hadoop yarn anchor hdp exec mkdir var log hadoop yarn anchor hdp exec mkdir var log hadoop yarn end var log hadoop yarn end depend exec mkdir exec mkdir grid hadoop yarn grid hadoop yarn failur failur truewarn truewarn stage hdp yarn nodemanag hdp yarn servic nodemanag hdp Directory_recursive_create var log hadoop yarn hdp exec mkdir stage hdp yarn nodemanag hdp yarn servic nodemanag hdp Directory_recursive_create var log hadoop yarn hdp exec mkdir var log hadoop yarn anchor hdp exec mkdir var log hadoop yarn anchor hdp exec mkdir var log hadoop yarn end var log hadoop yarn end skip fail dependenciesnotic dependenciesnotic stage hdp yarn nodemanag hdp yarn servic nodemanag hdp Directory_recursive_create var log hadoop yarn hdp directori var log hadoop yarn file var log hadoop yarn stage hdp yarn nodemanag hdp yarn servic nodemanag hdp Directory_recursive_create var log hadoop yarn hdp directori var log hadoop yarn file var log hadoop yarn depend exec mkdir exec mkdir grid hadoop yarn grid hadoop yarn failur failur truewarn truewarn stage hdp yarn nodemanag hdp yarn servic nodemanag hdp Directory_recursive_create var log hadoop yarn hdp directori var log hadoop yarn file var log hadoop yarn stage hdp yarn nodemanag hdp yarn servic nodemanag hdp Directory_recursive_create var log hadoop yarn hdp directori var log hadoop yarn file var log hadoop yarn skip fail dependenciesnotic dependenciesnotic stage hdp yarn nodemanag hdp yarn servic nodemanag hdp Directory_recursive_create var run hadoop yarn yarn hdp exec mkdir stage hdp yarn nodemanag hdp yarn servic nodemanag hdp Directory_recursive_create var run hadoop yarn yarn hdp exec mkdir var run hadoop yarn yarn anchor hdp exec mkdir var run hadoop yarn yarn anchor hdp exec mkdir var run hadoop yarn yarn begin var run hadoop yarn yarn begin depend exec mkdir exec mkdir grid hadoop yarn grid hadoop yarn failur failur truewarn truewarn stage hdp yarn nodemanag hdp yarn servic nodemanag hdp Directory_recursive_create var run hadoop yarn yarn hdp exec mkdir stage hdp yarn nodemanag hdp yarn servic nodemanag hdp Directory_recursive_create var run hadoop yarn yarn hdp exec mkdir var run hadoop yarn yarn anchor hdp exec mkdir var run hadoop yarn yarn anchor hdp exec mkdir var run hadoop yarn yarn begin var run hadoop yarn yarn begin skip fail dependenciesnotic dependenciesnotic stage hdp yarn nodemanag hdp yarn servic nodemanag hdp Directory_recursive_create var run hadoop yarn yarn hdp exec mkdir stage hdp yarn nodemanag hdp yarn servic nodemanag hdp Directory_recursive_create var run hadoop yarn yarn hdp exec mkdir var run hadoop yarn yarn exec mkdir var run hadoop yarn yarn exec mkdir var run hadoop yarn yarn var run hadoop yarn yarn depend exec mkdir exec mkdir grid hadoop yarn grid hadoop yarn failur failur truewarn truewarn stage hdp yarn nodemanag hdp yarn servic nodemanag hdp Directory_recursive_create var run hadoop yarn yarn hdp exec mkdir stage hdp yarn nodemanag hdp yarn servic nodemanag hdp Directory_recursive_create var run hadoop yarn yarn hdp exec mkdir var run hadoop yarn yarn exec mkdir var run hadoop yarn yarn exec mkdir var run hadoop yarn yarn var run hadoop yarn yarn skip fail dependenciesnotic dependenciesnotic stage hdp yarn nodemanag hdp yarn servic nodemanag hdp Directory_recursive_create var run hadoop yarn yarn hdp exec mkdir stage hdp yarn nodemanag hdp yarn servic nodemanag hdp Directory_recursive_create var run hadoop yarn yarn hdp exec mkdir var run hadoop yarn yarn anchor hdp exec mkdir var run hadoop yarn yarn anchor hdp exec mkdir var run hadoop yarn yarn end var run hadoop yarn yarn end depend exec mkdir exec mkdir grid hadoop yarn grid hadoop yarn failur failur truewarn truewarn stage hdp yarn nodemanag hdp yarn servic nodemanag hdp Directory_recursive_create var run hadoop yarn yarn hdp exec mkdir stage hdp yarn nodemanag hdp yarn servic nodemanag hdp Directory_recursive_create var run hadoop yarn yarn hdp exec mkdir var run hadoop yarn yarn anchor hdp exec mkdir var run hadoop yarn yarn anchor hdp exec mkdir var run hadoop yarn yarn end var run hadoop yarn yarn end skip fail dependenciesnotic dependenciesnotic stage hdp yarn nodemanag hdp yarn servic nodemanag hdp Directory_recursive_create var run hadoop yarn yarn hdp directori var run hadoop yarn yarn file var run hadoop yarn yarn stage hdp yarn nodemanag hdp yarn servic nodemanag hdp Directory_recursive_create var run hadoop yarn yarn hdp directori var run hadoop yarn yarn file var run hadoop yarn yarn depend exec mkdir exec mkdir grid hadoop yarn grid hadoop yarn failur failur truewarn truewarn stage hdp yarn nodemanag hdp yarn servic nodemanag hdp Directory_recursive_create var run hadoop yarn yarn hdp directori var run hadoop yarn yarn file var run hadoop yarn yarn stage hdp yarn nodemanag hdp yarn servic nodemanag hdp Directory_recursive_create var run hadoop yarn yarn hdp directori var run hadoop yarn yarn file var run hadoop yarn yarn skip fail dependenciesnotic dependenciesnotic stage hdp yarn nodemanag hdp yarn servic nodemanag hdp exec su stage hdp yarn nodemanag hdp yarn servic nodemanag hdp exec su yarn export HADOOP_LIBEXEC_DIR usr lib hadoop libexec HADOOP LIBEXEC DIR usr lib hadoop libexec amp amp amp amp usr lib hadoop yarn sbin yarn daemon sh usr lib hadoop yarn sbin yarn daemon sh config etc hadoop conf etc hadoop conf start nodemanag anchor hdp exec su nodemanag anchor hdp exec su yarn export HADOOP_LIBEXEC_DIR usr lib hadoop libexec HADOOP LIBEXEC DIR usr lib hadoop libexec amp amp amp amp usr lib hadoop yarn sbin yarn daemon sh usr lib hadoop yarn sbin yarn daemon sh config etc hadoop conf etc hadoop conf start nodemanag begin nodemanag begin depend exec mkdir exec mkdir grid hadoop yarn grid hadoop yarn failur failur truewarn truewarn stage hdp yarn nodemanag hdp yarn servic nodemanag hdp exec su stage hdp yarn nodemanag hdp yarn servic nodemanag hdp exec su yarn export HADOOP_LIBEXEC_DIR usr lib hadoop libexec HADOOP LIBEXEC DIR usr lib hadoop libexec amp amp amp amp usr lib hadoop yarn sbin yarn daemon sh usr lib hadoop yarn sbin yarn daemon sh config etc hadoop conf etc hadoop conf start nodemanag anchor hdp exec su nodemanag anchor hdp exec su yarn export HADOOP_LIBEXEC_DIR usr lib hadoop libexec HADOOP LIBEXEC DIR usr lib hadoop libexec amp amp amp amp usr lib hadoop yarn sbin yarn daemon sh usr lib hadoop yarn sbin yarn daemon sh config etc hadoop conf etc hadoop conf start nodemanag begin nodemanag begin skip fail dependenciesnotic dependenciesnotic stage hdp yarn nodemanag hdp yarn servic nodemanag hdp exec su stage hdp yarn nodemanag hdp yarn servic nodemanag hdp exec su yarn export HADOOP_LIBEXEC_DIR usr lib hadoop libexec HADOOP LIBEXEC DIR usr lib hadoop libexec amp amp amp amp usr lib hadoop yarn sbin yarn daemon sh usr lib hadoop yarn sbin yarn daemon sh config etc hadoop conf etc hadoop conf start nodemanag exec su nodemanag exec su yarn export HADOOP_LIBEXEC_DIR usr lib hadoop libexec HADOOP LIBEXEC DIR usr lib hadoop libexec amp amp amp amp usr lib hadoop yarn sbin yarn daemon sh usr lib hadoop yarn sbin yarn daemon sh config etc hadoop conf etc hadoop conf start nodemanag nodemanag depend exec mkdir exec mkdir grid hadoop yarn grid hadoop yarn failur failur truewarn truewarn stage hdp yarn nodemanag hdp yarn servic nodemanag hdp exec su stage hdp yarn nodemanag hdp yarn servic nodemanag hdp exec su yarn export HADOOP_LIBEXEC_DIR usr lib hadoop libexec HADOOP LIBEXEC DIR usr lib hadoop libexec amp amp amp amp usr lib hadoop yarn sbin yarn daemon sh usr lib hadoop yarn sbin yarn daemon sh config etc hadoop conf etc hadoop conf start nodemanag exec su nodemanag exec su yarn export HADOOP_LIBEXEC_DIR usr lib hadoop libexec HADOOP LIBEXEC DIR usr lib hadoop libexec amp amp amp amp usr lib hadoop yarn sbin yarn daemon sh usr lib hadoop yarn sbin yarn daemon sh config etc hadoop conf etc hadoop conf start nodemanag nodemanag skip fail dependenciesnotic dependenciesnotic stage hdp yarn nodemanag hdp yarn servic nodemanag hdp exec su stage hdp yarn nodemanag hdp yarn servic nodemanag hdp exec su yarn export HADOOP_LIBEXEC_DIR usr lib hadoop libexec HADOOP LIBEXEC DIR usr lib hadoop libexec amp amp amp amp usr lib hadoop yarn sbin yarn daemon sh usr lib hadoop yarn sbin yarn daemon sh config etc hadoop conf etc hadoop conf start nodemanag anchor hdp exec su nodemanag anchor hdp exec su yarn export HADOOP_LIBEXEC_DIR usr lib hadoop libexec HADOOP LIBEXEC DIR usr lib hadoop libexec amp amp amp amp usr lib hadoop yarn sbin yarn daemon sh usr lib hadoop yarn sbin yarn daemon sh config etc hadoop conf etc hadoop conf start nodemanag end nodemanag end depend exec mkdir exec mkdir grid hadoop yarn grid hadoop yarn failur failur truewarn truewarn stage hdp yarn nodemanag hdp yarn servic nodemanag hdp exec su stage hdp yarn nodemanag hdp yarn servic nodemanag hdp exec su yarn export HADOOP_LIBEXEC_DIR usr lib hadoop libexec HADOOP LIBEXEC DIR usr lib hadoop libexec amp amp amp amp usr lib hadoop yarn sbin yarn daemon sh usr lib hadoop yarn sbin yarn daemon sh config etc hadoop conf etc hadoop conf start nodemanag anchor hdp exec su nodemanag anchor hdp exec su yarn export HADOOP_LIBEXEC_DIR usr lib hadoop libexec HADOOP LIBEXEC DIR usr lib hadoop libexec amp amp amp amp usr lib hadoop yarn sbin yarn daemon sh usr lib hadoop yarn sbin yarn daemon sh config etc hadoop conf etc hadoop conf start nodemanag end nodemanag end skip fail dependenciesnotic dependenciesnotic stage hdp yarn nodemanag hdp yarn servic nodemanag hdp exec sleep stage hdp yarn nodemanag hdp yarn servic nodemanag hdp exec sleep ls var run hadoop yarn yarn yarn yarn nodemanag pid var run hadoop yarn yarn yarn yarn nodemanag pid gt dev null gt dev null gt amp gt amp amp amp amp amp ps cat var run hadoop yarn yarn yarn yarn nodemanag pid var run hadoop yarn yarn yarn yarn nodemanag pid gt dev null gt dev null gt amp anchor hdp exec sleep gt amp anchor hdp exec sleep ls var run hadoop yarn yarn yarn yarn nodemanag pid var run hadoop yarn yarn yarn yarn nodemanag pid gt dev null gt dev null gt amp gt amp amp amp amp amp ps cat var run hadoop yarn yarn yarn yarn nodemanag pid var run hadoop yarn yarn yarn yarn nodemanag pid gt dev null gt dev null gt amp begin gt amp begin depend exec mkdir exec mkdir grid hadoop yarn grid hadoop yarn failur failur truewarn truewarn stage hdp yarn nodemanag hdp yarn servic nodemanag hdp exec sleep stage hdp yarn nodemanag hdp yarn servic nodemanag hdp exec sleep ls var run hadoop yarn yarn yarn yarn nodemanag pid var run hadoop yarn yarn yarn yarn nodemanag pid gt dev null gt dev null gt amp gt amp amp amp amp amp ps cat var run hadoop yarn yarn yarn yarn nodemanag pid var run hadoop yarn yarn yarn yarn nodemanag pid gt dev null gt dev null gt amp anchor hdp exec sleep gt amp anchor hdp exec sleep ls var run hadoop yarn yarn yarn yarn nodemanag pid var run hadoop yarn yarn yarn yarn nodemanag pid gt dev null gt dev null gt amp gt amp amp amp amp amp ps cat var run hadoop yarn yarn yarn yarn nodemanag pid var run hadoop yarn yarn yarn yarn nodemanag pid gt dev null gt dev null gt amp begin gt amp begin skip fail dependenciesnotic dependenciesnotic stage hdp yarn nodemanag hdp yarn servic nodemanag hdp exec sleep stage hdp yarn nodemanag hdp yarn servic nodemanag hdp exec sleep ls var run hadoop yarn yarn yarn yarn nodemanag pid var run hadoop yarn yarn yarn yarn nodemanag pid gt dev null gt dev null gt amp gt amp amp amp amp amp ps cat var run hadoop yarn yarn yarn yarn nodemanag pid var run hadoop yarn yarn yarn yarn nodemanag pid gt dev null gt dev null gt amp exec sleep gt amp exec sleep ls var run hadoop yarn yarn yarn yarn nodemanag pid var run hadoop yarn yarn yarn yarn nodemanag pid gt dev null gt dev null gt amp gt amp amp amp amp amp ps cat var run hadoop yarn yarn yarn yarn nodemanag pid var run hadoop yarn yarn yarn yarn nodemanag pid gt dev null gt dev null gt amp gt amp depend exec mkdir exec mkdir grid hadoop yarn grid hadoop yarn failur failur truewarn truewarn stage hdp yarn nodemanag hdp yarn servic nodemanag hdp exec sleep stage hdp yarn nodemanag hdp yarn servic nodemanag hdp exec sleep ls var run hadoop yarn yarn yarn yarn nodemanag pid var run hadoop yarn yarn yarn yarn nodemanag pid gt dev null gt dev null gt amp gt amp amp amp amp amp ps cat var run hadoop yarn yarn yarn yarn nodemanag pid var run hadoop yarn yarn yarn yarn nodemanag pid gt dev null gt dev null gt amp exec sleep gt amp exec sleep ls var run hadoop yarn yarn yarn yarn nodemanag pid var run hadoop yarn yarn yarn yarn nodemanag pid gt dev null gt dev null gt amp gt amp amp amp amp amp ps cat var run hadoop yarn yarn yarn yarn nodemanag pid var run hadoop yarn yarn yarn yarn nodemanag pid gt dev null gt dev null gt amp gt amp skip fail dependenciesnotic dependenciesnotic stage hdp yarn nodemanag hdp yarn servic nodemanag hdp exec sleep stage hdp yarn nodemanag hdp yarn servic nodemanag hdp exec sleep ls var run hadoop yarn yarn yarn yarn nodemanag pid var run hadoop yarn yarn yarn yarn nodemanag pid gt dev null gt dev null gt amp gt amp amp amp amp amp ps cat var run hadoop yarn yarn yarn yarn nodemanag pid var run hadoop yarn yarn yarn yarn nodemanag pid gt dev null gt dev null gt amp anchor hdp exec sleep gt amp anchor hdp exec sleep ls var run hadoop yarn yarn yarn yarn nodemanag pid var run hadoop yarn yarn yarn yarn nodemanag pid gt dev null gt dev null gt amp gt amp amp amp amp amp ps cat var run hadoop yarn yarn yarn yarn nodemanag pid var run hadoop yarn yarn yarn yarn nodemanag pid gt dev null gt dev null gt amp end gt amp end depend exec mkdir exec mkdir grid hadoop yarn grid hadoop yarn failur failur truewarn truewarn stage hdp yarn nodemanag hdp yarn servic nodemanag hdp exec sleep stage hdp yarn nodemanag hdp yarn servic nodemanag hdp exec sleep ls var run hadoop yarn yarn yarn yarn nodemanag pid var run hadoop yarn yarn yarn yarn nodemanag pid gt dev null gt dev null gt amp gt amp amp amp amp amp ps cat var run hadoop yarn yarn yarn yarn nodemanag pid var run hadoop yarn yarn yarn yarn nodemanag pid gt dev null gt dev null gt amp anchor hdp exec sleep gt amp anchor hdp exec sleep ls var run hadoop yarn yarn yarn yarn nodemanag pid var run hadoop yarn yarn yarn yarn nodemanag pid gt dev null gt dev null gt amp gt amp amp amp amp amp ps cat var run hadoop yarn yarn yarn yarn nodemanag pid var run hadoop yarn yarn yarn yarn nodemanag pid gt dev null gt dev null gt amp end gt amp end skip fail dependenciesnotic dependenciesnotic stage hdp yarn nodemanag hdp yarn servic nodemanag anchor hdp yarn servic nodemanag end stage hdp yarn nodemanag hdp yarn servic nodemanag anchor hdp yarn servic nodemanag end depend exec mkdir exec mkdir grid hadoop yarn grid hadoop yarn failur failur truewarn truewarn stage hdp yarn nodemanag hdp yarn servic nodemanag anchor hdp yarn servic nodemanag end stage hdp yarn nodemanag hdp yarn servic nodemanag anchor hdp yarn servic nodemanag end skip fail dependenciesnotic dependenciesnotic stage hdp yarn nodemanag anchor hdp yarn nodemanag end stage hdp yarn nodemanag anchor hdp yarn nodemanag end depend exec mkdir exec mkdir grid hadoop yarn grid hadoop yarn failur failur truewarn truewarn stage hdp yarn nodemanag anchor hdp yarn nodemanag end stage hdp yarn nodemanag anchor hdp yarn nodemanag end skip fail dependenciesnotic dependenciesnotic stage hdp yarn initi hdp yarn Generate_common_configs yarn common config configgener configfil mapr site file etc hadoop conf mapr site xml content stage hdp yarn initi hdp yarn Generate_common_configs yarn common config configgener configfil mapr site file etc hadoop conf mapr site xml content content chang md cb dc md cb dc md cc ba ba notic md cc ba ba notic stage hdp yarn initi hdp yarn Generate_common_configs yarn common config configgener configfil mapr site file etc hadoop conf mapr site xml owner stage hdp yarn initi hdp yarn Generate_common_configs yarn common config configgener configfil mapr site file etc hadoop conf mapr site xml owner owner chang mapr mapr yarn notic yarn notic finish catalog run second,0,0,0,0,0,0,1 
3076,Billie Rinaldi,null,0,Jobs run date and duration not sorting correctly, job run date durat not sort correctli,Input and output bytes columns have been removed from the UI  but the web service doesn't know about that yet so it doesn't map the column index to a sort field correctly., input output byte column remov UI web servic know yet map column index sort field correctli correctli,0,0,0,0,0,0,1 
3077,Billie Rinaldi,null,0,Jobs summary has 'oldest' and 'youngest' run dates swapped, job summari oldest oldest youngest youngest run date swap,The web service is labeling these incorrectly when they are retrieved from the db., web servic label incorrectli retriev db db,0,0,0,0,0,0,1 
3093,Andrii Tkach,ambari-web,0,Incorrect units of measure for 'HBase Master Heap' widget on Dashboard, incorrect unit measur HBase base master heap heap widget dashboard,'HBase Master Heap' widget on Dashboard displays parameters in TB (param1.png)  but real values are in MB (param0.png)., HBase base master heap heap widget dashboard display paramet TB param png param png real valu MB param png param png,0,0,0,0,0,ambari-web/app/views/main/dashboard/widgets/hbase_master_heap.js;ambari-web/app/views/main/dashboard/widgets/namenode_heap.js;,0 
3095,Andrii Tkach,ambari-web,0,Incorrect color of rack indicators on 'Heatmaps' page, incorrect color rack indic heatmap heatmap page,Precondition: hadoop is installed. Total disk space for both machines is 100 GB. Used disk space is about 5-15%.Steps: Go to 'Heatmaps' page. Select 'Host Disk Space Used %' metric ('Maximum' input field has '100' value). Both indicators has green color (disk space usage is in 0-20% category). Choose 'Maximum' input field value to '99'.Result:One indicator has red color (79.2% - 99% category)  but real disk space usage is 8.3% and indicator should be green., precondit precondit hadoop instal instal total disk space machin GB GB use disk space step step Go heatmap heatmap page page select host host disk space use metric maximum maximum input field valu valu indic green color disk space usag categori categori choos maximum maximum input field valu result one result one indic red color categori categori real disk space usag indic green green,0,0,0,0,0,ambari-web/app/controllers/main/charts/heatmap_metrics/heatmap_metric.js;,0 
3099,Siddharth Wagle,ambari-server,0,Cannot change JMX ports using Ambari configuration API, cannot chang JMX port use ambari configur API,Ambari 1.2.5  attached the configs to the cluster  in order to provide ability for override behavior at the service and host component levels.The JMX ports read from the service configs can no longer be modified from their default values since the existing code reads the service configurations which do not exist., ambari attach config cluster order provid abil overrid behavior servic host compon level level JMX port read servic config no longer modifi default valu sinc exist code read servic configur not exist exist,0,0,0,0,0,0,1 
3105,Xi Wang,ambari-web,0,Random change of blocks for Summary and Alerts and health checks on some Service pages, random chang block summari alert health check servic page,The height of blocks 'Alerts and health checks' is changed sometimes after Service page refresh.It can change to normal sizes after another tries.Produced only in Firefox., height block alert alert health check check chang sometim servic page refresh refresh chang normal size anoth tri produc tri produc firefox firefox,0,0,0,0,0,0,0 
3112,Jaimin D Jetly,ambari-agent,0,Security wizard: disabling security does not return to initial condition after enabling security fails., secur wizard wizard disabl secur not return initi condit enabl secur fail fail,Steps to reproduce:1. enable security WITHOUT pre-configuring kerberos on cluster and see failures on '3. Start Services';2. disable security.In the end DataNode fails on ALL hosts without a possibility to get started.When you try to start DataNode manually it also ends with error:err: /Stage[2]/Hdp-hadoop::Datanode/Hdp-hadoop::Service[datanode]/Hdp::Exec[su - hdfs -c 'export HADOOP_LIBEXEC_DIR=/usr/lib/hadoop/libexec &amp;&amp; /usr/lib/hadoop/sbin/hadoop-daemon.sh --config /etc/hadoop/conf start datanode']/Exec[su - hdfs -c 'export HADOOP_LIBEXEC_DIR=/usr/lib/hadoop/libexec &amp;&amp; /usr/lib/hadoop/sbin/hadoop-daemon.sh --config /etc/hadoop/conf start datanode']/returns: change from notrun to 0 failed: su - hdfs -c 'export HADOOP_LIBEXEC_DIR=/usr/lib/hadoop/libexec &amp;&amp; /usr/lib/hadoop/sbin/hadoop-daemon.sh --config /etc/hadoop/conf start datanode' returned 1 instead of one of [0] at /var/lib/ambari-agent/puppet/modules/hdp/manifests/init.pp:479, step reproduc reproduc enabl secur WITHOUT pre configur pre configur kerbero cluster see failur start servic servic disabl secur secur end DataNode data node fail host without possibl get start start tri start DataNode data node manual also end error err error err stage hdp hadoop datanod hdp hadoop servic datanod hdp exec su stage hdp hadoop datanod hdp hadoop servic datanod hdp exec su hdf export HADOOP_LIBEXEC_DIR usr lib hadoop libexec HADOOP LIBEXEC DIR usr lib hadoop libexec amp amp amp amp usr lib hadoop sbin hadoop daemon sh usr lib hadoop sbin hadoop daemon sh config etc hadoop conf etc hadoop conf start datanod exec su datanod exec su hdf export HADOOP_LIBEXEC_DIR usr lib hadoop libexec HADOOP LIBEXEC DIR usr lib hadoop libexec amp amp amp amp usr lib hadoop sbin hadoop daemon sh usr lib hadoop sbin hadoop daemon sh config etc hadoop conf etc hadoop conf start datanod return datanod return chang notrun fail fail su hdf export HADOOP_LIBEXEC_DIR usr lib hadoop libexec HADOOP LIBEXEC DIR usr lib hadoop libexec amp amp amp amp usr lib hadoop sbin hadoop daemon sh usr lib hadoop sbin hadoop daemon sh config etc hadoop conf etc hadoop conf start datanod datanod return instead one var lib ambari agent puppet modul hdp manifest init pp var lib ambari agent puppet modul hdp manifest init pp,0,0,0,0,0,ambari-agent/src/main/puppet/modules/hdp-hadoop/manifests/service.pp;,0 
3115,Srimanth Gunturi,ambari-web,0,HBase Read/Write request metrics seem to have changed for 2.x stack, HBase base read write read write request metric seem chang stack,See the screenshot for HBase Cumulative Requests graph.The graph does not seem like it's displaying cumulative read/write requests  but rather showing the rate... so the label no longer makes sense.This is on the 2.0.5 stack. On the 1.x  I believe this graph would show cumulative read/write requests (which were less useful).So for 2.x stack  we should probably change the label for this graph to say Reads/Writes per Second (or whatever we are showing - need to confirm)., see screenshot HBase base cumul request graph graph graph not seem like display cumul read write read write request rather show rate rate label no longer make sens sens stack stack believ graph would show cumul read write read write request less use use stack probabl chang label graph say read write read write per second whatev show need confirm confirm,0,0,0,0,0,0,1 
3119,Siddharth Wagle,ambari-server,0,NullPointerException thrown while retrieving ganglia properties, NullPointerException null pointer except thrown retriev ganglia properti,API Call:curl -u admin:admin http://localhost:8080/api/v1/clusters/c1/services?fields=components/ServiceComponentInfo components/host_components components/host_components/HostRoles components/host_components/metrics/jvm/memHeapUsedM components/host_components/metrics/jvm/memHeapCommittedM components/host_components/metrics/mapred/jobtracker/trackers_decommissioned components/host_components/metrics/cpu/cpu_wio components/host_components/metrics/rpc/RpcQueueTime_avg_time components/host_components/metrics/flume/flume components/host_components/metrics/yarn/QueueAmbari log:20:54:57 044 WARN [qtp912472968-20] ServletHandler:514 - /api/v1/clusters/c1/servicesjava.lang.NullPointerException at org.apache.ambari.server.controller.ganglia.GangliaPropertyProvider.getRRDRequests(GangliaPropertyProvider.java:225) at org.apache.ambari.server.controller.ganglia.GangliaPropertyProvider.populateResources(GangliaPropertyProvider.java:110) at org.apache.ambari.server.controller.internal.VersioningPropertyProvider.populateResources(VersioningPropertyProvider.java:98), API call curl call curl admin admin admin admin compon host_components compon host_components compon host_components HostRoles compon host_components host role compon host_components metric jvm memHeapUsedM compon host_components metric jvm mem heap use compon host_components metric jvm memHeapCommittedM compon host_components metric jvm mem heap commit compon host_components metric mapr jobtrack trackers_decommissioned compon host_components metric mapr jobtrack trackers_decommissioned compon host_components metric cpu cpu_wio compon host_components metric cpu cpu_wio compon host_components metric rpc RpcQueueTime_avg_time compon host_components metric rpc rpc queue Time_avg_time compon host_components metric flume flume compon host_components metric flume flume compon host_components metric yarn QueueAmbari compon host_components metric yarn queue ambari log log WARN qtp qtp ServletHandler servlet handler api cluster servicesjava lang NullPointerException api cluster servicesjava lang null pointer except org apach ambari server control ganglia GangliaPropertyProvider getRRDRequests GangliaPropertyProvider java org apach ambari server control ganglia ganglia properti provid get RRD request ganglia properti provid java org apach ambari server control ganglia GangliaPropertyProvider populateResources GangliaPropertyProvider java org apach ambari server control ganglia ganglia properti provid popul resourc ganglia properti provid java org apach ambari server control intern VersioningPropertyProvider populateResources VersioningPropertyProvider java org apach ambari server control intern version properti provid popul resourc version properti provid java,0,0,0,0,0,0,0 
3124,Oleg Nechiporenko,ambari-web,0,Incorrect behavior after entering wrong current password while editing user;, incorrect behavior enter wrong current password edit user user,1. Go to Admin page -&gt; Users tab2. Click Edit for some user3. Try to enter wrong value for Current Password field.The message does not tell me that my entered current password is wrong  so it can be confusing for user.Another scenario:1. Go to Admin page -&gt; Users tab2. Click Edit for some user3. Try to enter wrong value for Current Password field and don't fill fields for a new passwordIt don't really change the password but it still allows to enter wrong Current Password without any message, Go admin page gt gt user tab tab click edit user user tri enter wrong valu current password field field messag not tell enter current password wrong confus user anoth user anoth scenario scenario Go admin page gt gt user tab tab click edit user user tri enter wrong valu current password field fill field new passwordIt password realli chang password still allow enter wrong current password without messag,0,0,0,0,0,0,1 
3135,Myroslav Papirkovskyy,ambari-server,0,Out of memory issues with Request API on large cluster, memori issu request API larg cluster,Number of ExecutionCommandEntity objects keep growing and result in Out of memory on large cluster (100 nodes).Script to re-create the issue:&#91;root@domain user&#93;# cat test1.shfor i in{0..100}doecho 'doing $i'curl -u admin:admin 'http://domain.net:8080/api/v1/clusters/c1/requests?to=end&amp;page_size=10&amp;fields= tasks/Tasks/*' &gt; /dev/nullsleep 5done, number ExecutionCommandEntity execut command entiti object keep grow result memori larg cluster node script node script creat creat issu root domain issu root domain user user cat test shfor test shfor doecho doecho curl curl admin admin admin admin http domain net api cluster request end amp page_size amp field http domain net api cluster request end amp page_size amp field task task task task gt gt dev nullsleep dev nullsleep done,0,0,0,0,0,0,1 
3136,Myroslav Papirkovskyy,ambari-server,0,Reduce the size of ExecutionCommand entity, reduc size ExecutionCommand execut command entiti,Currently  each ExecutionCommandEntity stores the whole config blob. This is a severe duplication of data as tagged configuration information is already available as immutable entry.We need to reduce the footprint of ExecutionCommandEntity by storing only configuration tags. The tags can be replaced with actual configuration value when the command is handed off to the agent.We need to ensure that when Ambari is upgraded and there is a mix of ExecutionCommandEntity instances with and without embedded config - it works., current ExecutionCommandEntity execut command entiti store whole config blob blob sever duplic data tag configur inform alreadi avail immut entri entri need reduc footprint ExecutionCommandEntity execut command entiti store configur tag tag tag replac actual configur valu command hand agent agent need ensur ambari upgrad mix ExecutionCommandEntity execut command entiti instanc without embed config work work,0,0,0,0,0,0,1 
3145,Vitaly Brodetskyi,ambari-agent,0,ambari-agent service script should return non-zero when the agent is not running, ambari agent ambari agent servic script return non zero non zero agent not run,The ambari-agent service script should return non-zero when the agent is not running. For example  if a customer wants to have puppet ensure the service is always running  it will not start a killed service because it thinks it's already running when it returns 0.&#91;root@host-123-123-123 init.d&#93;# service ambari-agent statusambari-agent currently not runningUsage: /usr/sbin/ambari-agent {start|stop|restart|status}&#91;root@host-123-123-123 init.d&#93;# echo $?0For comparison...&#91;root@host-123-123-123 init.d&#93;# service winbind statuswinbindd is stopped&#91;root@host-123-123-123 init.d&#93;# echo $?3Possible fix:AMBARI_AGENT_PID_PATH='/var/run/ambari-agent/ambari-agent.pid';RES='3';if [ -f $AMBARI_AGENT_PID_PATH ]then RES='cat $AMBARI_AGENT_PID_PATH | xargs ps -f -p | wc -l'; AMBARI_AGENT_PID='cat $AMBARI_AGENT_PID_PATH';else RES=-1;fiif [ $RES -eq '2' ]then echo 'OK: Ambari agent is running &#91;PID:$AMBARI_AGENT_PID&#93;'; exit 0;else echo 'CRITICAL: Ambari agent is not running &#91;$AMBARI_AGENT_PID_PATH not found&#93;'; exit 2;fi, ambari agent ambari agent servic script return non zero non zero agent not run run exampl custom want puppet ensur servic alway run not start kill servic think alreadi run return root host root host init init servic ambari agent ambari agent statusambari agent statusambari agent current not runningUsage run usag usr sbin ambari agent usr sbin ambari agent start stop restart statu root host start stop restart statu root host init init echo comparison root host comparison root host init init servic winbind statuswinbindd stop root host stop root host init init echo possibl possibl fix AMBARI_AGENT_PID_PATH var run ambari agent ambari agent pid RES fix AMBARI AGENT PID PATH var run ambari agent ambari agent pid RES AMBARI_AGENT_PID_PATH AMBARI AGENT PID PATH RES cat RES cat AMBARI_AGENT_PID_PATH AMBARI AGENT PID PATH xarg ps wc AMBARI_AGENT_PID cat AMBARI AGENT PID cat AMBARI_AGENT_PID_PATH els AMBARI AGENT PID PATH els RES fiif RES fiif RES RES eq echo OK OK ambari agent run PID AMBARI_AGENT_PID PID AMBARI AGENT PID exit els echo CRITICAL CRITICAL ambari agent not run AMBARI_AGENT_PID_PATH AMBARI AGENT PID PATH not found found exit fi,0,0,0,0,0,0,1 
3147,Sumit Mohanty,ambari-server,0,Modify ganglia config to match the data resolution of the older version, modifi ganglia config match data resolut older version,New ganglia version retains almost 50 times more data for higher resolution metrics collection. Ambari needs to modify the configuration to match the older resolution as the new default config has a very high disk space requirement.Looks like the default config for ganglia changed fromRRAs 'RRA:AVERAGE:0.5:1:244' 'RRA:AVERAGE:0.5:24:244' 'RRA:AVERAGE:0.5:168:244' 'RRA:AVERAGE:0.5:672:244' 'RRA:AVERAGE:0.5:5760:374'toRRAs 'RRA:AVERAGE:0.5:1:5856' 'RRA:AVERAGE:0.5:4:20160' 'RRA:AVERAGE:0.5:40:52704'Its an increase from 1350 data points to 78720. After reverting to older configuration the file size for a single metrics and its summary info are-rw-rw-rw- 1 nobody nobody 12224 Sep 7 18:29 ./HDPNameNode/c6402.ambari.apache.org/disk_free.rrd-rw-rw-rw- 1 nobody nobody 23656 Sep 7 18:29 ./HDPNameNode/__SummaryInfo__/disk_free.rrdIn contrast it was-rw-r--r-- 1 root root 630768 Sep 7 17:48 /tmp/rrds/HDPNameNode/c6402.ambari.apache.org/disk_free.rrd-rw-r--r-- 1 root root 1261000 Sep 7 17:47 /tmp/rrds/HDPNameNode/__SummaryInfo__/disk_free.rrdThe recommendation is to revert back to the old config (i.e. do not use the new default config). Confirming that with an older installation of Ambari., new ganglia version retain almost time data higher resolut metric collect collect ambari need modifi configur match older resolut new default config high disk space requir look requir look like default config ganglia chang fromRRAs RR RRA AVERAGE RRA AVERAGE RRA AVERAGE RRA AVERAGE RRA AVERAGE RRA AVERAGE RRA AVERAGE RRA AVERAGE RRA AVERAGE toRRAs RRA AVERAGE RR RRA AVERAGE RRA AVERAGE RRA AVERAGE RRA AVERAGE RRA AVERAGE RRA AVERAGE increas data point revert older configur file size singl metric summari info rw rw rw rw rw rw nobodi nobodi sep HDPNameNode ambari apach org disk_free rrd rw rw rw HDP name node ambari apach org disk_free rrd rw rw rw nobodi nobodi sep HDPNameNode SummaryInfo disk_free rrdIn HDP name node  summari info disk_free rrd contrast rw rw root root sep tmp rrd HDPNameNode ambari apach org disk_free rrd rw tmp rrd HDP name node ambari apach org disk_free rrd rw root root sep tmp rrd HDPNameNode SummaryInfo disk_free rrdThe tmp rrd HDP name node  summari info disk_free rrd recommend revert back old config not use new default config config confirm older instal ambari ambari,0,0,0,0,0,0,1 
3148,Vitaly Brodetskyi,ambari-agent,0,Oozie install fails with 'could not connect to database' when choosing 'use existing mysql database ' and choosing 'new mysql database' for Hive within Ambari, oozi instal fail could not connect databas databas choos use exist mysql databas choos new mysql databas databas hive within ambari,PROBLEM: When installing with Ambari and selecting an existing MySQL database for oozie and a new MySQL database for Hive  then the Ambariinstall fails when installing the oozie database. The error thrown is 'could not connect to database' [it appears to drop the 'existing' databaseand you are required to start MySQL on the machine and create the database]BUSINESS IMPACT: This will affect all customers who choose an existing MySQL database for oozie and a new MySQL DB for hive when installing a cluster using AmbariSTEPS TO REPRODUCE: Choose an exisiting oozie MySQL database and point Ambari at this  and select a new Hive MySQL database on the installation optionsACTUAL BEHAVIOR: It seems that it drops the exisiting oozie database and then fails with an errot of could not connect (This is due to MySQL being down  but also the Oozie database is not there anymore)After starting MySQL and creating the database then the installer can continue from where it left off.EXPECTED BEHAVIOR: The installer should not stop MySQL and drop the oozie database if you select create a new Hive database and exisiting MySQL database for oozie.SUPPORT ANALYSIS: Reproduced in the lab in HDP 1.3.2 by following the steps above., PROBLEM PROBLEM instal ambari select exist MySQL SQL databas oozi new MySQL SQL databas hive ambariinstal fail instal oozi databas databas error thrown could not connect databas databas appear drop exist exist databaseand requir start MySQL SQL machin creat databas BUSINESS databas BUSINESS IMPACT IMPACT affect custom choos exist MySQL SQL databas oozi new MySQL SQL DB hive instal cluster use AmbariSTEPS ambari STEPS REPRODUCE REPRODUCE choos exisit oozi MySQL SQL databas point ambari select new hive MySQL SQL databas instal optionsACTUAL option ACTUAL BEHAVIOR BEHAVIOR seem drop exisit oozi databas fail errot could not connect due MySQL SQL also oozi databas not anymor anymor start MySQL SQL creat databas instal continu left EXPECTED EXPECTED BEHAVIOR BEHAVIOR instal not stop MySQL SQL drop oozi databas select creat new hive databas exisit MySQL SQL databas oozi SUPPORT oozi SUPPORT ANALYSIS ANALYSIS reproduc lab HDP follow step,0,0,0,0,0,0,0 
3151,Sumit Mohanty,ambari-server,0,ambari-server command output should point to Apache Ambari documentation, ambari server ambari server command output point apach ambari document,ambari-server command outputs should point to a generic link for current ambari documentation., ambari server ambari server command output point gener link current ambari document document,0,0,0,0,0,0,1 
3153,Jaimin D Jetly,ambari-agent,0,Secure cluster: Yarn service check fails after configuring yarn for spnego authentication., secur cluster cluster yarn servic check fail configur yarn spnego authent authent,Yarn smoke test uses REST api exposed by ResourceManager to get its status. After configuring web authentication yarn client that is assigned yarn service check needs to negotiate 401 HTTP authentication response received while using REST api., yarn smoke test use REST api expos ResourceManager resourc manag get statu statu configur web authent yarn client assign yarn servic check need negoti HTTP authent respons receiv use REST api api,0,0,0,0,0,ambari-agent/src/main/puppet/modules/hdp-yarn/files/validateYarnComponentStatus.py;,1 
3154,Oleg Nechiporenko,ambari-web,0,ZKFailoverController should be shown as a component that can be started/stopped in Host Details page, ZKFailoverController ZK failov control shown compon start stop start stop host detail page,,,0,0,0,0,0,0,0 
3160,Vitaly Brodetskyi,ambari-agent,0,WebHCat alert does not nave any description, WebHCat web cat alert not nave descript,Steps to reproduce1. Go to Services page2. click on different services. They all have a status and a message for status in 'Alerts and Health Checks' list (as example hive.png)3. WebHCat service has a status but does not have a status message, step reproduc reproduc Go servic page page click differ servic servic statu messag statu alert alert health check check list exampl hive png hive png WebHCat web cat servic statu not statu messag,0,0,0,0,0,0,0 
3191,Sumit Mohanty,ambari-server,0,Cannot delete a stopped host_component in INSTALLED state, cannot delet stop host_component INSTALLED state,I have a host with 4 stopped host_components. When I issue a DELETE on say http://c6401:8080/api/v1/clusters/vmc/hosts/c6404.ambari.apache.org/host_components/DATANODEThe response is:{ 'status' : 500  'message' : 'org.apache.ambari.server.controller.spi.SystemException: An internal system exception occurred: To remove master or slave components they must be in MAINTENANCE/INIT/INSTALL_FAILED/UNKNOWN state. Current=INSTALLED.'}, host stop host_components host_components issu DELETE say respons statu statu messag messag org apach ambari server control spi SystemException org apach ambari server control spi system except intern system except occur occur remov master slave compon must MAINTENANCE INIT INSTALL_FAILED UNKNOWN MAINTENANCE INIT INSTALL FAILED UNKNOWN state state current INSTALLED current INSTALLED,0,0,0,0,0,0,1 
3198,Dmytro Sen,ambari-server,0,ambari-server reset is broken on centos5.8, ambari server ambari server reset broken cento cento,ambari-server reset fails due to syntax error in centos 5.8 (postgres 8.1).psql:/var/lib/ambari-server/resources/Ambari-DDL-Postgres-DROP.sql:18: LINE 1: DROP DATABASE IF EXISTS ambari;The IF EXISTS clause was only added to DROP command in PotgreSQL8.2.+Show warnings if any SQL commands failed during server reset or upgradestack, ambari server ambari server reset fail due syntax error cento postgr psql var lib ambari server resourc ambari DDL postgr DROP sql psql var lib ambari server resourc ambari DDL postgr DROP sql LINE DROP DATABASE EXISTS ambari ambari EXISTS claus ad DROP command PotgreSQL show potgr SQL show warn SQL command fail server reset upgradestack,0,0,0,0,0,0,1 
3221,Xi Wang,ambari-web,0,NameNode Uptime does not appear, NameNode name node uptim not appear,Due to backend change of the position of NameNode startTime property  this will not show up., due backend chang posit NameNode name node startTime start time properti not show,0,0,0,0,0,0,1 
3229,Mahadev konar,null,0,Ambari does not set the correct value for 'templeton.storage.class' in webhcat-site.xml, ambari not set correct valu templeton storag class templeton storag class webhcat site xml webhcat site xml,Ambari does not set the correct value for 'templeton.storage.class' in webhcat-site.xmlIn an Ambari deployed cluster currently the following value in /etc/hcatalog/conf/webhcat-site.xml is set incorrectly: &lt;property&gt; &lt;name&gt;templeton.storage.class&lt;/name&gt; &lt;value&gt;org.apache.hcatalog.templeton.tool.ZooKeeperStorage&lt;/value&gt; &lt;/property&gt;With the change from HIVE-4895 this should be: &lt;property&gt; &lt;name&gt;templeton.storage.class&lt;/name&gt; &lt;value&gt;org.apache.hive.hcatalog.templeton.tool.ZooKeeperStorage&lt;/value&gt; &lt;/property&gt;All jobs involving MapReduce fail because of this issue., ambari not set correct valu templeton storag class templeton storag class webhcat site xmlIn webhcat site xml ambari deploy cluster current follow valu etc hcatalog conf webhcat site xml etc hcatalog conf webhcat site xml set incorrectli incorrectli lt properti gt lt properti gt lt name gt templeton storag class lt name gt lt name gt templeton storag class lt name gt lt valu gt org apach hcatalog templeton tool ZooKeeperStorage lt valu gt lt valu gt org apach hcatalog templeton tool zoo keeper storag lt valu gt lt properti gt lt properti gt chang HIVE HIVE lt properti gt lt properti gt lt name gt templeton storag class lt name gt lt name gt templeton storag class lt name gt lt valu gt org apach hive hcatalog templeton tool ZooKeeperStorage lt valu gt lt valu gt org apach hive hcatalog templeton tool zoo keeper storag lt valu gt lt properti gt lt properti gt job involv MapReduce map reduc fail issu issu,0,0,0,0,0,0,1 
3240,Sumit Mohanty,ambari-server,0,URLStreamProvider reads are flooding the log, URLStreamProvider URL stream provid read flood log,These logs do not need to be at INFO level. When user is using the UI then theer is roughly one log per second.06:56:34 232 INFO [pool-1-thread-12] URLStreamProvider:81 - readFrom spec:http://c6402.ambari.apache.org:50075/jmx06:56:34 235 INFO [pool-1-thread-5] URLStreamProvider:81 - readFrom spec:http://c6401.ambari.apache.org:50075/jmx06:56:34 248 INFO [qtp1620999494-18] URLStreamProvider:81 - readFrom spec:http://c6401.ambari.apache.org/cgi-bin/rrd.py?c=HDPSlaves&amp;h=c6401.ambari.apache.org c6402.ambari.apache.org&amp;m=cpu_wio jvm.JvmMetrics.MemHeapUsedM rpc.rpc.RpcQueueTimeAvgTime jvm.JvmMetrics.MemHeapCommittedM&amp;e=now&amp;pt=true..., log not need INFO level level user use UI theer roughli one log per second second INFO pool thread pool thread URLStreamProvider URL stream provid readFrom read spec http ambari apach org jmx spec http ambari apach org jmx INFO pool thread pool thread URLStreamProvider URL stream provid readFrom read spec http ambari apach org jmx spec http ambari apach org jmx INFO qtp qtp URLStreamProvider URL stream provid readFrom read spec http ambari apach org cgi bin rrd py HDPSlaves amp ambari apach org spec http ambari apach org cgi bin rrd py HDP slave amp ambari apach org ambari apach org amp cpu_wio ambari apach org amp cpu_wio jvm JvmMetrics MemHeapUsedM jvm jvm metric mem heap use rpc rpc RpcQueueTimeAvgTime rpc rpc rpc queue time avg time jvm JvmMetrics MemHeapCommittedM amp amp pt true jvm jvm metric mem heap commit amp amp pt true,0,0,0,0,0,0,0 
3251,Dmitry Lysnichenko,ambari-server,0,When Bind DN credentials are incorrect - we should log it, bind DN credenti incorrect log,When integrating Ambari with LDAP if you specify the Bind DN  or Bind credentials that are invalid there is no logging to identify that the authentication fails  so the following search for the logging in user DN will fail. I had to use wireshark to figure out why the integration wasn't working., integr ambari LDAP specifi bind DN bind credenti invalid no log identifi authent fail follow search log user DN fail fail use wireshark figur integr work work,0,0,0,0,0,0,1 
3255,Oleg Nechiporenko,ambari-web,0,Read-only views of security admin tab became editable after visiting other tabs on admin page, read read view secur admin tab becam edit visit tab admin page,STR: Go to Admin page -&gt; Security tab Switch to another tab on admin page (Misc tab  HA tab  etc.) Go back to Security tab--------------------Verify that all input fields on this page are read-onlyExpected Result: Everything should be read-only.Actual Result: Some fields become editable ., STR STR Go admin page gt gt secur tab switch anoth tab admin page misc misc tab HA tab etc etc Go back secur tab verifi tab verifi input field page read onlyExpected read expect result result everyth read actual read actual result result field becom edit,0,0,0,0,0,0,0 
3260,Siddharth Wagle,ambari-server,0,Fix text for custom JCE policy setup, fix text custom JCE polici setup,Current text:-c JCE_POLICY  --jce-policy=JCE_POLICY Use specified jce_policy. Must be valid on all hostsThis is required only on ambari-server  the agents will download from the server., current text text JCE_POLICY JCE POLICY jce polici JCE_POLICY jce polici JCE POLICY use specifi jce_policy jce_policy must valid hostsThis host requir ambari server ambari server agent download server server,0,0,0,0,0,0,1 
3276,Xi Wang,ambari-web,0,Dashboard page: buttons are shifted if screen width is more than 1200px, dashboard page page button shift screen width px,,,0,0,0,0,0,0,0 
3279,Xi Wang,ambari-web,0,Strange behavior of 'JobTracker CPU WIO' dashboard widget, strang behavior JobTracker job tracker CPU WIO WIO dashboard widget,This happened because when fixing an old issue  jobTrackerCpu got ignored about that fix., happen fix old issu jobTrackerCpu job tracker cpu got ignor fix fix,0,0,0,0,0,0,1 
3285,Andrii Babiichuk,ambari-web,0,Help Text for NameService ID when enabling HA is random in responding to mouse movement and clicks., help text NameService name servic ID enabl HA random respond mous movement click click,,,0,0,0,0,0,0,0 
3292,Jaimin D Jetly,ambari-web,0,Security wizard: On NameNode HA mode  General category should have spnego principal and keytab field, secur wizard wizard NameNode name node HA mode gener categori spnego princip keytab field,Earlier dfs.web.authentication.kerberos.keytab field was being used for NameNode and SNameNode component. So we planned to pull this key to NameNode category when HA is enabled as it's the only component then using the key.After HDFS-5091 fix  journalNode also uses this key.So instead of pulling this config key in NameNode section  it should be kept in General category and the description of this principal and keytab location field should be changed accordingly., earlier df web authent kerbero keytab df web authent kerbero keytab field use NameNode name node SNameNode name node compon compon plan pull key NameNode name node categori HA enabl compon use key key HDFS HDFS fix journalNode journal node also use key key instead pull config key NameNode name node section kept gener categori descript princip keytab locat field chang accordingli accordingli,0,0,0,0,0,ambari-web/app/controllers/main/admin/security/add/step2.js;ambari-web/app/data/HDP2/secure_mapping.js;ambari-web/app/data/HDP2/secure_properties.js;,0 
3296,Vitaly Brodetskyi,ambari-agent,0,SSH key in logs?, SSH key log log,Notice after agent registration (automatic with SSH key)  I see the SSH key in the popup. Also see it in the ambari-agent.log.Not sure we want to capture this in the log and show in the UI?, notic agent registr automat SSH key key see SSH key popup popup also see ambari agent log not ambari agent log not sure want captur log show UI UI,0,0,0,0,0,0,1 
3301,Mahadev konar,null,0,Unavailable stacks should be hidden., unavail stack hidden hidden,Unavailable stacks should be hidden., unavail stack hidden hidden,0,0,0,0,0,0,1 
3302,Sumit Mohanty,null,0,Parameterize the repo url for latest stack, parameter repo url latest stack,Allow the latest stack repo url to be parameterized for the build. This allows the build to cater to the stack repo as it goes through dev/private/public builds each with different URLs., allow latest stack repo url parameter build build allow build cater stack repo goe dev privat public dev privat public build differ URLs UR Ls,0,0,0,0,0,0,1 
3304,Dmytro Shkvyra,ambari-agent,0,Nagios alert text for NodeManagers should say 'live', nagio alert text NodeManagers node manag say live live,Services &gt; YARNSee screen shot.Should say 'Percent NodeManagers live', servic gt gt YARNSee YARN see screen shot shot say percent percent NodeManagers node manag live live,0,0,0,0,0,0,1 
3307,Oleg Nechiporenko,ambari-web,0,Fix Unit tests and create new test for step3 installer, fix unit test creat new test step step instal,,,0,0,0,0,0,0,1 
3310,Oleg Nechiporenko,ambari-web,0,HDFS service check should not be disabled when NN HA is enabled and one NN is down, HDFS servic check not disabl NN HA enabl one NN,HDFS service check should not be disabled when NN HA is enabled and one NN is down. In fact  service check passing is an indication that NN is available with one NN down., HDFS servic check not disabl NN HA enabl one NN fact servic check pass indic NN avail one NN,0,0,0,0,0,0,1 
3315,Jaimin D Jetly,ambari-web,0,Security wizard: 'Create Principals and Keytabs' step doesn't save state after page refresh, secur wizard wizard creat creat princip keytab keytab step save state page refresh,,,0,0,0,0,0,ambari-web/app/controllers/main/admin/security.js;ambari-web/app/controllers/main/admin/security/add/step2.js;ambari-web/app/controllers/main/admin/security/add/step3.js;ambari-web/app/controllers/main/admin/security/add/step4.js;ambari-web/app/controllers/main/admin/security/disable.js;ambari-web/app/routes/main.js;ambari-web/app/utils/ajax.js;ambari-web/app/utils/db.js;,1 
3318,Yusaku Sako,ambari-web,0,Use correct case for YARN, use correct case YARN,,,0,0,0,0,0,0,1 
3324,Andrii Tkach,ambari-web,0,UI optimization: constrain hostComponents model loading, UI optim optim constrain hostComponents host compon model load,Constrain loading hostComponents into model  so then it loads only on initial loading or when added new hostComponents., constrain load hostComponents host compon model load initi load ad new hostComponents host compon,0,0,0,0,0,ambari-web/app/mappers/service_mapper.js;,1 
3328,Dmitry Lysnichenko,ambari-agent,0,Unit test for agents fail/hang at TestActionQueue and TestStackUpgrade., unit test agent fail hang fail hang TestActionQueue test action queue TestStackUpgrade test stack upgrad,Running mvn test on agent fails/hangs under Mac Os, run mvn test agent fail hang fail hang mac Os,0,0,0,0,0,0,1 
3332,Oleg Nechiporenko,ambari-web,0,switching to Configs tab causes Quick Links to disappear, switch config tab caus quick link disappear,In Ambari Web  browse to HDFS  YARN  MapReduce2  etc. Click on the Configs tab  the Quick Links option disappears.See the same regardless of 1.3.2 or 2.0.6  and tried on Firefox and Chrome, ambari web brows HDFS YARN MapReduce map reduc etc etc click config tab quick link option disappear see disappear see regardless tri firefox chrome,0,0,0,0,0,0,1 
3333,Andrii Tkach,ambari-web,0,'Services'  'Dashboard' 'Navigation errors, servic servic dashboard dashboard navig navig error,Navigation from Hosts to Services page or from Hosts to Dashboard pagesometimes fails (nothing happens besides highlighting 'Services' tab) and sometimes navigates to an empty page.Uncaught Error: assertion failed: calling set on destroyed object ember-latest.js:43Ember.assert ember-latest.js:43set ember-latest.js:1386Ember.Observable.Ember.Mixin.create.set ember-latest.js:7769App.MainServiceMenuView.Em.CollectionView.extend.renderOnRoute menu.js:52invokeAction ember-latest.js:3174iterateSet ember-latest.js:3156sendEvent ember-latest.js:3273notifyObservers ember-latest.js:1865Ember.notifyObservers ember-latest.js:1980propertyDidChange ember-latest.js:2613set ember-latest.js:1419(anonymous function) ember-latest.js:10459f.event.dispatch jquery-1.7.2.min.js:3h.handle.i jquery-1.7.2.min.js:3, navig host servic page host dashboard pagesometim fail noth happen besid highlight servic servic tab tab sometim navig empti page uncaught page uncaught error error assert fail fail call set destroy object ember latest js ember assert ember latest js ember assert ember latest js set ember latest js set ember latest js ember observ ember mixin creat set ember latest js ember observ ember mixin creat set ember latest js app MainServiceMenuView Em CollectionView extend renderOnRoute ember latest js app main servic menu view Em collect view extend render rout menu js invokeAction menu js invok action ember latest js iterateSet ember latest js iter set ember latest js sendEvent ember latest js send event ember latest js notifyObservers ember latest js notifi observ ember latest js ember notifyObservers ember latest js ember notifi observ ember latest js propertyDidChange ember latest js properti chang ember latest js set ember latest js set ember latest js anonym ember latest js anonym function function ember latest js event dispatch ember latest js event dispatch jqueri min js handl jqueri min js handl jqueri min js jqueri min js,0,0,0,0,0,ambari-web/app/app.js;ambari-web/app/views/main/host/summary.js;ambari-web/app/views/main/service/info/summary.js;ambari-web/app/views/wizard/step1_view.js;,1 
3336,Andrii Babiichuk,ambari-web,0,HDFS health status when HA config'd, HDFS health statu HA config config,When NameNode HA is config'd:1) HDFS status green if and only if there is Active NameNode; red otherwise2) green -&gt; HDFS Service Stop enabled  HDFS Service Start disabled. red -&gt; HDFS Service Start enabled  HDFS Service Stop disabled, NameNode name node HA config config HDFS statu green activ NameNode name node red otherwis otherwis green gt gt HDFS servic stop enabl HDFS servic start disabl disabl red gt gt HDFS servic start enabl HDFS servic stop disabl,0,0,0,0,0,ambari-web/app/mappers/status_mapper.js;,1 
3337,Artem Baranchuk,ambari-server; test,0,When invalid jce policy file path is specified  ambari-server setup silently switches over to downloading the file from public repo, invalid jce polici file path specifi ambari server ambari server setup silent switch download file public repo,When an non-existent file is provided as jce-policy parameter we should get ambari-server setup process failed instead of downloading the file from public repo.Also  if the path is a folder then we should gracefully error out instead of allowing shutil.copy to fail with an error stack., non exist non exist file provid jce polici jce polici paramet get ambari server ambari server setup process fail instead download file public repo also repo also path folder grace error instead allow shutil copi shutil copi fail error stack stack,0,0,0,0,0,0,1 
3350,Erin A Boyd,null,0,ambari-agent RPM claims ownership of /usr/sbin, ambari agent ambari agent RPM claim ownership usr sbin usr sbin,*This also affects trunk*The ambari-agent.spec (generated from rpm-maven-plugin) claims ownership of /usr/sbin $ grep sbin target/rpm/ambari-agent/SPECS/ambari-agent.spec | grep attr%attr(755 root root) /usr/sbinThis is a problem because the filesystem RPM owns /usr/sbin.According to rpm-maven-plugin documentation&#91;0&#93;  this is because the only file under /usr/sbin is ambari-agent and'directoryIncludedIf the value is true then the attribute string will be written for the directory if the sources identify all of the files in the directory (that is  no other mapping contributed files to the directory). This is the default behavior.'The 'no other mapping contributed files to the directory' bit is important.The solution is to add directoryInclude=false to the mapping.&#91;0&#93; http://mojo.codehaus.org/rpm-maven-plugin/map-params.html, also affect trunk trunk ambari agent spec ambari agent spec gener rpm maven plugin rpm maven plugin claim ownership usr sbin usr sbin grep sbin target rpm ambari agent SPECS ambari agent spec target rpm ambari agent SPECS ambari agent spec grep attr attr attr attr root root root usr sbinThis usr sbin problem filesystem RPM own usr sbin accord usr sbin accord rpm maven plugin rpm maven plugin document document file usr sbin usr sbin ambari agent ambari agent directoryIncludedIf directori includ valu true attribut string written directori sourc identifi file directori no map contribut file directori directori default behavior behavior no map contribut file directori directori bit import import solut add directoryInclude fals directori includ fals map map,0,0,0,0,0,0,1 
3356,Jaimin D Jetly,ambari-web,0,wrong property name for https address of NN in hdfs-site.xml, wrong properti name http address NN hdf site xml hdf site xml,The property which defines the https address of namenode is dfs.namenode.https-address. In ambari   the property name is mentioned as 'dfs.https.namenode.https-address', properti defin http address namenod df namenod http address df namenod http address ambari properti name mention df http namenod http address df http namenod http address,0,0,0,0,0,ambari-server/src/main/python/UpgradeHelper_HDP2.py;ambari-web/app/data/HDP2/config_mapping.js;,1 
3362,Sumit Mohanty,ambari-server,0,Modify the config mappings in the upgrade script to reflect the latest, modifi config map upgrad script reflect latest,Modify the upgrade mappings for hdfs-site  core-site  mapred-site  and global to reflect the latest., modifi upgrad map hdf site hdf site core site core site mapr site mapr site global reflect latest latest,0,0,0,0,0,0,1 
3363,Jaimin D Jetly,ambari-agent,0,wrong path being set for JSVC_HOME on suse OS in hadoop-env.sh., wrong path set JSVC_HOME JSVC HOME suse OS hadoop env sh hadoop env sh,JSVC_HOME is being set to /usr/lib/hadoop/sbin/Linux-amd64-64/ instead of /usr/lib/bigtop-utils., JSVC_HOME JSVC HOME set usr lib hadoop sbin linux amd usr lib hadoop sbin linux amd instead usr lib bigtop util usr lib bigtop util,0,0,0,0,0,ambari-agent/src/main/puppet/modules/hdp-hadoop/manifests/params.pp;,1 
3397,Oleg Nechiporenko,ambari-web,0,Deploy progress bar is not correct, deploy progress bar not correct,All ajax-requests are completed  but progress bar doesn't filled to 100%., ajax request ajax request complet progress bar fill,0,0,0,0,0,0,1 
3398,Andrii Babiichuk,ambari-web,0,The number of alerts in MapReduce item in menu gets out on the next line., number alert MapReduce map reduc item menu get next line line,STD:Make the browser window's width less than actual width of the page.Go to Services page.Stop all services.Result:The number of alerts in MapReduce item in menu gets out on the next line., STD make STD make browser window window width less actual width page Go page Go servic page stop page stop servic result servic result number alert MapReduce map reduc item menu get next line line,0,0,0,0,0,ambari-web/app/styles/application.less;ambari-web/app/templates/main/service.hbs;,1 
3402,Myroslav Papirkovskyy,ambari-server,0,ambari-server setup silently fails when it cannot connect to the remote oracle host, ambari server ambari server setup silent fail cannot connect remot oracl host,The oracle db was installed on a host where port 1521 was not accessible to the ambari-server host. However  'ambari-server setup' did not report failure.Enter advanced database configuration [y/n] (n)? y==============================================================================Choose one of the following options:[1] - PostgreSQL (Embedded)[2] - Oracle==============================================================================Enter choice (1): 2Hostname (localhost): test-sm1.iad1Port (1521):Select Oracle identifier type:1 - Service Name2 - SID(1):Service Name (ambari): XEUsername (ambari):Enter Database Password (bigdata):Copying JDBC drivers to server resources...Configuring remote database connection properties...Copying JDBC drivers to server resources...Ambari Server 'setup' completed successfully., oracl db instal host port not access ambari server ambari server host host howev ambari server ambari server setup setup not report failur enter failur enter advanc databas configur choos choos one follow option option PostgreSQL postgr SQL embed embed oracl enter oracl enter choic hostnam hostnam localhost localhost test sm iad port test sm iad port select select oracl identifi type type servic name name SID servic SID servic name ambari ambari XEUsername XE usernam ambari enter ambari enter databas password bigdata copi bigdata copi JDBC driver server resourc configur resourc configur remot databas connect properti copi properti copi JDBC driver server resourc ambari resourc ambari server setup setup complet success success,0,0,0,0,0,0,1 
3433,Mahadev konar,null,0,Add hcat.bin to pig.properties for hcat integration, add hcat bin hcat bin pig properti pig properti hcat integr,Add hcat.bin to pig.properties for hcat integration.hcat.bin=/usr/bin/hcat, add hcat bin hcat bin pig properti pig properti hcat integr hcat bin usr bin hcat integr hcat bin usr bin hcat,0,0,0,0,0,0,1 
3434,Yusaku Sako,ambari-web,0,On 2.x stack  dfs.block.local-path-access.user should not be set in hdfs-site, stack df block local path access user df block local path access user not set hdf site hdf site,,,0,0,0,0,0,0,1 
3435,Jaimin D Jetly,ambari-web,0,YARN cluster should not have shared directories between yarn.nodemanager.local-dirs and yarn.nodemanager.log-dirs, YARN cluster not share directori yarn nodemanag local dir yarn nodemanag local dir yarn nodemanag log dir yarn nodemanag log dir,,,0,0,0,0,0,ambari-server/src/main/resources/stacks/HDP/2.0.5/services/YARN/configuration/yarn-site.xml;ambari-server/src/main/resources/stacks/HDP/2.0.6/services/YARN/configuration/yarn-site.xml;ambari-server/src/main/resources/stacks/HDPLocal/2.0.5/services/YARN/configuration/yarn-site.xml;ambari-server/src/main/resources/stacks/HDPLocal/2.0.6/services/YARN/configuration/yarn-site.xml;ambari-web/app/data/HDP2/config_mapping.js;ambari-web/app/data/HDP2/global_properties.js;ambari-web/app/data/HDP2/site_properties.js;ambari-web/app/models/service_config.js;,1 
3437,Siddharth Wagle,ambari-agent,0,Incorrect alert for NodeManager, incorrect alert NodeManager node manag,Error with RM nagios alert for rpc latency.[1380746845] SERVICE NOTIFICATION: nagiosadmin;&lt;hostaname&gt;;RESOURCEMANAGER::ResourceManager RPC latency;CRITICAL;notify-service-by-email;CRITICAL: Data inaccessible  Status code = 200, error RM nagio alert rpc latenc latenc SERVICE NOTIFICATION NOTIFICATION nagiosadmin lt hostanam gt RESOURCEMANAGER ResourceManager nagiosadmin lt hostanam gt RESOURCEMANAGER resourc manag RPC latenc CRITICAL notifi servic email CRITICAL latenc CRITICAL notifi servic email CRITICAL data inaccess statu code,0,0,0,0,0,0,1 
3443,Oleg Nechiporenko,null,0,'Assign Slaves and Clients' step. 'all | none' click error, assign assign slave client client step step none none click error,Clicking on 'all|none' affects disabled checkboxes., click none none affect disabl checkbox checkbox,0,0,0,0,0,0,1 
3446,Andrii Babiichuk,ambari-web,0,When SSL is enabled on Hadoop JMX endpoints ResourceManager quick links become unavailable, SSL enabl hadoop JMX endpoint ResourceManager resourc manag quick link becom unavail,When hadoop.ssl.enabled=true  ResourceManager port is 8090. When it is false  the port is still 8088., hadoop ssl enabl true hadoop ssl enabl true ResourceManager resourc manag port fals port still,0,0,0,0,0,ambari-web/app/assets/test/tests.js;ambari-web/app/models/quick_links.js;ambari-web/app/views/common/quick_view_link_view.js;ambari-web/test/views/common/quick_link_view_test.js;,1 
3456,Andrii Babiichuk,ambari-web,0,Text of installation stage doesn't correspond to reality, text instal stage correspond realiti,STD:On the latter stages of installing cluster  refresh page 'Install  Start and Test'..Result:Appeared 'Next' button and progress of installation is setted to 100%  but message of installation on the second host says that the Nagios Server is not installed yet. After clicking 'Next' all seems good and Nagios Server is installed normally., STD STD latter stage instal cluster refresh page instal instal start test result appear test result appear next next button progress instal set messag instal second host say nagio server not instal yet yet click next next seem good nagio server instal normal normal,0,0,0,0,0,ambari-web/app/controllers/wizard/step9_controller.js;,1 
3457,Yusaku Sako,ambari-web,0,When multiple MR2 Clients are installed  the label is a bit off, multipl MR MR client instal label bit,When multiple MR2 Clients are installed  the MR2 summary panel has a label like: '3 MapReduce2 Client s Installed' (with an unnecessary space), multipl MR MR client instal MR MR summari panel label like like MapReduce map reduc client instal instal unnecessari space space,0,0,0,0,0,0,1 
3477,Andrii Tkach,ambari-web,0,JavaScript errors during service tab changing, JavaScript java script error servic tab chang,Steps:Open browser console.Run start or stop operation for any service.Switch between some services repeatedly.Result:'Calling set on destroyed view' was appeared in console., step open step open browser consol run consol run start stop oper servic switch servic switch servic repeatedli result call repeatedli result call set destroy view view appear consol consol,0,0,0,0,0,ambari-web/app/app.js;,1 
3488,Andrii Tkach,ambari-web,0,Status does not show up for newly added hosts, statu not show newli ad host,The problem is that host can have actual status only when service mapper recieve response(could be long latency  about 10 - 12 seconds) with new hostComponents and then status mapper compute them and set status to host., problem host actual statu servic mapper reciev respons could respons could long latenc second second new hostComponents host compon statu mapper comput set statu host host,0,0,0,0,0,ambari-web/app/mappers/status_mapper.js;,1 
3490,Dmitry Lysnichenko,ambari-agent,0,Remove RCO management logic at ambari-agent, remov RCO manag logic ambari agent ambari agent,In 1.5.0 release  ambari-agent will not need to process RCO to re-order/parallelizing tasks. Let's remove the code/unit-test and keep them aside in a JIRA targeted for release after 1.5.0. If possible  let's remove upgrade related code as well as there is no plan for automatic stack upgrade for Baikal. We can keep the python executor as there is a requirement for python executor., releas ambari agent ambari agent not need process RCO order parallel order parallel task task let let remov code unit test code unit test keep asid JIRA target releas possibl let let remov upgrad relat code well no plan automat stack upgrad baikal baikal keep python executor requir python executor executor,0,0,0,0,0,0,1 
3491,Jaimin D Jetly,ambari-web,0,HBase Master/RegionServer can no longer be started after reconfiguring HBase or HDFS with NameNode HA enabled, HBase base master RegionServer master region server no longer start reconfigur HBase base HDFS NameNode name node HA enabl,,,0,0,0,0,0,ambari-web/app/controllers/wizard/step8_controller.js;ambari-web/app/data/HDP2/config_mapping.js;ambari-web/app/utils/config.js;,1 
3498,Jaimin D Jetly,ambari-web,0,Hbase secure config properties in HDP-2.x stack revert back to non-secure values on reconfiguration, hbase secur config properti HDP HDP stack revert back non secur non secur valu reconfigur,,,0,0,0,0,0,ambari-web/app/data/HDP2/config_mapping.js;,1 
3507,Oleg Nechiporenko,ambari-web,0,'Assign Slaves' step. Error with installed NodeManagers, assign assign slave slave step step error instal NodeManagers node manag,Installed NodeManagers don't appears as selected checkboxes on the 'Assign Slaves' step., instal NodeManagers node manag appear select checkbox assign assign slave slave step step,0,0,0,0,0,0,0 
3512,Sumit Mohanty,null,0,Nagios doesn't start after upgrade [SLES11  1.3.2->2.0.6], nagio start upgrad SLES SLES,check_cpu needs to be disabled for Suse for JobHistory server and ResourceManager, check_cpu need disabl suse JobHistory job histori server ResourceManager resourc manag,0,0,0,0,0,0,0 
3521,Andrii Babiichuk,ambari-web,0,Incorrect status counters on cluster deploy, incorrect statu counter cluster deploy,In host stauts filter label shows incorrect number of hosts after deploy failed.Wrong progress bar color  on fail color should be red or yellow  instead of blue., host staut filter label show incorrect number host deploy fail wrong fail wrong progress bar color fail color red yellow instead blue blue,0,0,0,0,0,ambari-web/app/controllers/wizard/step9_controller.js;ambari-web/app/messages.js;,0 
3528,Oleg Nechiporenko,ambari-web,0,DB url isn't calculated automatically, DB url calcul automat,Select Hive or Oozie and go to step 'Customize services'.'Open' Oozie tab.Database Url is 'jdbc'.Click 'Existing MySQL Database'.Click 'New Derby Database'.Database Url became jdbc:derby:${oozie.data.dir}/${oozie.db.schema.name}-db;create=true.Expect:proper value should be right after step is loaded., select hive oozi go step custom custom servic open servic open oozi tab databas tab databas url jdbc click jdbc click exist exist MySQL SQL databas click databas click new new derbi databas databas databas databas url becam jdbc derbi oozi data dir oozi db schema name db creat true expect proper jdbc derbi oozi data dir oozi db schema name db creat true expect proper valu right step load load,0,0,0,0,0,0,0 
3534,Artem Baranchuk,ambari-server; test,0,Hadoop Core Health Check script needs to be included in Ambari HDP installations, hadoop core health check script need includ ambari HDP instal,,,0,0,0,0,0,0,0 
3535,Oleg Nechiporenko,ambari-web,0,skip 'Customize Services' step for services that can't be customized, skip custom custom servic servic step servic custom,Services like PIG  Sqoop can't be customized.Wizard should check services-list (that user want to add) and if no one service can't be customized  should skip 'Customize' step ('Back' click on the next step should also be verified)., servic like PIG sqoop custom wizard custom wizard check servic list servic list user want add add no one servic custom skip custom custom step back back click next step also verifi verifi,0,0,0,0,0,0,0 
3537,Dmytro Sen,ambari-agent,0,Allow log4j properties to be applied via the API in Ambari for hadoop/oozie/hbase/hive/zookeeper/pig, allow log log properti appli via API ambari hadoop oozi hbase hive zookeep pig hadoop oozi hbase hive zookeep pig,Allow log4j properties to be applied via the API in Ambari for hadoop/oozie/hbase/hive/zookeeper/pig., allow log log properti appli via API ambari hadoop oozi hbase hive zookeep pig hadoop oozi hbase hive zookeep pig,0,0,0,0,0,ambari-agent/src/main/python/resource_management/libraries/providers/__init__.py;ambari-agent/src/main/python/resource_management/libraries/providers/properties_file.py;ambari-agent/src/main/python/resource_management/libraries/resources/__init__.py;ambari-agent/src/main/python/resource_management/libraries/resources/properties_file.py;ambari-server/src/main/resources/stacks/HDP/1.3.3/hooks/before-START/scripts/params.py;ambari-server/src/main/resources/stacks/HDP/1.3.3/hooks/before-START/scripts/shared_initialization.py;ambari-server/src/main/resources/stacks/HDP/1.3.3/hooks/before-START/templates/log4j.properties.j2;ambari-server/src/main/resources/stacks/HDP/1.3.3/services/HBASE/configuration/hbase-log4j.xml;ambari-server/src/main/resources/stacks/HDP/1.3.3/services/HBASE/metainfo.xml;ambari-server/src/main/resources/stacks/HDP/1.3.3/services/HBASE/package/scripts/hbase.py;ambari-server/src/main/resources/stacks/HDP/1.3.3/services/HBASE/package/scripts/params.py;ambari-server/src/main/resources/stacks/HDP/1.3.3/services/HDFS/configuration/hdfs-log4j.xml;ambari-server/src/main/resources/stacks/HDP/1.3.3/services/HDFS/metainfo.xml;ambari-server/src/main/resources/stacks/HDP/1.3.3/services/HIVE/configuration/hive-exec-log4j.xml;ambari-server/src/main/resources/stacks/HDP/1.3.3/services/HIVE/configuration/hive-log4j.xml;ambari-server/src/main/resources/stacks/HDP/1.3.3/services/HIVE/metainfo.xml;ambari-server/src/main/resources/stacks/HDP/1.3.3/services/HIVE/package/scripts/hive.py;ambari-server/src/main/resources/stacks/HDP/1.3.3/services/HIVE/package/scripts/params.py;ambari-server/src/main/resources/stacks/HDP/1.3.3/services/MAPREDUCE/configuration/mapreduce-log4j.xml;ambari-server/src/main/resources/stacks/HDP/1.3.3/services/MAPREDUCE/metainfo.xml;ambari-server/src/main/resources/stacks/HDP/1.3.3/services/OOZIE/configuration/oozie-log4j.xml;ambari-server/src/main/resources/stacks/HDP/1.3.3/services/OOZIE/metainfo.xml;ambari-server/src/main/resources/stacks/HDP/1.3.3/services/OOZIE/package/scripts/oozie.py;ambari-server/src/main/resources/stacks/HDP/1.3.3/services/OOZIE/package/scripts/params.py;ambari-server/src/main/resources/stacks/HDP/1.3.3/services/OOZIE/package/templates/oozie-log4j.properties.j2;ambari-server/src/main/resources/stacks/HDP/1.3.3/services/PIG/configuration/pig-log4j.xml;ambari-server/src/main/resources/stacks/HDP/1.3.3/services/PIG/metainfo.xml;ambari-server/src/main/resources/stacks/HDP/1.3.3/services/PIG/package/scripts/params.py;ambari-server/src/main/resources/stacks/HDP/1.3.3/services/PIG/package/scripts/pig.py;ambari-server/src/main/resources/stacks/HDP/1.3.3/services/PIG/package/templates/log4j.properties.j2;ambari-server/src/main/resources/stacks/HDP/1.3.3/services/ZOOKEEPER/configuration/zookeeper-log4j.xml;ambari-server/src/main/resources/stacks/HDP/1.3.3/services/ZOOKEEPER/metainfo.xml;ambari-server/src/main/resources/stacks/HDP/1.3.3/services/ZOOKEEPER/package/scripts/params.py;ambari-server/src/main/resources/stacks/HDP/1.3.3/services/ZOOKEEPER/package/scripts/zookeeper.py;ambari-server/src/main/resources/stacks/HDP/1.3.3/services/ZOOKEEPER/package/templates/log4j.properties.j2;ambari-server/src/main/resources/stacks/HDP/2.1.1/hooks/before-START/scripts/params.py;ambari-server/src/main/resources/stacks/HDP/2.1.1/hooks/before-START/scripts/shared_initialization.py;ambari-server/src/main/resources/stacks/HDP/2.1.1/hooks/before-START/templates/log4j.properties.j2;ambari-server/src/main/resources/stacks/HDP/2.1.1/services/HBASE/configuration/hbase-log4j.xml;ambari-server/src/main/resources/stacks/HDP/2.1.1/services/HBASE/metainfo.xml;ambari-server/src/main/resources/stacks/HDP/2.1.1/services/HBASE/package/scripts/hbase.py;ambari-server/src/main/resources/stacks/HDP/2.1.1/services/HBASE/package/scripts/params.py;ambari-server/src/main/resources/stacks/HDP/2.1.1/services/HDFS/configuration/hdfs-log4j.xml;ambari-server/src/main/resources/stacks/HDP/2.1.1/services/HDFS/metainfo.xml;ambari-server/src/main/resources/stacks/HDP/2.1.1/services/HIVE/configuration/hive-exec-log4j.xml;ambari-server/src/main/resources/stacks/HDP/2.1.1/services/HIVE/configuration/hive-log4j.xml;ambari-server/src/main/resources/stacks/HDP/2.1.1/services/HIVE/metainfo.xml;ambari-server/src/main/resources/stacks/HDP/2.1.1/services/HIVE/package/scripts/hive.py;ambari-server/src/main/resources/stacks/HDP/2.1.1/services/HIVE/package/scripts/params.py;ambari-server/src/main/resources/stacks/HDP/2.1.1/services/OOZIE/configuration/oozie-log4j.xml;ambari-server/src/main/resources/stacks/HDP/2.1.1/services/OOZIE/metainfo.xml;ambari-server/src/main/resources/stacks/HDP/2.1.1/services/OOZIE/package/scripts/oozie.py;ambari-server/src/main/resources/stacks/HDP/2.1.1/services/OOZIE/package/scripts/params.py;ambari-server/src/main/resources/stacks/HDP/2.1.1/services/PIG/configuration/pig-log4j.xml;ambari-server/src/main/resources/stacks/HDP/2.1.1/services/PIG/metainfo.xml;ambari-server/src/main/resources/stacks/HDP/2.1.1/services/PIG/package/scripts/params.py;ambari-server/src/main/resources/stacks/HDP/2.1.1/services/PIG/package/scripts/pig.py;ambari-server/src/main/resources/stacks/HDP/2.1.1/services/PIG/package/templates/log4j.properties.j2;ambari-server/src/main/resources/stacks/HDP/2.1.1/services/YARN/configuration/yarn-log4j.xml;ambari-server/src/main/resources/stacks/HDP/2.1.1/services/YARN/metainfo.xml;ambari-server/src/main/resources/stacks/HDP/2.1.1/services/ZOOKEEPER/configuration/zookeeper-log4j.xml;ambari-server/src/main/resources/stacks/HDP/2.1.1/services/ZOOKEEPER/metainfo.xml;ambari-server/src/main/resources/stacks/HDP/2.1.1/services/ZOOKEEPER/package/scripts/params.py;ambari-server/src/main/resources/stacks/HDP/2.1.1/services/ZOOKEEPER/package/scripts/zookeeper.py;ambari-server/src/main/resources/stacks/HDP/2.1.1/services/ZOOKEEPER/package/templates/log4j.properties.j2;,0 
3553,Jaimin D Jetly,ambari-web,0,NameNode HA wizard: Refreshing the wizard displays incorrect manual commands., NameNode name node HA wizard wizard refresh wizard display incorrect manual command command,Install HDFS with customized hostname hdfs1. Start NameNode HA wizard and Refresh on step-2 (select host). Proceed ahead. Create checkpoint step asks to run command with incorrect user name:sudo su -l hdfs -c 'hdfs dfsadmin -safemode enter' Above command returns safemode: Access denied for user hdfs. Superuser privilege is required Actual command should be:sudo su -l hdfs1 -c 'hdfs dfsadmin -safemode enter', instal HDFS custom hostnam hdf hdf start NameNode name node HA wizard refresh step step select host host proce ahead ahead creat checkpoint step ask run command incorrect user name sudo name sudo su hdf hdf dfsadmin safemod enter enter command return safemod safemod access deni user hdf hdf superus privileg requir actual command sudo sudo su hdf hdf hdf dfsadmin safemod enter enter,0,0,0,0,0,0,1 
3569,Oleg Nechiporenko,ambari-web,0,'Config' step refresh, config config step refresh,Go to Config Step on the addServiceWizard.Refresh page.Got JS error  because selected services where not saved.Expect: get page with config list for selected services., Go config step addServiceWizard refresh add servic wizard refresh page got page got JS error select servic not save expect save expect get page config list select servic servic,0,0,0,0,0,0,0 
3582,Srimanth Gunturi,ambari-web,0,Cleanup UI restart calculations using actual_configs, cleanup UI restart calcul use actual_configs,As documented in AMBARI-3531  the restart flags will be provided in host_components itself and services will have an API to get restart host_components easily. Due to this  there is no need for actual_configs on the client  and the code to calculate diffs with global properties., document AMBARI AMBARI restart flag provid host_components servic API get restart host_components easili easili due no need actual_configs client code calcul diff global properti properti,0,0,0,0,0,0,1 
3584,Jaimin D Jetly,ambari-web,0,Reassign Master: Misc UI display fixes, reassign master master misc UI display fix,This ticket mainly covers UI label and message changes in reassign master wizard., ticket mainli cover UI label messag chang reassign master wizard wizard,0,0,0,0,0,ambari-web/app/config.js;ambari-web/app/controllers/main/service/reassign/step4_controller.js;ambari-web/app/controllers/main/service/reassign/step6_controller.js;ambari-web/app/messages.js;ambari-web/app/templates/main/admin/highAvailability/progress.hbs;ambari-web/app/templates/main/service/reassign/step1.hbs;ambari-web/app/views/main/service/reassign/step1_view.js;ambari-web/app/views/main/service/reassign/step4_view.js;ambari-web/app/views/main/service/reassign/step6_view.js;,1 
3589,Oleg Nechiporenko,ambari-web,0,Common storage for different wizards, common storag differ wizard,Some wizards (installer  addHosts  addServices) use common local storage objects.But each should has separated object (for example  based on controllerName)., wizard instal addHosts add host addServices add servic use common local storag object object separ object exampl base controllerName control name,0,0,0,0,0,0,1 
3594,Jaimin D Jetly,ambari-web,0,Service reconfiguration fails for multiple services, servic reconfigur fail multipl servic,Service reconfiguration fails for HDFS  MapReduce and Hive service with js error. For other services it fails silently without any error (no API call is triggered)., servic reconfigur fail HDFS MapReduce map reduc hive servic js error error servic fail silent without error no API call trigger trigger,0,0,0,0,0,ambari-web/app/controllers/main/service/info/configs.js;ambari-web/app/controllers/main/service/reassign_controller.js;ambari-web/app/utils/config.js;ambari-web/app/views/wizard/controls_view.js;,1 
3609,Trevor McKay,ambari-agent,0,os_type_check.sh for RHEL is too restrictive (Server vs Workstation), os_type_check sh os_type_check sh RHEL restrict server server vs workstat workstat,The /etc/redhat-release on my RHEL6.4 dev box containsRed Hat Enterprise Linux Workstation release 6.4 (Santiago)os_type_check.sh is checking for 'Server' on rhel boxes. It should simply check for Red Hat Enterprise Linux and ignore text up to the version number., etc redhat releas etc redhat releas RHEL RHEL dev box containsRed contain red hat enterpris linux workstat releas santiago os_type_check sh santiago os_type_check sh check server server rhel box box simpli check red hat enterpris linux ignor text version number number,0,0,0,0,0,0,1 
3613,Antonenko Alexander,ambari-web,0,Enable HA wizard loads after sign in, enabl HA wizard load sign,Steps: Go to 'Admin' page -&gt; 'High Availability' tab and run 'Enable NameNode HA' wizard. Close wizard. Sign out (or reopen browser). Sign in.Result:After sign in was opened first page of 'Enable NameNode HA' wizard instead 'Dashboard' page., step step Go admin admin page gt gt high high avail avail tab run enabl enabl NameNode name node HA HA wizard wizard close wizard wizard sign reopen browser browser sign result result sign open first page enabl enabl NameNode name node HA HA wizard instead dashboard dashboard page page,0,0,0,0,0,0,0 
3615,Dmytro Sen,ambari-agent,0,Ambari agent creates empty folder /var/ambari-agent, ambari agent creat empti folder var ambari agent var ambari agent,Ambari agent creates an empty directory /var/ambari-agent during installation.This directory isn't needed  /var/run/ambari-agent is used instead., ambari agent creat empti directori var ambari agent var ambari agent instal instal directori need var run ambari agent var run ambari agent use instead instead,0,0,0,0,0,0,1 
3618,Xi Wang,ambari-web,0,host actions UI changes based on new stop/start all and delete func, host action UI chang base new stop start stop start delet func,1. Do the right-float on the action menus on the Components section.2. Rename buttons: on SERVICE PAGES: Maintenance --&gt;Service Actions...on HOST PAGES: Maintenance --&gt; Host Actions...on HOST PAGES / COMPONENT SECTION: Actions --&gt; Actions..., right float right float action menu compon section section renam button button SERVICE PAGES PAGES mainten gt servic gt servic action action HOST PAGES PAGES mainten gt gt host action action HOST PAGES COMPONENT SECTION SECTION action gt gt action action,0,0,0,0,0,0,1 
3621,Andrii Babiichuk,ambari-web,0,cleanup dialog for unable to delete host, cleanup dialog unabl delet host,make dialog according to left mockup, make dialog accord left mockup,0,0,0,0,0,ambari-web/app/messages.js;ambari-web/app/templates/main/host/details/raiseDeleteComponentErrorPopup.hbs;,1 
3623,Artem Baranchuk,ambari-agent; test,0,LiveStatus of the component is not updated when username is changed, LiveStatus live statu compon not updat usernam chang,Steps to reproduce: On installer wizard  make install phase fail by killing any install task of master component. Go back and change hdfs username to hdfs1. Proceed ahead and installer wizard completes successfully. HDFS service is red. Nagios shows no alerts  but API returns INSTALLED status for all hdfs host components. UI impact: On starting HDFS  all tasks completes successfully with 100% green progress bar but service status always remains red. Restarting agent resolves the issue.Looks like AmbariConfig.servicesToPidNames is not getting updated when username is changed., step reproduc reproduc instal wizard make instal phase fail kill instal task master compon compon Go back chang hdf usernam hdf hdf proce ahead instal wizard complet success success HDFS servic red red nagio show no alert API return INSTALLED statu hdf host compon compon UI impact impact start HDFS task complet success green progress bar servic statu alway remain red red restart agent resolv issu look issu look like AmbariConfig servicesToPidNames ambari config servic pid name not get updat usernam chang chang,0,0,0,0,0,0,1 
3631,Dmytro Shkvyra,ambari-agent,0,traceback when attempting to stop ambari-agent as non-root, traceback attempt stop ambari agent ambari agent non root non root,I attempted to stop the ambari-agent without going to root first. Prints a pretty bad traceback.&#91;vagrant@c6403 ~&#93;$ ambari-agent stop/usr/sbin/ambari-agent: line 66: /var/lib/ambari-agent/ambari-env.sh: Permission deniedVerifying Python version compatibility...Using python /usr/bin/python2.6Found ambari-agent PID: 2996Stopping ambari-agentTraceback (most recent call last):File '/usr/lib/python2.6/site-packages/ambari_agent/main.py'  line 235  in &lt;module&gt;main()File '/usr/lib/python2.6/site-packages/ambari_agent/main.py'  line 190  in mainsetup_logging(options.verbose)File '/usr/lib/python2.6/site-packages/ambari_agent/main.py'  line 73  in setup_loggingrotateLog = logging.handlers.RotatingFileHandler(logfile  'a'  10000000  25)File '/usr/lib64/python2.6/logging/handlers.py'  line 112  in initBaseRotatingHandler.init(self  filename  mode  encoding  delay)File '/usr/lib64/python2.6/logging/handlers.py'  line 64  in initlogging.FileHandler.init(self  filename  mode  encoding  delay)File '/usr/lib64/python2.6/logging/init.py'  line 827  in __initStreamHandler.init(self  self._open())File '/usr/lib64/python2.6/logging/init.py'  line 846  in _openstream = open(self.baseFilename  self.mode)IOError: &#91;Errno 13&#93; Permission denied: '/var/log/ambari-agent/ambari-agent.log'Removing PID file at /var/run/ambari-agent/ambari-agent.pidrm: cannot remove '/var/run/ambari-agent/ambari-agent.pid': Permission deniedambari-agent successfully stopped, attempt stop ambari agent ambari agent without go root first first print pretti bad traceback vagrant traceback vagrant ambari agent ambari agent stop usr sbin ambari agent stop usr sbin ambari agent line var lib ambari agent ambari env sh var lib ambari agent ambari env sh permiss deniedVerifying deni verifi python version compat use compat use python usr bin python found usr bin python found ambari agent ambari agent PID PID stop stop ambari agentTraceback ambari agent traceback recent call last file last file usr lib python site packag ambari_agent main py usr lib python site packag ambari_agent main py line lt modul gt main file lt modul gt main file usr lib python site packag ambari_agent main py usr lib python site packag ambari_agent main py line mainsetup_logging option verbos file mainsetup_logging option verbos file usr lib python site packag ambari_agent main py usr lib python site packag ambari_agent main py line setup_loggingrotateLog setup_loggingrotate log log handler RotatingFileHandler logfil log handler rotat file handler logfil file file usr lib python log handler py usr lib python log handler py line initBaseRotatingHandler init self init base rotat handler init self filenam mode encod delay file delay file usr lib python log handler py usr lib python log handler py line initlog FileHandler init self initlog file handler init self filenam mode encod delay file delay file usr lib python log init py usr lib python log init py line __initStreamHandler init self __init stream handler init self self _open file self _open file usr lib python log init py usr lib python log init py line _openstream open self baseFilename open self base filenam self mode IOError self mode IO error errno errno permiss deni deni var log ambari agent ambari agent log remov var log ambari agent ambari agent log remov PID file var run ambari agent ambari agent pidrm var run ambari agent ambari agent pidrm cannot remov var run ambari agent ambari agent pid var run ambari agent ambari agent pid permiss deniedambari agent deniedambari agent success stop,0,0,0,0,0,0,1 
3645,Xi Wang,ambari-web,0,HA cluster: some dashboard's widgets contain 'Null'  'NaN' values after services stop, HA cluster cluster dashboard dashboard widget contain null null NaN Na valu servic stop,Steps:Stop YARN service.Go to 'Dashboard'.Result:'NodeManagers Live' widget contains 'null' values.Similar problem is present for 'HBase Ave Load' widget - 'NaN' value., step stop step stop YARN servic Go servic Go dashboard result NodeManagers dashboard result node manag live live widget contain null null valu similar valu similar problem present HBase base ave load load widget NaN Na valu valu,0,0,0,0,0,0,1 
3648,Vitaly Brodetskyi,ambari-agent,0,Failed to start Hive Metastore (centos5.8  Stack 2.0), fail start hive metastor cento cento stack,Occurred during install as warning (could not start the service). Clicked next to continue  when into Ambari  then tried to start Hive there as well  same issue., occur instal warn could not start servic servic click next continu ambari tri start hive well issu issu,0,0,0,0,0,0,0 
3650,Andrii Tkach,ambari-web,0,Poll for host_components which have stale_configs, poll host_components stale_configs,UI needs to know which host_components need restart due to stale_configs (saved but not picked up). Server API provide stale_configs flag per host-component. We need this polled and maintained on client model., UI need know host_components need restart due stale_configs save not pick server API provid stale_configs flag per host compon host compon need poll maintain client model model,0,0,0,0,0,ambari-web/app/assets/data/services/host_component_stale_configs.json;ambari-web/app/controllers/global/cluster_controller.js;ambari-web/app/controllers/global/update_controller.js;ambari-web/app/controllers/main/service/info/configs.js;ambari-web/app/initialize.js;ambari-web/app/mappers/component_config_mapper.js;ambari-web/app/models/service.js;ambari-web/app/views/main/host/summary.js;,1 
3674,Srimanth Gunturi,ambari-web,0,UI does not update active hbase master in display, UI not updat activ hbase master display,When we have 3 HBase masters we show in UI that one of them is active. When the master is stopped  the other HBase master is not marked as active in UI. In API it does become active., HBase base master show UI one activ activ master stop HBase base master not mark activ UI UI API becom activ activ,0,0,0,0,0,0,1 
3675,Jaimin D Jetly,ambari-web,0,Default value of 'Default virtual memory for a job's map-task' is not valid, default valu default default virtual memori job job map task map task not valid,The default value of 'Default virtual memory for a job's map-task' (in Customize Services page -&gt; MapReduce2 tab -&gt; General) was '619.5'.Warning hint says 'Must contain digits only'Value depends on quantity of installed components., default valu default default virtual memori job job map task map task custom servic page gt gt MapReduce map reduc tab gt gt gener gener warn warn hint say must must contain digit valu valu depend quantiti instal compon compon,0,0,0,0,0,ambari-web/app/controllers/wizard/step7_controller.js;ambari-web/app/utils/config.js;ambari-web/app/utils/defaults_providers/yarn_defaults_provider.js;ambari-web/app/utils/helper.js;ambari-web/app/utils/string_utils.js;,1 
3679,Dmytro Shkvyra,ambari-agent,0,Better error message needed when incompatible ambari-agents installed, better error messag need incompat ambari agent ambari agent instal,On a few days old cluster I attempted to add a host. The add host failed due to ambari-server trying to install ambari-agent-1.4.1.17 and the repo having ambari-agent-1.4.1.23-1.The message in /var/run/ambari-server/bootstrap/11/hostname.log was:STDERRscp /usr/lib/python2.6/site-packages/ambari_server/setupAgent.py done for host srimanth1-5.c.pramod-thangali.internal  exitcode=0Copying files finishedRunning setup agent...STDOUTError: Nothing to do{'exitstatus': 1  'log': ('Loaded plugins: downloadonly  fastestmirror  security/nDetermining fastest mirrors/n * base: www.gtlib.gatech.edu/n * extras: centos.mirror.netriplex.com/n * updates: mirror.cogentco.com/nSetting up Install Process/nNo package ambari-agent-1.4.1.17 available./n'  None)}, day old cluster attempt add host host add host fail due ambari server ambari server tri instal ambari agent ambari agent repo ambari agent ambari agent messag var run ambari server bootstrap hostnam log var run ambari server bootstrap hostnam log STDERRscp STDER rscp usr lib python site packag ambari_server setupAgent py usr lib python site packag ambari_server setup agent py done host srimanth pramod thangali intern srimanth pramod thangali intern exitcod copi exitcod copi file finishedRunning finish run setup agent STDOUTError agent STDOUT error noth exitstatu exitstatu log log load load plugin plugin downloadonli fastestmirror secur nDetermining secur determin fastest mirror mirror base base www gtlib gatech edu www gtlib gatech edu extra extra cento mirror netriplex com cento mirror netriplex com updat updat mirror cogentco com nSetting mirror cogentco com set instal process nNo process No packag ambari agent ambari agent avail avail none none,0,0,0,0,0,0,1 
3686,Antonenko Alexander,ambari-web,0,NameNode HA wizard (Configure Components step): Task 'Reconfigure HDFS' always fail  and user cannot proceed to next step, NameNode name node HA wizard configur configur compon step step task reconfigur reconfigur HDFS HDFS alway fail user cannot proceed next step,This task fails due to bad request:/api/v1/clusters/c1/hosts/HDFS_CLIENT/host_components/dev01.hortonworks.comShould be: api/v1/clusters/c1/hosts/dev01.hortonworks.com/host_components/HDFS_CLIENT, task fail due bad request api cluster host HDFS_CLIENT host_components dev hortonwork comShould request api cluster host HDFS CLIENT host_components dev hortonwork com api cluster host dev hortonwork com host_components HDFS_CLIENT api cluster host dev hortonwork com host_components HDFS CLIENT,0,0,0,0,0,0,0 
3690,Yusaku Sako,ambari-web,0,Typo in text label on Hosts page, typo text label host page,On the Hosts page  we have a typo in the label 'filterd'. Should be 'filtered'., host page typo label filterd filterd filter filter,0,0,0,0,0,0,1 
3695,Dmytro Shkvyra,ambari-agent,0,'Confirm hosts' shows 'ntpd not running' warning  but it's running on host, confirm confirm host host show ntpd not run run warn run host,STR: Install  setup and start Ambari server by default. Reach 'Choose services' phase of installer.Actual result:'Confirm hosts' shows warning that ntpd service isn't running on hosts  but it's running in console by command service ntpd status, STR STR instal setup start ambari server default default reach choos choos servic servic phase instal actual instal actual result confirm result confirm host host show warn ntpd servic run host run consol command servic ntpd statu,0,0,0,0,0,0,1 
3701,Dmytro Shkvyra,ambari-server,0,Reduce logs emitted to report heartbeats from agents, reduc log emit report heartbeat agent,For a 657 node cluster:~10 minute for 10 MB and 20 log files store about 200 minutes (~3 hours) of log. This is not ideal if an error overnight needs to be investigated. We should try for the log to last 24 hours - ideally 72 hours to account for weekends.-rw-r--r-- 1 root root 10485854 Oct 17 17:35 ambari-server.log.6-rw-r--r-- 1 root root 10485836 Oct 17 17:44 ambari-server.log.5-rw-r--r-- 1 root root 10485811 Oct 17 17:52 ambari-server.log.4-rw-r--r-- 1 root root 10485793 Oct 17 18:01 ambari-server.log.3-rw-r--r-- 1 root root 10485793 Oct 17 18:10 ambari-server.log.2-rw-r--r-- 1 root root 10485854 Oct 17 18:18 ambari-server.log.1, node cluster cluster minut MB log file store minut hour hour log log not ideal error overnight need investig investig tri log last hour ideal hour account weekend rw weekend rw root root oct ambari server log rw ambari server log rw root root oct ambari server log rw ambari server log rw root root oct ambari server log rw ambari server log rw root root oct ambari server log rw ambari server log rw root root oct ambari server log rw ambari server log rw root root oct ambari server log ambari server log,0,0,0,0,0,0,1 
3708,Srimanth Gunturi,ambari-web,0,Reconfigure of dynamic configs not showing modified values, reconfigur dynam config not show modifi valu,Modifications of dynamic properties are being persisted on server  but default values are being shown in UI. Also  we should not validate dynamic configs which are of type string. mapreduce.map.java.opts mapreduce.reduce.java.opts yarn.app.mapreduce.am.command-opts, modif dynam properti persist server default valu shown UI UI also not valid dynam config type string string mapreduc map java opt mapreduc map java opt mapreduc reduc java opt mapreduc reduc java opt yarn app mapreduc command opt yarn app mapreduc command opt,0,0,0,0,0,0,1 
3713,Oleg Nechiporenko,ambari-web,0,When filtering on hosts  the table column sizes shift  should stay fixed., filter host tabl column size shift stay fix fix,For the 'defaultsProvider' and 'serviceValidator' functionalities  we need unit tests, defaultsProvider default provid serviceValidator servic valid function need unit test,0,0,0,0,0,0,1 
3715,Antonenko Alexander,ambari-web,0,Reassign Master Wizard does not display folder and hosts on 'Manual commands' page after browser reopening, reassign master wizard not display folder host manual manual command command page browser reopen,Steps: Open 'Reassign Master Wizard' for NameNode or SNameNode. Go to 'Manual commands' page. Close browser and open it again.Result: Was opened 'Manual commands' page  but hostnames and foldername were replaced with '{1}'  '{2}' etc.Attached picture for other page  but behavior is similar., step step open reassign reassign master wizard wizard NameNode name node SNameNode name node Go manual manual command command page page close browser open result result open manual manual command command page hostnam foldernam replac etc attach etc attach pictur page behavior similar similar,0,0,0,0,0,0,1 
3720,Xi Wang,ambari-web,0,Provide read-only view of repo options in Ambari Web, provid read read view repo option ambari web,If a user is using local repos  and customizes Advanced Repository Options during install  the user might need this info to debug post install (since it is used in Add Hosts)  for example.Note: We should show this information regardless if the user customizes repos or not during install., user use local repo custom advanc repositori option instal user might need info debug post instal sinc use add host host exampl note exampl note show inform regardless user custom repo not instal instal,0,0,0,0,0,ambari-web/app/utils/ajax.js;,1 
3724,Andrii Tkach,ambari-web,0,Incorrect host status when slave down, incorrect host statu slave,When host has slave down status 'No Heartbeat' status is shown instead of 'Slave Down'., host slave statu No No heartbeat heartbeat statu shown instead slave slave,0,0,0,0,0,ambari-web/app/models/host.js;,1 
3726,Antonenko Alexander,ambari-web,0,Restart indicators for services and hosts disappear after some time., restart indic servic host disappear time time,Goto Service (that have stale configs) -&gt; configs   no restart indicators are shown. Refresh page  for 10-15 seconds you see indicators then they disappear. The same for host detail page, goto servic stale config config gt gt config no restart indic shown shown refresh page second see indic disappear disappear host detail page,0,0,0,0,0,0,1 
3729,Artem Baranchuk,null,0,Ganglia monitor started with second or third attempt on secure cluster, ganglia monitor start second third attempt secur cluster,,,0,0,0,0,0,0,1 
3738,Andrii Babiichuk,ambari-web,0,Background ops dialog checkbox UI cleanup, background op dialog checkbox UI cleanup,The OK and the text should be on the same centerline row., OK text centerlin row row,0,0,0,0,0,ambari-web/app/styles/application.less;ambari-web/app/templates/common/modal_popup.hbs;ambari-web/app/views/common/modal_popup.js;,1 
3739,Siddharth Wagle,ambari-server,0,Remove Exception message printed to log for successful starts, remov except messag print log success start,Following error messages are printed to log with default log level and are misleading.04:19:52 438 ERROR [main] MasterKeyServiceImpl:109 - Master key is not provided as a System property or an environment varialble.04:19:52 439 INFO [main] Configuration:415 - Credential provider creation failed.Master key initialization failed., follow error messag print log default log level mislead mislead ERROR main main MasterKeyServiceImpl master key servic impl master key not provid system properti environ varialbl varialbl INFO main main configur configur credenti provid creation fail master fail master key initi fail fail,0,0,0,0,0,0,1 
3742,Andrii Babiichuk,ambari-web,0,HBase Links widget has 'more' button out of bounds and looks broken when there are multiple masters, HBase base link widget button bound look broken multipl master,When there are multiple HBase Masters  the HBase Links widget looks broken. Let's get rid of the 'and X Standby Masters' static text as it is not a link and not very useful.So the widget would look like:'HBase Master''X RegionServers''Master Web UI', multipl HBase base master HBase base link widget look broken broken let let get rid standbi master master static text not link not use use widget would look like HBase like base master master RegionServers master region server master web UI UI,0,0,0,0,0,ambari-web/app/messages.js;ambari-web/app/templates/main/dashboard/widgets/hbase_links.hbs;ambari-web/app/views/main/dashboard/service/hbase.js;ambari-web/app/views/main/dashboard/widgets/hbase_links.js;,1 
3752,Srimanth Gunturi,ambari-web,0,MR jobs are hanging on a 2-node cluster with default configuration, MR job hang node cluster default configur,This is a 2-node cluster with 2GB of RAM each. Cluster deployment goes fine but MR jobs do not complete resulting in service check failures for MR  OOZIE  Pig  etc., node cluster GB GB RAM cluster deploy goe fine MR job not complet result servic check failur MR OOZIE pig etc etc,0,0,0,0,0,0,1 
3759,Antonenko Alexander,ambari-web,0,Add host wizard: After successfully bootstrapping host  'next' button is disabled, add host wizard wizard success bootstrap host next next button disabl,See screenshot, see screenshot,0,0,0,0,0,0,1 
3760,Antonenko Alexander,ambari-web,0,Provide config-group support in add-host wizard, provid config group config group support add host add host wizard,When adding hosts  a user should be able to select which config-groups this host belongs to. Configurations of that group (Default or config-group) will be applied on that host., ad host user abl select config group config group host belong configur group default default config group config group appli host host,0,0,0,0,0,0,1 
3761,Andrii Babiichuk,ambari-web,0,'Uncaught exception' in JS while navigating through services on Services page, uncaught uncaught except except JS navig servic servic page,This one was discovered while quick navigating through services on Services page.To reproduce just try to click on services links fast.After that service content is not displayed., one discov quick navig servic servic page page reproduc tri click servic link fast fast servic content not display display,0,0,0,0,0,ambari-web/app/views/common/quick_view_link_view.js;,1 
3770,Dmytro Shkvyra,null,0,Need better error log message when agent unable to reach server, need better error log messag agent unabl reach server,http://hortonworks.com/community/forums/topic/installing-hdp2-0-6-on-centos6-4/The current ERROR in the agent log can be cryptic., current ERROR agent log cryptic cryptic,0,0,0,0,0,0,1 
3779,Tom Beerbower,null,0,During cluster install cannot go past Step0, cluster instal cannot go past step step,UI makes a call to http://c6401.ambari.apache.org:8080/api/v1/stacks2/HDP/versions?fields=Versions operatingSystems/repositories/Repositories.The API is missing the operatingSystems info  except for the suse11 one:{ 'href' : 'http://c6401.ambari.apache.org:8080/api/v1/stacks2/HDP/versions?fields=Versions operatingSystems/repositories/Repositories'  'items' : [ { 'href' : 'http://c6401.ambari.apache.org:8080/api/v1/stacks2/HDP/versions/1.2.0'  'Versions' : { 'active' : false  'min_upgrade_version' : null  'parent_stack_version' : null  'stack_name' : 'HDP'  'stack_version' : '1.2.0' }  'operatingSystems' : [ ] }  { 'href' : 'http://c6401.ambari.apache.org:8080/api/v1/stacks2/HDP/versions/1.2.1'  'Versions' : { 'active' : false  'min_upgrade_version' : null  'parent_stack_version' : null  'stack_name' : 'HDP'  'stack_version' : '1.2.1' }  'operatingSystems' : [ ] }  { 'href' : 'http://c6401.ambari.apache.org:8080/api/v1/stacks2/HDP/versions/1.3.0'  'Versions' : { 'active' : false  'min_upgrade_version' : null  'parent_stack_version' : null  'stack_name' : 'HDP'  'stack_version' : '1.3.0' }  'operatingSystems' : [ ] }  { 'href' : 'http://c6401.ambari.apache.org:8080/api/v1/stacks2/HDP/versions/1.3.2'  'Versions' : { 'active' : true  'min_upgrade_version' : null  'parent_stack_version' : null  'stack_name' : 'HDP'  'stack_version' : '1.3.2' }  'operatingSystems' : [ ] }  { 'href' : 'http://c6401.ambari.apache.org:8080/api/v1/stacks2/HDP/versions/1.3.3'  'Versions' : { 'active' : true  'min_upgrade_version' : null  'parent_stack_version' : null  'stack_name' : 'HDP'  'stack_version' : '1.3.3' }  'operatingSystems' : [ ] }  { 'href' : 'http://c6401.ambari.apache.org:8080/api/v1/stacks2/HDP/versions/2.0.5'  'Versions' : { 'active' : false  'min_upgrade_version' : null  'parent_stack_version' : null  'stack_name' : 'HDP'  'stack_version' : '2.0.5' }  'operatingSystems' : [ ] }  { 'href' : 'http://c6401.ambari.apache.org:8080/api/v1/stacks2/HDP/versions/2.0.6'  'Versions' : { 'active' : true  'min_upgrade_version' : null  'parent_stack_version' : null  'stack_name' : 'HDP'  'stack_version' : '2.0.6' }  'operatingSystems' : [ { 'href' : 'http://c6401.ambari.apache.org:8080/api/v1/stacks2/HDP/versions/2.0.6/operatingSystems/centos5'  'OperatingSystems' : { 'os_type' : 'centos5'  'stack_name' : 'HDP'  'stack_version' : '2.0.6' }  'repositories' : [ ] }  { 'href' : 'http://c6401.ambari.apache.org:8080/api/v1/stacks2/HDP/versions/2.0.6/operatingSystems/centos6'  'OperatingSystems' : { 'os_type' : 'centos6'  'stack_name' : 'HDP'  'stack_version' : '2.0.6' }  'repositories' : [ ] }  { 'href' : 'http://c6401.ambari.apache.org:8080/api/v1/stacks2/HDP/versions/2.0.6/operatingSystems/oraclelinux5'  'OperatingSystems' : { 'os_type' : 'oraclelinux5'  'stack_name' : 'HDP'  'stack_version' : '2.0.6' }  'repositories' : [ ] }  { 'href' : 'http://c6401.ambari.apache.org:8080/api/v1/stacks2/HDP/versions/2.0.6/operatingSystems/oraclelinux6'  'OperatingSystems' : { 'os_type' : 'oraclelinux6'  'stack_name' : 'HDP'  'stack_version' : '2.0.6' }  'repositories' : [ ] }  { 'href' : 'http://c6401.ambari.apache.org:8080/api/v1/stacks2/HDP/versions/2.0.6/operatingSystems/redhat5'  'OperatingSystems' : { 'os_type' : 'redhat5'  'stack_name' : 'HDP'  'stack_version' : '2.0.6' }  'repositories' : [ ] }  { 'href' : 'http://c6401.ambari.apache.org:8080/api/v1/stacks2/HDP/versions/2.0.6/operatingSystems/redhat6'  'OperatingSystems' : { 'os_type' : 'redhat6'  'stack_name' : 'HDP'  'stack_version' : '2.0.6' }  'repositories' : [ ] }  { 'href' : 'http://c6401.ambari.apache.org:8080/api/v1/stacks2/HDP/versions/2.0.6/operatingSystems/sles11'  'OperatingSystems' : { 'os_type' : 'sles11'  'stack_name' : 'HDP'  'stack_version' : '2.0.6' }  'repositories' : [ ] }  { 'href' : 'http://c6401.ambari.apache.org:8080/api/v1/stacks2/HDP/versions/2.0.6/operatingSystems/suse11'  'OperatingSystems' : { 'os_type' : 'suse11'  'stack_name' : 'HDP'  'stack_version' : '2.0.6' }  'repositories' : [ { 'href' : 'http://c6401.ambari.apache.org:8080/api/v1/stacks2/HDP/versions/2.0.6/operatingSystems/suse11/repositories/HDP-2.0.6'  'Repositories' : { 'base_url' : 'http://public-repo-1.hortonworks.com/HDP/suse11/2.x/updates/2.0.6.0'  'default_base_url' : 'http://public-repo-1.hortonworks.com/HDP/suse11/2.x/updates/2.0.6.0'  'mirrors_list' : null  'os_type' : 'suse11'  'repo_id' : 'HDP-2.0.6'  'repo_name' : 'HDP'  'stack_name' : 'HDP'  'stack_version' : '2.0.6' } } ] } ] } ]}, UI make call operatingSystems repositori repositori oper system repositori repositori API miss operatingSystems oper system info except suse suse one one href href http ambari apach org api stack HDP version field version http ambari apach org api stack HDP version field version operatingSystems repositori repositori oper system repositori repositori item item href href http ambari apach org api stack HDP version http ambari apach org api stack HDP version version version activ activ fals min_upgrade_version min_upgrade_version null parent_stack_version parent_stack_version null stack_name stack_name HDP HDP stack_version stack_version operatingSystems oper system href href http ambari apach org api stack HDP version http ambari apach org api stack HDP version version version activ activ fals min_upgrade_version min_upgrade_version null parent_stack_version parent_stack_version null stack_name stack_name HDP HDP stack_version stack_version operatingSystems oper system href href http ambari apach org api stack HDP version http ambari apach org api stack HDP version version version activ activ fals min_upgrade_version min_upgrade_version null parent_stack_version parent_stack_version null stack_name stack_name HDP HDP stack_version stack_version operatingSystems oper system href href http ambari apach org api stack HDP version http ambari apach org api stack HDP version version version activ activ true min_upgrade_version min_upgrade_version null parent_stack_version parent_stack_version null stack_name stack_name HDP HDP stack_version stack_version operatingSystems oper system href href http ambari apach org api stack HDP version http ambari apach org api stack HDP version version version activ activ true min_upgrade_version min_upgrade_version null parent_stack_version parent_stack_version null stack_name stack_name HDP HDP stack_version stack_version operatingSystems oper system href href http ambari apach org api stack HDP version http ambari apach org api stack HDP version version version activ activ fals min_upgrade_version min_upgrade_version null parent_stack_version parent_stack_version null stack_name stack_name HDP HDP stack_version stack_version operatingSystems oper system href href http ambari apach org api stack HDP version http ambari apach org api stack HDP version version version activ activ true min_upgrade_version min_upgrade_version null parent_stack_version parent_stack_version null stack_name stack_name HDP HDP stack_version stack_version operatingSystems oper system href href http ambari apach org api stack HDP version operatingSystems cento http ambari apach org api stack HDP version oper system cento OperatingSystems oper system os_type os_type cento cento stack_name stack_name HDP HDP stack_version stack_version repositori repositori href href http ambari apach org api stack HDP version operatingSystems cento http ambari apach org api stack HDP version oper system cento OperatingSystems oper system os_type os_type cento cento stack_name stack_name HDP HDP stack_version stack_version repositori repositori href href http ambari apach org api stack HDP version operatingSystems oraclelinux http ambari apach org api stack HDP version oper system oraclelinux OperatingSystems oper system os_type os_type oraclelinux oraclelinux stack_name stack_name HDP HDP stack_version stack_version repositori repositori href href http ambari apach org api stack HDP version operatingSystems oraclelinux http ambari apach org api stack HDP version oper system oraclelinux OperatingSystems oper system os_type os_type oraclelinux oraclelinux stack_name stack_name HDP HDP stack_version stack_version repositori repositori href href http ambari apach org api stack HDP version operatingSystems redhat http ambari apach org api stack HDP version oper system redhat OperatingSystems oper system os_type os_type redhat redhat stack_name stack_name HDP HDP stack_version stack_version repositori repositori href href http ambari apach org api stack HDP version operatingSystems redhat http ambari apach org api stack HDP version oper system redhat OperatingSystems oper system os_type os_type redhat redhat stack_name stack_name HDP HDP stack_version stack_version repositori repositori href href http ambari apach org api stack HDP version operatingSystems sle http ambari apach org api stack HDP version oper system sle OperatingSystems oper system os_type os_type sle sle stack_name stack_name HDP HDP stack_version stack_version repositori repositori href href http ambari apach org api stack HDP version operatingSystems suse http ambari apach org api stack HDP version oper system suse OperatingSystems oper system os_type os_type suse suse stack_name stack_name HDP HDP stack_version stack_version repositori repositori href href http ambari apach org api stack HDP version operatingSystems suse repositori HDP http ambari apach org api stack HDP version oper system suse repositori HDP repositori repositori base_url base_url http public repo hortonwork com HDP suse updat http public repo hortonwork com HDP suse updat default_base_url default_base_url http public repo hortonwork com HDP suse updat http public repo hortonwork com HDP suse updat mirrors_list mirrors_list null os_type os_type suse suse repo_id repo_id HDP HDP repo_name repo_name HDP HDP stack_name stack_name HDP HDP stack_version stack_version,0,0,0,0,0,ambari-server/src/main/java/org/apache/ambari/server/api/handlers/QueryCreateHandler.java;ambari-server/src/main/java/org/apache/ambari/server/api/query/QueryImpl.java;ambari-server/src/main/java/org/apache/ambari/server/api/resources/ResourceInstance.java;ambari-server/src/main/java/org/apache/ambari/server/api/services/persistence/PersistenceManagerImpl.java;ambari-server/src/main/java/org/apache/ambari/server/controller/AmbariManagementControllerImpl.java;ambari-server/src/main/java/org/apache/ambari/server/controller/OperatingSystemResponse.java;ambari-server/src/main/java/org/apache/ambari/server/controller/RepositoryResponse.java;ambari-server/src/main/java/org/apache/ambari/server/controller/RootServiceComponentResponse.java;ambari-server/src/main/java/org/apache/ambari/server/controller/RootServiceHostComponentResponse.java;ambari-server/src/main/java/org/apache/ambari/server/controller/StackConfigurationResponse.java;ambari-server/src/main/java/org/apache/ambari/server/controller/StackServiceComponentResponse.java;ambari-server/src/main/java/org/apache/ambari/server/controller/StackServiceResponse.java;ambari-server/src/main/java/org/apache/ambari/server/controller/StackVersionResponse.java;ambari-server/src/main/java/org/apache/ambari/server/controller/internal/ClusterResourceProvider.java;ambari-server/src/main/java/org/apache/ambari/server/controller/internal/OperatingSystemResourceProvider.java;ambari-server/src/main/java/org/apache/ambari/server/controller/internal/RepositoryResourceProvider.java;ambari-server/src/main/java/org/apache/ambari/server/controller/internal/RootServiceComponentResourceProvider.java;ambari-server/src/main/java/org/apache/ambari/server/controller/internal/RootServiceHostComponentResourceProvider.java;ambari-server/src/main/java/org/apache/ambari/server/controller/internal/RootServiceResourceProvider.java;ambari-server/src/main/java/org/apache/ambari/server/controller/internal/StackConfigurationResourceProvider.java;ambari-server/src/main/java/org/apache/ambari/server/controller/internal/StackResourceProvider.java;ambari-server/src/main/java/org/apache/ambari/server/controller/internal/StackServiceComponentResourceProvider.java;ambari-server/src/main/java/org/apache/ambari/server/controller/internal/StackServiceResourceProvider.java;ambari-server/src/main/java/org/apache/ambari/server/controller/internal/StackVersionResourceProvider.java;ambari-server/src/main/java/org/apache/ambari/server/controller/internal/TaskResourceProvider.java;ambari-server/src/test/java/org/apache/ambari/server/api/handlers/QueryCreateHandlerTest.java;ambari-server/src/test/java/org/apache/ambari/server/api/services/PersistenceManagerImplTest.java;ambari-server/src/test/java/org/apache/ambari/server/controller/internal/RepositoryResourceProviderTest.java;ambari-server/src/test/java/org/apache/ambari/server/controller/internal/StackResourceProviderTest.java;,1 
3791,Antonenko Alexander,ambari-web,0,Provide add/remove/rename/duplicate actions in manage-config-groups dialog, provid add remov renam duplic add remov renam duplic action manag config group manag config group dialog,Various config-group actions (add/remove/rename/duplicate) should be provided in the manage-config-groups dialog. Any of these should not rely on the Save button  but are immediately persisted via API., variou config group config group action add remov renam duplic add remov renam duplic provid manag config group manag config group dialog dialog not reli save button immedi persist via API API,0,0,0,0,0,0,0 
3793,Vitaly Brodetskyi,ambari-agent,0,Do not store disks_info in DB. Store it as dynamic info in memory that can be used to show on the UI., not store disks_info DB DB store dynam info memori use show UI UI,Currently  we store disks info in DB and this information is never updated after registration. As disks details can change (space availability changes  disks get mounted/unmounted  etc.) the persisted information is not useful.We should instead hold the details in memory and refresh it at certain intervals (e.g. once every 10 minutes) and then alert if space availability hits some lower limit., current store disk info DB inform never updat registr registr disk detail chang space avail chang disk get mount unmount mount unmount etc etc persist inform not use use instead hold detail memori refresh certain interv everi minut minut alert space avail hit lower limit limit,0,0,0,0,0,0,0 
3805,Oleg Nechiporenko,ambari-web,0,'Add service' if nothing to add, add add servic servic noth add,Disable and gray out the Add Services button if there aren't any more services to be added.Upon hover  show a tooltip saying 'No more services to be added'.Although we hide the 'Add Component' button when no more components are to be added  we don't actually like that and want to move towards 'disabling/graying out with hover tooltip' pattern., disabl gray add servic button servic ad upon ad upon hover show tooltip say No No servic ad although ad although hide add add compon compon button no compon ad actual like want move toward disabl gray disabl gray hover tooltip tooltip pattern pattern,0,0,0,0,0,0,0 
3815,Antonenko Alexander,ambari-web,0,Remove  Rename actions enabled for 'Default' config group, remov renam action enabl default default config group,In the Manager Configuration Groups dialog I selected the Default config-group  and the actions to remove and rename config-group are enabled. These ops are not allowed for Default config-group., manag configur group dialog select default config group config group action remov renam config group config group enabl enabl op not allow default config group config group,0,0,0,0,0,0,0 
3824,Andrii Tkach,ambari-web,0,Provide change config-group action on host configs, provid chang config group config group action host config,On a host's configs page  provide a Change action beside config-group to switch from one group to another  or to Default., host host config page provid chang action besid config group config group switch one group anoth default default,0,0,0,0,0,ambari-web/app/controllers/main/host/configs_service.js;ambari-web/app/messages.js;ambari-web/app/templates/common/configs/service_config.hbs;ambari-web/app/utils/config.js;ambari-web/app/views/common/configs/services_config.js;,0 
3836,Antonenko Alexander,ambari-web,0,Unable to close manage-config-groups dialog when only Default group present, unabl close manag config group manag config group dialog default group present,I had only the Default config-group when I launched the manage config-groups dialog. When I clicked on Cancel or X  it would not close dialog with the following error:Uncaught TypeError: Cannot read property 'id' of null This was in method updateConfigGroupOnServicePage() at the first line belowselectedConfigGroup = managedConfigGroups.findProperty('id'  selectedConfigGroup.id); if(selectedConfigGroup){ mainServiceInfoConfigsController.set('selectedConfigGroup'  selectedConfigGroup); }else{ mainServiceInfoConfigsController.set('selectedConfigGroup'  managedConfigGroups.findProperty('isDefault'  true)); }, default config group config group launch manag config group config group dialog dialog click cancel would not close dialog follow error uncaught error uncaught TypeError type error cannot read properti id id null method updateConfigGroupOnServicePage updat config group servic page first line belowselectedConfigGroup belowselect config group managedConfigGroups findProperty id manag config group find properti id selectedConfigGroup id select config group id selectedConfigGroup select config group mainServiceInfoConfigsController set selectedConfigGroup main servic info config control set select config group selectedConfigGroup select config group els els mainServiceInfoConfigsController set selectedConfigGroup main servic info config control set select config group managedConfigGroups findProperty isDefault manag config group find properti default true true,0,0,0,0,0,0,0 
3838,Mikhail Bayuk,ambari-web,0,Services sidebar for host configs needs vertical gap, servic sidebar host config need vertic gap,When you go to host configs page  there is no gap between the services sidebar and the tabs. This should be changed so that the config-group bar and services sidebar have the same gap from the tabs at top., go host config page no gap servic sidebar tab tab chang config group config group bar servic sidebar gap tab top top,0,0,0,0,0,0,0 
3842,Andrii Babiichuk,ambari-web,0,Host configs page should properly order services, host config page properli order servic,When App.supports.hostOverridesHost is enabled  and you visit the configs page for a host  the services are in some random order. They should be in the same order as the services page.Also  there is a small empty entry in the menu  which gives like a 5px extra space between some services. You can even hover on this empty entry and it will highlight., app support hostOverridesHost app support host overrid host enabl visit config page host servic random order order order servic page also page also small empti entri menu give like px extra space servic servic even hover empti entri highlight highlight,0,0,0,0,0,ambari-web/app/mappers/service_mapper.js;ambari-web/app/models/service.js;ambari-web/app/utils/misc.js;ambari-web/app/views/main/host/configs_service_menu.js;ambari-web/app/views/main/service/menu.js;,0 
3844,Aleksandr Kovalenko,ambari-web,0,Error in saving host for newly created config group, error save host newli creat config group,After creating new Config Group in Manage Configuration Groups dialog try to add host to this group and save. Also sometimes '+' button to add hosts is disabled for newly created group., creat new config group manag configur group dialog tri add host group save save also sometim button add host disabl newli creat group group,0,0,0,0,0,0,0 
3857,Oleg Nechiporenko,ambari-web,0,Clicking on Settings link navigates to login page for a non-admin user., click set link navig login page non admin non admin user user,This happens because non-admin users are not authorized to make POST/PUT calls to any resource  including 'persist'.For now  let's hide 'Settings' if the user is a non-admin user., happen non admin non admin user not author make POST PUT POST PUT call resourc includ persist persist let let hide set set user non admin non admin user user,0,0,0,0,0,0,0 
3864,Xi Wang,ambari-web,0,JS Error in 'Add Host Wizard' if we proceed with failed registered hosts, JS error add add host wizard wizard proceed fail regist host,1. Add two hosts in Add Host Wizard.2. In Conform Hosts step  one registered successfully  the other failed.3. Proceed to next  JS error happened when deploy  wizard UI hang up., add two host add host wizard wizard conform host step one regist success fail fail proce next JS error happen deploy wizard UI hang,0,0,0,0,0,0,0 
3868,Jaimin D Jetly,ambari-web,0,Add host fails after configuring NN HA with JavaScript error, add host fail configur NN HA JavaScript java script error,,,0,0,0,0,0,ambari-web/app/models/service_config.js;,0 
3873,Eugene Chekanskiy,ambari-server,0,Unittests for User resource an all it's attributes, unittest user resourc attribut,Test resource User of resource management . Test all actions and all the attributes. Please make sure we mock to check both cases when user already exists and when it's not.Note here we should not call directly provider methods like action_create  but make resource management library do that for us  by calling env.run(). In other case test won't cover resources definitions  and other import logic, test resourc user resourc manag test action attribut attribut pleas make sure mock check case user alreadi exist not note not note not call directli provid method like action_create make resourc manag librari us call env run env run case test cover resourc definit import logic,0,0,0,0,0,0,0 
3877,Andrii Babiichuk,ambari-web,0,Duplicate config-group action not duplicate configs, duplic config group config group action not duplic config,Override like 3 configs in a config group and save. Now go to the Manage Config Groups dialog and select this group and click on Duplicate action. A popup with name and description pops up and hitting OK creates the duplicated config group.Though this duplicated config group has the correct name/description  it does not have the duplicated configs (3 that we overrode). When doing the POST call  we should populate the desired_configs to be the exact same as the source config-group., overrid like config config group save save go manag config group dialog select group click duplic action action popup name descript pop hit OK creat duplic config group though group though duplic config group correct name descript name descript not duplic config overrod overrod POST call popul desired_configs exact sourc config group config group,0,0,0,0,0,ambari-web/app/controllers/main/service/manage_config_groups_controller.js;ambari-web/app/utils/ajax.js;,0 
3878,Xi Wang,ambari-web,0,ResourceManager Heap metrics is not correct on Ambari console, ResourceManager resourc manag heap metric not correct ambari consol,PROBLEM: The ResourceManager Heap metrics on Ambari web console doesn't show the correct value  not only the current heap usage doesn't reflect the correct usage  but also the total heap size doesn't match what we configure for the ResourceManager Heap size  even the total heap size number is changing constantly., PROBLEM PROBLEM ResourceManager resourc manag heap metric ambari web consol show correct valu not current heap usag reflect correct usag also total heap size match configur ResourceManager resourc manag heap size even total heap size number chang constantli constantli,0,0,0,0,0,0,0 
3881,Jaimin D Jetly,ambari-web,0,UI incorrect behavior during upgrade, UI incorrect behavior upgrad,This issue was discovered while upgrading the cluster to hash 87adc8c2d29b20a30f01e54c12f67dcbbe34b32e of 1.4.2 branch. The logic inside configuration_controller.js function getConfigsByTags(tagObject) has a reference to undefined variable and js error was encountered. This happened when any of the service page was rendered and program flow from quick_view_link_view.js function didInsertElement() -&gt; setQuickLinks() -&gt; loadTags() -&gt; loadTagsSuccess(data) -&gt; getSecurityProperties() -&gt; configurationController.getConfigsByTags(tag), issu discov upgrad cluster hash adc dcbbe adc dcbbe branch branch logic insid configuration_controller js configuration_controller js function getConfigsByTags tagObject get config tag tag object refer undefin variabl js error encount encount happen servic page render program flow quick_view_link_view js quick_view_link_view js function didInsertElement insert element gt gt setQuickLinks set quick link gt gt loadTags load tag gt gt loadTagsSuccess data load tag success data gt gt getSecurityProperties get secur properti gt gt configurationController getConfigsByTags tag configur control get config tag tag,0,0,0,0,0,0,0 
3882,Xi Wang,ambari-web,0,Background operations popup window minimum size should be fixed when narrowing down the browser, background oper popup window minimum size fix narrow browser,,,0,0,0,0,0,0,0 
3888,Denys Buzhor,ambari-web,0,Incorrect restart required tooltip view, incorrect restart requir tooltip view,When components and hosts required to restart we show refresh icon near the service name. On icon hover event we show tooltip with count of components and hosts., compon host requir restart show refresh icon near servic name name icon hover event show tooltip count compon host host,0,0,0,0,0,0,0 
3890,Denys Buzhor,ambari-web,0,Background operations: two scrollbars  if width is lower then 1450px, background oper oper two scrollbar width lower px,Screenshot attached., screenshot attach attach,0,0,0,0,0,0,0 
3897,Srimanth Gunturi,ambari-web,0,Restart indicator flags not showing up for HDP 1.3.x stack services, restart indic flag not show HDP stack servic,When config-groups are used for HDP 1.3.x stack services  the stale_configs are always false., config group config group use HDP stack servic stale_configs alway fals fals,0,0,0,0,0,0,0 
3899,Jaimin D Jetly,ambari-web,0,'HDFS Short-circuit read' config property is repeated, HDFS HDFS short circuit short circuit read read config properti repeat,,,0,0,0,0,0,ambari-web/app/data/HDP2/global_properties.js;,0 
3911,Srimanth Gunturi,ambari-web,0,Security Wizard: Service Configuration page is broken, secur wizard wizard servic configur page broken,Trying to enable security  the configurations page is blank., tri enabl secur configur page blank blank,0,0,0,0,0,0,0 
3914,Andrii Tkach,ambari-web,0,Add Host wizard stuck on configuration step, add host wizard stuck configur step,Cluster should have service(HDFS PIG SQOOP) which doesn't have any slave or client host-components.1. Run Add Host wizard2. Proceed to configuration stepResult: Wizard popup stuck in loading processJS error:Uncaught TypeError: Cannot call method 'get' of undefined app.js:10245(anonymous function) app.js:10245App.AddHostController.App.WizardController.extend.loadServiceConfigGroups app.js:10242(anonymous function) app.js:43659f.Callbacks.o vendor.js:95f.Callbacks.p.add vendor.js:95(anonymous function) app.js:43657f.Callbacks.o vendor.js:95f.Callbacks.p.fireWith vendor.js:95f.Callbacks.p.fire vendor.js:95(anonymous function), cluster servic HDFS servic HDFS PIG SQOOP SQOOP slave client host compon host compon run add host wizard wizard proce configur stepResult step result wizard popup stuck load processJS process JS error uncaught error uncaught TypeError type error cannot call method get get undefin app js anonym app js anonym function function app js app AddHostController app WizardController extend loadServiceConfigGroups app js app add host control app wizard control extend load servic config group app js anonym app js anonym function function app js callback app js callback vendor js callback add vendor js callback add vendor js anonym vendor js anonym function function app js callback app js callback vendor js callback fireWith vendor js callback fire vendor js callback fire vendor js callback fire vendor js anonym vendor js anonym function function,0,0,0,0,0,ambari-web/app/controllers/main/host/add_controller.js;ambari-web/app/mappers/server_data_mapper.js;ambari-web/app/mappers/status_mapper.js;,0 
3921,Andrii Tkach,ambari-web,0,Hovers stay after manage-config-groups dialog is closed, hover stay manag config group manag config group dialog close,I opened the manage-config-groups dialog and hovered on one of the actions (remove host from config-group). Then I saved or cancelled to close the dialog. The hover still remains in the middle of page.I have seen this in other usages as well. We need to make sure that all hovers are closed when the focus is lost., open manag config group manag config group dialog hover one action remov host config group config group save cancel close dialog dialog hover still remain middl page page seen usag well well need make sure hover close focu lost lost,0,0,0,0,0,ambari-web/app/controllers/wizard/step3_controller.js;ambari-web/app/utils/helper.js;ambari-web/app/views/common/configs/services_config.js;ambari-web/app/views/main/dashboard/service.js;ambari-web/app/views/main/dashboard/service/yarn.js;ambari-web/app/views/main/dashboard/widget.js;ambari-web/app/views/main/host.js;ambari-web/app/views/main/host/details.js;ambari-web/app/views/main/host/summary.js;ambari-web/app/views/main/service.js;ambari-web/app/views/main/service/info/summary.js;ambari-web/app/views/main/service/manage_config_groups_view.js;ambari-web/app/views/main/service/menu.js;ambari-web/app/views/wizard/step6_view.js;,0 
3925,Antonenko Alexander,ambari-web,0,Adding host to multiple groups at the same time fails, ad host multipl group time fail,Steps:1. Create 2 config groups2. Rename 1 config group3. Add hosts to renamed config group4. Add host to other config group.Result:Save stops working. Error in the JS console.Error in JS console:Uncaught TypeError: Cannot call method 'sort' of undefined manage_config_groups_controller.js:460(anonymous function) manage_config_groups_controller.js:460(anonymous function) manage_config_groups_controller.js:458ComputedPropertyPrototype.get ember-latest.js:2949get ember-latest.js:1355getPath ember-latest.js:1477get ember-latest.js:1348Ember.Observable.Ember.Mixin.create.get ember-latest.js:7695App.ModalPopup.show.onPrimary item.js:251newFunc ember-latest.js:949ActionHelper.registeredActions.(anonymous function).handler ember-latest.js:19458(anonymous function) ember-latest.js:11250f.event.dispatch jquery-1.7.2.min.js:3h.handle.i, step step creat config group group renam config group group add host renam config group group add host config group result save group result save stop work work error JS consol error consol error JS consol uncaught consol uncaught TypeError type error cannot call method sort sort undefin manage_config_groups_controller js anonym manage_config_groups_controller js anonym function function manage_config_groups_controller js anonym manage_config_groups_controller js anonym function function manage_config_groups_controller js ComputedPropertyPrototype get manage_config_groups_controller js comput properti prototyp get ember latest js get ember latest js get ember latest js getPath ember latest js get path ember latest js get ember latest js get ember latest js ember observ ember mixin creat get ember latest js ember observ ember mixin creat get ember latest js app ModalPopup show onPrimary ember latest js app modal popup show primari item js newFunc item js new func ember latest js ActionHelper registeredActions anonym ember latest js action helper regist action anonym function handler function handler ember latest js anonym ember latest js anonym function function ember latest js event dispatch ember latest js event dispatch jqueri min js handl jqueri min js handl,0,0,0,0,0,0,0 
3930,Andrii Tkach,ambari-web,0,Missing host message on cluster deploy, miss host messag cluster deploy,When execute any service check  host message become empty. Server return  unsupported on UI  command of task - 'SERVICE_CHECK'., execut servic check host messag becom empti empti server return unsupport UI command task SERVICE_CHECK SERVICE CHECK,0,0,0,0,0,ambari-web/app/controllers/wizard/step9_controller.js;,0 
3938,Yusaku Sako,ambari-web,0,JS error when switching config groups in Hive / Oozie service config pages, JS error switch config group hive oozi servic config page,,,0,0,0,0,0,0,0 
3953,Dmytro Sen,ambari-agent,0,HBase Master alerts are confusing in multi-master environment, HBase base master alert confus multi master multi master environ,When multiple HBase Masters are set up  HBase service-level alert section shows multiples of the following: HBase Master process HBase Master Web UI HBase Master CPU utilizationThe label is exactly the same for all masters  so you can't distinguish which alert is for which master. Ambari should mirror what ambari does for NameNode alerts so that the user can tell them apart (append hostname in the alert label)., multipl HBase base master set HBase base servic level servic level alert section show multipl follow follow HBase base master process HBase base master web UI HBase base master CPU utilizationThe util label exactli master distinguish alert master master ambari mirror ambari NameNode name node alert user tell apart append hostnam alert label label,0,0,0,0,0,ambari-agent/src/main/puppet/modules/hdp-nagios/templates/hadoop-services.cfg.erb;,0 
3954,Oleg Nechiporenko,ambari-web,0,hbase.zookeeper.quorum changing inconsistently on hosts after adding ZookeeperServer, hbase zookeep quorum hbase zookeep quorum chang inconsist host ad ZookeeperServer zookeep server,Issue 1:Steps followed: 1. Install a 3-node cluster with Hbase and Zookeeper and 3 zookeeper servers. 2. After installation on each host the property hbase.zookeeper.quorum in /etc/hbase/conf/hbase-site.xml has:&lt;name&gt;hbase.zookeeper.quorum&lt;/name&gt; &lt;value&gt;c6401.ambari.apache.org c6402.ambari.apache.org c6403.ambari.apache.org&lt;/value&gt;3. After adding a host with Hbase Region Server  and after that a ZookeeperServer to it  the property on the added c6404.ambari.apache.org host has the same value  as in 2. 4. After restarting HBase master on c6401 (which is proposed by UI)  the property value on c6401 becomes:  &lt;name&gt;hbase.zookeeper.quorum&lt;/name&gt; &lt;value&gt;c6401.ambari.apache.org&lt;/value&gt;. On other hosts it remains unchanged. 5. After restarting HbaseRegionServers on the rest of the hosts (not proposed by ui)  the property changes too  to the same value  as in 4. __________________________________________________________Issue 2:Property templeton.zookeeper.hosts in /etc/hcatalog/conf/webhcat-site.xmlPrior to adding a zookeeperServer on host c6404  config on WebHCat server lookes like:[root@c6402 vagrant]# cat /etc/hcatalog/conf/webhcat-site.xml |grep templeton.zookeeper.hosts -C 2 &lt;configuration&gt; &lt;property&gt; &lt;name&gt;templeton.zookeeper.hosts&lt;/name&gt; &lt;value&gt;c6401.ambari.apache.org:2181 c6402.ambari.apache.org:2181 c6403.ambari.apache.org:2181&lt;/value&gt; &lt;/property&gt;After adding a ZookeeperServer on c6404 and restarting WebHCatServer on c6402: [root@c6402 vagrant]# cat /etc/hcatalog/conf/webhcat-site.xml |grep templeton.zookeeper.hosts -C 2 &lt;/property&gt; &lt;property&gt; &lt;name&gt;templeton.zookeeper.hosts&lt;/name&gt; &lt;value&gt;c6401.ambari.apache.org&lt;/value&gt; &lt;/property&gt;__________________________________________________________Issue 3. On a 3-node cluster with HA-enbaled  property ha.zookeeper.quorum in /etc/hadoop/conf/core-site.xml  has the same value on all hosts:  &lt;name&gt;ha.zookeeper.quorum&lt;/name&gt; &lt;value&gt;c6401.ambari.apache.org:2181 c6402.ambari.apache.org:2181 c6403.ambari.apache.org:2181&lt;/value&gt;It doesn't change on either of the hosts after adding c6404 to the cluster  installing ZookeeperServer on it and restarting HDFS., issu step step follow follow instal node cluster hbase zookeep zookeep server server instal host properti hbase zookeep quorum hbase zookeep quorum etc hbase conf hbase site xml etc hbase conf hbase site xml lt name gt hbase zookeep quorum lt name gt lt name gt hbase zookeep quorum lt name gt lt valu gt ambari apach org lt valu gt ambari apach org ambari apach org ambari apach org ambari apach org lt valu gt ambari apach org lt valu gt ad host hbase region server ZookeeperServer zookeep server properti ad ambari apach org ambari apach org host valu restart HBase base master propos UI UI properti valu becom becom lt name gt hbase zookeep quorum lt name gt lt name gt hbase zookeep quorum lt name gt lt valu gt ambari apach org lt valu gt lt valu gt ambari apach org lt valu gt host remain unchang unchang restart HbaseRegionServers hbase region server rest host not propos ui ui properti chang valu __________________________________________________________Issue  issu properti properti templeton zookeep host templeton zookeep host etc hcatalog conf webhcat site xmlPrior etc hcatalog conf webhcat site xml prior ad zookeeperServer zookeep server host config WebHCat web cat server look like root like root vagrant vagrant cat etc hcatalog conf webhcat site xml etc hcatalog conf webhcat site xml grep templeton zookeep host templeton zookeep host lt configur gt lt configur gt lt properti gt lt properti gt lt name gt templeton zookeep host lt name gt lt name gt templeton zookeep host lt name gt lt valu gt ambari apach org lt valu gt ambari apach org ambari apach org ambari apach org ambari apach org lt valu gt ambari apach org lt valu gt lt properti gt lt properti gt ad ZookeeperServer zookeep server restart WebHCatServer web cat server root root vagrant vagrant cat etc hcatalog conf webhcat site xml etc hcatalog conf webhcat site xml grep templeton zookeep host templeton zookeep host lt properti gt lt properti gt lt properti gt lt properti gt lt name gt templeton zookeep host lt name gt lt name gt templeton zookeep host lt name gt lt valu gt ambari apach org lt valu gt lt valu gt ambari apach org lt valu gt lt properti gt __________________________________________________________Issue lt properti gt  issu node cluster HA enbal HA enbal properti ha zookeep quorum ha zookeep quorum etc hadoop conf core site xml etc hadoop conf core site xml valu host host lt name gt ha zookeep quorum lt name gt lt name gt ha zookeep quorum lt name gt lt valu gt ambari apach org lt valu gt ambari apach org ambari apach org ambari apach org ambari apach org lt valu gt ambari apach org lt valu gt chang either host ad cluster instal ZookeeperServer zookeep server restart HDFS HDFS,0,0,0,0,0,0,0 
3981,Artem Baranchuk,ambari-server,0,Services mysteriously disappear after Stack upgrade, servic mysteri disappear stack upgrad,,,0,0,0,0,0,0,0 
3982,Xi Wang,ambari-web,0,Background operations window  called from wizard doesn't react to 'Do not show this dialog...' flag, background oper window call wizard react not show dialog dialog flag,STR:Go through the Reassign NameNode wizard.On the last step click on the Start All Services link.Change the state of flag Do not show this dialog again when starting a background operation.Click OK.Click Start All Services link again.Result: State of flag was not changed., STR Go STR Go reassign NameNode name node wizard wizard last step click start servic link chang link chang state flag not show dialog start background oper click oper click OK click OK click start servic link result result state flag not chang chang,0,0,0,0,0,0,0 
3984,Xi Wang,ambari-web,0,Config Groups: Background popup show up needs to be integrated when restarting components, config group group background popup show need integr restart compon,1. Change config group for a service.2. Click 'Stop components' on service config page.3. Click 'Start components' on the same page.Actual results:Background Operations popup will always show up. (as attached)Expected results:Load the 'do not show this dialog..' flag first  then determine if show this popup., chang config group servic servic click stop stop compon compon servic config page page click start start compon compon page actual page actual result background result background oper popup alway show attach expect attach expect result load result load not show dialog dialog flag first determin show popup popup,0,0,0,0,0,0,0 
3986,Denys Buzhor,ambari-web,0,YARN and MapReduce2 configs is not displayed, YARN MapReduce map reduc config not display,In Services -&gt; Configs YARN and MapReduce2 configs is not displayed., servic gt gt config YARN MapReduce map reduc config not display display,0,0,0,0,0,0,0 
3987,Tom Beerbower,null,0,Resource providers are set with wrong stack version., resourc provid set wrong stack version version,AbstractProviderModule.updateClusterVersion sets the cluster version for the resource providers with the following ... PropertyHelper.MetricsVersion version = clusterVersion.startsWith('HDP-1') ? PropertyHelper.MetricsVersion.HDP1 : PropertyHelper.MetricsVersion.HDP2;So  the Cluster/version property set to 'HDPLocal-1.3.2' will incorrectly be detected as HDP2. This causes the property providers to use the wrong metric mapping files which causes many JMX properties not to be set properly., AbstractProviderModule updateClusterVersion abstract provid modul updat cluster version set cluster version resourc provid follow PropertyHelper MetricsVersion properti helper metric version version clusterVersion startsWith HDP cluster version start HDP PropertyHelper MetricsVersion HDP properti helper metric version HDP PropertyHelper MetricsVersion HDP properti helper metric version HDP cluster version cluster version properti set HDPLocal HDP local incorrectli detect HDP HDP caus properti provid use wrong metric map file caus mani JMX properti not set properli properli,0,0,0,0,0,ambari-server/src/main/java/org/apache/ambari/server/controller/internal/AbstractProviderModule.java;ambari-server/src/test/java/org/apache/ambari/server/controller/internal/AbstractProviderModuleTest.java;,0 
3991,Andrii Babiichuk,ambari-web,0,Manage config group links needed in save config-group confirmation, manag config group link need save config group config group confirm,When any service config-group is saved  we have a confirmation popup saying save was successful. We should enhance that popup to have a button to Manage Config Groups dialog  along with appropriate message. When button is clicked  the popup should go away and the Manage Config Groups dialog should show., servic config group config group save confirm popup say save success success enhanc popup button manag config group dialog along appropri messag messag button click popup go away manag config group dialog show show,0,0,0,0,0,ambari-web/app/messages.js;ambari-web/app/styles/application.less;ambari-web/app/templates/common/configs/saveConfigGroup.hbs;ambari-web/app/utils/config.js;,0 
3992,Oleg Nechiporenko,ambari-web,0,After making config changes w/o saving  prompt user if they try to navigate away, make config chang save prompt user tri navig away,1) Browse to Services &gt; HDFS &gt; Configs2) Change some props3) Do not click save4) Browse away  to Summary or to another serviceUser would have lost config changes. We should prompt before allowing user to navigate away from Configs.'You have unsaved changes. Save changes or discard?'&#91;Discard&#93; &#91;Save&#93;, brows servic gt gt HDFS gt gt config config chang prop prop not click save save brows away summari anoth serviceUser servic user would lost config chang chang prompt allow user navig away config config unsav chang chang save chang discard discard discard discard save save,0,0,0,0,0,0,0 
3997,Siddharth Wagle,ambari-server,0,Config-Group POST call should tolerate name reuse, config group config group POST call toler name reus,Cluster wide we prohibit reuse of config-group name. However names can be reused across services. The API should be updated to tolerate POST/PUT of similar named config-groups., cluster wide prohibit reus config group config group name name howev name reus across servic servic API updat toler POST PUT POST PUT similar name config group config group,0,0,0,0,0,0,0 
3999,Xi Wang,ambari-web,0,Long host names are inconvenient for viewing in background operations popup, long host name inconveni view background oper popup,Steps: Open background operations window and select any operation.Result: If the host name is too long  they are not placed on designated place.Solution:If the host name is too long  we show part of the string with '...' at the end.Also the string should keep in a single line all the time, step step open background oper window select oper result oper result host name long not place design place solut place solut host name long show part string end also end also string keep singl line time,0,0,0,0,0,0,0 
4003,Denys Buzhor,ambari-web,0,Add Service Wizard: Customize Services configs are not displayed., add servic wizard wizard custom servic config not display display,In 'Customize services' step in 'Add Service Wizard' config group and configs are not displayed. See screenshot., custom custom servic servic step add add servic wizard wizard config group config not display display see screenshot screenshot,0,0,0,0,0,ambari-web/app/controllers/installer.js;ambari-web/app/controllers/main/service/add_controller.js;ambari-web/app/controllers/wizard.js;ambari-web/app/routes/add_service_routes.js;,0 
4004,Andrii Tkach,ambari-web,0,Duplicate hosts after closing addServiceWizard, duplic host close addServiceWizard add servic wizard,Install cluster with 2 hosts (with HDFS  ZooKeeper).Go to Add Service Wizard.Select some configurable service.Go to Step 4 (Customize services).Close wizard.Go to Hosts page.Result:each host appears two times., instal cluster host HDFS ZooKeeper Go zoo keeper Go add servic wizard select wizard select configur servic Go servic Go step custom custom servic close servic close wizard Go wizard Go host page result page result host appear two time time,0,0,0,0,0,ambari-web/app/controllers/wizard/step7_controller.js;,0 
4012,Xi Wang,ambari-web,0,NameNode max heap is not showing in HDP 1.3.2 stack, NameNode name node max heap not show HDP stack,Reason:We use in-consistent value to show Heap size for different components.And some of them are missing.Solution:Make sure all Heap size percentage value (including NN  RM  JT and HBase Master) use the same property., reason reason use consist consist valu show heap size differ compon compon miss solut make miss solut make sure heap size percentag valu includ NN RM JT HBase base master master use properti properti,0,0,0,0,0,0,0 
4024,Mahadev konar,null,0,HiveSchema file for Hive should be hive-schema-0.12.0.oracle.sql, HiveSchema hive schema file hive hive schema oracl sql hive schema oracl sql,HiveSchema file for Hive should be hive-schema-0.12.0.oracle.sql, HiveSchema hive schema file hive hive schema oracl sql hive schema oracl sql,0,0,0,0,0,0,0 
4028,Andrii Tkach,ambari-web,0,Dashboard quick links polls desired_configs every 6s, dashboard quick link poll desired_configs everi,On the dashboard  calls to /clusters/{clusterName}?fields=Clusters/desired_configs are made every 6s. We need to verify if this really is necessary. Initial investigation revealed calls from quick-links  where links were set based on security being enabled. But there is no need to poll every 6s for this., dashboard call cluster clusterName field cluster desired_configs cluster cluster name field cluster desired_configs made everi need verifi realli necessari necessari initi investig reveal call quick link quick link link set base secur enabl enabl no need poll everi,0,0,0,0,0,ambari-web/app/views/common/quick_view_link_view.js;,0 
4040,Aleksandr Kovalenko,ambari-web,0,In installer  behavior of actions in manage config-groups dialog different from reconfigure, instal behavior action manag config group config group dialog differ reconfigur,During reconfigure  in the Manage Config Groups dialog  the actions below the config-groups table (left table - Add/Remove/Duplicate/Rename) are immediate - you do not need to hit Save. Save is only for host membership changes. If host membership changes  the actions under left-table are disabled till Save. During install however  all actions are allowed till Save is hit. If you rename/duplicate and hit Cancel  all changes are lost - something which does not happen during reconfigure.The installer dialog should have similar behavior to reconfigure dialog., reconfigur manag config group dialog action config group config group tabl left tabl add remov duplic renam add remov duplic renam immedi not need hit save save save host membership chang chang host membership chang action left tabl left tabl disabl till save save instal howev action allow till save hit hit renam duplic renam duplic hit cancel chang lost someth not happen reconfigur reconfigur instal dialog similar behavior reconfigur dialog dialog,0,0,0,0,0,0,0 
4044,Oleg Nechiporenko,ambari-web,0,Refactor templates and popups, refactor templat popup,,,0,0,0,0,0,0,0 
4048,Mikhail Bayuk,ambari-web,0,Minor manage-config-group dialog UI changes, minor manag config group manag config group dialog UI chang,Label on top of left hand config-group table should be removed Left hand table and right hand table should occupy 1/3 and 2/3 of the dialog., label top left hand config group config group tabl remov left hand tabl right hand tabl occupi dialog dialog,0,0,0,0,0,0,0 
4052,Denys Buzhor,ambari-web,0,Rename config-group dialog should allow only description change also, renam config group config group dialog allow descript chang also,We wanted to change just the config-group description  but were unable to change without changing the name. The rename config-group dialog should allow changing description only also., want chang config group config group descript unabl chang without chang name name renam config group config group dialog allow chang descript also also,0,0,0,0,0,0,0 
4054,Oleg Nechiporenko,ambari-web,0,Need to show stale-config indicator on hosts page, need show stale config stale config indic host page,We show the restart indicator for stale-configs on services and individual host. Since we already have that information on the client  we need to show that on the Hosts page table. We need a filter to select stale-config hosts  and also show beside each host the stale-config indicator., show restart indic stale config stale config servic individu host host sinc alreadi inform client need show host page tabl tabl need filter select stale config stale config host also show besid host stale config stale config indic indic,0,0,0,0,0,0,0 
4058,Sumit Mohanty,ambari-server,0,ambari-agent/server should start automatically upon reboot, ambari agent server ambari agent server start automat upon reboot,ambari-agent and server are not set to start automatically  so if a machine reboots it becomes inaccessible., ambari agent ambari agent server not set start automat machin reboot becom inaccess inaccess,0,0,0,0,0,0,0 
4069,Xi Wang,ambari-web,0,Add hosts  if using Local Repository  UI incorrectly says 'no', add host use local repositori UI incorrectli say no no,On review page of install wizard/add host wizard -List the repos with their OS-Say 'Repositories'  not 'Local Repository'-Not a yes or no, review page instal wizard add wizard add host wizard list list repo OS say OS say repositori repositori not local local repositori not repositori not ye no,0,0,0,0,0,0,0 
4076,Mikhail Bayuk,ambari-web,0,Installer's host list doesn't show masters at top, instal instal host list show master top,Installer's host list should show masters at top, instal instal host list show master top,0,0,0,0,0,0,0 
4089,Oleg Nechiporenko,ambari-web,0,HDFS/ZKFC relations in EmberData, HDFS ZKFC HDFS ZKFC relat EmberData ember data,After enabling HA go to hosts page.Open host's page for host that has ZKFC.ZKFC doesn't have service.Expect:ZKFC should have HDFS as service., enabl HA go host page open page open host host page host ZKFC ZKFC ZKFC ZKFC servic expect ZKFC servic expect ZKFC HDFS servic servic,0,0,0,0,0,0,0 
4092,Andrii Babiichuk,ambari-web,0,Need tooltip showing error why local repo is bad, need tooltip show error local repo bad,I selected HDP 2.0.8 stack and Centos5 base-url was bad. The reason was given in the response - but it is not shown anywhere in UI. On the red exclamation mark we need a tooltip showing the error message from server along with HTTP error code., select HDP stack cento cento base url base url bad bad reason given respons not shown anywher UI UI red exclam mark need tooltip show error messag server along HTTP error code code,0,0,0,0,0,ambari-web/app/controllers/installer.js;ambari-web/app/templates/wizard/step1.hbs;ambari-web/app/views/wizard/step1_view.js;ambari-web/app/controllers/installer.js;,0 
4104,Dmytro Sen,ambari-agent,0,TestHardware.test_fqdnDomainHostname() fails, TestHardware test_fqdnDomainHostname test hardwar test_fqdn domain hostnam fail,The unit test failsFAIL: test_fqdnDomainHostname (TestHardware.TestHardware)----------------------------------------------------------------------Traceback (most recent call last): File '/home/dmitry/incubator-ambari/ambari-common/src/test/python/mock/mock.py'  line 1199  in patched return func(*args  **keywargs) File '/home/dmitry/incubator-ambari/ambari-agent/src/test/python/ambari_agent/TestHardware.py'  line 83  in test_fqdnDomainHostname self.assertEquals(result['hostname']  'ambari')AssertionError: 'dmitry-pc' != 'ambari', unit test failsFAIL fail FAIL test_fqdnDomainHostname test_fqdn domain hostnam TestHardware TestHardware traceback test hardwar test hardwar traceback recent call last last file home dmitri incub ambari ambari common src test python mock mock py home dmitri incub ambari ambari common src test python mock mock py line patch return func arg func arg keywarg keywarg file home dmitri incub ambari ambari agent src test python ambari_agent TestHardware py home dmitri incub ambari ambari agent src test python ambari_agent test hardwar py line test_fqdnDomainHostname test_fqdn domain hostnam self assertEquals result hostnam self assert equal result hostnam ambari AssertionError ambari assert error dmitri pc dmitri pc ambari ambari,0,0,0,0,0,ambari-agent/src/test/python/ambari_agent/TestHardware.py;,0 
4106,Andrii Babiichuk,ambari-web,0,Should not allow blank config group name, not allow blank config group name,1) Create config group2) just enter a &lt;space&gt; for the name3) That enables the OK button to save4) You can save that config group w/o a name.is reproducible on installer (works fine after installation), creat config group group enter lt space gt lt space gt name name enabl OK button save save save config group name name reproduc instal work fine instal instal,0,0,0,0,0,ambari-web/app/controllers/main/service/manage_config_groups_controller.js;,0 
4118,Oleg Nechiporenko,ambari-web,0,Manage Config Group link appears on host detail page (and cannot dismiss it once opened), manag config group link appear host detail page cannot dismiss open open,,,0,0,0,0,0,0,0 
4129,Jaimin D Jetly,ambari-web,0,HA wizard not accessible after upgrade, HA wizard not access upgrad,,,0,0,0,0,0,ambari-web/app/controllers/main/admin/highAvailability_controller.js;ambari-web/app/controllers/main/host/details.js;ambari-web/app/controllers/main/service.js;ambari-web/app/controllers/main/service/item.js;ambari-web/app/routes/main.js;ambari-web/app/utils/db.js;,0 
4132,Siddharth Wagle,ambari-server,0,Stale config indicator not shown when reconfiguring WebHCat  Ganglia  Nagios  ZooKeeper, stale config indic not shown reconfigur WebHCat web cat ganglia nagio ZooKeeper zoo keeper,Steps: Create a config group for any of the mentioned services and add a host to the config group. Save the config group.Result:Restart indicators do not appear., step step creat config group mention servic add host config group group save config group result restart group result restart indic not appear appear,0,0,0,0,0,0,0 
4135,Oleg Nechiporenko,ambari-web,0,Review page doesn't have info about Repositories, review page info repositori,Load Repositories info in the same way as for add Host Wizard., load repositori info way add host wizard wizard,0,0,0,0,0,0,0 
4145,Dmytro Sen,ambari-agent; ambari-server,0,Ability to restart a component, abil restart compon,Add option to Actions menu for 'restart'. That should queue the stop and start tasks.We should assume 'RESTART' as a default command. The base/default implementation is to call STOP and then START., add option action menu restart restart queue stop start task task assum RESTART RESTART default command command base default base default implement call STOP START START,0,0,0,0,0,ambari-agent/src/main/python/ambari_agent/CustomServiceOrchestrator.py;ambari-agent/src/main/python/resource_management/libraries/script/script.py;ambari-server/src/main/java/org/apache/ambari/server/RoleCommand.java;ambari-server/src/main/java/org/apache/ambari/server/agent/ExecutionCommand.java;ambari-server/src/main/java/org/apache/ambari/server/agent/HeartBeatHandler.java;ambari-server/src/main/java/org/apache/ambari/server/controller/AmbariCustomCommandExecutionHelperImpl.java;ambari-server/src/main/java/org/apache/ambari/server/metadata/ActionMetadata.java;ambari-server/src/main/java/org/apache/ambari/server/state/ComponentInfo.java;ambari-server/src/main/resources/stacks/HDP/2.0._/services/HBASE/metainfo.xml;ambari-server/src/main/resources/stacks/HDP/2.0._/services/HBASE/package/scripts/hbase_regionserver.py;ambari-server/src/test/java/org/apache/ambari/server/agent/TestHeartbeatHandler.java;ambari-server/src/test/java/org/apache/ambari/server/api/util/StackExtensionHelperTest.java;,0 
4152,Oleg Nechiporenko,contrib,0,Service Config page shows a blank page after enabling security (JS error), servic config page show blank page enabl secur JS JS error error,UI don't respond after enabling security, UI respond enabl secur,0,0,0,0,0,0,0 
4171,Oleg Nechiporenko,ambari-web,0,Fix UI Unit tests, fix UI unit test,,,0,0,0,0,0,0,0 
4177,Dmytro Shkvyra,ambari-agent,0,YARN check execute fails on install, YARN check execut fail instal,YARN check execute fails on install. See attached logs.IP Address on Hosts Page is shown as OS NOT SUPPORTED (w/o js errors  cluster installed using regular Nano-CentOS5.9 image type), YARN check execut fail instal instal see attach log IP log IP address host page shown OS NOT SUPPORTED js error cluster instal use regular nano CentOS nano cent OS imag type type,0,0,0,0,0,0,0 
4184,Mahadev konar,null,0,Fix versions of rpms in the stack to match the installed ones., fix version rpm stack match instal one one,Fix versions of rpms in the stack to match the installed ones., fix version rpm stack match instal one one,0,0,0,0,0,0,0 
4186,Oleg Nechiporenko,ambari-web,0,Global configs are not sent to server, global config not sent server,On the Deploy step Global Configs are not sent to server.So  Nagios and Ganglia (if installed via add service wizard) don't have any configs in service config page., deploy step global config not sent server server nagio ganglia instal via add servic wizard wizard config servic config page page,0,0,0,0,0,0,0 
4195,Andrii Babiichuk,ambari-web,0,Misalignment of 'Filter' combobox on installer when browser window is narrow, misalign filter filter combobox instal browser window narrow,,,0,0,0,0,0,ambari-web/app/styles/application.less;ambari-web/app/templates/common/configs/service_config.hbs;,0 
4200,Jeff Sposetti,ambari-web,0,Minor UI cleanup - remove double-borders  reduce text, minor UI cleanup remov doubl border doubl border reduc text,Remove double borders on alerts and host component page sections Remove some text to not wrap in 'delete host' dialog Remove 'Hosts' table header to clean-up config group dialog, remov doubl border alert host compon page section remov text not wrap delet host host dialog remov host host tabl header clean clean config group dialog,0,0,0,0,0,ambari-web/app/messages.js;ambari-web/app/styles/application.less;ambari-web/app/templates/main/service/manage_configuration_groups_popup.hbs;,0 
4206,Sumit Mohanty,ambari-server,0,Significant lag between host status update and slave/master component start/stop, signific lag host statu updat slave master slave master compon start stop start stop,Steps: Go to any host with slave component (DataNode  for example). Click 'Stop' options for slave component.Result: status marker for slave component start blinking red  but status marker for host behaves strangely: sometimes it also start blinking red immediately/ sometimes changes status to not-blinking red only after slave component stopping will be ended.The same for slave component starting., step step Go host slave compon DataNode data node exampl exampl click stop stop option slave compon result compon result statu marker slave compon start blink red statu marker host behav strang strang sometim also start blink red immedi immedi sometim chang statu not blink not blink red slave compon stop end end slave compon start start,0,0,0,0,0,0,0 
4211,Andrii Tkach,ambari-web,0,Empty content of review step in Add Host wizard, empti content review step add host wizard,JS error: Uncaught TypeError: Cannot call method 'forEach' of undefined, JS error error uncaught TypeError type error cannot call method forEach undefin,0,0,0,0,0,ambari-web/app/controllers/wizard/step8_controller.js;,0 
4220,Jeff Sposetti,ambari-web,0,Padding for config override properties, pad config overrid properti,,,0,0,0,0,0,0,0 
4224,Sumit Mohanty,ambari-server,0,When issuing Start/Stop of host components then predicate stale_config=true does not work, issu start stop start stop host compon predic stale_config true stale_config true not work,See the series of curl calls below.There are no components with stale configs but 4 components are being stopped. There are only 4 because Ambari only allows INSTALL call on already installed clients[root@c6401 vagrant]# curl -i -uadmin:admin -H 'X-Requested-By: ambari' http://c6401.ambari.apache.org:8080/api/v1/clusters/c1/host_components?HostRoles/stale_configs=true{ 'href' : 'http://c6401.ambari.apache.org:8080/api/v1/clusters/c1/host_components?HostRoles/stale_configs=true'  'items' : [ ]}[root@c6401 vagrant]# curl -i -uadmin:admin -H 'X-Requested-By: ambari'-d '{'HostRoles': { 'state': 'INSTALLED'}}' -X PUT http://c6401.ambari.apache.org:8080/api/v1/clusters/c1/host_components?HostRoles/stale_configs=true{ 'href' : 'http://c6401.ambari.apache.org:8080/api/v1/clusters/c1/requests/14'  'Requests' : { 'id' : 14  'status' : 'InProgress' }}[root@c6401 vagrant]# curl -i -uadmin:admin -H 'X-Requested-By: ambari' http://c6401.ambari.apache.org:8080/api/v1/clusters/c1/requests/14{ 'href' : 'http://c6401.ambari.apache.org:8080/api/v1/clusters/c1/requests/14'  'Requests' : { 'aborted_task_count' : 0  'cluster_name' : 'c1'  'completed_task_count' : 0  'failed_task_count' : 0  'id' : 14  'progress_percent' : 9.0  'queued_task_count' : 4  'request_context' : ''  'request_status' : 'PENDING'  'task_count' : 4  'timed_out_task_count' : 0 }  'tasks' : [ { 'href' : 'http://c6401.ambari.apache.org:8080/api/v1/clusters/c1/requests/14/tasks/178'  'Tasks' : { 'cluster_name' : 'c1'  'id' : 178  'request_id' : 14 } }  { 'href' : 'http://c6401.ambari.apache.org:8080/api/v1/clusters/c1/requests/14/tasks/179'  'Tasks' : { 'cluster_name' : 'c1'  'id' : 179  'request_id' : 14 } }  { 'href' : 'http://c6401.ambari.apache.org:8080/api/v1/clusters/c1/requests/14/tasks/180'  'Tasks' : { 'cluster_name' : 'c1'  'id' : 180  'request_id' : 14 } }  { 'href' : 'http://c6401.ambari.apache.org:8080/api/v1/clusters/c1/requests/14/tasks/181'  'Tasks' : { 'cluster_name' : 'c1'  'id' : 181  'request_id' : 14 } } ]}, see seri curl call no compon stale config compon stop stop ambari allow INSTALL call alreadi instal client root client root vagrant vagrant curl uadmin admin uadmin admin request request ambari ambari href href http ambari apach org api cluster host_components HostRoles stale_configs true http ambari apach org api cluster host_components host role stale_configs true item item root root vagrant vagrant curl uadmin admin uadmin admin request request ambari ambari HostRoles host role state state INSTALLED INSTALLED PUT href href http ambari apach org api cluster request http ambari apach org api cluster request request request id id statu statu InProgress progress root root vagrant vagrant curl uadmin admin uadmin admin request request ambari ambari href href http ambari apach org api cluster request http ambari apach org api cluster request request request aborted_task_count aborted_task_count cluster_name cluster_name completed_task_count completed_task_count failed_task_count failed_task_count id id progress_percent progress_percent queued_task_count queued_task_count request_context request_context request_status request_status PENDING PENDING task_count task_count timed_out_task_count timed_out_task_count task task href href http ambari apach org api cluster request task http ambari apach org api cluster request task task task cluster_name cluster_name id id request_id request_id href href http ambari apach org api cluster request task http ambari apach org api cluster request task task task cluster_name cluster_name id id request_id request_id href href http ambari apach org api cluster request task http ambari apach org api cluster request task task task cluster_name cluster_name id id request_id request_id href href http ambari apach org api cluster request task http ambari apach org api cluster request task task task cluster_name cluster_name id id request_id request_id,0,0,0,0,0,0,0 
4225,Yusaku Sako,ambari-web,0,Starting/Stopping components based on restart indicator floods request history and execution queue, start stop start stop compon base restart indic flood request histori execut queue,When starting/stopping components based on the Start/Stop Components buttons that show up after service reconfiguration  it creates one request per component (as shown in the Background Operations popup). This floods the request history and the user cannot see what has been done prior. From the user's standpoint  Start Components and Stop Components actions should each show up as one request.Also  this has major performance implications  since multiple requests cannot be processed in parallel by the server (unlike tasks within a single request)., start stop start stop compon base start stop start stop compon button show servic reconfigur creat one request per compon shown background oper popup popup flood request histori user cannot see done prior prior user user standpoint start compon stop compon action show one request also request also major perform implic sinc multipl request cannot process parallel server unlik task within singl request request,0,0,0,0,0,0,0 
4247,Andrii Tkach,ambari-web,0,Restart marker does not show up sometimes in the Hosts page, restart marker not show sometim host page,After reconfiguring  restart indicators do not show up on the Host pages sometimes.Clicking on an individual host shows the restart indicator in the Host Details page., reconfigur restart indic not show host page sometim click sometim click individu host show restart indic host detail page page,0,0,0,0,0,ambari-web/app/controllers/global/update_controller.js;ambari-web/app/models/host.js;ambari-web/app/views/main/host.js;,0 
4265,Jeff Sposetti,null,0,Add env AMBARI_JVM_ARGS to ambari-server start, add env AMBARI_JVM_ARGS AMBARI JVM ARGS ambari server ambari server start,Useful if you want to set AMBARI_JVM_ARGS in the environment. For example: Setting http proxy that Ambari Serverexport AMBARI_JVM_ARGS='-Dhttp.proxyHost=the.proxy.host -Dhttp.proxyPort=1234'ambari-server start, use want set AMBARI_JVM_ARGS AMBARI JVM ARGS environ environ exampl exampl set http proxi ambari serverexport AMBARI_JVM_ARGS dhttp proxyHost proxi host AMBARI JVM ARGS dhttp proxi host proxi host dhttp proxyPort ambari server dhttp proxi port ambari server start,0,0,0,0,0,0,0 
4279,Dmitry Lysnichenko,ambari-agent; test,0,Status commands are not executed for new services, statu command not execut new servic,For new services (those  that are not hardcoded at LiveStatus.py)  status commands are not executed., new servic not hardcod LiveStatus py live statu py statu command not execut execut,0,0,0,0,0,0,0 
4284,Oleg Nechiporenko,ambari-web,0,Alerts  Restart  Maintenance elements in the Hosts filters, alert restart mainten element host filter,Move this 3 elements to the second line (under All  Healthy...).Also refactor their code-realization., move element second line healthi also healthi also refactor code realiz code realiz,0,0,0,0,0,0,0 
4299,Myroslav Papirkovskyy,ambari-server,0,Ambari server unit test failure, ambari server unit test failur,Results :Failed tests: testDoWork(org.apache.ambari.server.state.scheduler.BatchRequestJobTest): (..)Tests run: 1265  Failures: 1  Errors: 0  Skipped: 8, result fail fail test test testDoWork org apach ambari server state schedul BatchRequestJobTest test work org apach ambari server state schedul batch request job test test test run run failur failur error error skip skip,0,0,0,0,0,0,0 
4300,Andrii Tkach,ambari-web,0,Service tab: growing number of calls to update alerts, servic tab tab grow number call updat alert,After routing by services on Service page number of calls to server(to get Alerts) grows.Also mock json with alerts need to be added., rout servic servic page number call server server get alert alert grow also grow also mock json alert need ad ad,0,0,0,0,0,ambari-web/app/assets/data/alerts/HDP2/alerts.json;ambari-web/app/assets/data/alerts/HDP2/host_alerts.json;ambari-web/app/assets/data/alerts/HDP2/service_alerts.json;ambari-web/app/assets/data/hosts/HDP2/hosts.json;ambari-web/app/assets/data/services/HDP2/services.json;ambari-web/app/controllers/main/alerts_controller.js;ambari-web/app/utils/ajax.js;,0 
4306,Siddharth Wagle,ambari-server,0,Request Schedule status not updated for Point in time execution request, request schedul statu not updat point time execut request,API call:curl -u admin:admin -H 'X-Requested-By:ambari' -i -X POST -d '[{'RequestSchedule':{'batch':[{'requests':[{'order_id' : '1' 'type':'POST' 'uri':'/api/v1/clusters/c1/requests' 'RequestBodyInfo':{'RequestInfo':{'context':'Restart Nagios' 'command':'RESTART' 'service_name':'NAGIOS' 'component_name':'NAGIOS_SERVER' 'hosts':'c6401.ambari.apache.org'}}}]} {'batch_settings':{'batch_separation_in_seconds':120 'task_failure_tolerance':1}}]}}]' http://c6401.ambari.apache.org:8080/api/v1/clusters/c1/request_schedulesRequest Schedule:{href: 'http://c6401.ambari.apache.org:8080/api/v1/clusters/c1/request_schedules/23' RequestSchedule: {batch: {batch_requests: [{order_id: 1 request_type: 'POST' request_uri: '/api/v1/clusters/c1/requests' request_body: '{'RequestInfo':{'context':'Restart Nagios' 'command':'RESTART' 'service_name':'NAGIOS' 'component_name':'NAGIOS_SERVER' 'hosts':'c6401.ambari.apache.org'}}' request_status: 'InProgress' return_code: 202}] batch_settings: {batch_separation_in_seconds: 120 task_failure_tolerance_limit: 1}} cluster_name: 'c1' description: null id: 23 last_execution_status: 'InProgress' schedule: null status: 'SCHEDULED'}}, API call curl call curl admin admin admin admin request ambari request ambari POST RequestSchedule batch request order_id request schedul batch request order_id type POST type POST uri api cluster request uri api cluster request RequestBodyInfo RequestInfo context restart request bodi info request info context restart nagio nagio command RESTART command RESTART service_name NAGIOS service_name NAGIOS component_name NAGIOS_SERVER component_name NAGIOS SERVER host ambari apach org host ambari apach org batch_settings batch_separation_in_seconds batch_settings batch_separation_in_seconds task_failure_tolerance task_failure_tolerance schedul href schedul href http ambari apach org api cluster request_schedules http ambari apach org api cluster request_schedules RequestSchedule request schedul batch batch batch_requests batch_requests order_id order_id request_type request_type POST POST request_uri request_uri api cluster request api cluster request request_body request_body RequestInfo context restart request info context restart nagio nagio command RESTART command RESTART service_name NAGIOS service_name NAGIOS component_name NAGIOS_SERVER component_name NAGIOS SERVER host ambari apach org host ambari apach org request_status request_status InProgress progress return_code return_code batch_settings batch_settings batch_separation_in_seconds batch_separation_in_seconds task_failure_tolerance_limit task_failure_tolerance_limit cluster_name cluster_name descript descript null id id last_execution_status last_execution_status InProgress progress schedul schedul null statu statu SCHEDULED SCHEDULED,0,0,0,0,0,0,0 
4318,Oleg Nechiporenko,ambari-web,0,Service Restart All action cleanup, servic restart action cleanup,1. There is no need to send request to restart clients.2. When user clicks on Restart All actions  components start restarting immediately. But all other actions shows confirmation popup like 'Are you sure?' (Start  Stop  Run Service Check etc)., no need send request restart client client user click restart action compon start restart immedi immedi action show confirm popup like sure sure start start stop run servic check etc etc,0,0,0,0,0,0,1 
4333,Antonenko Alexander,ambari-web,0,Incorrect behavior of 'Save' button in 'Manage Configuration Groups' window, incorrect behavior save save button manag manag configur group group window,Steps: Go to 'Customize Services' page. Open 'Manage Configuration Groups' window for any service. Add new custom group and assign host to it. Save changes. Open 'Manage Configuration Groups' window again. Select custom group and remove assigned host.Result: 'Save' button is disabled  'Add hosts' also is disabled.Note: after selecting default group 'Save' button become active.Also if after all steps try to add hosts to custom group  'Save' button will not be active., step step Go custom custom servic servic page page open manag manag configur group group window servic servic add new custom group assign host save chang chang open manag manag configur group group window select custom group remov assign host result host result save save button disabl add add host host also disabl note disabl note select default group save save button becom activ also activ also step tri add host custom group save save button not activ activ,0,0,0,0,0,0,0 
4336,Mahadev konar,null,0,Move 1.3.4 stack to 1.3.3 using the python libraries., move stack use python librari librari,Move 1.3.4 stack to 1.3.3 using the pythin libraries., move stack use pythin librari librari,0,0,0,0,0,0,1 
4341,Mahadev konar,null,0,Rename 2.0.8 to 2.1.1 in the stack definition., renam stack definit definit,Rename 2.0.8 to 2.1.1 in the stack definition., renam stack definit definit,0,0,0,0,0,0,1 
4349,Oleg Nechiporenko,ambari-web,0,Slaves API-calls, slave API call API call,For Slaves (DataNodes  NodeManagers  RegionServers  or TaskTrackers): Start Stop Restart Decommission Recommission, slave DataNodes data node NodeManagers node manag RegionServers region server TaskTrackers task tracker start stop restart decommiss recommiss,0,0,0,0,0,0,1 
4354,Dmytro Shkvyra,ambari-agent,0,HostCleanup should also clean /tmp/hadoop-*, HostCleanup host cleanup also clean tmp hadoop tmp hadoop,HostCleanup should also check the following directories (and clean):/tmp/hadoop-*For example  if the /tmp/hadoop-nagios directory is present  but it doesn't have the right ownership/perms for nagios user  the Hive Metastore Nagios alert will occur. I saw this after doing an install on an un-clean machine.Hive Metastore statusCRIT for about a minuteCRITICAL: Error accessing Hive Metastore status [Error creating temp dir in hadoop.tmp.dir /tmp/hadoop-nagios due to Permission denied]An easy way to reproduce this:1) Perform install2) Go to Nagios server machine3) Change perms on /tmp/hadoop-nagios so that the nagios user does not have access4) The Nagios alert will fire, HostCleanup host cleanup also check follow directori clean tmp hadoop clean tmp hadoop exampl tmp hadoop nagio tmp hadoop nagio directori present right ownership perm ownership perm nagio user hive metastor nagio alert occur occur saw instal un clean un clean machin hive machin hive metastor statusCRIT statu CRIT minuteCRITICAL minut CRITICAL error access hive metastor statu error error creat temp dir hadoop tmp dir hadoop tmp dir tmp hadoop nagio tmp hadoop nagio due permiss deni deni easi way reproduc perform instal instal Go nagio server machin machin chang perm tmp hadoop nagio tmp hadoop nagio nagio user not access access nagio alert fire,0,0,0,0,0,0,1 
4355,Siddharth Wagle,ambari-server,0,Add relocate resources scripts to the pom file, add reloc resourc script pom file,The relocate resources python script is not a part of the rpm package., reloc resourc python script not part rpm packag packag,0,0,0,0,0,0,1 
4361,Srimanth Gunturi,ambari-web,0,Rolling restart failure tolerance should be percentage values, roll restart failur toler percentag valu,Currently when we make rolling restart API calls  the task_failure_tolerance value is given as count of hosts. Rather it should be percentage of total hosts., current make roll restart API call task_failure_tolerance valu given count host host rather percentag total host host,0,0,0,0,0,0,1 
4365,Sumit Mohanty,ambari-server,0,Action definitions should be provided as declarative resources - read from XML files, action definit provid declar resourc read XML file,Currently  action definition are stored in database. This is not in-line with the declarative definition of stack and custom commands (as part of stack). The custom actions are essentially same as custom commands except they are defined at the level of clusters. So we should move the custom actions to XML formatted files that ambari-server can read when starting up. This means that when one needs to make any edit they will have to restart ambari-server. This requirement is OK as adding/modifying custom actions is not a frequently done operation., current action definit store databas databas not line line declar definit stack custom command part stack stack custom action essenti custom command except defin level cluster cluster move custom action XML format file ambari server ambari server read start mean one need make edit restart ambari server ambari server requir OK ad modifi ad modifi custom action not frequent done oper oper,0,0,0,0,0,0,1 
4367,Andrii Tkach,ambari-web,0,Alerts block shows spinner if Nagios not installed, alert block show spinner nagio not instal,When Nagios not installed Alerts block should show message that it's not installed instead of spinner., nagio not instal alert block show messag not instal instead spinner spinner,0,0,0,0,0,ambari-web/app/controllers/main/alerts_controller.js;,0 
4380,Oleg Nechiporenko,ambari-web,0,Hosts API-calls, host API call API call,For each host:P0: Start All Components Stop All ComponentsP1: Restart All Components, host host start compon stop ComponentsP compon restart compon,0,0,0,0,0,0,1 
4383,Eugene Chekanskiy,ambari-server,0,Datanode data directory is not created correctly, datanod data directori not creat correctli,dfs.datanode.data.dir must be handled as comma separated directories., df datanod data dir df datanod data dir must handl comma separ directori directori,0,0,0,0,0,0,1 
4395,Dmytro Shkvyra,ambari-server,0,ambari-server should use repo when downloading jdk 7, ambari server ambari server use repo download jdk,,,0,0,0,0,0,0,0 
4396,Oleg Nechiporenko,ambari-web,0,Misc code cleanup, misc code cleanup,,,0,0,0,0,0,0,1 
4402,Siddharth Wagle,ambari-server,0,Delete Config Group Host mapping broken due to error introduced by perf patch, delet config group host map broken due error introduc perf patch,Unit test: org.apache.ambari.server.state.ConfigGroupTest#testRemoveHostThis unit test is not a part of 1.4.3 branch  it was added later. (trunk)Exception thrown during ConfigGroupImpl.removeHost()2014-01-06 17:46:35 989 ERROR [main] configgroup.ConfigGroupImpl (ConfigGroupImpl.java:removeHost(274)) - Failed to delete config group host mapping  clusterName = foo  id = 1  hostname = h1java.lang.IllegalArgumentException: Object: org.apache.ambari.server.orm.cache.ConfigGroupHostMappingImpl@cc34948d is not a known entity type. at org.eclipse.persistence.internal.sessions.UnitOfWorkImpl.performRemove(UnitOfWorkImpl.java:3538) at org.eclipse.persistence.internal.jpa.EntityManagerImpl.remove(EntityManagerImpl.java:518) at org.apache.ambari.server.orm.dao.ConfigGroupHostMappingDAO.removeByPK(ConfigGroupHostMappingDAO.java:250) at com.google.inject.persist.jpa.JpaLocalTxnInterceptor.invoke(JpaLocalTxnInterceptor.java:58) at org.apache.ambari.server.state.configgroup.ConfigGroupImpl.removeHost(ConfigGroupImpl.java:272) at com.google.inject.persist.jpa.JpaLocalTxnInterceptor.invoke(JpaLocalTxnInterceptor.java:66) at org.apache.ambari.server.state.cluster.ClustersImpl.deleteConfigGroupHostMapping(ClustersImpl.java:640) at org.apache.ambari.server.state.cluster.ClustersImpl.unmapHostFromCluster(ClustersImpl.java:615) at org.apache.ambari.server.state.ConfigGroupTest.testRemoveHost(ConfigGroupTest.java:203), unit test test org apach ambari server state ConfigGroupTest testRemoveHostThis org apach ambari server state config group test test remov host unit test not part branch ad later later trunk except trunk except thrown ConfigGroupImpl removeHost config group impl remov host ERROR main main configgroup ConfigGroupImpl configgroup config group impl ConfigGroupImpl java removeHost config group impl java remov host fail delet config group host map clusterName cluster name foo id hostnam java lang IllegalArgumentException java lang illeg argument except object object org apach ambari server orm cach ConfigGroupHostMappingImpl cc org apach ambari server orm cach config group host map impl cc not known entiti type type org eclips persist intern session UnitOfWorkImpl performRemove UnitOfWorkImpl java org eclips persist intern session unit work impl perform remov unit work impl java org eclips persist intern jpa EntityManagerImpl remov EntityManagerImpl java org eclips persist intern jpa entiti manag impl remov entiti manag impl java org apach ambari server orm dao ConfigGroupHostMappingDAO removeByPK ConfigGroupHostMappingDAO java org apach ambari server orm dao config group host map DAO remov PK config group host map DAO java com googl inject persist jpa JpaLocalTxnInterceptor invok JpaLocalTxnInterceptor java com googl inject persist jpa jpa local txn interceptor invok jpa local txn interceptor java org apach ambari server state configgroup ConfigGroupImpl removeHost ConfigGroupImpl java org apach ambari server state configgroup config group impl remov host config group impl java com googl inject persist jpa JpaLocalTxnInterceptor invok JpaLocalTxnInterceptor java com googl inject persist jpa jpa local txn interceptor invok jpa local txn interceptor java org apach ambari server state cluster ClustersImpl deleteConfigGroupHostMapping ClustersImpl java org apach ambari server state cluster cluster impl delet config group host map cluster impl java org apach ambari server state cluster ClustersImpl unmapHostFromCluster ClustersImpl java org apach ambari server state cluster cluster impl unmap host cluster cluster impl java org apach ambari server state ConfigGroupTest testRemoveHost ConfigGroupTest java org apach ambari server state config group test test remov host config group test java,0,0,0,0,0,0,0 
4405,Sumit Mohanty,ambari-server,0,Remove property fs.checkpoint.size during upgrade, remov properti fs checkpoint size fs checkpoint size upgrad,Property fs.checkpoint.size is deprecated. The upgrade script should remove it. Users can add the replacement themselves - dfs.namenode.checkpoint.txns., properti fs checkpoint size fs checkpoint size deprec deprec upgrad script remov user add replac df namenod checkpoint txn df namenod checkpoint txn,0,0,0,0,0,0,1 
4408,Srimanth Gunturi,ambari-web,0,Background operations dialog in weird state after exception, background oper dialog weird state except,Background operations dialog goes into a weird state after hitting an exception with request_schedule information. It always expects request_schedule information to be present., background oper dialog goe weird state hit except request_schedule inform inform alway expect request_schedule inform present present,0,0,0,0,0,0,1 
4416,Dmytro Shkvyra,ambari-server,0,HDFS start failed on 2.1.1 stack, HDFS start fail stack,STR: Deployed minimal cluster with HDFS and ZK. HDFS start failed. Added YARN+MR2  Nagios and Ganglia. Picture with HDFS was the same.Output:Fail: Execution of 'ulimit -c unlimited &amp;&amp; if [ 'ulimit -c' != 'unlimited' ]; then exit 77; fi &amp;&amp; export HADOOP_LIBEXEC_DIR=/usr/lib/hadoop/libexec &amp;&amp; /usr/lib/hadoop/sbin/hadoop-daemon.sh --config /etc/hadoop/conf start secondarynamenode' returned 1. -bash: line 0: ulimit: core file size: cannot modify limit: Operation not permittedFull folders with logs are attached., STR STR deploy minim cluster HDFS ZK ZK HDFS start fail fail ad YARN MR YARN MR nagio ganglia ganglia pictur HDFS output fail output fail execut ulimit unlimit amp amp amp amp ulimit unlimit unlimit exit fi amp amp amp amp export HADOOP_LIBEXEC_DIR usr lib hadoop libexec HADOOP LIBEXEC DIR usr lib hadoop libexec amp amp amp amp usr lib hadoop sbin hadoop daemon sh usr lib hadoop sbin hadoop daemon sh config etc hadoop conf etc hadoop conf start secondarynamenod secondarynamenod return bash bash line ulimit ulimit core file size size cannot modifi limit limit oper not permittedFull permit full folder log attach attach,0,0,0,0,0,0,1 
4420,Siddharth Wagle,ambari-server,0,ORA-01795: maximum number of expressions in a list is 1000 for Oracle DB, ORA ORA maximum number express list oracl DB,PROBLEM:ORA-01795: maximum number of expressions in a list is 1000 in Ambari Server log. Customer recently upgraded to Ambari 1.4.2Error is:08:54:51 320 ERROR [qtp1280560314-2070] ReadHandler:84 - Caught a runtime exception executing a queryLocal Exception Stack: Exception [EclipseLink-4002] (Eclipse Persistence Services - 2.4.0.v20120608-r11652): org.eclipse.persistence.exceptions.DatabaseExceptionInternal Exception: java.sql.SQLSyntaxErrorException: ORA-01795: maximum number of expressions in a list is 1000Error Code: 1795Call: SELECT task_id  attempt_count  event  exitcode  host_name  last_attempt_time  request_id  role  role_command  stage_id  start_time  status  std_error  std_out FROM host_role_command WHERE (task_id IN (? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?)) ORDER BY task_id bind =&gt; [2551 parameters bound]Query: ReadAllQuery(referenceClass=HostRoleCommandEntity sql='SELECT task_id  attempt_count  event  exitcode  host_name  last_attempt_time  request_id  role  role_command  stage_id  start_time  status  std_error  std_out FROM host_role_command WHERE (task_id IN ?) ORDER BY task_id') at org.eclipse.persistence.exceptions.DatabaseException.sqlException(DatabaseException.java:333) at org.eclipse.persistence.internal.databaseaccess.DatabaseAccessor.basicExecuteCall(DatabaseAccessor.java:646) at org.eclipse.persistence.internal.databaseaccess.DatabaseAccessor.executeCall(DatabaseAccessor.java:537) at org.eclipse.persistence.internal.sessions.AbstractSession.basicExecuteCall(AbstractSession.java:1800)STEPS TO REPRODUCE: Over 1000 entries in the host_role_command and execution_command tables when oracle is used for Ambari backend databseACTUAL BEHAVIOR: Oracle throws the errorEXPECTED BEHAVIOR: There should be a limit to prevent this (possibly modify the syntax of the oracle query), PROBLEM ORA PROBLEM ORA maximum number express list ambari server log log custom recent upgrad ambari error error ERROR qtp qtp ReadHandler read handler caught runtim except execut queryLocal queri local except stack stack except EclipseLink eclips link eclips eclips persist servic org eclips persist except DatabaseExceptionInternal org eclips persist except databas except intern except except java sql SQLSyntaxErrorException java sql SQL syntax error except ORA ORA maximum number express list error error code code call call SELECT task_id attempt_count event exitcod host_name last_attempt_time request_id role role_command stage_id start_time statu std_error std_out host_role_command task_id ORDER task_id bind gt gt paramet bound queri bound queri ReadAllQuery referenceClass HostRoleCommandEntity read queri refer class host role command entiti sql SELECT sql SELECT task_id attempt_count event exitcod host_name last_attempt_time request_id role role_command stage_id start_time statu std_error std_out host_role_command task_id ORDER task_id task_id org eclips persist except DatabaseException sqlException DatabaseException java org eclips persist except databas except sql except databas except java org eclips persist intern databaseaccess DatabaseAccessor basicExecuteCall DatabaseAccessor java org eclips persist intern databaseaccess databas accessor basic execut call databas accessor java org eclips persist intern databaseaccess DatabaseAccessor executeCall DatabaseAccessor java org eclips persist intern databaseaccess databas accessor execut call databas accessor java org eclips persist intern session AbstractSession basicExecuteCall AbstractSession java STEPS org eclips persist intern session abstract session basic execut call abstract session java STEPS REPRODUCE REPRODUCE entri host_role_command execution_command tabl oracl use ambari backend databseACTUAL databs ACTUAL BEHAVIOR BEHAVIOR oracl throw errorEXPECTED error EXPECTED BEHAVIOR BEHAVIOR limit prevent possibl modifi syntax oracl queri queri,0,0,0,0,0,0,1 
4425,Vitaly Brodetskyi,ambari-agent,0,Add upgradestack support for MySQL, add upgradestack support MySQL SQL,Similar to Oracle/Postgres we need to make sure that ambari-server upgradestack works for MySQL, similar oracl postgr oracl postgr need make sure ambari server ambari server upgradestack work MySQL SQL,0,0,0,0,0,0,1 
4501,Oleg Nechiporenko,ambari-web,0,health status yellow (lost heartbeat) not showing icon, health statu yellow lost heartbeat heartbeat not show icon,See attached. Using 1.5.0.335On Hosts page. Other pages seem fine., see attach attach use host page page page seem fine fine,0,0,0,0,0,0,0 
4521,Oleg Nechiporenko,ambari-web,0,Bulk Ops: Restart on Slaves should popup rolling restart dialog, bulk op op restart slave popup roll restart dialog,When performing Restart on Slaves via Bulk Ops menu on the Hosts page  Restart should popup the rolling restart dialog  just like it does when Restarting Slaves under Service Actions., perform restart slave via bulk op menu host page restart popup roll restart dialog like restart slave servic action action,0,0,0,0,0,0,1 
4523,Perry Tian,ambari-agent,0,Host registering failure from primary/agent os checking on centos6, host regist failur primari agent primari agent os check cento cento,I am using Ambari (1.4.3.38) for hadoop cluster installation and management. All the cluster nodes are built on centos 6.0.During the ambari server installation  ambari-server recognized the primary/cluster os as redhat6 (see ambari.properties). During the ambari agent bootstrap/host register  ambari-agent regonized the agent os as centos linux6 (see log). From log files (ambari-server.log  ambari-agent.log)  I found the inconsistence caused the warning of ambari-agent bootstrapping and failure of host registering.I'm still not sure why this happen  but I guess it's caused by the differene of os checking methods among ambari server side code  ambari-agent bootstrap script (os_type_check.sh based on os release file) and registering script (Controller.py/Register.py based on os hardware profile) .I just share to see if anyone can fix the issue.BTW  for me  to solve the problem  I manually edited the script files to make it work temporarily:To avoid warning of agent bootstrapping  in os_type_check.sh  add current_os=$RH6 above the echo line or add res=0 after case statement;To make the node register work  in Controller.py  add data=data.replace('centos linux' 'redhat') before sending registering request;Thanks., use ambari hadoop cluster instal manag manag cluster node built cento ambari server instal ambari server ambari server recogn primari cluster primari cluster os redhat redhat see ambari properti ambari properti ambari agent bootstrap host bootstrap host regist ambari agent ambari agent regon agent os cento linux linux see log log log file ambari server log ambari server log ambari agent log ambari agent log found inconsist caus warn ambari agent ambari agent bootstrap failur host regist regist still not sure happen guess caus differen os check method among ambari server side code ambari agent ambari agent bootstrap script os_type_check sh os_type_check sh base os releas file file regist script control py regist py control py regist py base os hardwar profil profil share see anyon fix issu BTW issu BTW solv problem manual edit script file make work temporarili temporarili avoid warn agent bootstrap os_type_check sh os_type_check sh add current_os RH current_os RH echo line add re re case statement statement make node regist work control py control py add data data replac cento data data replac cento linux linux redhat redhat send regist request thank request thank,0,0,0,0,0,0,1 
4526,Eugene Chekanskiy,ambari-server,0,Oozie Server installation fails when Falcon is selected, oozi server instal fail falcon select,,,0,0,0,0,0,0,1 
4551,Andrii Babiichuk,ambari-web,0,Alert count badge and restart indicator issues, alert count badg restart indic issu,The alert badge shown in the left nav shows up a bit strange (too little padding on the right). Also  when the restart indicator appears  the padding for the alert badge fixes itself  but the restart indicator appears too close. See attached., alert badg shown left nav show bit strang littl pad right right also restart indic appear pad alert badg fix restart indic appear close close see attach attach,0,0,0,0,0,ambari-web/app/styles/application.less;ambari-web/app/templates/main/service/menu_item.hbs;,1 
4552,Andrii Babiichuk,ambari-web,0,OOS status for component on host detail page makes button too big, OOS statu compon host detail page make button big,,,0,0,0,0,0,ambari-web/app/messages.js;ambari-web/app/styles/application.less;ambari-web/app/templates/main/host/details/host_component.hbs;ambari-web/app/views/main/host/details/host_component_view.js;,1 
4560,Jaimin D Jetly,ambari-web,0,BG operation pop-up: JS error encountered on clicking on host in progress state., BG oper pop pop JS error encount click host progress state state,,,0,0,0,0,0,0,1 
4561,Yusaku Sako,ambari-web,0,Falcon Client install task shows up as just 'install' rather than 'Falcon Client install', falcon client instal task show instal instal rather falcon falcon client instal instal,See attached., see attach attach,0,0,0,0,0,0,0 
4570,Sumit Mohanty,ambari-server,0,Various issues related to decommission support, variou issu relat decommiss support,Tracking few issues related to decommission support Even with HBase HA only one master should be used for decommission Alternatively  for HDFS/MR/YARN use all master host components Do not use 'default' method while using python based system resources Add support for command details and custom command names, track issu relat decommiss support even HBase base HA one master use decommiss altern HDFS MR YARN HDFS MR YARN use master host compon not use default default method use python base system resourc add support command detail custom command name,0,0,0,0,0,0,1 
4574,Andrii Babiichuk,ambari-web,0,Upon restart of ambari-server  the service status on Dashboard page remain unchanged, upon restart ambari server ambari server servic statu dashboard page remain unchang,After ambari-server restart  if FE remains at the Dashboard page  the service status (Yellow buttons) never gets updated even if the API indicates that the status are all Green/Red. In my case  never is 6 minutes.Upon refresh or moving to other tabs the view is promptly updated., ambari server ambari server restart FE remain dashboard page servic statu yellow yellow button button never get updat even API indic statu green red green red case never minut upon minut upon refresh move tab view promptli updat updat,0,0,0,0,0,ambari-web/app/router.js;ambari-web/app/routes/installer.js;,1 
4575,Oleg Nechiporenko,ambari-web,0,Host Details > Actions pulldown likes to hide, host detail action pulldown like hide,Actions pull down on the Host Detail page likes to hide itself when it's open. This is a bit annoying., action pull host detail page like hide open open bit annoy annoy,0,0,0,0,0,0,1 
4600,Dmytro Shkvyra,ambari-server,0,Remove --jce-policy from warning statement, remov jce polici jce polici warn statement,We have removed option -c or --jce-policy. So the warning message should not use that option in the help statement.jce_download_fail_msg = ' Failed to download JCE Policy archive : {0}. ' / 'Please check that JCE Policy archive is available ' / 'at {1} . Also you may install JCE Policy archive manually using ' / '--jce-policy command line argument.'.format('{0}'  jce_url), remov option jce polici jce polici warn messag not use option help statement jce_download_fail_msg statement jce_download_fail_msg fail download JCE polici archiv pleas pleas check JCE polici archiv avail also may instal JCE polici archiv manual use jce polici jce polici command line argument format argument format jce_url jce_url,0,0,0,0,0,0,0 
4601,Andrii Babiichuk,ambari-web,0,adding more master components styling is missing, ad master compon style miss,,,0,0,0,0,0,ambari-web/app/controllers/wizard/step5_controller.js;,0 
4603,Andrii Babiichuk,ambari-web,0,Host names goes under text  icons, host name goe text icon,see attached, see attach,0,0,0,0,0,ambari-web/app/models/host.js;ambari-web/app/styles/application.less;ambari-web/app/templates/main/host.hbs;ambari-web/app/templates/main/service/info/summary/master_components.hbs;,1 
4605,Oleg Nechiporenko,ambari-web,0,Host details: clients list disappears, host detail detail client list disappear,Go to host page with some clients installedRefresh itGot: clients are not displayed on the pageExpected: list of installed clients, Go host page client installedRefresh instal refresh itGot got client not display pageExpected page expect list instal client,0,0,0,0,0,0,0 
4608,Andrii Babiichuk,ambari-web,0,medkit-icons are shifted out of their places  in hosts table in Safari., medkit icon medkit icon shift place host tabl safari safari,,,0,0,0,0,0,ambari-web/app/styles/application.less;,0 
4612,Siddharth Wagle,ambari-server,0,Exception on deploing step: java.sql.BatchUpdateException: ORA-00942, except deplo step step java sql BatchUpdateException java sql batch updat except ORA ORA,Exception trace:18:27:19 191 WARN [qtp1643608425-22] ServletHandler:514 - /api/v1/clusters/c1/servicesjavax.persistence.RollbackException: Exception [EclipseLink-4002] (Eclipse Persistence Services - 2.4.0.v20120608-r11652): org.eclipse.persistence.exceptions.DatabaseExceptionInternal Exception: java.sql.BatchUpdateException: ORA-00942: table or view does not existError Code: 942 at org.eclipse.persistence.internal.jpa.transaction.EntityTransactionImpl.commitInternal(EntityTransactionImpl.java:102) at org.eclipse.persistence.internal.jpa.transaction.EntityTransactionImpl.commit(EntityTransactionImpl.java:63) at com.google.inject.persist.jpa.JpaLocalTxnInterceptor.invoke(JpaLocalTxnInterceptor.java:87), except trace trace WARN qtp qtp ServletHandler servlet handler api cluster servicesjavax persist RollbackException api cluster servicesjavax persist rollback except except EclipseLink eclips link eclips eclips persist servic org eclips persist except DatabaseExceptionInternal org eclips persist except databas except intern except except java sql BatchUpdateException java sql batch updat except ORA ORA tabl view not existError exist error code code org eclips persist intern jpa transact EntityTransactionImpl commitInternal EntityTransactionImpl java org eclips persist intern jpa transact entiti transact impl commit intern entiti transact impl java org eclips persist intern jpa transact EntityTransactionImpl commit EntityTransactionImpl java org eclips persist intern jpa transact entiti transact impl commit entiti transact impl java com googl inject persist jpa JpaLocalTxnInterceptor invok JpaLocalTxnInterceptor java com googl inject persist jpa jpa local txn interceptor invok jpa local txn interceptor java,0,0,0,0,0,0,0 
4635,Antonenko Alexander,ambari-web,0,'SNN Process' alert displays after HA enabled successfully, SNN SNN process process alert display HA enabl success,STR:1. Install  setup and start Ambari server by default.2. Deploy Hadoop by default (stack 2.0.6  choose all services to install).3. Enable HA.4. Wait for at least 150 seconds.4. Go to HDFS Service/Hosts page page.Actual result:'Secondary NameNode Process' alert displayed.Expected result:There should not be 'Secondary NameNode' alert on page., STR STR instal setup start ambari server default default deploy hadoop default stack choos servic instal instal enabl HA HA wait least second second Go HDFS servic host servic host page page actual page actual result secondari result secondari NameNode name node process process alert display expect display expect result result not secondari secondari NameNode name node alert page page,0,0,0,0,0,0,1 
4637,Andrii Tkach,ambari-web,0,The user is not always redirected to the login page when unauthenticated, user not alway redirect login page unauthent,1. Try to enable HA with fail on 9th step for Start All services2. Use link http://&lt;host&gt;:8080/#/main/admin/highAvailability/enable/step13. HA Wizard is shown without previously loaded Login Page (see url and js errors in attached screenshot)Expexted result:Login Page should be loaded firts., tri enabl HA fail th step start servic servic use link HA wizard shown without previous load login page see url js error attach screenshot expext screenshot expext result login result login page load firt firt,0,0,0,0,0,ambari-web/app/models/cluster_states.js;ambari-web/app/router.js;ambari-web/app/routes/add_host_routes.js;ambari-web/app/routes/add_security.js;ambari-web/app/routes/add_service_routes.js;ambari-web/app/routes/high_availability_routes.js;ambari-web/app/routes/main.js;ambari-web/app/routes/reassign_master_routes.js;ambari-web/app/routes/rollbackHA_routes.js;ambari-web/app/routes/stack_upgrade.js;,1 
4643,Siddharth Wagle,ambari-server,0,Restart All fails for Client only components, restart fail client compon,Restart for a service calls stop and start on all components. Currently there is no implementation for stopping a client component. This leads to error message: 'Stop not implemented for component', restart servic call stop start compon compon current no implement stop client compon compon lead error messag messag stop stop not implement compon compon,0,0,0,0,0,0,1 
4658,Andrii Tkach,ambari-web,0,Routes are incorrect after launching wizard, rout incorrect launch wizard,Steps to reproduce:1. Launch Add Service wizard2. Close wizard3. Go by link #/main/services/add/step1 (type it in address bar)The router goes to nonexistent page '#/main/services/add/summary'., step reproduc reproduc launch add servic wizard wizard close wizard wizard Go link main servic add step main servic add step type address bar bar router goe nonexist page main servic add summari main servic add summari,0,0,0,0,0,ambari-web/app/routes/add_host_routes.js;ambari-web/app/routes/add_service_routes.js;ambari-web/app/routes/main.js;ambari-web/app/routes/reassign_master_routes.js;,1 
4662,Denys Buzhor,ambari-web,0,Install Wizard: Assign Masters: some selects disabled, instal wizard wizard assign master master select disabl,Step to reproduce.Go untill to Customize Services Page.Click to Choose Services menu link.Go to Assign Masters page., step reproduc Go reproduc Go until custom servic page click page click choos servic menu link Go link Go assign master page page,0,0,0,0,0,0,0 
4673,Oleg Nechiporenko,ambari-web,0,Bulk Ops: add Supervisor to Bulk Ops on Hosts page, bulk op op add supervisor bulk op host page,Add Supervisor to Hosts page's Bulk Ops menu if Storm is installed.Decommission and Recommission should be disabled  as Supervisors do not support these operations., add supervisor host page page bulk op menu storm instal decommiss instal decommiss recommiss disabl supervisor not support oper oper,0,0,0,0,0,0,1 
4682,Denys Buzhor,ambari-web,0,Customize Services page of Add Service Wizard offers to customize already installed Oozie, custom servic page add servic wizard offer custom alreadi instal oozi,Steps to reproduce: Deploy cluster without Ooozie and some other customizable service. Go to the Add Service wizard. Add Oozie service. Fail starting Oozie server. Close add service wizard. Ensure that Oozie was added as service. Go again to Add Service Wizard and choose some customizable service. Go to Customize Services page.Result: Customize Services page proposes to customize Oozie  but it was already added to the cluster during installation., step reproduc reproduc deploy cluster without ooozi customiz servic servic Go add servic wizard wizard add oozi servic servic fail start oozi server server close add servic wizard wizard ensur oozi ad servic servic Go add servic wizard choos customiz servic servic Go custom servic page result page result custom servic page propos custom oozi alreadi ad cluster instal instal,0,0,0,0,0,0,1 
4687,Eugene Chekanskiy,ambari-server,0,Write unnitests for HDFS install script on HDP1 and HDP2, write unnitest HDFS instal script HDP HDP HDP HDP,,,0,0,0,0,0,0,1 
4693,Oleg Nechiporenko,ambari-web,0,Hosts table: sort order arrows should be close to the respective column label, host tabl tabl sort order arrow close respect column label,The sort order arrows are right-justified within the column.This makes it look like the arrows apply to the column next to it.Instead  we should show the arrows right next to the respective column label.Like:Name (arrows) IP Address (arrows)Not:Name (arrows) IP Address, sort order arrow right justifi right justifi within column column make look like arrow appli column next instead instead show arrow right next respect column label like name label like name arrow arrow IP address arrow not name arrow not name arrow arrow IP address,0,0,0,0,0,0,0 
4700,Ivan Kozlov,ambari-server,0,Oozie tests fails, oozi test fail,Oozie tests fail, oozi test fail,0,0,0,0,0,0,0 
4708,Dmytro Sen,ambari-agent; ambari-server,0,Actual configs not updated after restart of host component, actual config not updat restart host compon,Updated HDFS configs aren't applied after RESTART.Steps: On a 3 node cluster  create a ConfigGroup for datanode. Override heap size to 1025m instead of 1024m Restart DN.Result: The /var/lib/ambari-agent/data/config.json  has the correct values for the config type:'global': {'2': 'version1392171779044'  'tag': 'version1'} The API call still shows global as default version:http://hostname1:8080/api/v1/clusters/c1/hosts/hostname1/host_components/DATANODE Note:It works after agent is restarted.{global: {overrides: {2: 'version1392171779044'} default: 'version1'}The cause is that hooks aren't executed for the custom_command like RESTART. Since configs for HDFS are generated in hook.py  we must execute hook.py before custom commands or move config generation from hook.py., updat HDFS config appli RESTART step RESTART step node cluster creat ConfigGroup config group datanod datanod overrid heap size instead restart DN result DN result var lib ambari agent data config json var lib ambari agent data config json correct valu config type global type global version version tag tag version version API call still show global default version http hostnam api cluster host hostnam host_components DATANODE version http hostnam api cluster host hostnam host_components DATANODE note note work agent restart global restart global overrid overrid version version default default version version caus hook execut custom_command like RESTART RESTART sinc config HDFS gener hook py hook py must execut hook py hook py custom command move config gener hook py hook py,0,0,0,0,0,0,0 
4710,Eugene Chekanskiy,ambari-server,0,Add unittets for hooks in secured mode., add unittet hook secur mode mode,,,0,0,0,0,0,0,0 
4737,Eugene Chekanskiy,ambari-server,0,Falcon Server can not be restarted, falcon server not restart,,,0,0,0,0,0,0,0 
4741,Vitaly Brodetskyi,ambari-agent,0,Alerts for ATS Component, alert ATS compon,Impl alert for ATS server ATS process (running / not running)Note: this alert should be disabled/removed when ATS gets deleted (when Kerb is enabled)., impl alert ATS server ATS process run not run note run note alert disabl remov disabl remov ATS get delet kerb enabl enabl,0,0,0,0,0,0,0 
4745,Denys Buzhor,ambari-web,0,Value 'storm.zookeeper.servers' not changing after adding new ZK server, valu storm zookeep server storm zookeep server not chang ad new ZK server,After adding new ZK server needs to change value of storm.zookeeper.servers property., ad new ZK server need chang valu storm zookeep server storm zookeep server properti properti,0,0,0,0,0,0,0 
4750,Srimanth Gunturi,ambari-web,0,Tez DAG UI not showing due to changed ATS responses, tez DAG UI not show due chang ATS respons,ATS has changed structure of http://server:8188:8188/ws/v1/apptimeline/HIVE_QUERY_ID/&lt;id&gt; where the entire query JSON structure is now represented as a string under 'otherinfo/query'. UI will need to deserialize this string back into JSON and continue., ATS chang structur entir queri JSON structur repres string otherinfo queri otherinfo queri UI need deseri string back JSON continu continu,0,0,0,0,0,0,0 
4764,Dmytro Shkvyra,ambari-server,0,AmbariManagementControllerTest Test fails with unable to delete the last user., AmbariManagementControllerTest ambari manag control test test fail unabl delet last user user,AmbariManagementControllerTest Test fails with unable to delete the last user.Results :Tests in error: testDeleteUsers(org.apache.ambari.server.controller.AmbariManagementControllerTest): Could not remove user user1. System should have at least one user with administrator role. Tests run: 1404  Failures: 0  Errors: 1  Skipped: 7, AmbariManagementControllerTest ambari manag control test test fail unabl delet last user result user result test test error error testDeleteUsers org apach ambari server control AmbariManagementControllerTest test delet user org apach ambari server control ambari manag control test could not remov user user user system least one user administr role role test run run failur failur error error skip skip,0,0,0,0,0,0,0 
4772,Jaimin D Jetly,ambari-web,0,Security Wizard: History Server should be a different section for MR service., secur wizard wizard histori server differ section MR servic servic,Earlier History Server was not a different service component and was always co-hosted with JobTracker for HDP-1.x. So we had a same section for Job Tracker and History server in security wizard config page.After AMBARI-2617 and AMBARI-4207 fix  it's possible to have JobTracker and History Server on different host via Ambari web-ui. With this capability it's important to show Job History Server as a different section in Security Wizard MR service config page., earlier histori server not differ servic compon alway co host co host JobTracker job tracker HDP HDP section job tracker histori server secur wizard config page page AMBARI AMBARI AMBARI AMBARI fix possibl JobTracker job tracker histori server differ host via ambari web ui web ui capabl import show job histori server differ section secur wizard MR servic config page page,0,0,0,0,0,0,0 
4777,Andrii Tkach,ambari-web,0,Restart indicators work incorrectly after adding component, restart indic work incorrectli ad compon,STR: Deploy cluster with DataNodes on 2 from 3 hosts. Change DataNode maximum Java heap size from 1024 to 1025. Check that Restart indicators appeared and 2 DataNodes require restart. Add DataNode on missing host. Change property DataNode maximum Java heap size back to 1024.Result: Those two DataNodes still require restart and added DataNode not.Gluster properties shouldn't be added unless GLUSTERFS is installed., STR STR deploy cluster DataNodes data node host host chang DataNode data node maximum java heap size check restart indic appear DataNodes data node requir restart restart add DataNode data node miss host host chang properti DataNode data node maximum java heap size back result result two DataNodes data node still requir restart ad DataNode data node not gluster not gluster properti ad unless GLUSTERFS instal instal,0,0,0,0,0,ambari-web/app/controllers/main/service/info/configs.js;ambari-web/app/controllers/wizard/step8_controller.js;ambari-web/app/data/HDP2/config_mapping.js;ambari-web/app/utils/config.js;,0 
4779,Oleg Nechiporenko,ambari-web,0,Add services wizard throw JS exception, add servic wizard throw JS except,See attached. During Customize Services.I installed a cluster w/o Storm  and went to add Storm., see attach attach custom servic servic instal cluster storm went add storm storm,0,0,0,0,0,0,0 
4787,Vitaly Brodetskyi,ambari-agent,0,/var/lib/hadoop-hdfs/ location does not has +x permission for others, var lib hadoop hdf var lib hadoop hdf locat not permiss other,The file defined by dfs.domain.socket.path must give +x permission for other user. &lt;property&gt; &lt;name&gt;dfs.domain.socket.path&lt;/name&gt; &lt;value&gt;/var/lib/hadoop-hdfs/dn_socket&lt;/value&gt; &lt;/property&gt;Currently  In ambari installed cluster  /var/lib/hadoop-hdfs does not give +x permission to other user[root@ambari-sec-1392876050-hdfs-re-8 ~]# stat /var/lib/hadoop-hdfs/ File: '/var/lib/hadoop-hdfs/' Size: 4096 Blocks: 8 IO Block: 4096 directoryDevice: 803h/2051d Inode: 1182008 Links: 3Access: (0750/drwxr-x---) Uid: ( 1005/ hdfs) Gid: ( 500/ hadoop)Access: 2014-02-18 18:10:35.000000000 -0800Modify: 2014-02-20 07:50:55.274766162 -0800Change: 2014-02-20 07:50:55.274766162 -0800Due to this Issue  hadoop commands are seeing below WARN messages. 2014-02-18 05:54:32 734|beaver.machine|INFO|RUNNING: /usr/bin/hdfs dfs -tail /user/hrt_qa/hdfsRegressionData/smallFiles/smallRDFile7552014-02-18 05:54:35 528|beaver.machine|INFO|14/02/18 05:54:35 WARN hdfs.BlockReaderLocal: error creating DomainSocket2014-02-18 05:54:35 528|beaver.machine|INFO|java.net.ConnectException: connect(2) error: Permission denied when trying to connect to '/var/lib/hadoop-hdfs/dn_socket'2014-02-18 05:54:35 528|beaver.machine|INFO|at org.apache.hadoop.net.unix.DomainSocket.connect0(Native Method)2014-02-18 05:54:35 529|beaver.machine|INFO|at org.apache.hadoop.net.unix.DomainSocket.connect(DomainSocket.java:250)2014-02-18 05:54:35 529|beaver.machine|INFO|at org.apache.hadoop.hdfs.DomainSocketFactory.createSocket(DomainSocketFactory.java:158)2014-02-18 05:54:35 529|beaver.machine|INFO|at org.apache.hadoop.hdfs.BlockReaderFactory.nextDomainPeer(BlockReaderFactory.java:691)2014-02-18 05:54:35 529|beaver.machine|INFO|at org.apache.hadoop.hdfs.BlockReaderFactory.createShortCircuitReplicaInfo(BlockReaderFactory.java:439)2014-02-18 05:54:35 529|beaver.machine|INFO|at org.apache.hadoop.hdfs.client.ShortCircuitCache.create(ShortCircuitCache.java:669)The expected Permissions on this location is as below.[root@ambari-sec-1392876050-yarn-10 ~]# stat /var/lib/hadoop-hdfs/ File: '/var/lib/hadoop-hdfs/' Size: 4096 Blocks: 8 IO Block: 4096 directoryDevice: 803h/2051d Inode: 1181767 Links: 3Access: (0751/drwxr-x--x) Uid: ( 1005/ hdfs) Gid: ( 500/ hadoop)Access: 2014-02-20 18:00:06.586040913 -0800Modify: 2014-02-20 07:06:28.267889888 -0800Change: 2014-02-20 17:59:56.629052410 -0800, file defin df domain socket path df domain socket path must give permiss user user lt properti gt lt properti gt lt name gt df domain socket path lt name gt lt name gt df domain socket path lt name gt lt valu gt var lib hadoop hdf dn_socket lt valu gt lt valu gt var lib hadoop hdf dn_socket lt valu gt lt properti gt current lt properti gt current ambari instal cluster var lib hadoop hdf var lib hadoop hdf not give permiss user root ambari sec hdf user root ambari sec hdf stat var lib hadoop hdf var lib hadoop hdf file file var lib hadoop hdf var lib hadoop hdf size size block block IO block block directoryDevice directori devic inod inod link link access access drwxr drwxr uid uid hdf hdf gid gid hadoop access hadoop access modifi modifi chang chang due due issu hadoop command see WARN messag messag beaver machin INFO RUNNING beaver machin INFO RUNNING usr bin hdf usr bin hdf df tail user hrt_qa hdfsRegressionData smallFiles smallRDFile user hrt_qa hdf regress data small file small RD file beaver machin INFO beaver machin INFO WARN hdf BlockReaderLocal hdf block reader local error creat DomainSocket domain socket beaver machin INFO java net ConnectException beaver machin INFO java net connect except connect connect error error permiss deni tri connect var lib hadoop hdf dn_socket var lib hadoop hdf dn_socket beaver machin INFO beaver machin INFO org apach hadoop net unix DomainSocket connect nativ org apach hadoop net unix domain socket connect nativ method method beaver machin INFO beaver machin INFO org apach hadoop net unix DomainSocket connect DomainSocket java org apach hadoop net unix domain socket connect domain socket java beaver machin INFO beaver machin INFO org apach hadoop hdf DomainSocketFactory createSocket DomainSocketFactory java org apach hadoop hdf domain socket factori creat socket domain socket factori java beaver machin INFO beaver machin INFO org apach hadoop hdf BlockReaderFactory nextDomainPeer BlockReaderFactory java org apach hadoop hdf block reader factori next domain peer block reader factori java beaver machin INFO beaver machin INFO org apach hadoop hdf BlockReaderFactory createShortCircuitReplicaInfo BlockReaderFactory java org apach hadoop hdf block reader factori creat short circuit replica info block reader factori java beaver machin INFO beaver machin INFO org apach hadoop hdf client ShortCircuitCache creat ShortCircuitCache java org apach hadoop hdf client short circuit cach creat short circuit cach java expect permiss locat root ambari sec yarn root ambari sec yarn stat var lib hadoop hdf var lib hadoop hdf file file var lib hadoop hdf var lib hadoop hdf size size block block IO block block directoryDevice directori devic inod inod link link access access drwxr drwxr uid uid hdf hdf gid gid hadoop access hadoop access modifi modifi chang chang,0,0,0,0,0,0,0 
4788,Jaimin D Jetly,ambari-web,0,NameNode fails to start due to 'fs.defaultFS' being null, NameNode name node fail start due fs defaultFS fs default FS null,,,0,0,0,0,0,0,0 
4790,Mahadev konar,null,0,Skip Failing tests for now., skip fail test,Skip Failing tests for now., skip fail test,0,0,0,0,0,0,0 
4794,Jaimin D Jetly,ambari-web,0,Reconfiguring memory related properties of a service suffixes 'm' to memory related properties of other service., reconfigur memori relat properti servic suffix memori relat properti servic servic,,,0,0,0,0,0,0,0 
4796,Sumit Mohanty,ambari-server,0,Do not automatically put host component in Maintenance Mode upon decommissioning (and out of Maintenance Mode when recommissioning), not automat put host compon mainten mode upon decommiss mainten mode recommiss recommiss,We originally wanted to couple decom/recom with putting the host component in / out of maintenance mode.After experimenting  we decided to undo that. This is the JIRA for the Ambari BE changes., origin want coupl decom recom decom recom put host compon mainten mode mode experi decid undo JIRA ambari chang chang,0,0,0,0,0,0,0 
4800,Oleg Nechiporenko,ambari-web,0,Hosts table UI cleanup, host tabl UI cleanup,1) has too much padding (See attached.)2) the sorting carets should have more padding-left so there is a bit more space between the column label3) the checkboxes should have more left padding. They are not balanced.4) The checkboxes and status icons are not vert centered with the hostname text.5) The input field for searching the hostname column should take up more horizontal space. with all that blank  makes it look like there is a missing column., much pad see see attach attach sort caret pad left pad left bit space column label label checkbox left pad pad not balanc balanc checkbox statu icon not vert center hostnam text text input field search hostnam column take horizont space space blank make look like miss column column,0,0,0,0,0,0,0 
4809,Eugene Chekanskiy,ambari-server,0,Allow Falcon to be configured with keytab/security and custom params, allow falcon configur keytab secur keytab secur custom param,,,0,0,0,0,0,0,0 
4818,Denys Buzhor,ambari-web,0,Do not show 'restart' op on non-admin user, not show restart restart op non admin non admin user,1) As admin  change a config but do not perform the restarts2) Create a test user (non-admin)3) login as test user4) in host details page  operation to restart is shown. Should not be shown, admin chang config not perform restart restart creat test user non admin non admin login test user user host detail page oper restart shown shown not shown,0,0,0,0,0,0,0 
4821,Andrii Tkach,ambari-web,0,Navigation from Hosts page to HostDetailsPage breaks occasionally, navig host page HostDetailsPage host detail page break occasion,STR: 1. Navigate to hosts page  wait for page loaded. 2. Click specific hosts link. 3. Wait for HostDetails page loaded. 4. Click Back. 5. Iterate. Actual result: sometimes the Hosts page hangs not resulting in presenting a HostDetails page. Speed of attached videos is 5 times faster than real., STR STR navig host page wait page load load click specif host link link wait HostDetails host detail page load load click back back iter iter actual result result sometim host page hang not result present HostDetails host detail page page speed attach video time faster real real,0,0,0,0,0,ambari-web/app/views/main/host.js;,0 
4841,Andrii Tkach,ambari-web,0,Incorrect behavior of HA wizard on second step, incorrect behavior HA wizard second step,STR:1) Deploy cluster by default;2) Go to HA wizard3) Second wizard stepExpected result:1) In 'Additional NameNode' combobox should NOT be ability to choose host where NameNode component already installed.2) In 'JournalNode' comboboxes should NOT be ability to choose more than one JournalNode on one hostActual results:1) In 'Additional NameNode' combobox can be chosen host with already installed NameNode (see first screenshot)2) JournalNode components might be chosen to install for any host  including case when three JournalNode's might be installed on one host (see second screenshot)., STR STR deploy cluster default default Go HA wizard wizard second wizard stepExpected step expect result result addit addit NameNode name node combobox NOT abil choos host NameNode name node compon alreadi instal instal JournalNode journal node combobox NOT abil choos one JournalNode journal node one hostActual host actual result result addit addit NameNode name node combobox chosen host alreadi instal NameNode name node see first screenshot screenshot JournalNode journal node compon might chosen instal host includ case three JournalNode journal node might instal one host see second screenshot screenshot,0,0,0,0,0,ambari-web/app/controllers/main/admin/highAvailability/step2_controller.js;ambari-web/app/controllers/wizard/step5_controller.js;ambari-web/app/messages.js;ambari-web/app/templates/main/admin/highAvailability/step2.hbs;ambari-web/app/views/wizard/step5_view.js;,0 
4842,Eugene Chekanskiy,ambari-server,0,Update falcon install scripts to recent changes, updat falcon instal script recent chang,Following features must be implemented: /apps/falcon directory on hdfs and owned by falcon user make falcon able to be runned from custom user change alerts text, follow featur must implement implement app falcon app falcon directori hdf own falcon user make falcon abl run custom user chang alert text,0,0,0,0,0,0,0 
4843,Vitaly Brodetskyi,ambari-agent,0,Ambari DDL for MySQL should not create ambarirca database, ambari DDL MySQL SQL not creat ambarirca databas,Ambari-DDL-MySQL-CREATE.sql includes 'create ambarirca' database.CREATE DATABASE ambarirca;USE ambarirca;1) At minimum  this DDL should not be creating an ambarirca database and instead mix in the RCA tables with core Ambari tables (that's how Oracle DDL does it &#8211; I think). Not ideal but better than creating an ambarirca database in this script (a user would be surprised to see this).2) Alternatively  we need to split out RCA DDL from the core Ambari. We can doc that if you plan to use HDP 1.3.x stack that you need to to setup an RCA database (since RCA is only applicable to those with HDP 1.3.x stack). If we go this route  for consistency  we would need to do the same for the oracle DDL.Note: Right now  looks like the oracle DDL just puts the RCA tables in the same database as ambari core tables (basically #1 above)., ambari DDL MySQL CREATE sql ambari DDL SQL CREATE sql includ creat ambarirca ambarirca databas CREATE databas CREATE DATABASE ambarirca USE ambarirca USE ambarirca ambarirca minimum DDL not creat ambarirca databas instead mix RCA tabl core ambari tabl oracl DDL think think not ideal better creat ambarirca databas script user would surpris see altern need split RCA DDL core ambari ambari doc plan use HDP stack need setup RCA databas sinc RCA applic HDP stack stack go rout consist would need oracl DDL note DDL note right look like oracl DDL put RCA tabl databas ambari core tabl basic,0,0,0,0,0,0,0 
4872,Vitaly Brodetskyi,ambari-agent,0,Nagios alerts are not shown on SUSE, nagio alert not shown SUSE,STR:1. Deploy cluster by default scenario w/o Storm and Falcon.2. Go to HDFS service page.3. Go to Nagios service page.4. Navigate to Nagios Web UI.5. Enter credentials nagiosadmin/passwordActual results: There are no alerts on service page. Web UI is unavailable due to ERROR 403.Screenshots attached., STR STR deploy cluster default scenario storm falcon falcon Go HDFS servic page page Go nagio servic page page navig nagio web UI UI enter credenti nagiosadmin passwordActual nagiosadmin password actual result result no alert servic page page web UI unavail due ERROR screenshot screenshot attach attach,0,0,0,0,0,0,0 
4893,Siddharth Wagle,ambari-server,0,Avoid printing stacktrace for state machine exceptions, avoid print stacktrac state machin except,Log gets filled on install failure.13:28:08 856 WARN [qtp615964260-72] HeartBeatHandler:361 - State machine exceptionorg.apache.ambari.server.state.fsm.InvalidStateTransitionException: Invalid event: HOST_SVCCOMP_OP_SUCCEEDED at INSTALL_FAILED at org.apache.ambari.server.state.fsm.StateMachineFactory.doTransition(StateMachineFactory.java:297) at org.apache.ambari.server.state.fsm.StateMachineFactory.access$300(StateMachineFactory.java:39) at org.apache.ambari.server.state.fsm.StateMachineFactory$InternalStateMachine.doTransition(StateMachineFactory.java:440) at org.apache.ambari.server.state.svccomphost.ServiceComponentHostImpl.handleEvent(ServiceComponentHostImpl.java:730) at com.google.inject.persist.jpa.JpaLocalTxnInterceptor.invoke(JpaLocalTxnInterceptor.java:66), log get fill instal failur failur WARN qtp qtp HeartBeatHandler heart beat handler state machin exceptionorg apach ambari server state fsm InvalidStateTransitionException exceptionorg apach ambari server state fsm invalid state transit except invalid event event HOST_SVCCOMP_OP_SUCCEEDED HOST SVCCOMP OP SUCCEEDED INSTALL_FAILED INSTALL FAILED org apach ambari server state fsm StateMachineFactory doTransition StateMachineFactory java org apach ambari server state fsm state machin factori transit state machin factori java org apach ambari server state fsm StateMachineFactory access StateMachineFactory java org apach ambari server state fsm state machin factori access state machin factori java org apach ambari server state fsm StateMachineFactory InternalStateMachine doTransition StateMachineFactory java org apach ambari server state fsm state machin factori intern state machin transit state machin factori java org apach ambari server state svccomphost ServiceComponentHostImpl handleEvent ServiceComponentHostImpl java org apach ambari server state svccomphost servic compon host impl handl event servic compon host impl java com googl inject persist jpa JpaLocalTxnInterceptor invok JpaLocalTxnInterceptor java com googl inject persist jpa jpa local txn interceptor invok jpa local txn interceptor java,0,0,0,0,0,0,0 
4895,Dmytro Sen,null,0,License header is repeated in oozie-log4j.properties, licens header repeat oozi log properti oozi log properti,# Licensed to the Apache Software Foundation (ASF) under one or more contributor license agreements. See the NOTICE file distributed with this work for additional information regarding copyright ownership. The ASF licenses this file to you under the Apache License  Version 2.0 (the 'License'); you may not use this file except in compliance with the License. You may obtain a copy of the License at##http://www.apache.org/licenses/LICENSE-2.0# Unless required by applicable law or agreed to in writing  software distributed under the License is distributed on an 'AS IS' BASIS  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND  either express or implied. See the License for the specific language governing permissions and limitations under the License.# http://www.apache.org/licenses/LICENSE-2.0# Unless required by applicable law or agreed to in writing  software distributed under the License is distributed on an 'AS IS' BASIS  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND  either express or implied. See the License for the specific language governing permissions and limitations under the License. See accompanying LICENSE file.#, licens apach softwar foundat ASF ASF one contributor licens agreement agreement see NOTICE file distribut work addit inform regard copyright ownership ownership ASF licens file apach licens version licens licens may not use file except complianc licens licens may obtain copi licens http www apach org licens LICENSE http www apach org licens LICENSE unless requir applic law agre write softwar distribut licens distribut BASIS WITHOUT WARRANTIES CONDITIONS KIND either express impli impli see licens specif languag govern permiss limit licens licens unless requir applic law agre write softwar distribut licens distribut BASIS WITHOUT WARRANTIES CONDITIONS KIND either express impli impli see licens specif languag govern permiss limit licens licens see accompani LICENSE file file,0,0,0,0,0,ambari-server/src/main/resources/stacks/HDP/1.3.2/services/OOZIE/configuration/oozie-log4j.xml;ambari-server/src/main/resources/stacks/HDP/2.0.6/services/OOZIE/configuration/oozie-log4j.xml;,0 
4902,Jaimin D Jetly,ambari-web,0,Service Check does not work, servic check not work,,,0,0,0,0,0,0,0 
4909,Oleg Nechiporenko,ambari-web,0,Slave component should include 'restart' command on host details page 'Actions', slave compon includ restart restart command host detail page action action,Slave components (such as DataNode  NodeManager  RegionServer  Supervisor  Ganglia Monitor) should include a 'Restart' command in their 'Actions' menu on the host details page.The Restart option should be shown and enabled when the component is started., slave compon DataNode data node NodeManager node manag RegionServer region server supervisor ganglia monitor monitor includ restart restart command action action menu host detail page page restart option shown enabl compon start start,0,0,0,0,0,0,0 
4939,Dmytro Shkvyra,ambari-agent; ambari-server,0,Ganglia alerts after adding YARN+MR2, ganglia alert ad YARN MR YARN MR,STR: Deploy cluster with HDFS+ZK  Nagios  Ganglia. Add YARN+MR2  Tez services.Result: Alerts Ganglia Monitor process for HistoryServer and Ganglia Monitor process for ResourceManager don't dissappear after restarting all services, STR STR deploy cluster HDFS ZK HDFS ZK nagio ganglia ganglia add YARN MR YARN MR tez servic result servic result alert ganglia monitor process HistoryServer histori server ganglia monitor process ResourceManager resourc manag dissappear restart servic,0,0,0,0,0,0,0 
4947,Vitaly Brodetskyi,ambari-agent,0,Change Hive alerts to move away from Hive metadata queries to port checks, chang hive alert move away hive metadata queri port check,1) remove 'Hive Metastore status' alert2) add 'Hive Metastore process' alert3) add 'HiveServer2 process' alert, remov hive hive metastor statu statu alert alert add hive hive metastor process process alert alert add HiveServer hive server process process alert,0,0,0,0,0,0,0 
4954,Vitaly Brodetskyi,ambari-agent,0,After configuring NNHA  nn process alerts don't work, configur NNHA nn process alert work,1) Configure NN HA2) stack 2.0.6 (but check stack 2.1 as well)3) Two alerts show' check_tcp: Port must be a positive integer'NameNode process on c6401.ambari.apache.orgNameNode process on c6402.ambari.apache.org4) Looked at /etc/nagios/objects/hadoop-services.cfg5) Saw:define service { host_name c6401.ambari.apache.org use hadoop-service service_description NAMENODE::NameNode process on c6401.ambari.apache.org servicegroups HDFS check_command check_tcp_wrapper!//test!-w 1 -c 1 normal_check_interval 0.5 retry_check_interval 0.25 max_check_attempts 3}define service { host_name c6402.ambari.apache.org use hadoop-service service_description NAMENODE::NameNode process on c6402.ambari.apache.org servicegroups HDFS check_command check_tcp_wrapper!//test!-w 1 -c 1 normal_check_interval 0.5 retry_check_interval 0.25 max_check_attempts 3}Notice in the above //test is the name of my nameservice.Attaching screen shot of my config. So looks like it's grabbing port from the wrong prop., configur NN HA HA stack check stack well well two alert show show check_tcp check_tcp port must posit integ NameNode integ name node process ambari apach orgNameNode ambari apach org name node process ambari apach org ambari apach org look etc nagio object hadoop servic cfg etc nagio object hadoop servic cfg saw defin saw defin servic host_name ambari apach org ambari apach org use hadoop servic hadoop servic service_description NAMENODE NameNode NAMENODE name node process ambari apach org ambari apach org servicegroup HDFS check_command check_tcp_wrapper test check_tcp_wrapper test normal_check_interval retry_check_interval max_check_attempts defin servic host_name ambari apach org ambari apach org use hadoop servic hadoop servic service_description NAMENODE NameNode NAMENODE name node process ambari apach org ambari apach org servicegroup HDFS check_command check_tcp_wrapper test check_tcp_wrapper test normal_check_interval retry_check_interval max_check_attempts notic notic test name nameservic attach nameservic attach screen shot config config look like grab port wrong prop prop,0,0,0,0,0,0,0 
4970,Mikhail Bayuk,ambari-web,0,Jobs popup message clicking continues to stay on the same page, job popup messag click continu stay page,1. Click on an app on ATS/jobs page which is running 2. It pops up a window with message 'Tez DAG has no ID associated with name hrt_qa_20140228161212_a5713292-8213-43a3-b61e-06685799a5b3'3. Press OK and the page refreshes and pops up the same window again.4. This goes on forever until the user closes the browser or enters a different URLInstead  the page should be redirected back to &lt;ambari server URL&gt;/#/main/jobs, click app ATS job ATS job page run pop window messag tez tez DAG no ID associ name hrtqa _a hrtqa _a press OK page refresh pop window goe forev user close browser enter differ URLInstead URL instead page redirect back lt ambari lt ambari server URL gt main job URL gt main job,0,0,0,0,0,0,0 
4983,Siddharth Wagle,ambari-server,0,During upgrade. migrate decommissioned DN hosts list to the new format, upgrad upgrad migrat decommiss DN host list new format,The details of how the notion of a decommissioned DN is stored has changed for 1.5.0. Add support to modify persisted data when Ambari is upgraded to 1.5.0., detail notion decommiss DN store chang add support modifi persist data ambari upgrad,0,0,0,0,0,0,0 
5020,Dmitry Lysnichenko,ambari-server,0,Lost heartbeat on host but ganglia shows a heartbeat lost, lost heartbeat host ganglia show heartbeat lost,3 hosts  third-host has only Ganglia monitor and Datanode.I kill the third machine agent. Hosts page correctly shows heartbeat lost.On the services page  ganglia shows 'yellow'  even though the ganglia server host is fine.Ganglia service should considered started if Ganglia Server is started., host third host third host ganglia monitor datanod datanod kill third machin agent agent host page correctli show heartbeat lost lost servic page ganglia show yellow yellow even though ganglia server host fine ganglia fine ganglia servic consid start ganglia server start start,0,0,0,0,0,0,0 
5028,Mahadev konar,null,0,Hive Service Check Failed during Install Wizard, hive servic check fail instal wizard,Hive Service Check Failed during Install Wizard, hive servic check fail instal wizard,0,0,0,0,0,0,0 
5036,Dmitry Lysnichenko,ambari-server; test,0,Secured: Start All Services task got stuck forever, secur secur start servic task got stuck forev,Deployed 2-node cluster. Added 3rd node. Enabled security.After steps above on all 3 hosts tasks jammed and don't want to perform or fail for a very long time.VMs are alive  ambari-server and all ambari-agents are running.Finally got a reproduce using 2 commandscurl 'http://vm-0.vm:8080/api/v1/clusters/cc/services?params/run_smoke_test=false' -X PUT -H 'X-Requested-By: X-Requested-By' -u admin:admin --data '{'RequestInfo': {'context': 'Start All Services'}  'Body': {'ServiceInfo': {'state': 'STARTED'}}}' ; sleep 3; curl 'http://vm-0.vm:8080/api/v1/clusters/cc/hosts/vm-0.vm/host_components/APP_TIMELINE_SERVER' -X DELETE -H 'X-Requested-By: X-Requested-By' -u admin:adminThe way to reproduce is a bit different compared to an original description (I issue a DELETE request in 3 seconds after START_ALL_SERVICES request has been issued)  but the symptoms are the same: ServiceComponentHostNotFoundException exception is posted to log and operation is stuck on stage that contains 'App Timeline Server Start' command., deploy node cluster cluster ad rd node node enabl secur secur step host task jam want perform fail long time VMs time Ms aliv ambari server ambari server ambari agent ambari agent run final run final got reproduc use commandscurl http vm vm api cluster cc servic param run_smoke_test fals http vm vm api cluster cc servic param run_smoke_test fals PUT request request request request admin admin admin admin data RequestInfo request info context context start start servic servic bodi bodi ServiceInfo servic info state state STARTED STARTED sleep curl http vm vm api cluster cc host vm vm host_components APP_TIMELINE_SERVER http vm vm api cluster cc host vm vm host_components APP TIMELINE SERVER DELETE request request request request admin adminThe admin admin way reproduc bit differ compar origin descript issu DELETE request second START_ALL_SERVICES START SERVICES request issu issu symptom ServiceComponentHostNotFoundException servic compon host not found except except post log oper stuck stage contain app app timelin server start start command command,0,0,0,0,0,0,0 
5040,Dmytro Sen,ambari-server,0,2-way auth fails when using jdk7, way auth fail use jdk jdk,Steps to reproduce:On the Ambari Server host  open /etc/ambari-server/conf/ambari.properties with a text editor.Add the following property:security.server.two_way_ssl = trueError messageINFO 2014-03-07 13:57:17 184 security.py:184 - Agent certificate not exists  sending sign requestINFO 2014-03-07 13:57:17 335 security.py:89 - SSL Connect being called.. connecting to the serverERROR 2014-03-07 13:57:17 414 security.py:76 - Two-way SSL authentication failed. Ensure that server and agent certificates were signed by the same CA and restart the agent. In order to receive a new agent certificate  remove existing certificate file from keys directory. As a workaround you can turn off two-way SSL authentication in server configuration(ambari.properties) Exiting.., step reproduc reproduc ambari server host open etc ambari server conf ambari properti etc ambari server conf ambari properti text editor add editor add follow properti secur server two_way_ssl properti secur server two_way_ssl trueError true error messageINFO messag INFO secur py secur py agent certif not exist send sign requestINFO request INFO secur py secur py SSL connect call call connect serverERROR server ERROR secur py secur py two way two way SSL authent fail fail ensur server agent certif sign CA restart agent agent order receiv new agent certif remov exist certif file key directori directori workaround turn two way two way SSL authent server configur ambari properti configur ambari properti exit exit,0,0,0,0,0,ambari-server/conf/unix/ca.config;ambari-server/pom.xml;ambari-server/src/main/java/org/apache/ambari/server/configuration/Configuration.java;ambari-server/src/main/java/org/apache/ambari/server/security/CertificateManager.java;ambari-server/src/main/resources/ca.config;ambari-server/src/test/java/org/apache/ambari/server/security/CertGenerationTest.java;,0 
5043,Yusaku Sako,ambari-server,0,oozie-site.xml defaults need to be updated for 2.1 stack, oozi site xml oozi site xml default need updat stack,oozie-site.xml needs the following two services added to the list of services:org.apache.oozie.service.XLogStreamingService (needed to display logs)org.apache.oozie.service.JobsConcurrencyService (needed to run Recovery Service - for example  this would handle jobs that are dangling and stuck in RUNNING state), oozi site xml oozi site xml need follow two servic ad list servic org apach oozi servic XLogStreamingService servic org apach oozi servic log stream servic need display log org apach oozi servic JobsConcurrencyService log org apach oozi servic job concurr servic need run recoveri servic exampl would handl job dangl stuck RUNNING state state,0,0,0,0,0,0,0 
5051,Oleg Nechiporenko,ambari-web,0,Start all services silently fails when a service is not startable, start servic silent fail servic not startabl,I clicked on Start All services button and nothing happened. Turns out that on the API call  the server throws a 500 exception that is silently lost. We should show in a dialog the error response from server. Similarly for Stop All action.PUT http://c6401:8080/api/v1/clusters/c1/services?params/run_smoke_test{'RequestInfo': {'context' :'_PARSE_.START.ALL_SERVICES'}  'Body': {'ServiceInfo': {'state': 'START{ 'status' : 500  'message' : 'org.apache.ambari.server.controller.spi.SystemException: An internal system exception occurred: Invalid transition for servicecomponenthost  clusterName=c1  clusterId=3  serviceName=OOZIE  componentName=OOZIE_SERVER  hostname=c6402.ambari.apache.org  currentState=INSTALL_FAILED  newDesiredState=STARTED'}, click start servic button noth happen happen turn API call server throw except silent lost lost show dialog error respons server server similarli stop action PUT action PUT context context PARSE START ALL_SERVICES  PARSE START SERVICES bodi bodi ServiceInfo servic info state state START START statu statu messag messag org apach ambari server control spi SystemException org apach ambari server control spi system except intern system except occur occur invalid transit servicecomponenthost clusterName cluster name clusterId cluster Id serviceName OOZIE servic name OOZIE componentName OOZIE_SERVER compon name OOZIE SERVER hostnam ambari apach org hostnam ambari apach org currentState INSTALL_FAILED current state INSTALL FAILED newDesiredState STARTED new desir state STARTED,0,0,0,0,0,0,0 
5060,Jaimin D Jetly,ambari-web,0,Security Wizard: enable Kerberos setup for Storm, secur wizard wizard enabl kerbero setup storm,1) Following jaas.conf file needs to be on all storm component hosts:Client { com.sun.security.auth.module.Krb5LoginModule required useKeyTab=true keyTab='$keytab' storeKey=true useTicketCache=false serviceName='zookeeper' principal='$principal';};2) In YAML  following java configurations should have jaas.conf options:nimbus.childopts: '-Djava.security.auth.login.config=/path/to/jaas.conf'ui.childopts: '-Djava.security.auth.login.config=/path/to/jaas.conf'supervisor.childopts: '-Djava.security.auth.login.config=/path/to/jaas.conf', follow jaa conf jaa conf file need storm compon host client host client com sun secur auth modul krb LoginModule com sun secur auth modul krb login modul requir useKeyTab true use key tab true keyTab keytab key tab keytab storeKey true store key true useTicketCache fals use ticket cach fals serviceName zookeep servic name zookeep princip princip princip princip YAML follow java configur jaa conf jaa conf option nimbu childopt option nimbu childopt djava secur auth login config path jaa conf ui childopt djava secur auth login config path jaa conf ui childopt djava secur auth login config path jaa conf supervisor childopt djava secur auth login config path jaa conf supervisor childopt djava secur auth login config path jaa conf djava secur auth login config path jaa conf,0,0,0,0,0,0,0 
5097,Jaimin D Jetly,ambari-web,0,Retry failure after installation failure triggers start all services request, retri failur instal failur trigger start servic request,Steps to reproduce: Make Install all services request fail. Hit on Retry button. Make retry attempt to install all services fail.This will trigger start all services call and error pop-up will be displayed.Expected behavior: Start all services call should not be called., step reproduc reproduc make instal servic request fail fail hit retri button button make retri attempt instal servic fail fail trigger start servic call error pop pop display expect display expect behavior behavior start servic call not call call,0,0,0,0,0,0,0 
5103,Oleg Nechiporenko,ambari-web,0,Maintenance Mode: maintenance icon changes on Host Details page, mainten mode mode mainten icon chang host detail page,For host components whose service is in maintenance mode  the maintenance mode icon should be displayed to the right of the service name and we should display the host component health (green / red  etc) on the far left.When the host itself is in maintenance mode  we should not show any maintenance mode icon on the host component (unless the service is in maintenance mode). This allows the UI to distinguish which host components are in service-derived maintenance mode vs host-derived. Also  on this page  host-level operations apply to all but the host components in service-derived maintenance mode (regardless of the host maintenance mode)  so this display is more natural and easier to understand for the end user., host compon whose servic mainten mode mainten mode icon display right servic name display host compon health green red etc etc far left left host mainten mode not show mainten mode icon host compon unless servic mainten mode mode allow UI distinguish host compon servic deriv servic deriv mainten mode vs host deriv host deriv also page host level host level oper appli host compon servic deriv servic deriv mainten mode regardless host mainten mode mode display natur easier understand end user user,0,0,0,0,0,0,0 
5112,Dmytro Sen,ambari-agent,0,hadoop-mapreduce.jobsummary.log is empty when specified custom YARN Log Dir, hadoop mapreduc jobsummari log hadoop mapreduc jobsummari log empti specifi custom YARN log dir,Reproduced with such preconditions:On Customize Services page specify 'YARN Log Dir Prefix' to some custom dir. After deploying  run MapReduce2 Service check and check that:hadoop-mapreduce.jobsummary.log is empty  but /var/log/hadoop-yarn/yarn/hadoop-mapreduce.jobsummary.log contains jobs records., reproduc precondit precondit custom servic page specifi YARN YARN log dir prefix prefix custom dir dir deploy run MapReduce map reduc servic check check hadoop mapreduc jobsummari log hadoop mapreduc jobsummari log empti var log hadoop yarn yarn hadoop mapreduc jobsummari log var log hadoop yarn yarn hadoop mapreduc jobsummari log contain job record record,0,0,0,0,0,ambari-server/src/main/resources/stacks/HDP/1.3.2/services/MAPREDUCE/configuration/mapreduce-log4j.xml;ambari-server/src/main/resources/stacks/HDP/2.0.6/services/YARN/configuration/yarn-log4j.xml;ambari-server/src/main/resources/stacks/HDP/2.0.6/services/YARN/package/scripts/resourcemanager.py;ambari-server/src/main/resources/stacks/HDP/2.0.6/services/YARN/package/scripts/yarn.py;ambari-server/src/test/python/stacks/2.0.6/YARN/test_historyserver.py;ambari-server/src/test/python/stacks/2.0.6/YARN/test_mapreduce2_client.py;ambari-server/src/test/python/stacks/2.0.6/YARN/test_nodemanager.py;ambari-server/src/test/python/stacks/2.0.6/YARN/test_resourcemanager.py;ambari-server/src/test/python/stacks/2.0.6/YARN/test_yarn_client.py;ambari-server/src/test/python/stacks/2.1/YARN/test_apptimelineserver.py;,0 
5123,Oleg Nechiporenko,ambari-web,0,Background Operations window does not appear after triggering Rolling Restart, background oper window not appear trigger roll restart,STR: Deploy cluster. Check that flag Do not show the Background Operations dialog when starting an operation is set to false. Click Restart DataNodes in Actions menu of HDFS. Click 'Trigger Restart' in appeared modal window.Result: Background Operations was not appeared., STR STR deploy cluster cluster check flag not show background oper dialog start oper set fals fals click restart DataNodes data node action menu HDFS HDFS click trigger trigger restart restart appear modal window result window result background oper not appear appear,0,0,0,0,0,0,0 
5128,Andrii Babiichuk,ambari-web,0,Rolling Restart dialog shows incorrect message that slaves won't be restarted when service is in maintenance mode, roll restart dialog show incorrect messag slave restart servic mainten mode,The fix for this issue would be to display that the slaves whose host is in 'host' maintenance mode will be skipped.For example  we have 3 hosts (host1  host2  and host3) with NodeManager installed on each. Say host3 is in maintenance mode.Rolling Restart dialog should say '1 NodeManager in maintenance mode will not be restarted'., fix issu would display slave whose host host host mainten mode skip skip exampl host host host host host host host NodeManager node manag instal say host host mainten mode roll mode roll restart dialog say NodeManager node manag mainten mode not restart restart,0,0,0,0,0,ambari-web/app/views/common/rolling_restart_view.js;,0 
5146,Vitaly Brodetskyi,ambari-agent,0,After Ambari is upgraded to 1.5.0  previous JAVA_HOME is overwritten to /usr/jdk64/jdk1.6.0_3, ambari upgrad previou JAVA_HOME JAVA HOME overwritten usr jdk jdk  usr jdk jdk ,After upgrading Ambari from 1.2.5 to 1.5.0 and Stack from 1.3.2 to 2.0.10When starting HDFS service  Datanode and SNameNode on the agent host failed to start due to JAVA_HOME=cbin/java is missing. In ambari.properties  java.home=/usr/jdk64/jdk1.6.0_3 after upgrade., upgrad ambari stack start HDFS servic datanod SNameNode name node agent host fail start due JAVA_HOME cbin java JAVA HOME cbin java miss miss ambari properti ambari properti java home usr jdk jdk  java home usr jdk jdk  upgrad upgrad,0,0,0,0,0,0,0 
5156,Siddharth Wagle,ambari-agent,0,Hive CLI using Tez runtime does not start by throwing HDFS exception, hive CLI use tez runtim not start throw HDFS except,In a cluster node we had set the below in /etc/hive/conf/hive-site.xml&lt;property&gt; &lt;name&gt;hive.jar.directory&lt;/name&gt; &lt;value&gt;hdfs:///apps/hive/install&lt;/value&gt;&lt;/property&gt;The HDFS folder has the following contents# hadoop fs -ls -R /apps/hive/drwxr-xr-x - hive hdfs 0 2014-03-19 17:10 /apps/hive/install-rwxr-xr-x 3 hive hdfs 14719276 2014-03-19 17:10 /apps/hive/install/hive-exec.jardrwxrwxrwx - hive hdfs 0 2014-03-19 17:08 /apps/hive/warehouseAs user ambari-qa I run the hive command to hit this exception$ hiveLogging initialized using configuration in file:/etc/hive/conf.dist/hive-log4j.propertiesException in thread 'main' java.lang.RuntimeException: org.apache.hadoop.security.AccessControlException: Permission denied: user=ambari-qa  access=WRITE  inode='/apps/hive/install':hive:hdfs:drwxr-xr-x at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkFsPermission(FSPermissionChecker.java:265) at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:251) at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:232) at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:176) at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5481) at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5463) at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkAncestorAccess(FSNamesystem.java:5437) at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInternal(FSNamesystem.java:2265) at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2218) at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2171) at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:517) at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:354) at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java) at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585) at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928) at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2003) at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1999) at java.security.AccessController.doPrivileged(Native Method) at javax.security.auth.Subject.doAs(Subject.java:415) at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1548) at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1997) at org.apache.hadoop.hive.ql.session.SessionState.start(SessionState.java:345) at org.apache.hadoop.hive.cli.CliDriver.run(CliDriver.java:682) at org.apache.hadoop.hive.cli.CliDriver.main(CliDriver.java:626) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:606) at org.apache.hadoop.util.RunJar.main(RunJar.java:212)Caused by: org.apache.hadoop.security.AccessControlException: Permission denied: user=ambari-qa  access=WRITE  inode='/apps/hive/install':hive:hdfs:drwxr-xr-x at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkFsPermission(FSPermissionChecker.java:265) at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:251) at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:232) at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:176) at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5481) at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5463) at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkAncestorAccess(FSNamesystem.java:5437) at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInternal(FSNamesystem.java:2265) at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2218) at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2171) at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:517) at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:354) at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java) at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585) at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928) at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2003) at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1999) at java.security.AccessController.doPrivileged(Native Method) at javax.security.auth.Subject.doAs(Subject.java:415) at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1548) at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1997) at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57) at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45) at java.lang.reflect.Constructor.newInstance(Constructor.java:526) at org.apache.hadoop.ipc.RemoteException.instantiateException(RemoteException.java:106) at org.apache.hadoop.ipc.RemoteException.unwrapRemoteException(RemoteException.java:73) at org.apache.hadoop.hdfs.DFSOutputStream.newStreamForCreate(DFSOutputStream.java:1602) at org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1461) at org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1386) at org.apache.hadoop.hdfs.DistributedFileSystem$6.doCall(DistributedFileSystem.java:394) at org.apache.hadoop.hdfs.DistributedFileSystem$6.doCall(DistributedFileSystem.java:390) at org.apache.had, cluster node set etc hive conf hive site xml lt properti gt etc hive conf hive site xml lt properti gt lt name gt hive jar directori lt name gt lt name gt hive jar directori lt name gt lt valu gt hdf app hive instal lt valu gt lt properti gt lt valu gt hdf app hive instal lt valu gt lt properti gt HDFS folder follow content content hadoop fs ls app hive drwxr xr app hive drwxr xr hive hdf app hive instal rwxr xr app hive instal rwxr xr hive hdf app hive instal hive exec jardrwxrwxrwx app hive instal hive exec jardrwxrwxrwx hive hdf app hive warehouseAs app hive warehous user ambari qa ambari qa run hive command hit except except hiveLogging hive log initi use configur file etc hive conf dist hive log propertiesException file etc hive conf dist hive log properti except thread main main java lang RuntimeException java lang runtim except org apach hadoop secur AccessControlException org apach hadoop secur access control except permiss deni deni user ambari qa user ambari qa access WRITE access WRITE inod app hive instal hive hdf drwxr xr inod app hive instal hive hdf drwxr xr org apach hadoop hdf server namenod FSPermissionChecker checkFsPermission FSPermissionChecker java org apach hadoop hdf server namenod FS permiss checker check Fs permiss FS permiss checker java org apach hadoop hdf server namenod FSPermissionChecker check FSPermissionChecker java org apach hadoop hdf server namenod FS permiss checker check FS permiss checker java org apach hadoop hdf server namenod FSPermissionChecker check FSPermissionChecker java org apach hadoop hdf server namenod FS permiss checker check FS permiss checker java org apach hadoop hdf server namenod FSPermissionChecker checkPermission FSPermissionChecker java org apach hadoop hdf server namenod FS permiss checker check permiss FS permiss checker java org apach hadoop hdf server namenod FSNamesystem checkPermission FSNamesystem java org apach hadoop hdf server namenod FS namesystem check permiss FS namesystem java org apach hadoop hdf server namenod FSNamesystem checkPermission FSNamesystem java org apach hadoop hdf server namenod FS namesystem check permiss FS namesystem java org apach hadoop hdf server namenod FSNamesystem checkAncestorAccess FSNamesystem java org apach hadoop hdf server namenod FS namesystem check ancestor access FS namesystem java org apach hadoop hdf server namenod FSNamesystem startFileInternal FSNamesystem java org apach hadoop hdf server namenod FS namesystem start file intern FS namesystem java org apach hadoop hdf server namenod FSNamesystem startFileInt FSNamesystem java org apach hadoop hdf server namenod FS namesystem start file int FS namesystem java org apach hadoop hdf server namenod FSNamesystem startFile FSNamesystem java org apach hadoop hdf server namenod FS namesystem start file FS namesystem java org apach hadoop hdf server namenod NameNodeRpcServer creat NameNodeRpcServer java org apach hadoop hdf server namenod name node rpc server creat name node rpc server java org apach hadoop hdf protocolPB ClientNamenodeProtocolServerSideTranslatorPB creat ClientNamenodeProtocolServerSideTranslatorPB java org apach hadoop hdf protocol PB client namenod protocol server side translat PB creat client namenod protocol server side translat PB java org apach hadoop hdf protocol proto ClientNamenodeProtocolProtos ClientNamenodeProtocol callBlockingMethod ClientNamenodeProtocolProtos java org apach hadoop hdf protocol proto client namenod protocol proto client namenod protocol call block method client namenod protocol proto java org apach hadoop ipc ProtobufRpcEngine server ProtoBufRpcInvoker call ProtobufRpcEngine java org apach hadoop ipc protobuf rpc engin server proto buf rpc invok call protobuf rpc engin java org apach hadoop ipc RPC server call RPC java org apach hadoop ipc RPC server call RPC java org apach hadoop ipc server handler run server java org apach hadoop ipc server handler run server java org apach hadoop ipc server handler run server java org apach hadoop ipc server handler run server java java secur AccessController doPrivileged nativ java secur access control privileg nativ method method javax secur auth subject doAs subject java javax secur auth subject subject java org apach hadoop secur UserGroupInformation doAs UserGroupInformation java org apach hadoop secur user group inform user group inform java org apach hadoop ipc server handler run server java org apach hadoop ipc server handler run server java org apach hadoop hive ql session SessionState start SessionState java org apach hadoop hive ql session session state start session state java org apach hadoop hive cli CliDriver run CliDriver java org apach hadoop hive cli cli driver run cli driver java org apach hadoop hive cli CliDriver main CliDriver java org apach hadoop hive cli cli driver main cli driver java sun reflect NativeMethodAccessorImpl invok nativ sun reflect nativ method accessor impl invok nativ method method sun reflect NativeMethodAccessorImpl invok NativeMethodAccessorImpl java sun reflect nativ method accessor impl invok nativ method accessor impl java sun reflect DelegatingMethodAccessorImpl invok DelegatingMethodAccessorImpl java sun reflect deleg method accessor impl invok deleg method accessor impl java java lang reflect method invok method java java lang reflect method invok method java org apach hadoop util RunJar main RunJar java caus org apach hadoop util run jar main run jar java caus org apach hadoop secur AccessControlException org apach hadoop secur access control except permiss deni deni user ambari qa user ambari qa access WRITE access WRITE inod app hive instal hive hdf drwxr xr inod app hive instal hive hdf drwxr xr org apach hadoop hdf server namenod FSPermissionChecker checkFsPermission FSPermissionChecker java org apach hadoop hdf server namenod FS permiss checker check Fs permiss FS permiss checker java org apach hadoop hdf server namenod FSPermissionChecker check FSPermissionChecker java org apach hadoop hdf server namenod FS permiss checker check FS permiss checker java org apach hadoop hdf server namenod FSPermissionChecker check FSPermissionChecker java org apach hadoop hdf server namenod FS permiss checker check FS permiss checker java org apach hadoop hdf server namenod FSPermissionChecker checkPermission FSPermissionChecker java org apach hadoop hdf server namenod FS permiss checker check permiss FS permiss checker java org apach hadoop hdf server namenod FSNamesystem checkPermission FSNamesystem java org apach hadoop hdf server namenod FS namesystem check permiss FS namesystem java org apach hadoop hdf server namenod FSNamesystem checkPermission FSNamesystem java org apach hadoop hdf server namenod FS namesystem check permiss FS namesystem java org apach hadoop hdf server namenod FSNamesystem checkAncestorAccess FSNamesystem java org apach hadoop hdf server namenod FS namesystem check ancestor access FS namesystem java org apach hadoop hdf server namenod FSNamesystem startFileInternal FSNamesystem java org apach hadoop hdf server namenod FS namesystem start file intern FS namesystem java org apach hadoop hdf server namenod FSNamesystem startFileInt FSNamesystem java org apach hadoop hdf server namenod FS namesystem start file int FS namesystem java org apach hadoop hdf server namenod FSNamesystem startFile FSNamesystem java org apach hadoop hdf server namenod FS namesystem start file FS namesystem java org apach hadoop hdf server namenod NameNodeRpcServer creat NameNodeRpcServer java org apach hadoop hdf server namenod name node rpc server creat name node rpc server java org apach hadoop hdf protocolPB ClientNamenodeProtocolServerSideTranslatorPB creat ClientNamenodeProtocolServerSideTranslatorPB java org apach hadoop hdf protocol PB client namenod protocol server side translat PB creat client namenod protocol server side translat PB java org apach hadoop hdf protocol proto ClientNamenodeProtocolProtos ClientNamenodeProtocol callBlockingMethod ClientNamenodeProtocolProtos java org apach hadoop hdf protocol proto client namenod protocol proto client namenod protocol call block method client namenod protocol proto java org apach hadoop ipc ProtobufRpcEngine server ProtoBufRpcInvoker call ProtobufRpcEngine java org apach hadoop ipc protobuf rpc engin server proto buf rpc invok call protobuf rpc engin java org apach hadoop ipc RPC server call RPC java org apach hadoop ipc RPC server call RPC java org apach hadoop ipc server handler run server java org apach hadoop ipc server handler run server java org apach hadoop ipc server handler run server java org apach hadoop ipc server handler run server java java secur AccessController doPrivileged nativ java secur access control privileg nativ method method javax secur auth subject doAs subject java javax secur auth subject subject java org apach hadoop secur UserGroupInformation doAs UserGroupInformation java org apach hadoop secur user group inform user group inform java org apach hadoop ipc server handler run server java org apach hadoop ipc server handler run server java sun reflect NativeConstructorAccessorImpl newInstance nativ sun reflect nativ constructor accessor impl new instanc nativ method method sun reflect NativeConstructorAccessorImpl newInstance NativeConstructorAccessorImpl java sun reflect nativ constructor accessor impl new instanc nativ constructor accessor impl java sun reflect DelegatingConstructorAccessorImpl newInstance DelegatingConstructorAccessorImpl java sun reflect deleg constructor accessor impl new instanc deleg constructor accessor impl java java lang reflect constructor newInstance constructor java java lang reflect constructor new instanc constructor java org apach hadoop ipc RemoteException instantiateException RemoteException java org apach hadoop ipc remot except instanti except remot except java org apach hadoop ipc RemoteException unwrapRemoteException RemoteException java org apach hadoop ipc remot except unwrap remot except remot except java org apach hadoop hdf DFSOutputStream newStreamForCreate DFSOutputStream java org apach hadoop hdf DFS output stream new stream creat DFS output stream java org apach hadoop hdf DFSClient creat DFSClient java org apach hadoop hdf DFS client creat DFS client java org apach hadoop hdf DFSClient creat DFSClient java org apach hadoop hdf DFS client creat DFS client java org apach hadoop hdf DistributedFileSystem doCall DistributedFileSystem java org apach hadoop hdf distribut file system call distribut file system java org apach hadoop hdf DistributedFileSystem doCall DistributedFileSystem java org apach hadoop hdf distribut file system call distribut file system java org apach org apach,0,0,0,0,0,0,0 
5173,Dmytro Sen,ambari-server,0,The status of App Timeline Server affect the health status of YARN service., statu app timelin server affect health statu YARN servic servic,When stopping ATS  YARN service indicator blinks red giving the idea that YARN is going down and become solid red after that. YARN service should not be indicated as STOPPED if ATS is down., stop ATS YARN servic indic blink red give idea YARN go becom solid red YARN servic not indic STOPPED ATS,0,0,0,0,0,ambari-server/src/main/resources/stacks/HDP/2.1/services/YARN/metainfo.xml;,0 
5223,Vitaly Brodetskyi,ambari-agent,0,hive-env.sh overwrites user value of HIVE_AUX_JARS_PATH, hive env sh hive env sh overwrit user valu HIVE_AUX_JARS_PATH HIVE AUX JARS PATH,This line at the bottom of hive-env.sh disregards any user-provided values  masking them from the launch script.# Folder containing extra ibraries required for hive compilation/execution can be controlled by:export HIVE_AUX_JARS_PATH=/usr/lib/hcatalog/share/hcatalog/hcatalog-core.jarThis breaks this feature for users of both the environment export HIVE_AUX_JARS_PATH='my custom value' and the command line hive --auxpath 'my custom value' ., line bottom hive env sh hive env sh disregard user provid user provid valu mask launch script script folder contain extra ibrari requir hive compil execut compil execut control export export HIVE_AUX_JARS_PATH usr lib hcatalog share hcatalog hcatalog core jarThis HIVE AUX JARS PATH usr lib hcatalog share hcatalog hcatalog core jar break featur user environ export HIVE_AUX_JARS_PATH HIVE AUX JARS PATH custom valu valu command line hive auxpath custom valu valu,0,0,0,0,0,0,0 
5235,Jaimin D Jetly,ambari-web,0,Add component of clients in Ambari doesn't work in a secured cluster, add compon client ambari work secur cluster,The reason of bug is wrong query formation while triggering API to create clients on host.The data sent with the POST call to create client components on the host is:{'RequestInfo':{'context':'Install Clients'} 'Body':{'host_components':[{'HostRoles':{'component_name':'CLIENTS'}}]}}This is incorrect. There is no component with name 'CLIENTS'., reason bug wrong queri format trigger API creat client host host data sent POST call creat client compon host RequestInfo context instal request info context instal client client bodi host_components HostRoles component_name CLIENTS bodi host_components host role component_name CLIENTS incorrect incorrect no compon name CLIENTS CLIENTS,0,0,0,0,0,0,0 
5244,Oleg Nechiporenko,ambari-web,0,Wizard Step7 JS error on load page (add service wizard), wizard step step JS error load page add servic wizard wizard,Add Nagios  Ganglia via Add Service WizardProceed to step 'Customize Services'JS-error appears about null-object:/app/controllers/wizard/step7_controller.js : loadServiceTagsSuccess()if (serviceConfigsDef.sites.indexOf(site) &gt; -1)Also  HDFS by default is selected as active tab  but one of the 'new' services (Nagios for example) should be selected., add nagio ganglia via add servic WizardProceed wizard proce step custom custom servic JS error servic JS error appear null object app control wizard step _controller js null object app control wizard step _controller js loadServiceTagsSuccess load servic tag success serviceConfigsDef site indexOf site servic config def site index site gt gt also also HDFS default select activ tab one new new servic nagio nagio exampl exampl select select,0,0,0,0,0,0,0 
5246,Andrii Babiichuk,ambari-web,0,Mistake in title of operation 'Restart APP_TIMELINE_SERVER on ..., mistak titl oper restart restart APP_TIMELINE_SERVER APP TIMELINE SERVER,We should show displayName  not componentName, show displayName display name not componentName compon name,0,0,0,0,0,ambari-web/app/controllers/main/host/details.js;,0 
5258,Oleg Nechiporenko,ambari-web,0,Installer: 'Undo' button for repo BaseURL does not work, instal instal undo undo button repo BaseURL base URL not work,STR: during installer phase go to &lt;cluster&gt;:8080 /#/installer/step1 ; Change/delete any of BaseURL of repos ; Click 'Undo' buttonActual Results:Undo button does not work. Moreover  if we click Undo after any update of text in BaseURL  it leads to cleanup of it value atall., STR STR instal phase go lt cluster gt lt cluster gt instal step instal step chang delet chang delet BaseURL base URL repo click undo undo buttonActual button actual result undo result undo button not work work moreov click undo updat text BaseURL base URL lead cleanup valu atal atal,0,0,0,0,0,0,0 
5264,Vitaly Brodetskyi,ambari-agent,0,Ganglia Server goes to 'installed' state after double 'Ganglia rrdcached base directory' config changing, ganglia server goe instal instal state doubl ganglia ganglia rrdcach base directori directori config chang,STR:1) Deploy cluster by default2) Go to Ganglia service page -&gt; Config tab 3) Change value 'Ganglia rrdcached base directory' (e.g. /var/lib/ganglia/rrd8)4) Restart Ganglia5) Change 'Ganglia rrdcached base directory' back to old value (by default - /var/lib/ganglia/rrds)6) Restart GangliaExpected result: Ganglia should be restarted successfullyCurrent result: Ganglia Server goes to 'installed' state and stuck thereError message from gmetad file:=============================Starting hdp-gmetad...=============================Base directory (-b) resolved via file system links!Please consult rrdcached '-b' documentation!Consider specifying the real directory (/var/lib/ganglia/rrd8)chgrp: cannot access '/var/run/ganglia/hdp/rrdcached.sock': No such file or directorychgrp: cannot access '/var/run/ganglia/hdp/rrdcached.limited.sock': No such file or directoryFailed to start /usr/bin/rrdcachedNot starting /usr/sbin/gmetad because starting /usr/bin/rrdcached failed.root 16990 0.0 0.0 108164 1560 ? S 03:19 0:00 /bin/bash --login -c service hdp-gmetad start &gt;&gt; /tmp/gmetad.log 2&gt;&amp;1 ; /bin/ps auwx | /bin/grep [g]metad &gt;&gt; /tmp/gmetad.log 2&gt;&amp;1, STR STR deploy cluster default default Go ganglia servic page gt gt config tab chang valu ganglia ganglia rrdcach base directori directori var lib ganglia rrd var lib ganglia rrd restart ganglia ganglia chang ganglia ganglia rrdcach base directori directori back old valu default var lib ganglia rrd var lib ganglia rrd restart GangliaExpected ganglia expect result result ganglia restart successfullyCurrent success current result result ganglia server goe instal instal state stuck thereError error messag gmetad file start file start hdp gmetad base hdp gmetad base directori resolv via file system link pleas link pleas consult rrdcach document consid document consid specifi real directori var lib ganglia rrd chgrp var lib ganglia rrd chgrp cannot access var run ganglia hdp rrdcach sock var run ganglia hdp rrdcach sock No file directorychgrp directorychgrp cannot access var run ganglia hdp rrdcach limit sock var run ganglia hdp rrdcach limit sock No file directoryFailed directori fail start usr bin rrdcachedNot usr bin rrdcach not start usr sbin gmetad usr sbin gmetad start usr bin rrdcach usr bin rrdcach fail root fail root bin bash bin bash login servic hdp gmetad hdp gmetad start gt gt gt gt tmp gmetad log tmp gmetad log gt amp gt amp bin ps bin ps auwx bin grep bin grep metad metad gt gt gt gt tmp gmetad log tmp gmetad log gt amp gt amp,0,0,0,0,0,0,0 
5274,Aleksandr Kovalenko,ambari-web,0,Supervisor under supervision fails w/o ganglia server, supervisor supervis fail ganglia server,JMXetricAgent instrumented JVM  see https://github.com/ganglia/jmxetricMar 28  2014 6:40:13 PM info.ganglia.jmxetric.JMXetricAgent premainSEVERE: Exception starting JMXetricAgentjava.net.UnknownHostException: {0}: Name or service not known at java.net.Inet6AddressImpl.lookupAllHostAddr(Native Method) at java.net.InetAddress$1.lookupAllHostAddr(InetAddress.java:901) at java.net.InetAddress.getAddressesFromNameService(InetAddress.java:1293) at java.net.InetAddress.getAllByName0(InetAddress.java:1246) at java.net.InetAddress.getAllByName(InetAddress.java:1162) at java.net.InetAddress.getAllByName(InetAddress.java:1098) at java.net.InetAddress.getByName(InetAddress.java:1048) at info.ganglia.gmetric4j.gmetric.AbstractProtocol.&lt;init&gt;(AbstractProtocol.java:29) at info.ganglia.gmetric4j.gmetric.Protocolv31x.&lt;init&gt;(Protocolv31x.java:34) at info.ganglia.gmetric4j.gmetric.GMetric.&lt;init&gt;(GMetric.java:108) at info.ganglia.jmxetric.XMLConfigurationService.configureGangliaFromXML(XMLConfigurationService.java:165) at info.ganglia.jmxetric.XMLConfigurationService.configure(XMLConfigurationService.java:67) at info.ganglia.jmxetric.JMXetricAgent.premain(JMXetricAgent.java:51) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:606) at sun.instrument.InstrumentationImpl.loadClassAndStartAgent(InstrumentationImpl.java:382) at sun.instrument.InstrumentationImpl.loadClassAndCallPremain(InstrumentationImpl.java:397)The reason here is this config send from ui:...childopts: '-javaagent:/usr/lib/storm/contrib/storm-jmxetric/lib/jmxetric-1.0.4.jar=host={0} ...'it can't find hostname {0}  however this works fine:...childopts: '-javaagent:/usr/lib/storm/contrib/storm-jmxetric/lib/jmxetric-1.0.4.jar=host= port...'So let's leave it as empty if no ganglia server is present, JMXetricAgent JM xetric agent instrument JVM see PM info ganglia jmxetric JMXetricAgent info ganglia jmxetric JM xetric agent premainSEVERE premain SEVERE except start JMXetricAgentjava net UnknownHostException JM xetric agentjava net unknown host except name servic not known java net inet AddressImpl lookupAllHostAddr nativ java net inet address impl lookup host addr nativ method method java net InetAddress lookupAllHostAddr InetAddress java java net inet address lookup host addr inet address java java net InetAddress getAddressesFromNameService InetAddress java java net inet address get address name servic inet address java java net InetAddress getAllByName InetAddress java java net inet address get name inet address java java net InetAddress getAllByName InetAddress java java net inet address get name inet address java java net InetAddress getAllByName InetAddress java java net inet address get name inet address java java net InetAddress getByName InetAddress java java net inet address get name inet address java info ganglia gmetric gmetric AbstractProtocol lt init gt AbstractProtocol java info ganglia gmetric gmetric abstract protocol lt init gt abstract protocol java info ganglia gmetric gmetric protocolv lt init gt protocolv java info ganglia gmetric gmetric protocolv lt init gt protocolv java info ganglia gmetric gmetric GMetric lt init gt GMetric java info ganglia gmetric gmetric metric lt init gt metric java info ganglia jmxetric XMLConfigurationService configureGangliaFromXML XMLConfigurationService java info ganglia jmxetric XML configur servic configur ganglia XML XML configur servic java info ganglia jmxetric XMLConfigurationService configur XMLConfigurationService java info ganglia jmxetric XML configur servic configur XML configur servic java info ganglia jmxetric JMXetricAgent premain JMXetricAgent java info ganglia jmxetric JM xetric agent premain JM xetric agent java sun reflect NativeMethodAccessorImpl invok nativ sun reflect nativ method accessor impl invok nativ method method sun reflect NativeMethodAccessorImpl invok NativeMethodAccessorImpl java sun reflect nativ method accessor impl invok nativ method accessor impl java sun reflect DelegatingMethodAccessorImpl invok DelegatingMethodAccessorImpl java sun reflect deleg method accessor impl invok deleg method accessor impl java java lang reflect method invok method java java lang reflect method invok method java sun instrument InstrumentationImpl loadClassAndStartAgent InstrumentationImpl java sun instrument instrument impl load class start agent instrument impl java sun instrument InstrumentationImpl loadClassAndCallPremain InstrumentationImpl java sun instrument instrument impl load class call premain instrument impl java reason config send ui childopt ui childopt javaag usr lib storm contrib storm jmxetric lib jmxetric jar host javaag usr lib storm contrib storm jmxetric lib jmxetric jar host find hostnam howev work fine childopt fine childopt javaag usr lib storm contrib storm jmxetric lib jmxetric jar host javaag usr lib storm contrib storm jmxetric lib jmxetric jar host port port let let leav empti no ganglia server present,0,0,0,0,0,ambari-server/src/main/resources/stacks/HDP/2.1/services/STORM/configuration/storm-site.xml;ambari-web/app/controllers/wizard/step7_controller.js;,0 
5282,Dmitry Lysnichenko,ambari-server; test,0,supervisor.enable should be removed from Ambari's Storm Config section, supervisor enabl supervisor enabl remov ambari ambari storm config section,Ambari exposes the supervisor.enable property and in some early builds defaults it to true which causes the supervisor's to not launch workers assigned to them. The supervisor's will start up  the assignments are there  but the supervisor's just ignore them. We need to remove the supervisor.enable from Ambari as it seems like a very dangerous switch that doesn't have broad applicability., ambari expos supervisor enabl supervisor enabl properti earli build default true caus supervisor supervisor not launch worker assign supervisor supervisor start assign supervisor supervisor ignor need remov supervisor enabl supervisor enabl ambari seem like danger switch broad applic applic,0,0,0,0,0,0,0 
5301,Andrii Tkach,ambari-web,0,Table of Confirm Hosts step is collapsed, tabl confirm host step collaps,Steps to reproduce:1. Run hosts registration2. Switch to Registering category3. Wait till all hosts become registeredResult: Table is collapsed.JS error occured: Uncaught Error: assertion failed: calling set on destroyed object, step reproduc reproduc run host registr registr switch regist categori categori wait till host becom registeredResult regist result tabl collaps JS collaps JS error occur occur uncaught error error assert fail fail call set destroy object,0,0,0,0,0,ambari-web/app/views/wizard/step3_view.js;ambari-web/app/views/wizard/step9_view.js;,0 
5311,Yusaku Sako,ambari-web,0,Falcon fails to deploy, falcon fail deploy,Looks like Falcon service definition on the stack has changed by AMBARI-5278.Currently  any new definition of globals require duplicating them in the UI code but that was not done  so this is breaking Falcon installation., look like falcon servic definit stack chang AMBARI current AMBARI current new definit global requir duplic UI code not done break falcon instal instal,0,0,0,0,0,0,0 
5313,Oleg Nechiporenko,ambari-web,0,Icon 'Asterisk' on 'Assign Masters'/-Slaves steps does not display with 8-bit depth, icon asterisk asterisk assign assign master slave master slave step not display bit depth,,,0,0,0,0,0,0,0 
5332,Mahadev konar,null,0,Print better logs for openssl issues on centos/rhel 6.5., print better log openssl issu cento rhel cento rhel,Print better logs for openssl issues on centos/rhel 6.5., print better log openssl issu cento rhel cento rhel,0,0,0,0,0,0,0 
5340,Antonenko Alexander,ambari-web,0,Tez DAG Operator hover text not wrapping wide content, tez DAG oper hover text not wrap wide content,When a Hive Tez DAG operator has a plan with very wide content  the text is not wrapped and hence bleeds out of the hover box. An additional problem is that this causes the hover to lose focus and hence close - thereby user cannot even see the hover (opens &amp; closes almost instantly)., hive tez DAG oper plan wide content text not wrap henc bleed hover box box addit problem caus hover lose focu henc close therebi user cannot even see hover open amp amp close almost instantli instantli,0,0,0,0,0,0,0 
5342,Dmytro Sen,ambari-server,0,Ambari YARN UI - Quick Link - JMX breaks if RM port is changed, ambari YARN UI quick link JMX break RM port chang,If you change RM port from 8088 to 50030 for migration of 1.x to 2.x   JVM metrics and few others are missing which results in yarn service summary page having multiple fields with n/a value.Step1: Change property below yarn.resourcemanager.webapp.address = localhost:50030Step 2: Start the service Click on Dashboard JMX is issue  Quick links is issue. RM gets started successfully., chang RM port migrat JVM metric other miss result yarn servic summari page multipl field valu step valu step chang properti yarn resourcemanag webapp address yarn resourcemanag webapp address localhost step localhost step start servic click dashboard JMX issu quick link issu issu RM get start success success,0,0,0,0,0,ambari-server/src/main/java/org/apache/ambari/server/controller/internal/AbstractProviderModule.java;ambari-server/src/test/java/org/apache/ambari/server/controller/internal/JMXHostProviderTest.java;,0 
5344,Myroslav Papirkovskyy,ambari-server,0,Error with finding FK constraint, error find FK constraint,Steps: Install Ambari-1.3.2 with Oracle DB. Upgrade ambari to 1.5.0 Run 'ambari-server upgrade' command.Seems like check before execute doesn't work for Oracle. Since we ignore failures this is not block the upgrade.Exception:16:41:36 719 WARN [main] DBAccessorImpl:416 - Error executing query: ALTER TABLE clusterconfigmapping ADD CONSTRAINT FK_clustercfgmap_cluster_id FOREIGN KEY (cluster_id) REFERENCES clusters (cluster_id)java.sql.SQLSyntaxErrorException: ORA-02275: such a referential constraint already exists in the table at oracle.jdbc.driver.T4CTTIoer.processError(T4CTTIoer.java:445) at oracle.jdbc.driver.T4CTTIoer.processError(T4CTTIoer.java:396) at oracle.jdbc.driver.T4C8Oall.processError(T4C8Oall.java:879) at oracle.jdbc.driver.T4CTTIfun.receive(T4CTTIfun.java:450) at oracle.jdbc.driver.T4CTTIfun.doRPC(T4CTTIfun.java:192) at oracle.jdbc.driver.T4C8Oall.doOALL(T4C8Oall.java:531) at oracle.jdbc.driver.T4CStatement.doOall8(T4CStatement.java:193) at oracle.jdbc.driver.T4CStatement.executeForRows(T4CStatement.java:1033) at oracle.jdbc.driver.OracleStatement.doExecuteWithTimeout(OracleStatement.java:1329) at oracle.jdbc.driver.OracleStatement.executeInternal(OracleStatement.java:1909) at oracle.jdbc.driver.OracleStatement.execute(OracleStatement.java:1871) at oracle.jdbc.driver.OracleStatementWrapper.execute(OracleStatementWrapper.java:318) at org.apache.ambari.server.orm.DBAccessorImpl.executeQuery(DBAccessorImpl.java:413) at org.apache.ambari.server.orm.DBAccessorImpl.executeQuery(DBAccessorImpl.java:399) at org.apache.ambari.server.orm.DBAccessorImpl.addFKConstraint(DBAccessorImpl.java:262) at org.apache.ambari.server.upgrade.UpgradeCatalog150.executeDDLUpdates(UpgradeCatalog150.java:375) at org.apache.ambari.server.upgrade.AbstractUpgradeCatalog.upgradeSchema(AbstractUpgradeCatalog.java:177) at org.apache.ambari.server.upgrade.SchemaUpgradeHelper.executeUpgrade(SchemaUpgradeHelper.java:174) at org.apache.ambari.server.upgrade.SchemaUpgradeHelper.main(SchemaUpgradeHelper.java:234)16:41:36 720 WARN [main] DBAccessorImpl:264 - Add FK constraint failed  constraintName = FK_clustercfgmap_cluster_id  tableName = clusterconfigmapping  errorCode = 2275  message = ORA-02275: such a referential constraint already exists in the table, step step instal ambari ambari oracl DB DB upgrad ambari run ambari server ambari server upgrad upgrad command seem command seem like check execut work oracl oracl sinc ignor failur not block upgrad except upgrad except WARN main main DBAccessorImpl DB accessor impl error execut queri queri ALTER TABLE clusterconfigmap ADD CONSTRAINT FK_clustercfgmap_cluster_id FOREIGN KEY cluster_id cluster_id REFERENCES cluster cluster_id java sql SQLSyntaxErrorException cluster_id java sql SQL syntax error except ORA ORA referenti constraint alreadi exist tabl oracl jdbc driver CTTIoer processError CTTIoer java oracl jdbc driver CTT ioer process error CTT ioer java oracl jdbc driver CTTIoer processError CTTIoer java oracl jdbc driver CTT ioer process error CTT ioer java oracl jdbc driver oall processError oall java oracl jdbc driver oall process error oall java oracl jdbc driver CTTIfun receiv CTTIfun java oracl jdbc driver CTT ifun receiv CTT ifun java oracl jdbc driver CTTIfun doRPC CTTIfun java oracl jdbc driver CTT ifun RPC CTT ifun java oracl jdbc driver oall doOALL oall java oracl jdbc driver oall OALL oall java oracl jdbc driver CStatement doOall CStatement java oracl jdbc driver statement oall statement java oracl jdbc driver CStatement executeForRows CStatement java oracl jdbc driver statement execut row statement java oracl jdbc driver OracleStatement doExecuteWithTimeout OracleStatement java oracl jdbc driver oracl statement execut timeout oracl statement java oracl jdbc driver OracleStatement executeInternal OracleStatement java oracl jdbc driver oracl statement execut intern oracl statement java oracl jdbc driver OracleStatement execut OracleStatement java oracl jdbc driver oracl statement execut oracl statement java oracl jdbc driver OracleStatementWrapper execut OracleStatementWrapper java oracl jdbc driver oracl statement wrapper execut oracl statement wrapper java org apach ambari server orm DBAccessorImpl executeQuery DBAccessorImpl java org apach ambari server orm DB accessor impl execut queri DB accessor impl java org apach ambari server orm DBAccessorImpl executeQuery DBAccessorImpl java org apach ambari server orm DB accessor impl execut queri DB accessor impl java org apach ambari server orm DBAccessorImpl addFKConstraint DBAccessorImpl java org apach ambari server orm DB accessor impl add FK constraint DB accessor impl java org apach ambari server upgrad UpgradeCatalog executeDDLUpdates UpgradeCatalog java org apach ambari server upgrad upgrad catalog execut DDL updat upgrad catalog java org apach ambari server upgrad AbstractUpgradeCatalog upgradeSchema AbstractUpgradeCatalog java org apach ambari server upgrad abstract upgrad catalog upgrad schema abstract upgrad catalog java org apach ambari server upgrad SchemaUpgradeHelper executeUpgrade SchemaUpgradeHelper java org apach ambari server upgrad schema upgrad helper execut upgrad schema upgrad helper java org apach ambari server upgrad SchemaUpgradeHelper main SchemaUpgradeHelper java org apach ambari server upgrad schema upgrad helper main schema upgrad helper java WARN main main DBAccessorImpl DB accessor impl add FK constraint fail constraintName constraint name FK_clustercfgmap_cluster_id tableName tabl name clusterconfigmap errorCode error code messag ORA ORA referenti constraint alreadi exist tabl,0,0,0,0,0,0,0 
5359,Dmitry Lysnichenko,test,0,unittest NagiosPropertyProviderTest fails, unittest NagiosPropertyProviderTest nagio properti provid test fail,testNoNagiosServerCompoonent(org.apache.ambari.server.controller.nagios.NagiosPropertyProviderTest): Expected no alertstestNoNagiosService(org.apache.ambari.server.controller.nagios.NagiosPropertyProviderTest): Expected no alerts, testNoNagiosServerCompoonent org apach ambari server control nagio NagiosPropertyProviderTest test No nagio server compoon org apach ambari server control nagio nagio properti provid test expect no alertstestNoNagiosService org apach ambari server control nagio NagiosPropertyProviderTest alertstest No nagio servic org apach ambari server control nagio nagio properti provid test expect no alert,0,0,0,0,0,0,0 
5362,Siddharth Wagle,ambari-agent,0,Automatic bootstrap failed on CentOS 6.5 (No module named common_functions), automat bootstrap fail CentOS cent OS No No modul name common_functions common_functions,SSH bootstrap of agents failed on CentOS 6.5.==========================Copying OS type check script...==========================Could not create directory '/root/.ssh'.Warning: Permanently added 'c6502.ambari.apache.org 192.168.65.102' (RSA) to the list of known hosts.scp /usr/lib/python2.6/site-packages/ambari_server/os_check_type.pyhost=c6502.ambari.apache.org  exitcode=0==========================Running OS type check...==========================Traceback (most recent call last): File '/tmp/os_check_type1396641340.py'  line 22  in &lt;module&gt; from common_functions import OSCheckImportError: No module named common_functionsConnection to c6502.ambari.apache.org closed.SSH command execution finishedhost=c6502.ambari.apache.org  exitcode=1ERROR: Bootstrap of host c6502.ambari.apache.org fails because previous action finished with non-zero exit code (1)ERROR MESSAGE: tcgetattr: Invalid argumentConnection to c6502.ambari.apache.org closed.STDOUT: Traceback (most recent call last): File '/tmp/os_check_type1396641340.py'  line 22  in &lt;module&gt; from common_functions import OSCheckImportError: No module named common_functionsConnection to c6502.ambari.apache.org closed., SSH bootstrap agent fail CentOS cent OS copi copi OS type check script could script could not creat directori root ssh warn root ssh warn perman ad ambari apach org ambari apach org RSA RSA list known host scp host scp usr lib python site packag ambari_server os_check_type pyhost ambari apach org usr lib python site packag ambari_server os_check_type pyhost ambari apach org exitcod run exitcod run OS type check traceback check traceback recent call last last file tmp os_check_type py tmp os_check_type py line lt modul gt lt modul gt common_functions import OSCheckImportError OS check import error No modul name common_functionsConnection common_functions connect ambari apach org ambari apach org close SSH close SSH command execut finishedhost ambari apach org finishedhost ambari apach org exitcod ERROR exitcod ERROR bootstrap host ambari apach org ambari apach org fail previou action finish non zero non zero exit code ERROR ERROR MESSAGE MESSAGE tcgetattr tcgetattr invalid argumentConnection argument connect ambari apach org ambari apach org close STDOUT close STDOUT traceback recent call last last file tmp os_check_type py tmp os_check_type py line lt modul gt lt modul gt common_functions import OSCheckImportError OS check import error No modul name common_functionsConnection common_functions connect ambari apach org ambari apach org close close,0,0,0,0,0,0,0 
5371,Oleg Nechiporenko,ambari-web,0,Dashboard: dashboard actions do not work for non-admin users, dashboard dashboard dashboard action not work non admin non admin user,For non-admin users action 'Switch to classic dashboard' returns JS error and 'Reset all widgets to default' action throws to Login page., non admin non admin user action switch switch classic dashboard dashboard return JS error reset reset widget default default action throw login page page,0,0,0,0,0,0,0 
5381,Xi Wang,ambari-web,0,Installer: 'Undo' button for repo BaseURL is unnecessarily present, instal instal undo undo button repo BaseURL base URL unnecessarili present,STR:on Installer phase go to &lt;cluster&gt;:8080 /#/installer/step1Do not do any updates of 'Base Url' fieldcheck the 'Undo' button for 2.1 stack.Actual Result:Undo is present for all 3 Os reposExpected Result:Undo should be present only after any update of 'BaseURL' field----------Seems  functionally this does not affect us  but might be confusing for users., STR STR instal phase go lt cluster gt lt cluster gt instal step instal step not updat base base url url fieldcheck undo undo button stack actual stack actual result undo result undo present Os reposExpected repo expect result undo result undo present updat BaseURL base URL field seem field seem function not affect us might confus user user,0,0,0,0,0,0,0 
5382,Myroslav Papirkovskyy,ambari-server,0,Schema Upgrade failed when upgrading to 1.5.1, schema upgrad fail upgrad,While upgrade  schema upgrade fails.Example error output (Oracle):rg.apache.ambari.server.AmbariException: Current database store version is not compatible with current server version  serverVersion=1.5.1.96  schemaVersion=1.4.1.25 at org.apache.ambari.server.controller.AmbariServer.checkDBVersion(AmbariServer.java:479) at org.apache.ambari.server.controller.AmbariServer.run(AmbariServer.java:149) at org.apache.ambari.server.controller.AmbariServer.main(AmbariServer.java:528)and Postgres 11:39:27 364 ERROR [main] AmbariServer:531 - Failed to run the Ambari Serverorg.apache.ambari.server.AmbariException: Current database store version is not compatible with current server version  serverVersion=1.5.1.96  schemaVersion=1.5.0 at org.apache.ambari.server.controller.AmbariServer.checkDBVersion(AmbariServer.java:479) at org.apache.ambari.server.controller.AmbariServer.run(AmbariServer.java:149) at org.apache.ambari.server.controller.AmbariServer.main(AmbariServer.java:528), upgrad schema upgrad fail exampl fail exampl error output oracl rg apach ambari server AmbariException oracl rg apach ambari server ambari except current databas store version not compat current server version serverVersion server version schemaVersion schema version org apach ambari server control AmbariServer checkDBVersion AmbariServer java org apach ambari server control ambari server check DB version ambari server java org apach ambari server control AmbariServer run AmbariServer java org apach ambari server control ambari server run ambari server java org apach ambari server control AmbariServer main AmbariServer java org apach ambari server control ambari server main ambari server java postgr ERROR main main AmbariServer ambari server fail run ambari serverorg apach ambari server AmbariException serverorg apach ambari server ambari except current databas store version not compat current server version serverVersion server version schemaVersion schema version org apach ambari server control AmbariServer checkDBVersion AmbariServer java org apach ambari server control ambari server check DB version ambari server java org apach ambari server control AmbariServer run AmbariServer java org apach ambari server control ambari server run ambari server java org apach ambari server control AmbariServer main AmbariServer java org apach ambari server control ambari server main ambari server java,0,0,0,0,0,0,0 
5386,Yusaku Sako,ambari-web,0,Deploy stuck during generating tasks on Review page (not always reproduced), deploy stuck gener task review page not alway reproduc reproduc,After the user clicks 'Deploy' in the Installer Wizard  sometimes an error is shown showing 'java.lang.IllegalArgumentException: Could not access base url'. This happens while the wizard tries to save the user-specified repo base URLs.Installer should not be performing validation during deploy  because it had already been done during Select Stacks., user click deploy deploy instal wizard sometim error shown show java lang IllegalArgumentException java lang illeg argument except could not access base url url happen wizard tri save user specifi user specifi repo base URLs instal UR Ls instal not perform valid deploy alreadi done select stack stack,0,0,0,0,0,0,0 
5402,Andrii Babiichuk,ambari-web,0,Remove classic dashboard view from Ambari, remov classic dashboard view ambari,remove classic dashboard from Ambari  as it's not used any more and doesn't support new services, remov classic dashboard ambari not use support new servic,0,0,0,0,0,ambari-web/app/templates/main/dashboard.hbs;ambari-web/app/templates/main/dashboard/service/flume.hbs;ambari-web/app/templates/main/dashboard/service/hbase.hbs;ambari-web/app/templates/main/dashboard/service/hdfs.hbs;ambari-web/app/templates/main/dashboard/service/hive.hbs;ambari-web/app/templates/main/dashboard/service/mapreduce.hbs;ambari-web/app/templates/main/dashboard/service/mapreduce2.hbs;ambari-web/app/templates/main/dashboard/service/oozie.hbs;ambari-web/app/templates/main/dashboard/service/storm.hbs;ambari-web/app/templates/main/dashboard/service/yarn.hbs;ambari-web/app/templates/main/dashboard/service/zookeeper.hbs;ambari-web/app/templates/main/service/info/summary.hbs;ambari-web/app/templates/main/service/services/flume.hbs;ambari-web/app/templates/main/service/services/hbase.hbs;ambari-web/app/templates/main/service/services/hdfs.hbs;ambari-web/app/templates/main/service/services/hive.hbs;ambari-web/app/templates/main/service/services/mapreduce.hbs;ambari-web/app/templates/main/service/services/mapreduce2.hbs;ambari-web/app/templates/main/service/services/oozie.hbs;ambari-web/app/templates/main/service/services/storm.hbs;ambari-web/app/templates/main/service/services/yarn.hbs;ambari-web/app/templates/main/service/services/zookeeper.hbs;ambari-web/app/views.js;ambari-web/app/views/main/dashboard.js;ambari-web/app/views/main/dashboard/service.js;ambari-web/app/views/main/dashboard/service/flume.js;ambari-web/app/views/main/dashboard/service/hbase.js;ambari-web/app/views/main/dashboard/service/hdfs.js;ambari-web/app/views/main/dashboard/service/hive.js;ambari-web/app/views/main/dashboard/service/mapreduce.js;ambari-web/app/views/main/dashboard/service/mapreduce2.js;ambari-web/app/views/main/dashboard/service/oozie.js;ambari-web/app/views/main/dashboard/service/storm.js;ambari-web/app/views/main/dashboard/service/yarn.js;ambari-web/app/views/main/dashboard/service/zookeeper.js;ambari-web/app/views/main/service/service.js;ambari-web/app/views/main/service/services/flume.js;ambari-web/app/views/main/service/services/hbase.js;ambari-web/app/views/main/service/services/hdfs.js;ambari-web/app/views/main/service/services/hive.js;ambari-web/app/views/main/service/services/mapreduce.js;ambari-web/app/views/main/service/services/mapreduce2.js;ambari-web/app/views/main/service/services/oozie.js;ambari-web/app/views/main/service/services/storm.js;ambari-web/app/views/main/service/services/yarn.js;ambari-web/app/views/main/service/services/zookeeper.js;,0 
5406,Erin A Boyd,ambari-agent,0,Pig unit test class named wrong, pig unit test class name wrong,Typo in unit test. File said class was Hcat rather than Pig, typo unit test test file said class hcat rather pig,0,0,0,0,0,0,0 
5412,Vitaly Brodetskyi,ambari-agent,0,Operation 'Supervisor start' failed during installation but all supervisors are alive, oper supervisor supervisor start start fail instal supervisor aliv,STR:1. Deploy Hadoop by default scenario with all services.2. Try to start Storm.Actual results: 'Start All Services' operation failed because of 'Supervisor start' failed. 'Start Storm' operation does not contain 'Supervisor start' popups  but all supervisors are STARTED after it have finished., STR STR deploy hadoop default scenario servic servic tri start storm actual storm actual result result start start servic servic oper fail supervisor supervisor start start fail fail start start storm storm oper not contain supervisor supervisor start start popup supervisor STARTED finish finish,0,0,0,0,0,0,0 
5413,Siddharth Wagle,ambari-agent,0,OS type check for centos 6.5 can fail if the /etc/issue has CentOS Linux release 6.5, OS type check cento fail etc issu etc issu CentOS cent OS linux releas,I tried default centos 6.5 it works fine. But if I change /etc/issues and /etc/redhat-release to say:CentOS Linux release 6.5 (Final)then the registration fails with:INFO 2014-04-09 14:39:22 501 security.py:51 - SSL connection established. Two-way SSL authentication is turned off on the server.ERROR 2014-04-09 14:39:22 563 Controller.py:100 - Cannot register host with not supported os type  hostname=c6501.ambari.apache.org  serverOsType=redhat6  agentOstype=centos linux6In the agent logs.By default centos 6.5 has:CentOS release 6.5 (Final)but sometimes can have:CentOS Linux release 6.5 (Final), tri default cento work fine fine chang etc issu etc issu etc redhat releas etc redhat releas say CentOS say cent OS linux releas final final registr fail INFO INFO secur py secur py SSL connect establish establish two way two way SSL authent turn server ERROR server ERROR control py control py cannot regist host not support os type hostnam ambari apach org hostnam ambari apach org serverOsType redhat server Os type redhat agentOstype cento agent ostyp cento linux linux agent log log default cento CentOS cent OS releas final final sometim CentOS cent OS linux releas final final,0,0,0,0,0,0,0 
5433,Sumit Mohanty,null,0,Add Host failed on upgraded cluster on Suse, add host fail upgrad cluster suse,This is due to upgrade. We need to change it manually after upgrade://Now we have (redhat  suse  debian  other_detected_by_python)vi /etc/ambari-server/conf/ambari.properties(server.os_type=sles11) --&gt;( server.os_type=suse11)+restart the serverShould upgrade automatically deal with this?old code: os_info = platform.linux_distribution( None  None  None  ['SuSE'  'redhat' ]  0 ) os_name = os_info[0].lower() if os_name == 'suse': os_name = 'sles' os_version = os_info[1].split('.'  1)[0] master_os_type = os_name + os_version write_property(OS_TYPE_PROPERTY  master_os_type), due upgrad upgrad need chang manual upgrad upgrad redhat suse debian other_detected_by_python vi other_detected_by_python vi etc ambari server conf ambari properti server os_type sle etc ambari server conf ambari properti server os_type sle gt gt server os_type suse restart server os_type suse restart serverShould server upgrad automat deal old old code code os_info platform linux_distribution platform linux_distribution none none none SuSE Su SE redhat redhat os_name os_info lower os_info lower os_name suse suse os_name sle sle os_version os_info split os_info split master_os_type os_name os_version write_property OS_TYPE_PROPERTY write_property OS TYPE PROPERTY master_os_type master_os_type,0,0,0,0,0,0,0 
5455,Srimanth Gunturi,ambari-web,0,Ambari configuration for map join conversion and tez container size seems wrong, ambari configur map join convers tez contain size seem wrong,For hive:hive.auto.convert.join.noconditionaltask.size is set to 1000000000 This should be a fraction (1/3) of the container size.hive.tez.java.opts has '-Xmx1024m'This is different from both map and reduce sizes. Desired values are: map size if map size &gt; 2g else reduce sizemap size is set on the same cluster to ~500mbThe settings as the are will lead to many failed queries because the mapjoin conversion is to aggressive. If we don't change the container sizes based on cluster configs we will see wide spread problems with containers being killed or perf problems., hive hive auto convert join noconditionaltask size hive hive auto convert join noconditionaltask size set fraction contain size hive tez java opt size hive tez java opt xmx xmx differ map reduc size size desir valu map size map size gt gt els reduc sizemap size set cluster mbThe mb set lead mani fail queri mapjoin convers aggress aggress chang contain size base cluster config see wide spread problem contain kill perf problem problem,0,0,0,0,0,0,0 
5457,Andrii Babiichuk,ambari-web,0,Host Checks: alternatives check results are not surfaced in Host Check popup, host check check altern check result not surfac host check popup,Ambari Agent  as part of host checks  identifies conflicting 'alternatives' settings and reports back inside the 'last_agent_env' object.UI is not surfacing this in Host Checks popup.We should have a section called 'Alternatives Issues' and list out the alternatives names.For example: 'last_agent_env' : { 'stackFoldersAndFiles' : [ ... ]  'alternatives' : [ { 'name' : 'zookeeper-conf'  'target' : '/etc/zookeeper/conf.dist' }  { 'name' : 'hadoop-conf'  'target' : '/etc/hadoop/conf.dist' }  ]  'existingUsers' : [ .... ]  'existingRepos' : [ ... ]  ...In the above case  we want to highlight the fact that hadoop-conf and zookeeper-conf have conflicts.Alternatives Issues--------The following alternatives should be removedAlternativeshadoop-conf Exists on 3 hostszookeeper-conf Exists on 3 hosts, ambari agent part host check identifi conflict altern altern set report back insid last_agent_env last_agent_env object UI object UI not surfac host check popup popup section call altern altern issu issu list altern name name exampl exampl last_agent_env last_agent_env stackFoldersAndFiles stack folder file altern altern name name zookeep conf zookeep conf target target etc zookeep conf dist etc zookeep conf dist name name hadoop conf hadoop conf target target etc hadoop conf dist etc hadoop conf dist existingUsers exist user existingRepos exist repo case want highlight fact hadoop conf hadoop conf zookeep conf zookeep conf conflict altern conflict altern issu issu follow altern removedAlternativeshadoop conf remov alternativeshadoop conf exist hostszookeep conf hostszookeep conf exist host,0,0,0,0,0,ambari-web/app/controllers/wizard/step3_controller.js;ambari-web/app/messages.js;ambari-web/app/templates/wizard/step3_host_warnings_popup.hbs;,0 
5472,Dmytro Sen,ambari-server,0,Use SchemaTool in Hive for init metastore DB schema, use SchemaTool schema tool hive init metastor DB schema,When Ambari create the metastore database in MySQL it uses auto create feature. This does not create the transaction tables  so any ACID operations (including streaming ingest) will not work., ambari creat metastor databas MySQL SQL use auto creat featur featur not creat transact tabl ACID oper includ stream ingest ingest not work work,0,0,0,0,0,ambari-server/src/main/resources/stacks/HDP/2.0.6/services/HIVE/package/scripts/hive.py;ambari-server/src/test/python/stacks/2.1/HIVE/test_hive_metastore.py;,0 
5511,Antonenko Alexander,ambari-web,0,Misleading hardcoded command in paragraph 2 on step 'Manual commands' of 'Move Master' wizard, mislead hardcod command paragraph step manual manual command command move move master master wizard,STR:1. Deploy cluster with multiplied NN directory(in our case /grid/0/hadoop/hdfs/namenode  /grid/1/hadoop/hdfs/namenode).2. Start NN moving.3. Reach step 'Manual commands'.Actual results:Paragraph 1 contains information about all dirs we should move.Paragraph 2 contains message 'Login to the target host XXX and change permissons for the NameNode dirs by running:' and only one command with hardcoded NN dir:chown -R hdfs:hadoop /hadoop/hdfs/namenode/Screenshot attached.When there are multiple directories specified  we need to show the actual path (but replace commas with a space).In case of '/grid/0/hadoop/hdfs/namenode /grid/1/hadoop/hdfs/namenode' as in the attached image  we should display:chown -R hdfs:hadoop /grid/0/hadoop/hdfs/namenode /grid/1/hadoop/hdfs/namenode, STR STR deploy cluster multipli NN directori directori case grid hadoop hdf namenod grid hadoop hdf namenod grid hadoop hdf namenod grid hadoop hdf namenod start NN move move reach step manual manual command actual command actual result paragraph result paragraph contain inform dir move paragraph move paragraph contain messag login login target host XXX chang permisson NameNode name node dir run run one command hardcod NN dir chown dir chown hdf hadoop hdf hadoop hadoop hdf namenod screenshot hadoop hdf namenod screenshot attach attach multipl directori specifi need show actual path replac comma space space case grid hadoop hdf namenod grid hadoop hdf namenod grid hadoop hdf namenod grid hadoop hdf namenod attach imag display chown display chown hdf hadoop hdf hadoop grid hadoop hdf namenod grid hadoop hdf namenod grid hadoop hdf namenod grid hadoop hdf namenod,0,0,0,0,0,0,1 
5512,Antonenko Alexander,ambari-web,0,Move wizard and HA wizard gets stuck on any deploy step, move wizard HA wizard get stuck deploy step,Because of JS error (page refresh makes no effect)., JS error page refresh make no effect effect,0,0,0,0,0,0,0 
5524,Oleg Nechiporenko,ambari-web,0,Unit tests for number_utils  string_utils  validator and misc files., unit test number_utils string_utils valid misc file file,Create unit tests for following files:utils/misc.jsutils/number_utils.jsutils/string_utils.jsutils/validator.js, creat unit test follow file util misc jsutil number_utils jsutil string_utils jsutil valid js file util misc jsutil number_utils jsutil string_utils jsutil valid js,0,0,0,0,0,0,0 
5531,Srimanth Gunturi,ambari-web,0,Switch SQL standard authorization to be off by default., switch SQL standard author default default,For Ambari 1.5.1 SQL standard authorization was on by default.Users with certification suites are running into problems related to this feature (which were not bugs in the auth systems  rather they were additional requirements to using it). This needs to be turned off by default. The feature is controlled by:hive.security.authorization.enabledWe want the default value to be set to false in Ambari 1.6.0., ambari SQL standard author default user default user certif suit run problem relat featur not bug auth system rather addit requir use need turn default default featur control hive secur author enabledWe hive secur author enabl want default valu set fals ambari,0,0,0,0,0,0,0 
5543,Oleg Nechiporenko,ambari-web,0,Unit tests for steps 6 (with small refactor), unit test step small refactor refactor,,,0,0,0,0,0,0,0 
5546,Dmytro Sen,null,0,Call for requests with 'page_size' always return 10 most recent, call request page_size page_size alway return recent,Problem:Call: /api/v1/clusters/cl1/requests?to=end&amp;page_size=20Actually result: return most recent 10 requestsExpected result: return most recent 20 requests.Call: /api/v1/clusters/cl1/requests?from=start&amp;page_size=3Actually result: return first 3 requests started from the first in most recent 10Expected result: return first 3 requests started from the very first('install services')In this case  we can never get history requests made before most recent 10., problem call problem call api cluster cl request end amp page_size actual api cluster cl request end amp page_size actual result result return recent requestsExpected request expect result result return recent request call request call api cluster cl request start amp page_size actual api cluster cl request start amp page_size actual result result return first request start first recent expect expect result result return first request start first instal first instal servic servic case never get histori request made recent,0,0,0,0,0,ambari-server/src/main/java/org/apache/ambari/server/actionmanager/ActionDBAccessor.java;ambari-server/src/main/java/org/apache/ambari/server/actionmanager/ActionDBAccessorImpl.java;ambari-server/src/main/java/org/apache/ambari/server/actionmanager/ActionManager.java;ambari-server/src/main/java/org/apache/ambari/server/api/query/QueryImpl.java;ambari-server/src/main/java/org/apache/ambari/server/api/services/BaseRequest.java;ambari-server/src/main/java/org/apache/ambari/server/controller/internal/RequestResourceProvider.java;ambari-server/src/main/java/org/apache/ambari/server/controller/utilities/PropertyHelper.java;ambari-server/src/main/java/org/apache/ambari/server/orm/dao/HostRoleCommandDAO.java;ambari-server/src/test/java/org/apache/ambari/server/actionmanager/TestActionDBAccessorImpl.java;ambari-server/src/test/java/org/apache/ambari/server/actionmanager/TestActionManager.java;ambari-server/src/test/java/org/apache/ambari/server/controller/internal/RequestResourceProviderTest.java;,0 
5551,Jaimin D Jetly,ambari-web,0,Checkbox 'client' without upper case letter, checkbox client client without upper case letter,,,0,0,0,0,0,0,0 
5555,Oleg Nechiporenko,ambari-web,0,NameNode HA wizard: Review page appears blank, NameNode name node HA wizard wizard review page appear blank,,,0,0,0,0,0,0,0 
5558,Andrii Babiichuk,ambari-web,0,Navigating back from Host page to Heatmaps page is broken, navig back host page heatmap page broken,STR: Go to Dashboard page. Switch to 'Heatmaps' tab. Click on first host. On host page click 'Back'.Actual result: Appeared 'Cluster Status and Metrics' tab.Expected result: Should appear 'Heatmaps' tab., STR STR Go dashboard page page switch heatmap heatmap tab tab click first host host host page click back actual back actual result result appear cluster cluster statu metric metric tab expect tab expect result result appear heatmap heatmap tab tab,0,0,0,0,0,ambari-web/app/routes/main.js;ambari-web/app/views/main/dashboard.js;,0 
5569,Oleg Nechiporenko,ambari-web,0,Fix UI Unit tests, fix UI unit test,,,0,0,0,0,0,0,0 
5571,Aleksandr Kovalenko,ambari-web,0,Restart option is enabled for components in 'Decommissioned' state but it should not, restart option enabl compon decommiss decommiss state not,'Restart' option should not be enabled if a slave component is in 'decommissioned' state  but it is.STR:1) Go to 'Host details' page2) Make any slave component 'Decommissioned'Actual result: 'Restart' option is enabled (see screenshot)Expected result: 'Restart' option should be disabled., restart restart option not enabl slave compon decommiss decommiss state STR STR Go host host detail detail page page make slave compon decommiss actual decommiss actual result result restart restart option enabl see screenshot expect screenshot expect result result restart restart option disabl disabl,0,0,0,0,0,0,0 
5577,Dmitry Lysnichenko,ambari-server,0,Turn Off Maintenance Mode for HDFS does not work (problems with ambari-agent), turn mainten mode HDFS not work problem ambari agent ambari agent,STR:Turn On Maintenance Mode for HDFSTurn Off Maintenance Mode for HDFSExpected result:Have not problems with ambari-agent.Actual result:Have problems with ambari-agent., STR turn STR turn mainten mode HDFSTurn HDFS turn mainten mode HDFSExpected HDFS expect result result not problem ambari agent actual ambari agent actual result result problem ambari agent ambari agent,0,0,0,0,0,0,0 
5603,Xi Wang,ambari-web,0,Ambari version is unknown during installer via UI, ambari version unknown instal via UI,During installer user does not see Ambari Version from UI (see screenshot)  but on monitoring phase it's available in the same Admin -&gt; About, instal user not see ambari version UI see screenshot screenshot monitor phase avail admin gt gt,0,0,0,0,0,0,0 
5605,Xi Wang,ambari-web,0,Usability UX: Default key actions for dialog boxes, usabl UX UX default key action dialog box,PROBLEM: Default action for dialog boxes in AmbariUSE CASE: Ambari UI doesn't allow you to press enter and trigger default actions. When a default action is high lighted 'green button' you should be able to hit enter and have the action be triggered. In this case add hit enter should make okay button trigger. Also  pressing escape should cancel the dialog box., PROBLEM PROBLEM default action dialog box AmbariUSE ambari USE CASE CASE ambari UI allow press enter trigger default action action default action high light green button button abl hit enter action trigger trigger case add hit enter make okay button trigger trigger also press escap cancel dialog box box,0,0,0,0,0,0,0 
5607,Michael Harp,null,0,Yarn Nodemanager Metrics only update every few minutes, yarn nodemanag metric updat everi minut,Yarn Nodemanager Metrics take far too long between updates.To demonstrate:Run Terasort or anything that runs mapreduce:hdfs dfs -mkdir -p benchmarks/terasorthadoop jar /usr/lib/hadoop-mapreduce/hadoop-mapreduce-examples.jar teragen -Dmapred.map.tasks=72 -Dmapred.reduce.tasks=36 1000000 benchmarks/terasort/inputhadoop jar /usr/lib/hadoop-mapreduce/hadoop-mapreduce-examples.jar terasort -Dmapred.map.tasks=72 -Dmapred.reduce.tasks=36 benchmarks/terasort/input benchmarks/terasort/outputhdfs dfs -rm -R -skipTrash benchmarks/terasortThen repeatedly probe the API at:https://&lt;server&gt;:8081/api/v1/clusters/c1/services/YARN/components/NODEMANAGER?fields=host_components/metrics/yarnIt usually takes 2-3 minutes to see the metrics update  very repeatable., yarn nodemanag metric take far long updat updat demonstr run demonstr run terasort anyth run mapreduc hdf mapreduc hdf df mkdir benchmark terasorthadoop benchmark terasorthadoop jar usr lib hadoop mapreduc hadoop mapreduc exampl jar usr lib hadoop mapreduc hadoop mapreduc exampl jar teragen dmapr map task dmapr map task dmapr reduc task dmapr reduc task benchmark terasort inputhadoop benchmark terasort inputhadoop jar usr lib hadoop mapreduc hadoop mapreduc exampl jar usr lib hadoop mapreduc hadoop mapreduc exampl jar terasort dmapr map task dmapr map task dmapr reduc task dmapr reduc task benchmark terasort input benchmark terasort input benchmark terasort outputhdf benchmark terasort outputhdf df rm skipTrash skip trash benchmark terasortThen benchmark terasort repeatedli probe API http lt server gt api cluster servic YARN compon NODEMANAGER field host_components metric yarnIt http lt server gt api cluster servic YARN compon NODEMANAGER field host_components metric yarn usual take minut see metric updat repeat repeat,0,0,0,0,0,ambari-server/src/main/resources/stacks/HDP/1.3.2/services/GANGLIA/package/files/rrd.py;ambari-server/src/main/resources/stacks/HDP/2.0.6/services/GANGLIA/package/files/rrd.py;,0 
5612,Oleg Nechiporenko,ambari-web,0,Unit tests for object_utils  date  ui_effects  updater, unit test object_utils date ui_effects updat,Create unit tests for following files: utils/object.js utils/date_utils.js utils/ui_effects_utils.js utils/updater.js, creat unit test follow file file util object js util object js util date_utils js util date_utils js util ui_effects_utils js util ui_effects_utils js util updat js util updat js,0,0,0,0,0,0,0 
5622,Myroslav Papirkovskyy,ambari-server,0,'Upgrading schema' failed during upgrading to 1.6.0, upgrad upgrad schema schema fail upgrad,Postgres issue:new restart_required relies on eclipselink default type converters  we avoided this in pastorg.postgresql.util.PSQLException: ERROR: column 'restart_required' is of type boolean but expression is of type integer Hint: You will need to rewrite or cast the expression. Position: 57 at org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2161) at org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:1890) at org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:255) at org.postgresql.jdbc2.AbstractJdbc2Statement.execute(AbstractJdbc2Statement.java:559) at org.postgresql.jdbc2.AbstractJdbc2Statement.executeWithFlags(AbstractJdbc2Statement.java:403) at org.postgresql.jdbc2.AbstractJdbc2Statement.executeUpdate(AbstractJdbc2Statement.java:331) at org.apache.ambari.server.orm.DBAccessorImpl.updateTable(DBAccessorImpl.java:447) at org.apache.ambari.server.orm.DBAccessorImpl.addColumn(DBAccessorImpl.java:371) at org.apache.ambari.server.upgrade.UpgradeCatalog160.executeDDLUpdates(UpgradeCatalog160.java:72) at org.apache.ambari.server.upgrade.AbstractUpgradeCatalog.upgradeSchema(AbstractUpgradeCatalog.java:177) at org.apache.ambari.server.upgrade.SchemaUpgradeHelper.executeUpgrade(SchemaUpgradeHelper.java:176) at org.apache.ambari.server.upgrade.SchemaUpgradeHelper.main(SchemaUpgradeHelper.java:225)MySQL issue:Inreresting MySQL feature  there should be no space between function name and parenthesis18:57:00 629 WARN [main] DBAccessorImpl:469 - Error executing query: insert into request(request_id  cluster_id  request_context  start_time  end_time  create_time) select distinct s.request_id  s.cluster_id  s.request_context  coalesce (cmd.start_time  -1)  coalesce (cmd.end_time  -1)  -1 from (select distinct request_id  cluster_id  request_context from stage ) s left join (select request_id  min(start_time) as start_time  max(end_time) as end_time from host_role_command group by request_id) cmd on s.request_id=cmd.request_idcom.mysql.jdbc.exceptions.jdbc4.MySQLSyntaxErrorException: FUNCTION ambari.coalesce does not exist at sun.reflect.GeneratedConstructorAccessor14.newInstance(Unknown Source) at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45) at java.lang.reflect.Constructor.newInstance(Constructor.java:526) at com.mysql.jdbc.Util.handleNewInstance(Util.java:411) at com.mysql.jdbc.Util.getInstance(Util.java:386) at com.mysql.jdbc.SQLError.createSQLException(SQLError.java:1054) at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:4237) at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:4169) at com.mysql.jdbc.MysqlIO.sendCommand(MysqlIO.java:2617) at com.mysql.jdbc.MysqlIO.sqlQueryDirect(MysqlIO.java:2778) at com.mysql.jdbc.ConnectionImpl.execSQL(ConnectionImpl.java:2828) at com.mysql.jdbc.ConnectionImpl.execSQL(ConnectionImpl.java:2777) at com.mysql.jdbc.StatementImpl.execute(StatementImpl.java:949) at com.mysql.jdbc.StatementImpl.execute(StatementImpl.java:795) at org.apache.ambari.server.orm.DBAccessorImpl.executeQuery(DBAccessorImpl.java:466) at org.apache.ambari.server.orm.DBAccessorImpl.executeQuery(DBAccessorImpl.java:452) at org.apache.ambari.server.upgrade.UpgradeCatalog150.executeDDLUpdates(UpgradeCatalog150.java:325) at org.apache.ambari.server.upgrade.AbstractUpgradeCatalog.upgradeSchema(AbstractUpgradeCatalog.java:177) at org.apache.ambari.server.upgrade.SchemaUpgradeHelper.executeUpgrade(SchemaUpgradeHelper.java:176) at org.apache.ambari.server.upgrade.SchemaUpgradeHelper.main(SchemaUpgradeHelper.java:225), postgr issu new issu new restart_required reli eclipselink default type convert avoid pastorg postgresql util PSQLException pastorg postgresql util PSQL except ERROR ERROR column restart_required restart_required type boolean express type integ hint hint need rewrit cast express express posit posit org postgresql core QueryExecutorImpl receiveErrorResponse QueryExecutorImpl java org postgresql core queri executor impl receiv error respons queri executor impl java org postgresql core QueryExecutorImpl processResults QueryExecutorImpl java org postgresql core queri executor impl process result queri executor impl java org postgresql core QueryExecutorImpl execut QueryExecutorImpl java org postgresql core queri executor impl execut queri executor impl java org postgresql jdbc AbstractJdbc statement execut AbstractJdbc statement java org postgresql jdbc abstract jdbc statement execut abstract jdbc statement java org postgresql jdbc AbstractJdbc statement executeWithFlags AbstractJdbc statement java org postgresql jdbc abstract jdbc statement execut flag abstract jdbc statement java org postgresql jdbc AbstractJdbc statement executeUpdate AbstractJdbc statement java org postgresql jdbc abstract jdbc statement execut updat abstract jdbc statement java org apach ambari server orm DBAccessorImpl updateTable DBAccessorImpl java org apach ambari server orm DB accessor impl updat tabl DB accessor impl java org apach ambari server orm DBAccessorImpl addColumn DBAccessorImpl java org apach ambari server orm DB accessor impl add column DB accessor impl java org apach ambari server upgrad UpgradeCatalog executeDDLUpdates UpgradeCatalog java org apach ambari server upgrad upgrad catalog execut DDL updat upgrad catalog java org apach ambari server upgrad AbstractUpgradeCatalog upgradeSchema AbstractUpgradeCatalog java org apach ambari server upgrad abstract upgrad catalog upgrad schema abstract upgrad catalog java org apach ambari server upgrad SchemaUpgradeHelper executeUpgrade SchemaUpgradeHelper java org apach ambari server upgrad schema upgrad helper execut upgrad schema upgrad helper java org apach ambari server upgrad SchemaUpgradeHelper main SchemaUpgradeHelper java MySQL org apach ambari server upgrad schema upgrad helper main schema upgrad helper java SQL issu inrerest issu inrerest MySQL SQL featur no space function name parenthesi parenthesi WARN main main DBAccessorImpl DB accessor impl error execut queri queri insert request request_id request request_id cluster_id request_context start_time end_time create_time create_time select distinct request_id request_id cluster_id cluster_id request_context request_context coalesc cmd start_time cmd start_time coalesc cmd end_time cmd end_time select distinct request_id cluster_id request_context stage left join select request_id min start_time min start_time start_time max end_time max end_time end_time host_role_command group request_id request_id cmd request_id cmd request_idcom mysql jdbc except jdbc MySQLSyntaxErrorException request_id cmd request_idcom mysql jdbc except jdbc SQL syntax error except FUNCTION ambari coalesc ambari coalesc not exist sun reflect GeneratedConstructorAccessor newInstance unknown sun reflect gener constructor accessor new instanc unknown sourc sourc sun reflect DelegatingConstructorAccessorImpl newInstance DelegatingConstructorAccessorImpl java sun reflect deleg constructor accessor impl new instanc deleg constructor accessor impl java java lang reflect constructor newInstance constructor java java lang reflect constructor new instanc constructor java com mysql jdbc util handleNewInstance util java com mysql jdbc util handl new instanc util java com mysql jdbc util getInstance util java com mysql jdbc util get instanc util java com mysql jdbc SQLError createSQLException SQLError java com mysql jdbc SQL error creat SQL except SQL error java com mysql jdbc MysqlIO checkErrorPacket MysqlIO java com mysql jdbc mysql IO check error packet mysql IO java com mysql jdbc MysqlIO checkErrorPacket MysqlIO java com mysql jdbc mysql IO check error packet mysql IO java com mysql jdbc MysqlIO sendCommand MysqlIO java com mysql jdbc mysql IO send command mysql IO java com mysql jdbc MysqlIO sqlQueryDirect MysqlIO java com mysql jdbc mysql IO sql queri direct mysql IO java com mysql jdbc ConnectionImpl execSQL ConnectionImpl java com mysql jdbc connect impl exec SQL connect impl java com mysql jdbc ConnectionImpl execSQL ConnectionImpl java com mysql jdbc connect impl exec SQL connect impl java com mysql jdbc StatementImpl execut StatementImpl java com mysql jdbc statement impl execut statement impl java com mysql jdbc StatementImpl execut StatementImpl java com mysql jdbc statement impl execut statement impl java org apach ambari server orm DBAccessorImpl executeQuery DBAccessorImpl java org apach ambari server orm DB accessor impl execut queri DB accessor impl java org apach ambari server orm DBAccessorImpl executeQuery DBAccessorImpl java org apach ambari server orm DB accessor impl execut queri DB accessor impl java org apach ambari server upgrad UpgradeCatalog executeDDLUpdates UpgradeCatalog java org apach ambari server upgrad upgrad catalog execut DDL updat upgrad catalog java org apach ambari server upgrad AbstractUpgradeCatalog upgradeSchema AbstractUpgradeCatalog java org apach ambari server upgrad abstract upgrad catalog upgrad schema abstract upgrad catalog java org apach ambari server upgrad SchemaUpgradeHelper executeUpgrade SchemaUpgradeHelper java org apach ambari server upgrad schema upgrad helper execut upgrad schema upgrad helper java org apach ambari server upgrad SchemaUpgradeHelper main SchemaUpgradeHelper java org apach ambari server upgrad schema upgrad helper main schema upgrad helper java,0,0,0,0,0,0,0 
5628,Srimanth Gunturi,ambari-web,0,Explicitly disabling datanucleus l2 cache for hive, explicitli disabl datanucleu cach hive,Ambari installations of hive currently do not set any datanucleus related properties. There is such a thing as a datanucleus l2 cache  that is pretty bad for hive in a distributed environment if it is set. (If there is a lone embedded hive instance  with no other codepaths to the db  then it's fine  but that never happens in a distributed environment.)By default  if no setting is present  datanucleus defaults the l2 cache to being on  so hive ups the ante by defaulting to turning it off by default if no other setting is configured.Now  in a war of 'defaults'  the hive default should win  but this is an area where we have had recurring support issues from clients that turn it on expecting improved performance. Thus  I'd like ambari installed hive-site.xml to explicitly have this config parameter turned off  with a comment asking users to not switch it on as it impacts hive negatively.The parameter in question is 'datanucleus.cache.level2.type'   and it's value should be 'none'. (Note that I've seen some older configs that seem to do things like turning datanucleus.cache.level2 = false and stuff like that  that is bogus config and does nothing and should not be assumed to be a catch-all enabler.)As a comment  I'd like the following comment 'Disables datanucleus l2 cache. This must be set to 'none' for hive to work properly' or something to that effect., ambari instal hive current not set datanucleu relat properti properti thing datanucleu cach pretti bad hive distribut environ set set lone embed hive instanc no codepath db fine never happen distribut environ environ default no set present datanucleu default cach hive up ant default turn default no set configur configur war default default hive default win area recur support issu client turn expect improv perform perform thu like ambari instal hive site xml hive site xml explicitli config paramet turn comment ask user not switch impact hive neg neg paramet question datanucleu cach level type datanucleu cach level type valu none none note note seen older config seem thing like turn datanucleu cach level datanucleu cach level fals stuff like bogu config noth not assum catch catch enabl enabl comment like follow comment disabl disabl datanucleu cach cach must set none none hive work properli properli someth effect effect,0,0,0,0,0,0,0 
5633,Dmitry Lysnichenko,ambari-agent,0,Start Services command gets stuck for about 30 mins, start servic command get stuck min,On Security wizard Start Services command ZOOKEEPER_SERVER Start task scheduled on ambari-server host remained in QUEUED status for about 30 mins and other non-completed commands were in PENDING status. For this time interval no command was in IN_PROGRESS status.Later executing stop all services command on the same cluster also made ZOOKEEPER_SERVER Stop task scheduled on ambari-server host to remain in QUEUED status for around 20 mins., secur wizard start servic command ZOOKEEPER_SERVER ZOOKEEPER SERVER start task schedul ambari server ambari server host remain QUEUED statu min non complet non complet command PENDING statu statu time interv no command IN_PROGRESS PROGRESS statu later statu later execut stop servic command cluster also made ZOOKEEPER_SERVER ZOOKEEPER SERVER stop task schedul ambari server ambari server host remain QUEUED statu around min min,0,0,0,0,0,0,0 
5643,Jaimin D Jetly,ambari-web,0,Add Services is disabled after upgrading the stack from HDP-2.0 to HDP-2.1, add servic disabl upgrad stack HDP HDP HDP HDP,Prior to upgrade  launch Add Services wizard using Ambari 1.5.0 (crucial step) Upgrade stack to a stack with new services and Ambari to 1.5.1 Add Services button is disabled  even though there are services that have not been added to the cluster, prior upgrad launch add servic wizard use ambari crucial step step upgrad stack stack new servic ambari add servic button disabl even though servic not ad cluster,0,0,0,0,0,0,0 
5646,Srimanth Gunturi,ambari-web,0,Jobs dont show up as links for a moment when page is visited, job dont show link moment page visit,I had a couple of finished jobs showing the jobs page. Then I clicked on one job and went back to the jobs page. For a moment both jobs were not shown as links - though they are clickable. This is basically an appearance issue where the job doesnt look like a link for a moment., coupl finish job show job page page click one job went back job page page moment job not shown link though clickabl clickabl basic appear issu job doesnt look like link moment moment,0,0,0,0,0,0,0 
5656,Xi Wang,ambari-web,0,Views: do not let the user click on the Views icon in the top nav, view view not let user click view icon top nav,When clicking on the Views icon in the top nav  the page content turns blank.We will show a view index page in a later release  but for now  let's just disable clicking on that icon., click view icon top nav page content turn blank blank show view index page later releas let let disabl click icon icon,0,0,0,0,0,0,0 
5668,Aleksandr Kovalenko,ambari-web,0,JobsDiagnostic|2.1.1: No job status and end time is shown for interrupted job, JobsDiagnostic job diagnost No job statu end time shown interrupt job,Enabled tez engine for hive;Executed select query;If while job is running I stop it by double pressign CTRL-C in hive shell then job will not have end time shown in jobs table and no failed icon (red X)  but in job details it will have status 'killed' and correct end time.If job is killed with yarn application -kill it will have correct end time and failed icon displayed in jobs table  but in job details it will not have neither status nor end time., enabl tez engin hive execut hive execut select queri queri job run stop doubl pressign CTRL CTRL hive shell job not end time shown job tabl no fail icon red job detail statu kill kill correct end time time job kill yarn applic kill correct end time fail icon display job tabl job detail not neither statu nor end time time,0,0,0,0,0,0,0 
5669,Xi Wang,ambari-web,0,Alternatives issues has error message (missing translation), altern issu error messag miss translat translat,Build 1.6.0-151Missing translation: installer.step3.hostWarningsPopup.alternatives.emptyinstaller.step3.hostWarningsPopup.alternatives.empty, build miss miss translat translat instal step hostWarningsPopup altern emptyinstal step hostWarningsPopup altern empti instal step host warn popup altern emptyinstal step host warn popup altern empti,0,0,0,0,0,0,0 
5688,Dmytro Sen,null,0,Zookeeper smoke test failed after being triggered after deleting a host  containing ZookeeperServer, zookeep smoke test fail trigger delet host contain ZookeeperServer zookeep server,1. Stopped all host components on a host ( to be deleted) with ZookeeperServer. 2. Deleted a host from cluster. 3. Ran Zookeeper Service Check.Actual result: failed. Expected: ok., stop host compon host delet delet ZookeeperServer zookeep server delet host cluster cluster ran zookeep servic check actual check actual result result fail fail expect expect ok ok,0,0,0,0,0,ambari-server/src/main/java/org/apache/ambari/server/api/services/AmbariMetaInfo.java;ambari-server/src/main/java/org/apache/ambari/server/api/util/StackExtensionHelper.java;ambari-server/src/main/java/org/apache/ambari/server/controller/AmbariManagementControllerImpl.java;ambari-server/src/main/java/org/apache/ambari/server/state/ServiceInfo.java;ambari-server/src/main/resources/stacks/HDP/1.3.2/services/ZOOKEEPER/metainfo.xml;ambari-server/src/main/resources/stacks/HDP/2.0.6/services/ZOOKEEPER/metainfo.xml;ambari-server/src/test/java/org/apache/ambari/server/api/services/AmbariMetaInfoTest.java;ambari-server/src/test/java/org/apache/ambari/server/api/util/StackExtensionHelperTest.java;ambari-server/src/test/java/org/apache/ambari/server/controller/AmbariManagementControllerTest.java;ambari-server/src/test/resources/stacks/HDP/2.0.7/services/ZOOKEEPER/metainfo.xml;,0 
5692,Oleg Nechiporenko,ambari-web,0,Unit tests for utils/config.js part 1, unit test util config js util config js part,Update unit tests for utils/config.js., updat unit test util config js util config js,0,0,0,0,0,0,0 
5714,Xi Wang,ambari-web,0,Views list not loading in Ambari Web, view list not load ambari web,In build 1.6.0-159  the views call is being made but it's not listing the views in the dropdown.This was due to the API change and Ambari Web hasn't adjusted yet to this introduction of /versions/., build view call made not list view dropdown dropdown due API chang ambari web adjust yet introduct version version,0,0,0,0,0,0,0 
5716,Jaimin D Jetly,ambari-web,0,Disable security fails occasionally, disabl secur fail occasion,There is a possibility that 'Start all Services' command will fail on Disable Security wizard if App.Service DS model was not populated on the load of 'Disable security page' (timing issue). We need to make sure that the Service model has populated before the 'Disable Security page' is rendered., possibl start start servic servic command fail disabl secur wizard app servic app servic DS model not popul load disabl disabl secur page page time issu issu need make sure servic model popul disabl disabl secur page page render render,0,0,0,0,0,0,0 
5720,Jonathan Hurley,null,0,pig.properties should set pig.location.check.strict to false, pig properti pig properti set pig locat check strict pig locat check strict fals,pig.properties should set pig.location.check.strict to false, pig properti pig properti set pig locat check strict pig locat check strict fals,0,0,0,0,0,0,0 
5722,Jonathan Hurley,null,0,All Services Fail To Deploy Due To Agent Parsing Exception, servic fail deploy due agent pars except,When deploying a brand new cluster  all services fail to install due to a parsing exception thrown from the Ambari Agents.File '/usr/lib/python2.6/site-packages/ambari_agent/CustomServiceOrchestrator.py'  line 113  in runCommandjson_path = self.dump_command_to_json(command)File '/usr/lib/python2.6/site-packages/ambari_agent/CustomServiceOrchestrator.py'  line 209  in dump_command_to_jsoncommand'clusterHostInfo' = manifestGenerator.decompressClusterHostInfo(command'clusterHostInfo')File '/usr/lib/python2.6/site-packages/ambari_agent/manifestGenerator.py'  line 116  in decompressClusterHostInfoindexes = convertRangeToList(v)File '/usr/lib/python2.6/site-packages/ambari_agent/manifestGenerator.py'  line 57  in convertRangeToListraise AgentException.AgentException('Broken data in given range  expected - ''m-n'' or ''m''  got : ' + str(r))AgentException: 'Broken data in given range  expected - m-n or m  got : -1he command being sent is{hs_host=[2]  namenode_host=[1]  snamenode_host=[2]  zookeeper_hosts=[0-2]  ganglia_server_host=[1]  nm_hosts=[0]  ganglia_monitor_hosts=[0-2]  all_hosts=[c6403.ambari.apache.org  c6401.ambari.apache.org  c6402.ambari.apache.org]  rm_host=[2]  app_timeline_server_hosts=[2]  slave_hosts=[0]  ambari_server_host=[-1]  nagios_server_host=[1]  all_ping_ports=[8670:0-2]}Notice the ambari-server-host which was added in that commit; it value is 1which would not parse correctly in manifestGenerator.pyI suspect Git e667dc7c9870864ff537374c819b7c1d1dd88e98 caused this problem.Steps to reproduce:1) Provision 3 c64 hosts2) Wipe your server database and re-create it with the embedded PSQL script3) Attempt to provision a cluster with various services.All services will fail to deploy b/c of the above exception. This was working without issues before the above suspect commit., deploy brand new cluster servic fail instal due pars except thrown ambari agent file agent file usr lib python site packag ambari_agent CustomServiceOrchestrator py usr lib python site packag ambari_agent custom servic orchestr py line runCommandjson_path run Commandjson_path self dump_command_to_json command file self dump_command_to_json command file usr lib python site packag ambari_agent CustomServiceOrchestrator py usr lib python site packag ambari_agent custom servic orchestr py line dump_command_to_jsoncommand clusterHostInfo dump_command_to_jsoncommand cluster host info manifestGenerator decompressClusterHostInfo command clusterHostInfo file manifest gener decompress cluster host info command cluster host info file usr lib python site packag ambari_agent manifestGenerator py usr lib python site packag ambari_agent manifest gener py line decompressClusterHostInfoindexes decompress cluster host infoindex convertRangeToList file convert rang list file usr lib python site packag ambari_agent manifestGenerator py usr lib python site packag ambari_agent manifest gener py line convertRangeToListraise convert rang listrais AgentException AgentException broken agent except agent except broken data given rang expect got str AgentException str agent except broken broken data given rang expect got command sent hs_host hs_host namenode_host namenode_host snamenode_host snamenode_host zookeeper_hosts zookeeper_hosts ganglia_server_host ganglia_server_host nm_hosts nm_hosts ganglia_monitor_hosts ganglia_monitor_hosts all_hosts ambari apach org all_hosts ambari apach org ambari apach org ambari apach org ambari apach org ambari apach org rm_host rm_host app_timeline_server_hosts app_timeline_server_hosts slave_hosts slave_hosts ambari_server_host ambari_server_host nagios_server_host nagios_server_host all_ping_ports notic all_ping_ports notic ambari server host ambari server host ad commit commit valu would not pars correctli manifestGenerator pyI manifest gener py suspect git dc ff dd dc ff dd caus problem step problem step reproduc reproduc provis host host wipe server databas creat creat embed PSQL script script attempt provis cluster variou servic servic servic fail deploy except except work without issu suspect commit commit,0,0,0,0,0,0,0 
5726,Jaimin D Jetly,ambari-web,0,Adding Oozie failed at service check, ad oozi fail servic check,This happens because HDFS and YARN/MapReduce requires to be restarted for Oozie smoke test to pass successfullyAs a fix to this issue: Don't run smoke test on 'Install  Start and Test' page of the add service wizard. Review page should ask user to restart all stale services., happen HDFS YARN MapReduce YARN map reduc requir restart oozi smoke test pass successfullyAs success fix issu issu run smoke test instal instal start test test page add servic wizard wizard review page ask user restart stale servic servic,0,0,0,0,0,0,0 
5730,Vitaly Brodetskyi,ambari-agent,0,Space Error in container-executor.cfg, space error contain executor cfg contain executor cfg,There is a space between 'banned.user' and '=' which make configuration here is ignored by container-executor  so some default banned users works to include hdfs. Space should be deleted between 'banned.user' and '='yarn.nodemanager.local-dirs=/grid/0/hadoop/yarn/local /grid/1/hadoop/yarn/localyarn.nodemanager.log-dirs=/grid/0/hadoop/yarn/log /grid/1/hadoop/yarn/logyarn.nodemanager.linux-container-executor.group=hadoopbanned.users = hdfs yarn mapred binmin.user.id=1000It should be banned.users=hdfs yarn mapred bin, space ban user ban user make configur ignor contain executor contain executor default ban user work includ hdf hdf space delet ban user ban user yarn nodemanag local dir grid hadoop yarn local yarn nodemanag local dir grid hadoop yarn local grid hadoop yarn localyarn nodemanag log dir grid hadoop yarn log grid hadoop yarn localyarn nodemanag log dir grid hadoop yarn log grid hadoop yarn logyarn nodemanag linux contain executor group hadoopban user grid hadoop yarn logyarn nodemanag linux contain executor group hadoopban user hdf yarn mapr binmin user id binmin user id ban user hdf ban user hdf yarn mapr bin,0,0,0,0,0,0,0 
5735,Dmitry Lysnichenko,ambari-server,0,HDP deployment failed in CentOS5, HDP deploy fail CentOS cent OS,Fail: Execution of 'mkdir -p /tmp/HDP-artifacts/ ; curl --noproxy hadoop -kf --retry 10 http://hadoop:8080/resources//jdk-7u45-linux-x64.tar.gz -o /tmp/HDP-artifacts//jdk-7u45-linux-x64.tar.gz' returned 2. curl: option --noproxy: is unknownversion of curl that is available at Centos 5 and SLES 11 SP1 seems to have no support for '--noproxy' option.But such workaround works:no_proxy=i.ua curl http://www.i.ua -iI'm going to replace all '--noproxy' invocations with usage of $no_proxy env variable., fail fail execut mkdir tmp HDP artifact tmp HDP artifact curl noproxi hadoop kf retri tmp HDP artifact jdk linux tar gz tmp HDP artifact jdk linux tar gz return curl curl option noproxi noproxi unknownvers curl avail cento SLES SP SP seem no support noproxi noproxi option option workaround work no_proxy ua work no_proxy ua curl iI go replac noproxi noproxi invoc usag no_proxy env variabl variabl,0,0,0,0,0,0,0 
5739,Jaimin D Jetly,ambari-web,0,File View Cleanup, file view cleanup,A few items that need to be rectified for the File view submission:1. Modify code to abide by Ambari Coding Standards2. JavaDoc Interfaces and Methods.https://cwiki.apache.org/confluence/display/AMBARI/Coding+Guidelines+for+Ambari., item need rectifi file view submiss submiss modifi code abid ambari code standard standard JavaDoc java doc interfac method http cwiki apach org confluenc display AMBARI code guidelin ambari method http cwiki apach org confluenc display AMBARI code guidelin ambari,0,0,0,0,0,0,0 
5751,Myroslav Papirkovskyy,ambari-server,0,Ambari upgrade to Ambari-1.6.0 from Ambari-1.5.1 logs PSQLException, ambari upgrad ambari ambari ambari ambari log PSQLException PSQL except,Following upgrade documentation at http://docs.hortonworks.com/HDPDocuments/Ambari-1.5.1.0/bk_upgrading_Ambari/content/ambari-chap7_2x.html On executing ambari-server upgrade  PSQLException is logged inambari-server.log:21:36:20 498 INFO [main] SchemaUpgradeHelper:211 - Upgrading schema to target version = 1.6.021:36:20 528 INFO [main] SchemaUpgradeHelper:220 - Upgrading schema from source version = 1.5.1.11021:36:20 530 INFO [main] SchemaUpgradeHelper:141 - Upgrade path: [{ org.apache.ambari.server.upgrade.UpgradeCatalog160$$EnhancerByGuice$$ff8a4f66: sourceVersion = null  targetVersion = 1.6.0 }]21:36:20 530 INFO [main] SchemaUpgradeHelper:171 - Executing DDL upgrade...21:36:20 533 INFO [main] DBAccessorImpl:463 - Executing query: ALTER SCHEMA ambari OWNER TO 'ambari';21:36:20 534 INFO [main] DBAccessorImpl:463 - Executing query: ALTER ROLE 'ambari' SET search_path to 'ambari';21:36:20 598 INFO [main] DBAccessorImpl:463 - Executing query: CREATE TABLE hostgroup_configuration (blueprint_name VARCHAR(255) NOT NULL  hostgroup_name VARCHAR(255) NOT NULL  type_name VARCHAR(255) NOT NULL  config_data BYTEA NOT NULL  PRIMARY KEY (blueprint_name  hostgroup_name  type_name))21:36:20 962 INFO [main] DBAccessorImpl:463 - Executing query: CREATE TABLE viewentity (id BIGINT NOT NULL  view_name VARCHAR(255) NOT NULL  view_instance_name VARCHAR(255) NOT NULL  class_name VARCHAR(255) NOT NULL  id_property VARCHAR(255)  PRIMARY KEY (id))21:36:21 010 INFO [main] DBAccessorImpl:463 - Executing query: ALTER TABLE hostcomponentdesiredstate ADD restart_required BOOLEAN21:36:21 078 INFO [main] DBAccessorImpl:463 - Executing query: ALTER TABLE hostgroup_configuration ADD CONSTRAINT FK_hg_config_blueprint_name FOREIGN KEY (blueprint_name) REFERENCES hostgroup (blueprint_name)21:36:21 084 WARN [main] DBAccessorImpl:469 - Error executing query: ALTER TABLE hostgroup_configuration ADD CONSTRAINT FK_hg_config_blueprint_name FOREIGN KEY (blueprint_name) REFERENCES hostgroup (blueprint_name)org.postgresql.util.PSQLException: ERROR: there is no unique constraint matching given keys for referenced table 'hostgroup' at org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2161) at org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:1890) at org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:255) at org.postgresql.jdbc2.AbstractJdbc2Statement.execute(AbstractJdbc2Statement.java:559) at org.postgresql.jdbc2.AbstractJdbc2Statement.executeWithFlags(AbstractJdbc2Statement.java:403) at org.postgresql.jdbc2.AbstractJdbc2Statement.execute(AbstractJdbc2Statement.java:395) at org.apache.ambari.server.orm.DBAccessorImpl.executeQuery(DBAccessorImpl.java:466) at org.apache.ambari.server.orm.DBAccessorImpl.executeQuery(DBAccessorImpl.java:452) at org.apache.ambari.server.orm.DBAccessorImpl.addFKConstraint(DBAccessorImpl.java:337) at org.apache.ambari.server.orm.DBAccessorImpl.addFKConstraint(DBAccessorImpl.java:321) at org.apache.ambari.server.upgrade.UpgradeCatalog160.executeDDLUpdates(UpgradeCatalog160.java:85) at org.apache.ambari.server.upgrade.AbstractUpgradeCatalog.upgradeSchema(AbstractUpgradeCatalog.java:250) at org.apache.ambari.server.upgrade.SchemaUpgradeHelper.executeUpgrade(SchemaUpgradeHelper.java:176) at org.apache.ambari.server.upgrade.SchemaUpgradeHelper.main(SchemaUpgradeHelper.java:225)21:36:21 089 WARN [main] DBAccessorImpl:339 - Add FK constraint failed  constraintName = FK_hg_config_blueprint_name  tableName = hostgroup_configurationorg.postgresql.util.PSQLException: ERROR: there is no unique constraint matching given keys for referenced table 'hostgroup' at org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2161) at org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:1890) at org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:255) at org.postgresql.jdbc2.AbstractJdbc2Statement.execute(AbstractJdbc2Statement.java:559) at org.postgresql.jdbc2.AbstractJdbc2Statement.executeWithFlags(AbstractJdbc2Statement.java:403) at org.postgresql.jdbc2.AbstractJdbc2Statement.execute(AbstractJdbc2Statement.java:395) at org.apache.ambari.server.orm.DBAccessorImpl.executeQuery(DBAccessorImpl.java:466) at org.apache.ambari.server.orm.DBAccessorImpl.executeQuery(DBAccessorImpl.java:452) at org.apache.ambari.server.orm.DBAccessorImpl.addFKConstraint(DBAccessorImpl.java:337) at org.apache.ambari.server.orm.DBAccessorImpl.addFKConstraint(DBAccessorImpl.java:321) at org.apache.ambari.server.upgrade.UpgradeCatalog160.executeDDLUpdates(UpgradeCatalog160.java:85) at org.apache.ambari.server.upgrade.AbstractUpgradeCatalog.upgradeSchema(AbstractUpgradeCatalog.java:250) at org.apache.ambari.server.upgrade.SchemaUpgradeHelper.executeUpgrade(SchemaUpgradeHelper.java:176) at org.apache.ambari.server.upgrade.SchemaUpgradeHelper.main(SchemaUpgradeHelper.java:225), follow upgrad document execut ambari server ambari server upgrad PSQLException PSQL except log inambari server log inambari server log INFO main main SchemaUpgradeHelper schema upgrad helper upgrad schema target version INFO main main SchemaUpgradeHelper schema upgrad helper upgrad schema sourc version INFO main main SchemaUpgradeHelper schema upgrad helper upgrad path path org apach ambari server upgrad UpgradeCatalog EnhancerByGuice ff org apach ambari server upgrad upgrad catalog enhanc guic ff sourceVersion sourc version null targetVersion target version INFO main main SchemaUpgradeHelper schema upgrad helper execut DDL upgrad upgrad INFO main main DBAccessorImpl DB accessor impl execut queri queri ALTER SCHEMA ambari OWNER ambari ambari INFO main main DBAccessorImpl DB accessor impl execut queri queri ALTER ROLE ambari ambari SET search_path ambari ambari INFO main main DBAccessorImpl DB accessor impl execut queri queri CREATE TABLE hostgroup_configuration blueprint_name VARCHAR VARCHAR NOT NULL hostgroup_name VARCHAR VARCHAR NOT NULL type_name VARCHAR VARCHAR NOT NULL config_data BYTEA NOT NULL PRIMARY KEY blueprint_name hostgroup_name type_name type_name INFO main main DBAccessorImpl DB accessor impl execut queri queri CREATE TABLE viewent id BIGINT NOT NULL view_name VARCHAR VARCHAR NOT NULL view_instance_name VARCHAR VARCHAR NOT NULL class_name VARCHAR VARCHAR NOT NULL id_property VARCHAR VARCHAR PRIMARY KEY id id INFO main main DBAccessorImpl DB accessor impl execut queri queri ALTER TABLE hostcomponentdesiredst ADD restart_required BOOLEAN BOOLEAN INFO main main DBAccessorImpl DB accessor impl execut queri queri ALTER TABLE hostgroup_configuration ADD CONSTRAINT FK_hg_config_blueprint_name FOREIGN KEY blueprint_name blueprint_name REFERENCES hostgroup blueprint_name blueprint_name WARN main main DBAccessorImpl DB accessor impl error execut queri queri ALTER TABLE hostgroup_configuration ADD CONSTRAINT FK_hg_config_blueprint_name FOREIGN KEY blueprint_name blueprint_name REFERENCES hostgroup blueprint_name org postgresql util PSQLException blueprint_name org postgresql util PSQL except ERROR ERROR no uniqu constraint match given key referenc tabl hostgroup hostgroup org postgresql core QueryExecutorImpl receiveErrorResponse QueryExecutorImpl java org postgresql core queri executor impl receiv error respons queri executor impl java org postgresql core QueryExecutorImpl processResults QueryExecutorImpl java org postgresql core queri executor impl process result queri executor impl java org postgresql core QueryExecutorImpl execut QueryExecutorImpl java org postgresql core queri executor impl execut queri executor impl java org postgresql jdbc AbstractJdbc statement execut AbstractJdbc statement java org postgresql jdbc abstract jdbc statement execut abstract jdbc statement java org postgresql jdbc AbstractJdbc statement executeWithFlags AbstractJdbc statement java org postgresql jdbc abstract jdbc statement execut flag abstract jdbc statement java org postgresql jdbc AbstractJdbc statement execut AbstractJdbc statement java org postgresql jdbc abstract jdbc statement execut abstract jdbc statement java org apach ambari server orm DBAccessorImpl executeQuery DBAccessorImpl java org apach ambari server orm DB accessor impl execut queri DB accessor impl java org apach ambari server orm DBAccessorImpl executeQuery DBAccessorImpl java org apach ambari server orm DB accessor impl execut queri DB accessor impl java org apach ambari server orm DBAccessorImpl addFKConstraint DBAccessorImpl java org apach ambari server orm DB accessor impl add FK constraint DB accessor impl java org apach ambari server orm DBAccessorImpl addFKConstraint DBAccessorImpl java org apach ambari server orm DB accessor impl add FK constraint DB accessor impl java org apach ambari server upgrad UpgradeCatalog executeDDLUpdates UpgradeCatalog java org apach ambari server upgrad upgrad catalog execut DDL updat upgrad catalog java org apach ambari server upgrad AbstractUpgradeCatalog upgradeSchema AbstractUpgradeCatalog java org apach ambari server upgrad abstract upgrad catalog upgrad schema abstract upgrad catalog java org apach ambari server upgrad SchemaUpgradeHelper executeUpgrade SchemaUpgradeHelper java org apach ambari server upgrad schema upgrad helper execut upgrad schema upgrad helper java org apach ambari server upgrad SchemaUpgradeHelper main SchemaUpgradeHelper java org apach ambari server upgrad schema upgrad helper main schema upgrad helper java WARN main main DBAccessorImpl DB accessor impl add FK constraint fail constraintName constraint name FK_hg_config_blueprint_name tableName tabl name hostgroup_configurationorg postgresql util PSQLException hostgroup_configurationorg postgresql util PSQL except ERROR ERROR no uniqu constraint match given key referenc tabl hostgroup hostgroup org postgresql core QueryExecutorImpl receiveErrorResponse QueryExecutorImpl java org postgresql core queri executor impl receiv error respons queri executor impl java org postgresql core QueryExecutorImpl processResults QueryExecutorImpl java org postgresql core queri executor impl process result queri executor impl java org postgresql core QueryExecutorImpl execut QueryExecutorImpl java org postgresql core queri executor impl execut queri executor impl java org postgresql jdbc AbstractJdbc statement execut AbstractJdbc statement java org postgresql jdbc abstract jdbc statement execut abstract jdbc statement java org postgresql jdbc AbstractJdbc statement executeWithFlags AbstractJdbc statement java org postgresql jdbc abstract jdbc statement execut flag abstract jdbc statement java org postgresql jdbc AbstractJdbc statement execut AbstractJdbc statement java org postgresql jdbc abstract jdbc statement execut abstract jdbc statement java org apach ambari server orm DBAccessorImpl executeQuery DBAccessorImpl java org apach ambari server orm DB accessor impl execut queri DB accessor impl java org apach ambari server orm DBAccessorImpl executeQuery DBAccessorImpl java org apach ambari server orm DB accessor impl execut queri DB accessor impl java org apach ambari server orm DBAccessorImpl addFKConstraint DBAccessorImpl java org apach ambari server orm DB accessor impl add FK constraint DB accessor impl java org apach ambari server orm DBAccessorImpl addFKConstraint DBAccessorImpl java org apach ambari server orm DB accessor impl add FK constraint DB accessor impl java org apach ambari server upgrad UpgradeCatalog executeDDLUpdates UpgradeCatalog java org apach ambari server upgrad upgrad catalog execut DDL updat upgrad catalog java org apach ambari server upgrad AbstractUpgradeCatalog upgradeSchema AbstractUpgradeCatalog java org apach ambari server upgrad abstract upgrad catalog upgrad schema abstract upgrad catalog java org apach ambari server upgrad SchemaUpgradeHelper executeUpgrade SchemaUpgradeHelper java org apach ambari server upgrad schema upgrad helper execut upgrad schema upgrad helper java org apach ambari server upgrad SchemaUpgradeHelper main SchemaUpgradeHelper java org apach ambari server upgrad schema upgrad helper main schema upgrad helper java,0,0,0,0,0,0,0 
5753,Jaimin D Jetly,ambari-web,0,Storm fails to start after disabling security, storm fail start disabl secur,nimbus.childopts  ui.childopts and supervisor.childopts points to sasl configuration files after the security is disabled. web-ui should remove -Djava.security.auth.login.config parameter from these properties while disabling security., nimbu childopt nimbu childopt ui childopt ui childopt supervisor childopt supervisor childopt point sasl configur file secur disabl disabl web ui web ui remov djava secur auth login config djava secur auth login config paramet properti disabl secur secur,0,0,0,0,0,0,0 
5761,Myroslav Papirkovskyy,ambari-server,0,2000-node cluster testing: during install phase of cluster deployment  install tasks were stuck in PENDING state, node cluster test test instal phase cluster deploy instal task stuck PENDING state,ActionScheduler is stucked when adding tasks to ActionQueue on large clusters (&gt;1000 nodes), ActionScheduler action schedul stuck ad task ActionQueue action queue larg cluster gt gt node node,0,0,0,0,0,0,0 
5778,Myroslav Papirkovskyy,ambari-server,0,In some upgrade scenarios  Ambari Web's persist key-value store state causes the UI to act unpredictably, upgrad scenario ambari web web persist key valu key valu store state caus UI act unpredict,During Ambari upgrade  automatically clear the persist state to prevent potential issues with Ambari Web not working properly (this was observed a number of times on upgraded clusters). Currently  we make the following call to get out of the inconsistent state so that Ambari Web works properly:curl -i -u admin:admin -H 'X-Requested-By: ambari' -X POST -d '{ 'CLUSTER_CURRENT_STATUS': '{/'clusterState/':/'CLUSTER_STARTED_5/'}' }' http://localhost:8080/api/v1/persistWe need to do something equivalent during upgrade., ambari upgrad automat clear persist state prevent potenti issu ambari web not work properli observ number time upgrad cluster cluster current make follow call get inconsist state ambari web work properli curl properli curl admin admin admin admin request request ambari ambari POST CLUSTER_CURRENT_STATUS CLUSTER CURRENT STATUS clusterState CLUSTERSTARTED cluster state CLUSTER STARTED need someth equival upgrad upgrad,0,0,0,0,0,0,0 
5779,Myroslav Papirkovskyy,ambari-server,0,Recommission a DN fails when https is enabled in Ambari server, recommiss DN fail http enabl ambari server,After https is enable in Ambari server  Recommission a DN will fails with the following error message found in the Ambari-server log:WARN &#91;qtp1103265648-610&#93; nio:651 - javax.net.ssl.SSLException: Received fatal alert: certificate_unknown 00:32:05 458 INFO &#91;ExecutionScheduler_Worker-1&#93; JobRunShell:207 - Job LinearExecutionJobs.BatchRequestJob-2-1 threw a JobExecutionException: org.quartz.JobExecutionException: org.apache.ambari.server.AmbariException: Exception occurred while performing request &#91;See nested exception: org.apache.ambari.server.AmbariException: Exception occurred while performing request&#93; at org.apache.ambari.server.scheduler.AbstractLinearExecutionJob.execute(AbstractLinearExecutionJob.java:94) at org.quartz.core.JobRunShell.run(JobRunShell.java:202) at org.quartz.simpl.SimpleThreadPool$WorkerThread.run(SimpleThreadPool.java:573) Caused by: org.apache.ambari.server.AmbariException: Exception occurred while performing request at org.apache.ambari.server.scheduler.ExecutionScheduleManager.executeBatchRequest(ExecutionScheduleManager.java:479) at org.apache.ambari.server.state.scheduler.BatchRequestJob.doWork(BatchRequestJob.java:77) at org.apache.ambari.server.scheduler.AbstractLinearExecutionJob.execute(AbstractLinearExecutionJob.java:88) ... 2 more Caused by: com.sun.jersey.api.client.ClientHandlerException: javax.net.ssl.SSLHandshakeException: java.security.cert.CertificateException: No name matching localhost found at com.sun.jersey.client.urlconnection.URLConnectionClientHandler.handle(URLConnectionClientHandler.java:149) at com.sun.jersey.api.client.filter.CsrfProtectionFilter.handle(CsrfProtectionFilter.java:97) at org.apache.ambari.server.security.authorization.internal.InternalTokenClientFilter.handle(InternalTokenClientFilter.java:39) at com.sun.jersey.api.client.Client.handle(Client.java:648) at com.sun.jersey.api.client.WebResource.handle(WebResource.java:670) at com.sun.jersey.api.client.WebResource.method(WebResource.java:311) at org.apache.ambari.server.scheduler.ExecutionScheduleManager.performApiRequest(ExecutionScheduleManager.java:619) at org.apache.ambari.server.scheduler.ExecutionScheduleManager.executeBatchRequest(ExecutionScheduleManager.java:469) ... 4 more Caused by: javax.net.ssl.SSLHandshakeException: java.security.cert.CertificateException: No name matching localhost found at sun.security.ssl.Alerts.getSSLException(Alerts.java:192) at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1884) at sun.security.ssl.Handshaker.fatalSE(Handshaker.java:276) at sun.security.ssl.Handshaker.fatalSE(Handshaker.java:270) at sun.security.ssl.ClientHandshaker.serverCertificate(ClientHandshaker.java:1341) at sun.security.ssl.ClientHandshaker.processMessage(ClientHandshaker.java:153) at sun.security.ssl.Handshaker.processLoop(Handshaker.java:868) at sun.security.ssl.Handshaker.process_record(Handshaker.java:804) at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:1016) at sun.security.ssl.SSLSocketImpl.performInitialHandshake(SSLSocketImpl.java:1312) at sun.security.ssl.SSLSocketImpl.startHandshake(SSLSocketImpl.java:1339) at sun.security.ssl.SSLSocketImpl.startHandshake(SSLSocketImpl.java:1323) at sun.net.www.protocol.https.HttpsClient.afterConnect(HttpsClient.java:563) at sun.net.www.protocol.https.AbstractDelegateHttpsURLConnection.connect(AbstractDelegateHttpsURLConnection.java:185) at sun.net.www.protocol.http.HttpURLConnection.getOutputStream(HttpURLConnection.java:1091) at sun.net.www.protocol.https.HttpsURLConnectionImpl.getOutputStream(HttpsURLConnectionImpl.java:250), http enabl ambari server recommiss DN fail follow error messag found ambari server ambari server log WARN log WARN qtp qtp nio nio javax net ssl SSLException javax net ssl SSL except receiv fatal alert alert certificate_unknown INFO ExecutionScheduler_Worker execut schedul worker JobRunShell job run shell job LinearExecutionJobs BatchRequestJob linear execut job batch request job threw JobExecutionException job execut except org quartz JobExecutionException org quartz job execut except org apach ambari server AmbariException org apach ambari server ambari except except occur perform request see see nest except except org apach ambari server AmbariException org apach ambari server ambari except except occur perform request request org apach ambari server schedul AbstractLinearExecutionJob execut AbstractLinearExecutionJob java org apach ambari server schedul abstract linear execut job execut abstract linear execut job java org quartz core JobRunShell run JobRunShell java org quartz core job run shell run job run shell java org quartz simpl SimpleThreadPool WorkerThread run SimpleThreadPool java org quartz simpl simpl thread pool worker thread run simpl thread pool java caus org apach ambari server AmbariException org apach ambari server ambari except except occur perform request org apach ambari server schedul ExecutionScheduleManager executeBatchRequest ExecutionScheduleManager java org apach ambari server schedul execut schedul manag execut batch request execut schedul manag java org apach ambari server state schedul BatchRequestJob doWork BatchRequestJob java org apach ambari server state schedul batch request job work batch request job java org apach ambari server schedul AbstractLinearExecutionJob execut AbstractLinearExecutionJob java org apach ambari server schedul abstract linear execut job execut abstract linear execut job java caus com sun jersey api client ClientHandlerException com sun jersey api client client handler except javax net ssl SSLHandshakeException javax net ssl SSL handshak except java secur cert CertificateException java secur cert certif except No name match localhost found com sun jersey client urlconnect URLConnectionClientHandler handl URLConnectionClientHandler java com sun jersey client urlconnect URL connect client handler handl URL connect client handler java com sun jersey api client filter CsrfProtectionFilter handl CsrfProtectionFilter java com sun jersey api client filter csrf protect filter handl csrf protect filter java org apach ambari server secur author intern InternalTokenClientFilter handl InternalTokenClientFilter java org apach ambari server secur author intern intern token client filter handl intern token client filter java com sun jersey api client client handl client java com sun jersey api client client handl client java com sun jersey api client WebResource handl WebResource java com sun jersey api client web resourc handl web resourc java com sun jersey api client WebResource method WebResource java com sun jersey api client web resourc method web resourc java org apach ambari server schedul ExecutionScheduleManager performApiRequest ExecutionScheduleManager java org apach ambari server schedul execut schedul manag perform api request execut schedul manag java org apach ambari server schedul ExecutionScheduleManager executeBatchRequest ExecutionScheduleManager java org apach ambari server schedul execut schedul manag execut batch request execut schedul manag java caus javax net ssl SSLHandshakeException javax net ssl SSL handshak except java secur cert CertificateException java secur cert certif except No name match localhost found sun secur ssl alert getSSLException alert java sun secur ssl alert get SSL except alert java sun secur ssl SSLSocketImpl fatal SSLSocketImpl java sun secur ssl SSL socket impl fatal SSL socket impl java sun secur ssl handshak fatalSE handshak java sun secur ssl handshak fatal SE handshak java sun secur ssl handshak fatalSE handshak java sun secur ssl handshak fatal SE handshak java sun secur ssl ClientHandshaker serverCertificate ClientHandshaker java sun secur ssl client handshak server certif client handshak java sun secur ssl ClientHandshaker processMessage ClientHandshaker java sun secur ssl client handshak process messag client handshak java sun secur ssl handshak processLoop handshak java sun secur ssl handshak process loop handshak java sun secur ssl handshak process_record handshak java sun secur ssl handshak process_record handshak java sun secur ssl SSLSocketImpl readRecord SSLSocketImpl java sun secur ssl SSL socket impl read record SSL socket impl java sun secur ssl SSLSocketImpl performInitialHandshake SSLSocketImpl java sun secur ssl SSL socket impl perform initi handshak SSL socket impl java sun secur ssl SSLSocketImpl startHandshake SSLSocketImpl java sun secur ssl SSL socket impl start handshak SSL socket impl java sun secur ssl SSLSocketImpl startHandshake SSLSocketImpl java sun secur ssl SSL socket impl start handshak SSL socket impl java sun net www protocol http HttpsClient afterConnect HttpsClient java sun net www protocol http http client connect http client java sun net www protocol http AbstractDelegateHttpsURLConnection connect AbstractDelegateHttpsURLConnection java sun net www protocol http abstract deleg http URL connect connect abstract deleg http URL connect java sun net www protocol http HttpURLConnection getOutputStream HttpURLConnection java sun net www protocol http http URL connect get output stream http URL connect java sun net www protocol http HttpsURLConnectionImpl getOutputStream HttpsURLConnectionImpl java sun net www protocol http http URL connect impl get output stream http URL connect impl java,0,0,0,0,0,0,0 
5782,Jaimin D Jetly,ambari-web,0,View: Files UI clean-up and adjustments, view view file UI clean clean adjust,,,0,0,0,0,0,0,0 
5783,Siddharth Wagle,null,0,Pig fails to install through blueprint, pig fail instal blueprint,During installation through blueprint pig install fails with next exception:Traceback (most recent call last): File '/var/lib/ambari-agent/cache/stacks/HDP/2.0.6/services/PIG/package/scripts/pig_client.py'  line 41  in &lt;module&gt; PigClient().execute() File '/usr/lib/python2.6/site-packages/resource_management/libraries/script/script.py'  line 112  in execute method(env) File '/var/lib/ambari-agent/cache/stacks/HDP/2.0.6/services/PIG/package/scripts/pig_client.py'  line 30  in install self.configure(env) File '/var/lib/ambari-agent/cache/stacks/HDP/2.0.6/services/PIG/package/scripts/pig_client.py'  line 35  in configure pig() File '/var/lib/ambari-agent/cache/stacks/HDP/2.0.6/services/PIG/package/scripts/pig.py'  line 40  in pig properties=params.pig_properties) File '/usr/lib/python2.6/site-packages/resource_management/core/base.py'  line 148  in __init__ self.env.run() File '/usr/lib/python2.6/site-packages/resource_management/core/environment.py'  line 149  in run self.run_action(resource  action) File '/usr/lib/python2.6/site-packages/resource_management/core/environment.py'  line 115  in run_action provider_action() File '/usr/lib/python2.6/site-packages/resource_management/libraries/providers/properties_file.py'  line 48  in action_create mode = self.resource.mode File '/usr/lib/python2.6/site-packages/resource_management/core/base.py'  line 148  in __init__ self.env.run() File '/usr/lib/python2.6/site-packages/resource_management/core/environment.py'  line 149  in run self.run_action(resource  action) File '/usr/lib/python2.6/site-packages/resource_management/core/environment.py'  line 115  in run_action provider_action() File '/usr/lib/python2.6/site-packages/resource_management/core/providers/system.py'  line 96  in action_create content = self._get_content() File '/usr/lib/python2.6/site-packages/resource_management/core/providers/system.py'  line 136  in _get_content return content() File '/usr/lib/python2.6/site-packages/resource_management/core/source.py'  line 47  in __call__ return self.get_content() File '/usr/lib/python2.6/site-packages/resource_management/core/source.py'  line 126  in get_content rendered = self.template.render(self.context) File '/usr/lib/python2.6/site-packages/jinja2/environment.py'  line 891  in render return self.environment.handle_exception(exc_info  True) File '&lt;template&gt;'  line 2  in top-level template code File '/usr/lib/python2.6/site-packages/jinja2/filters.py'  line 176  in do_dictsort return sorted(value.items()  key=sort_func)AttributeError: 'unicode' object has no attribute 'items', instal blueprint pig instal fail next except traceback except traceback recent call last last file var lib ambari agent cach stack HDP servic PIG packag script pig_client py var lib ambari agent cach stack HDP servic PIG packag script pig_client py line lt modul gt lt modul gt PigClient execut pig client execut file usr lib python site packag resource_management librari script script py usr lib python site packag resource_management librari script script py line execut method env method env file var lib ambari agent cach stack HDP servic PIG packag script pig_client py var lib ambari agent cach stack HDP servic PIG packag script pig_client py line instal self configur env self configur env file var lib ambari agent cach stack HDP servic PIG packag script pig_client py var lib ambari agent cach stack HDP servic PIG packag script pig_client py line configur pig pig file var lib ambari agent cach stack HDP servic PIG packag script pig py var lib ambari agent cach stack HDP servic PIG packag script pig py line pig properti param pig_properties properti param pig_properties file usr lib python site packag resource_management core base py usr lib python site packag resource_management core base py line init self env run self env run file usr lib python site packag resource_management core environ py usr lib python site packag resource_management core environ py line run self run_action resourc self run_action resourc action action file usr lib python site packag resource_management core environ py usr lib python site packag resource_management core environ py line run_action provider_action provider_action file usr lib python site packag resource_management librari provid properties_file py usr lib python site packag resource_management librari provid properties_file py line action_create mode self resourc mode self resourc mode file usr lib python site packag resource_management core base py usr lib python site packag resource_management core base py line init self env run self env run file usr lib python site packag resource_management core environ py usr lib python site packag resource_management core environ py line run self run_action resourc self run_action resourc action action file usr lib python site packag resource_management core environ py usr lib python site packag resource_management core environ py line run_action provider_action provider_action file usr lib python site packag resource_management core provid system py usr lib python site packag resource_management core provid system py line action_create content self _get_content self _get_content file usr lib python site packag resource_management core provid system py usr lib python site packag resource_management core provid system py line _get_content return content content file usr lib python site packag resource_management core sourc py usr lib python site packag resource_management core sourc py line call return self get_content self get_content file usr lib python site packag resource_management core sourc py usr lib python site packag resource_management core sourc py line get_content render self templat render self context self templat render self context file usr lib python site packag jinja environ py usr lib python site packag jinja environ py line render return self environ handle_exception exc_info self environ handle_exception exc_info true true file lt templat gt lt templat gt line top level top level templat code file usr lib python site packag jinja filter py usr lib python site packag jinja filter py line do_dictsort return sort valu item sort valu item key sort_func AttributeError key sort_func attribut error unicod unicod object no attribut item item,0,0,0,0,0,0,0 
5855,Andrii Babiichuk,ambari-web,0,Global properties are not being surfaced on service config page, global properti not surfac servic config page,Post install  Global properties are not being surfaced on service config page., post instal global properti not surfac servic config page page,0,0,0,0,0,ambari-web/app/controllers/main/service/info/configs.js;,0 
5866,Oleg Nechiporenko,ambari-web,0,Populate actions drop down of Slider App details page, popul action drop slider app detail page,Slider App details page should have an actions dropdown with the following actions Freeze: show when status == RUNNING Thaw: show when status == FROZEN Flex: show when status != FINISHED Destroy: show when status == FROZENExcept for Thaw  all actions will show a confirmation dialog. Hitting OK will make the call. Destroy should call DELETE on the app endpoint Freeze and Thaw should call PUT on app endpoint app state being set to FROZEN or RUNNING., slider app detail page action dropdown follow action freez freez show statu RUNNING thaw thaw show statu FROZEN flex flex show statu FINISHED destroy destroy show statu FROZENExcept FROZEN except thaw action show confirm dialog dialog hit OK make call call destroy call DELETE app endpoint freez thaw call PUT app endpoint app state set FROZEN RUNNING RUNNING,0,0,0,0,0,0,1 
5886,Srimanth Gunturi,ambari-server,0,Implement app_types endpoint to provide app definitions, implement app_types endpoint provid app definit,Slider Apps View should provide /api/v1/app_types endpoint to provide definitions of various app_types supported by this Slider Apps View. Only apps in this type can be created through UI., slider app view provid api app_types api app_types endpoint provid definit variou app_types support slider app view view app type creat UI UI,0,0,0,0,0,0,1 
5894,Oleg Nechiporenko,ambari-web,0,New slider app wizard should show app-types from /apptypes endpoint, new slider app wizard show app type app type apptyp endpoint,Currently the new slider app wizard shows hardcoded app-types. We should instead show only those app-types which are returned by http://c6401:8080/api/v1/views/SLIDER/versions/1.0.0/instances/SLIDER_1/apptypes?fields=* endpoint.{ 'href' : 'http://c6401:8080/api/v1/views/SLIDER/versions/1.0.0/instances/SLIDER_1/apptypes?fields=*'  'items' : [ { 'href' : 'http://c6401:8080/api/v1/views/SLIDER/versions/1.0.0/instances/SLIDER_1/apptypes/ACCUMULO'  'id' : 'ACCUMULO'  'instance_name' : 'SLIDER_1'  'typeComponents' : [ { 'id' : 'ACCUMULO_MASTER'  'name' : 'ACCUMULO_MASTER'  'category' : 'MASTER'  'displayName' : 'ACCUMULO_MASTER'  'priority' : 1  'instanceCount' : 0  'maxInstanceCount' : 0  'yarnMemory' : 1024  'yarnCpuCores' : 1 }  { 'id' : 'ACCUMULO_MONITOR'  'name' : 'ACCUMULO_MONITOR'  'category' : 'MASTER'  'displayName' : 'ACCUMULO_MONITOR'  'priority' : 3  'instanceCount' : 0  'maxInstanceCount' : 0  'yarnMemory' : 1024  'yarnCpuCores' : 1 }  { 'id' : 'ACCUMULO_GC'  'name' : 'ACCUMULO_GC'  'category' : 'MASTER'  'displayName' : 'ACCUMULO_GC'  'priority' : 4  'instanceCount' : 0  'maxInstanceCount' : 0  'yarnMemory' : 1024  'yarnCpuCores' : 1 }  { 'id' : 'ACCUMULO_TRACER'  'name' : 'ACCUMULO_TRACER'  'category' : 'MASTER'  'displayName' : 'ACCUMULO_TRACER'  'priority' : 5  'instanceCount' : 0  'maxInstanceCount' : 0  'yarnMemory' : 1024  'yarnCpuCores' : 1 }  { 'id' : 'ACCUMULO_TSERVER'  'name' : 'ACCUMULO_TSERVER'  'category' : 'SLAVE'  'displayName' : 'ACCUMULO_TSERVER'  'priority' : 2  'instanceCount' : 0  'maxInstanceCount' : 0  'yarnMemory' : 1024  'yarnCpuCores' : 1 }  { 'id' : 'ACCUMULO_CLIENT'  'name' : 'ACCUMULO_CLIENT'  'category' : 'CLIENT'  'displayName' : 'ACCUMULO_CLIENT'  'priority' : 0  'instanceCount' : 0  'maxInstanceCount' : 0  'yarnMemory' : 1024  'yarnCpuCores' : 1 } ]  'typeDescription' : 'The Apache Accumulo sorted  distributed key/value store is a robust /n scalable  high performance data storage system that features cell-based/n access control and customizable server-side processing. It is based on/n Google's BigTable design and is built on top of Apache Hadoop /n Zookeeper  and Thrift./n Requirements:/n 1. Ensure parent dir for path (accumulo-site/instance.dfs.dir) is accessible to the App owner.'  'typeName' : 'ACCUMULO'  'typePackageFileName' : 'accumulo_v151.zip'  'typeVersion' : '1.5.1'  'version' : '1.0.0'  'view_name' : 'SLIDER'  'typeConfigs' : { 'agent.conf' : '/slider/agent/conf/agent.ini'  'application.def' : '/slider/accumulo_v151.zip'  'config_types' : 'accumulo-site'  'java_home' : '/usr/jdk64/jdk1.7.0_45'  'package_list' : 'files/accumulo-1.5.1-bin.tar.gz'  'site.accumulo-site.gc.port.client' : '0'  'site.accumulo-site.general.classpaths' : '$ACCUMULO_HOME/lib/accumulo-server.jar /n$ACCUMULO_HOME/lib/accumulo-core.jar /n$ACCUMULO_HOME/lib/accumulo-start.jar /n$ACCUMULO_HOME/lib/accumulo-fate.jar /n$ACCUMULO_HOME/lib/accumulo-proxy.jar /n$ACCUMULO_HOME/lib/[^.].*.jar /n$ZOOKEEPER_HOME/zookeeper[^.].*.jar /n$HADOOP_CONF_DIR /n$HADOOP_PREFIX/[^.].*.jar /n$HADOOP_PREFIX/lib/[^.].*.jar /n$HADOOP_PREFIX/share/hadoop/common/.*.jar /n$HADOOP_PREFIX/share/hadoop/common/lib/.*.jar /n$HADOOP_PREFIX/share/hadoop/hdfs/.*.jar /n$HADOOP_PREFIX/share/hadoop/mapreduce/.*.jar /n$HADOOP_PREFIX/share/hadoop/yarn/.*.jar /n/usr/lib/hadoop/.*.jar /n/usr/lib/hadoop/lib/.*.jar /n/usr/lib/hadoop-hdfs/.*.jar /n/usr/lib/hadoop-mapreduce/.*.jar /n/usr/lib/hadoop-yarn/.*.jar '  'site.accumulo-site.instance.dfs.dir' : '/apps/accumulo/data'  'site.accumulo-site.instance.secret' : 'DEFAULT'  'site.accumulo-site.instance.zookeeper.host' : '${ZK_HOST}'  'site.accumulo-site.master.port.client' : '0'  'site.accumulo-site.monitor.port.client' : '${ACCUMULO_MONITOR.ALLOCATED_PORT}'  'site.accumulo-site.monitor.port.log4j' : '0'  'site.accumulo-site.trace.port.client' : '0'  'site.accumulo-site.trace.token.property.password' : 'secret'  'site.accumulo-site.trace.user' : 'root'  'site.accumulo-site.tserver.cache.data.size' : '7M'  'site.accumulo-site.tserver.cache.index.size' : '20M'  'site.accumulo-site.tserver.memory.maps.max' : '80M'  'site.accumulo-site.tserver.port.client' : '0'  'site.accumulo-site.tserver.sort.buffer.size' : '50M'  'site.accumulo-site.tserver.walog.max.size' : '100M'  'site.global.accumulo_instance_name' : 'instancename'  'site.global.accumulo_root_password' : 'secret'  'site.global.app_install_dir' : '${AGENT_WORK_ROOT}/app/install'  'site.global.app_log_dir' : '${AGENT_LOG_ROOT}/app/log'  'site.global.app_pid_dir' : '${AGENT_WORK_ROOT}/app/run'  'site.global.app_root' : '${AGENT_WORK_ROOT}/app/install/accumulo-1.5.1'  'site.global.app_user' : 'yarn'  'site.global.gc_heapsize' : '64m'  'site.global.hadoop_conf_dir' : '/etc/hadoop/conf'  'site.global.hadoop_prefix' : '/usr/lib/hadoop'  'site.global.master_heapsize' : '128m'  'site.global.monitor_heapsize' : '64m'  'site.global.other_heapsize' : '128m'  'site.global.security_enabled' : 'false'  'site.global.tserver_heapsize' : '128m'  'site.global.user_group' : 'hadoop'  'site.global.zookeeper_home' : '/usr/lib/zookeeper' } }  { 'href' : 'http://c6401:8080/api/v1/views/SLIDER/versions/1.0.0/instances/SLIDER_1/apptypes/HBASE'  'id' : 'HBASE'  'instance_name' : 'SLIDER_1'  'typeComponents' : [ { 'id' : 'HBASE_MASTER'  'name' : 'HBASE_MASTER'  'category' : 'MASTER'  'displayName' : 'HBASE_MASTER'  'priority' : 1  'instanceCount' : 1  'maxInstanceCount' : 2  'yarnMemory' : 1024  'yarnCpuCores' : 1 }  { 'id' : 'HBASE_REGIONSERVER'  'name' : 'HBASE_REGIONSERVER'  'category' : 'SLAVE'  'displayName' : 'HBASE_REGIONSERVER'  'priority' : 2  'instanceCount' : 1  'maxInstanceCount' : 0  'yarnMemory' : 1024  'yarnCpuCores' : 1 }  { 'id' : 'HBASE_CLIENT'  'name' : 'HBASE_CLIENT'  'category' : 'CLIENT'  'displayName' : 'HBASE_CLIENT'  'priority' : 0  'instanceCount' : 0  'maxInstanceCount' : 0  'yarnMemory' : 1024  'yarnCpuCores' : 1 } ]  'typeDescription' : 'Apache HBase is the Hadoop database  a distributed  scalable  big data store./n Requirements:/n 1. Ensure parent dir for path (hbase-site/hbase.rootdir) is accessible to the App owner./n 2. Ensure ZK root (hbase-site/zookeeper.znode.parent) is unique for the App instance.'  'typeName' : 'HBASE'  'typePackageFileName' : 'hbase_v096 (1).zip'  'typeVersion' : '0.96.0.2.1.1'  'version' : '1.0.0'  'view_name' : 'SLIDER'  'typeConfigs' : { 'agent.conf' : '/slider/agent/conf/agent.ini'  'application.def' : '/slider/hbase_v096.zip'  'config_types' : 'core-site hdfs-site hbase-site'  'java_home' : '/usr/jdk64/jdk1.7.0_45'  'package_list' : 'files/hbase-0.96.1-hadoop2-bin.tar.gz'  'site.core-site.fs.defaultFS' : '${NN_URI}'  'site.global.app_install_dir' : '${AGENT_WORK_ROOT}/app/install'  'site.global.app_log_dir' : '${AGENT_LOG_ROOT}/app/log'  'site.global.app_pid_dir' : '${AGENT_WORK_ROOT}/app/run'  'site.global.app_root' : '${AGENT_WORK_ROOT}/app/install/hbase-0.96.1-hadoop2'  'site.global.app_user' : 'yarn'  'site.global.ganglia_server_host' : '${NN_HOST}'  'site.global.ganglia_server_id' : 'Application1'  'site.global.ganglia_server_port' : '8667'  'site.global.hbase_master_heapsize' : '1024m'  'site.global.hbase_regionserver_heapsize' : '1024m'  'site.global.security_enabled' : 'false'  'site.global.user_group' : 'hadoop'  'site.hbase-site.hbase.client.keyvalue.maxsize' : '10485760'  'site.hbase-site.hbase.client.scanner.caching' : '100'  'site.hbase-site.hbase.cluster.distributed' : 'true'  'site.hbase-site.hbase.defaults.for.version.skip' : 'true'  'site.hbase-site.hbase.hregion.majorcompaction' : '86400000'  'site.hbase-site.hbase.hregion.max.filesize' : '10737418240'  'site.hbase-site.hbase.hregion.memstore.block.multiplier' : '2'  'site.hbase-site.hbase.hregion.memstore.flush.size' : '134217728'  'site.hbase-site.hbase.hregion.memstore.mslab.enabled' : 'true'  'site.hbase-site.hbase.hstore.blockingStoreFiles' : '10'  'site.hbase-site.hbase.hstore.compactionThreshold' : '3'  'site.hbase-site.hbase.hstore.flush.retries.number' : '120'  'site.hbase-site.hbase.local.dir' : '${hbase.tmp.dir}/local'  'site.hbase-site.hbase.master.info.port' : '${HBASE_MASTER.ALLOCATED_PORT}'  'site.hbase-site.hbase.regionserver.global.memstore.lowerLimit' : '0.38'  'site.hbase-site.hbase.regionserver.global.memstore.upperLimit' : '0.4'  'site.hbase-site.hbase.regionserver.handler.count' : '60'  'site.hbase-site.hbase.regionserver.info.port' : '0'  'site.hbase-site.hbase.regionserver.port' : '0'  'site.hbase-site.hbase.rootdir' : '${NN_URI}/apps/hbase/data'  'site.hbase-site.hbase.security.authentication' : 'simple'  'site.hbase-site.hbase.security.authorization' : 'false'  'site.hbase-site.hbase.stagingdir' : '${NN_URI}/apps/hbase/staging'  'site.hbase-site.hbase.superuser' : 'yarn'  'site.hbase-site.hbase.tmp.dir' : '${AGENT_WORK_ROOT}/work/app/tmp'  'site.hbase-site.hbase.zookeeper.property.clientPort' : '2181'  'site.hbase-site.hbase.zookeeper.quorum' : '${ZK_HOST}'  'site.hbase-site.hbase.zookeeper.useMulti' : 'true'  'site.hbase-site.hfile.block.cache.size' : '0.40'  'site.hbase-site.zookeeper.session.timeout' : '30000'  'site.hbase-site.zookeeper.znode.parent' : '/hbase-unsecure'  'site.hdfs-site.dfs.namenode.http-address' : '${NN_HOST}:50070'  'site.hdfs-site.dfs.namenode.https-address' : '${NN_HOST}:50470' } }  { 'href' : 'http://c6401:8080/api/v1/views/SLIDER/versions/1.0.0/instances/SLIDER_1/apptypes/STORM'  'id' : 'STORM'  'instance_name' : 'SLIDER_1'  'typeComponents' : [ { 'id' : 'NIMBUS'  'name' : 'NIMBUS'  'category' : 'MASTER'  'displayName' : 'NIMBUS'  'priority' : 1  'instanceCount' : 0  'maxInstanceCount' : 0  'yarnMemory' : 1024  'yarnCpuCores' : 1 }  { 'id' : 'STORM_REST_API'  'name' : 'STORM_REST_API'  'category' : 'MASTER'  'displayName' : 'STORM_REST_API'  'priority' : 2  'instanceCount' : 0  'maxInstanceCount' : 0  'yarnMemory' : 1024  'yarnCpuCores' : 1 }  { 'id' : 'SUPERVISOR'  'name' : 'SUPERVISOR'  'category' : 'SLAVE'  'displayName' : 'SUPERVISOR'  'priority' : 5  'instanceCount' : 0  'maxInstanceCount' : 0  'yarnMemory' : 1024  'yarnCpuCores' : 1 }  { 'id' : 'STORM_UI_SERVER'  'name' : 'STORM_UI_SERVER'  'category' : 'MASTER'  'displayName' : 'STORM_UI_SERVER'  'priority' : 3  'instanceCount' : 0  'maxInstanceCount' : 0  'yarnMemory' : 1024  'yarnCpuCores' : 1 }  { 'id' : 'DRPC_SERVER'  'name' : 'DRPC_SERVER'  'category' : 'MASTER'  'displayName' : 'DRPC_SERVER'  'priority' : 4  'instanceCount' : 0  'maxInstanceCount' : 0  'yarnMemory' : 1024  'yarnCpuCores' : 1 } ]  'typeDescription' : 'Apache Hadoop Stream processing framework'  'typeName' : 'STORM'  'typePackageFileName' : 'storm_v091.zip'  'typeVersion' : '0.9.1.2.1'  'version' : '1.0.0'  'view_name' : 'SLIDER'  'typeConfigs' : { 'agent.conf' : '/slider/agent/conf/agent.ini'  'application.def' : '/slider/storm_v091.zip'  'config_types' : 'storm-site'  'java_home' : '/usr/jdk64/jdk1.7.0_45'  'package_list' : 'files/apache-storm-0.9.1.2.1.1.0-237.tar.gz'  'site.global.app_root' : '${AGENT_WORK_ROOT}/app/install/apache-storm-0.9.1.2.1.1.0-237'  'site.global.app_user' : 'yarn'  'site.global.ganglia_server_host' : '${NN_HOST}'  'site.global.ganglia_server_id' : 'Application2'  'site.global.rest_api_admin_port' : '${STORM_REST_API.ALLOCATED_PORT}'  'site.global.rest_api_port' : '${STORM_REST_API.ALLOCATED_PORT}'  'site.global.security_enabled' : 'false'  'site.global.user_group' : 'hadoop'  'site.storm-site.dev.zookeeper.path' : '${AGENT_WORK_ROOT}/app/tmp/dev-storm-zookeeper'  'site.storm-site.drpc.childopts' : '-Xmx768m'  'site.storm-site.drpc.invocations.port' : '${DRPC_SERVER.ALLOCATED_PORT}'  'site.storm-site.drpc.port' : '${DRPC_SERVER.ALLOCATED_PORT}'  'site.storm-site.drpc.queue.size' : '128'  'site.storm-site.drpc.request.timeout.secs' : '600'  'site.storm-site.drpc.worker.threads' : '64'  'site.storm-site.java.library.path' : '/usr/local/lib:/opt/local/lib:/usr/lib'  'site.storm-site.logviewer.appender.name' : 'A1'  'site.storm-site.logviewer.childopts' : '-Xmx128m'  'site.storm-site.logviewer.port' : '${SUPERVISOR.ALLOCATED_PORT}'  'site.storm-site.nimbus.childopts' : '-Xmx1024m -Djava.security.auth.login.config=/etc/storm/storm_jaas.conf -javaagent:${AGENT_WORK_ROOT}/app/install/apache-storm-0.9.1.2.1.1.0-237/contrib/storm-jmxetric/lib/jmxetric-1.0.4.jar=host={0} port=8669 wireformat31x=true mode=multicast config=${AGENT_WORK_ROOT}/app/install/apache-storm-0.9.1.2.1.1.0-237/contrib/storm-jmxetric/conf/jmxetric-conf.xml process=Nimbus_JVM'  'site.storm-site.nimbus.cleanup.inbox.freq.secs' : '600'  'site.storm-site.nimbus.file.copy.expiration.secs' : '600'  'site.storm-site.nimbus.host' : '${NIMBUS_HOST}'  'site.storm-site.nimbus.inbox.jar.expiration.secs' : '3600'  'site.storm-site.nimbus.monitor.freq.secs' : '10'  'site.storm-site.nimbus.reassign' : 'true'  'site.storm-site.nimbus.supervisor.timeout.secs' : '60'  'site.storm-site.nimbus.task.launch.secs' : '120'  'site.storm-site.nimbus.task.timeout.secs' : '30'  'site.storm-site.nimbus.thrift.max_buffer_size' : '1048576'  'site.storm-site.nimbus.thrift.port' : '${NIMBUS.ALLOCATED_PORT}'  'site.storm-site.nimbus.topology.validator' : 'backtype.storm.nimbus.DefaultTopologyValidator'  'site.storm-site.storm.cluster.mode' : 'distributed'  'site.storm-site.storm.local.dir' : '${AGENT_WORK_ROOT}/app/tmp/storm'  'site.storm-site.storm.local.mode.zmq' : 'false'  'site.storm-site.storm.messaging.netty.buffer_size' : '5242880'  'site.storm-site.storm.messaging.netty.client_worker_threads' : '1'  'site.storm-site.storm.messaging.netty.max_retries' : '30'  'site.storm-site.storm.messaging.netty.max_wait_ms' : '1000'  'site.storm-site.storm.messaging.netty.min_wait_ms' : '100'  'site.storm-site.storm.messaging.netty.server_worker_threads' : '1'  'site.storm-site.storm.messaging.transport' : 'backtype.storm.messaging.netty.Context'  'site.storm-site.storm.thrift.transport' : 'backtype.storm.security.auth.SimpleTransportPlugin'  'site.storm-site.storm.zookeeper.connection.timeout' : '15000'  'site.storm-site.storm.zookeeper.port' : '2181'  'site.storm-site.storm.zookeeper.retry.interval' : '1000'  'site.storm-site.storm.zookeeper.retry.intervalceiling.millis' : '30000'  'site.storm-site.storm.zookeeper.retry.times' : '5'  'site.storm-site.storm.zookeeper.root' : '/storm'  'site.storm-site.storm.zookeeper.servers' : '['${ZK_HOST}']'  'site.storm-site.storm.zookeeper.session.timeout' : '20000'  'site.storm-site.supervisor.childopts' : '-Xmx256m -Djava.security.auth.login.config=/etc/storm/storm_jaas.conf -Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.ssl=false -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.port=${SUPERVISOR.ALLOCATED_PORT} -javaagent:${AGENT_WORK_ROOT}/app/install/apache-storm-0.9.1.2.1.1.0-237/contrib/storm-jmxetric/lib/jmxetric-1.0.4.jar=host={0} port=8669 wireformat31x=true mode=multicast config=${AGENT_WORK_ROOT}/app/install/apache-storm-0.9.1.2.1.1.0-237/contrib/storm-jmxetric/conf/jmxetric-conf.xml process=Supervisor_JVM'  'site.storm-site.supervisor.enable' : 'true'  'site.storm-site.supervisor.heartbeat.frequency.secs' : '5'  'site.storm-site.supervisor.monitor.frequency.secs' : '3'  'site.storm-site.supervisor.slots.ports' : '[${SUPERVISOR.ALLOCATED_PORT}  ${SUPERVISOR.ALLOCATED_PORT}]'  'site.storm-site.supervisor.worker.start.timeout.secs' : '120'  'site.storm-site.supervisor.worker.timeout.secs' : '30'  'site.storm-site.task.heartbeat.frequency.secs' : '3'  'site.storm-site.task.refresh.poll.secs' : '10'  'site.storm-site.topology.acker.executors' : 'null'  'site.storm-site.topology.builtin.metrics.bucket.size.secs' : '60'  'site.storm-site.topology.debug' : 'false'  'site.storm-site.topology.disruptor.wait.strategy' : 'com.lmax.disruptor.BlockingWaitStrategy'  'site.storm-site.topology.enable.message.timeouts' : 'true'  'site.storm-site.topology.error.throttle.interval.secs' : '10'  'site.storm-site.topology.executor.receive.buffer.size' : '1024'  'site.storm-site.topology.executor.send.buffer.size' : '1024'  'site.storm-site.topology.fall.back.on.java.serialization' : 'true'  'site.storm-site.topology.kryo.factory' : 'backtype.storm.serialization.DefaultKryoFactory'  'site.storm-site.topology.max.error.report.per.interval' : '5'  'site.storm-site.topology.max.spout.pending' : 'null'  'site.storm-site.topology.max.task.parallelism' : 'null'  'site.storm-site.topology.message.timeout.secs' : '30'  'site.storm-site.topology.optimize' : 'true'  'site.storm-site.topology.receiver.buffer.size' : '8'  'site.storm-site.topology.skip.missing.kryo.registrations' : 'false'  'site.storm-site.topology.sleep.spout.wait.strategy.time.ms' : '1'  'site.storm-site.topology.spout.wait.strategy' : 'backtype.storm.spout.SleepSpoutWaitStrategy'  'site.storm-site.topology.state.synchronization.timeout.secs' : '60'  'site.storm-site.topology.stats.sample.rate' : '0.05'  'site.storm-site.topology.tick.tuple.freq.secs' : 'null'  'site.storm-site.topology.transfer.buffer.size' : '1024'  'site.storm-site.topology.trident.batch.emit.interval.millis' : '500'  'site.storm-site.topology.tuple.serializer' : 'backtype.storm.serialization.types.ListDelegateSerializer'  'site.storm-site.topology.worker.childopts' : 'null'  'site.storm-site.topology.worker.shared.thread.pool.size' : '4'  'site.storm-site.topology.workers' : '1'  'site.storm-site.transactional.zookeeper.port' : 'null'  'site.storm-site.transactional.zookeeper.root' : '/transactional'  'site.storm-site.transactional.zookeeper.servers' : 'null'  'site.storm-site.ui.port' : '${STORM_UI_SERVER.ALLOCATED_PORT}'  'site.storm-site.worker.childopts' : '-Xmx768m -javaagent:${AGENT_WORK_ROOT}/app/install/apache-storm-0.9.1.2.1.1.0-237/contrib/storm-jmxetric/lib/jmxetric-1.0.4.jar=host={0} port=8669 wireformat31x=true mode=multicast config=${AGENT_WORK_ROOT}/app/install/apache-storm-0.9.1.2.1.1.0-237/contrib/storm-jmxetric/conf/jmxetric-conf.xml process=Worker_%ID%_JVM'  'site.storm-site.worker.heartbeat.frequency.secs' : '1'  'site.storm-site.zmq.hwm' : '0'  'site.storm-site.zmq.linger.millis' : '5000'  'site.storm-site.zmq.threads' : '1' } } ]}, current new slider app wizard show hardcod app type app type instead show app type app type return endpoint endpoint href href http api view SLIDER version instanc SLIDER apptyp field http api view SLIDER version instanc SLIDER apptyp field item item href href http api view SLIDER version instanc SLIDER apptyp ACCUMULO http api view SLIDER version instanc SLIDER apptyp ACCUMULO id id ACCUMULO ACCUMULO instance_name instance_name SLIDER SLIDER typeComponents type compon id id ACCUMULO_MASTER ACCUMULO MASTER name name ACCUMULO_MASTER ACCUMULO MASTER categori categori MASTER MASTER displayName display name ACCUMULO_MASTER ACCUMULO MASTER prioriti prioriti instanceCount instanc count maxInstanceCount max instanc count yarnMemory yarn memori yarnCpuCores yarn cpu core id id ACCUMULO_MONITOR ACCUMULO MONITOR name name ACCUMULO_MONITOR ACCUMULO MONITOR categori categori MASTER MASTER displayName display name ACCUMULO_MONITOR ACCUMULO MONITOR prioriti prioriti instanceCount instanc count maxInstanceCount max instanc count yarnMemory yarn memori yarnCpuCores yarn cpu core id id ACCUMULO_GC ACCUMULO GC name name ACCUMULO_GC ACCUMULO GC categori categori MASTER MASTER displayName display name ACCUMULO_GC ACCUMULO GC prioriti prioriti instanceCount instanc count maxInstanceCount max instanc count yarnMemory yarn memori yarnCpuCores yarn cpu core id id ACCUMULO_TRACER ACCUMULO TRACER name name ACCUMULO_TRACER ACCUMULO TRACER categori categori MASTER MASTER displayName display name ACCUMULO_TRACER ACCUMULO TRACER prioriti prioriti instanceCount instanc count maxInstanceCount max instanc count yarnMemory yarn memori yarnCpuCores yarn cpu core id id ACCUMULO_TSERVER ACCUMULO TSERVER name name ACCUMULO_TSERVER ACCUMULO TSERVER categori categori SLAVE SLAVE displayName display name ACCUMULO_TSERVER ACCUMULO TSERVER prioriti prioriti instanceCount instanc count maxInstanceCount max instanc count yarnMemory yarn memori yarnCpuCores yarn cpu core id id ACCUMULO_CLIENT ACCUMULO CLIENT name name ACCUMULO_CLIENT ACCUMULO CLIENT categori categori CLIENT CLIENT displayName display name ACCUMULO_CLIENT ACCUMULO CLIENT prioriti prioriti instanceCount instanc count maxInstanceCount max instanc count yarnMemory yarn memori yarnCpuCores yarn cpu core typeDescription type descript apach accumulo sort distribut key valu key valu store robust scalabl high perform data storag system featur cell base cell base access control customiz server side server side process process base googl googl BigTable big tabl design built top apach hadoop zookeep thrift thrift requir requir ensur parent dir path accumulo site instanc df dir accumulo site instanc df dir access app owner owner typeName type name ACCUMULO ACCUMULO typePackageFileName type packag file name accumulo_v zip accumulo_v zip typeVersion type version version version view_name view_name SLIDER SLIDER typeConfigs type config agent conf agent conf slider agent conf agent ini slider agent conf agent ini applic def applic def slider accumulo_v zip slider accumulo_v zip config_types config_types accumulo site accumulo site java_home java_home usr jdk jdk  usr jdk jdk  package_list package_list file accumulo bin tar gz file accumulo bin tar gz site accumulo site gc port client site accumulo site gc port client site accumulo site gener classpath site accumulo site gener classpath ACCUMULO_HOME lib accumulo server jar ACCUMULO HOME lib accumulo server jar ACCUMULO_HOME lib accumulo core jar ACCUMULO HOME lib accumulo core jar ACCUMULO_HOME lib accumulo start jar ACCUMULO HOME lib accumulo start jar ACCUMULO_HOME lib accumulo fate jar ACCUMULO HOME lib accumulo fate jar ACCUMULO_HOME lib accumulo proxi jar ACCUMULO HOME lib accumulo proxi jar ACCUMULO_HOME lib jar ACCUMULO HOME lib jar ZOOKEEPER_HOME zookeep jar ZOOKEEPER HOME zookeep jar HADOOP_CONF_DIR HADOOP CONF DIR HADOOP_PREFIX jar HADOOP PREFIX jar HADOOP_PREFIX lib jar HADOOP PREFIX lib jar HADOOP_PREFIX share hadoop common jar HADOOP PREFIX share hadoop common jar HADOOP_PREFIX share hadoop common lib jar HADOOP PREFIX share hadoop common lib jar HADOOP_PREFIX share hadoop hdf jar HADOOP PREFIX share hadoop hdf jar HADOOP_PREFIX share hadoop mapreduc jar HADOOP PREFIX share hadoop mapreduc jar HADOOP_PREFIX share hadoop yarn jar HADOOP PREFIX share hadoop yarn jar usr lib hadoop jar usr lib hadoop jar usr lib hadoop lib jar usr lib hadoop lib jar usr lib hadoop hdf jar usr lib hadoop hdf jar usr lib hadoop mapreduc jar usr lib hadoop mapreduc jar usr lib hadoop yarn jar usr lib hadoop yarn jar site accumulo site instanc df dir site accumulo site instanc df dir app accumulo data app accumulo data site accumulo site instanc secret site accumulo site instanc secret DEFAULT DEFAULT site accumulo site instanc zookeep host site accumulo site instanc zookeep host ZK_HOST ZK HOST site accumulo site master port client site accumulo site master port client site accumulo site monitor port client site accumulo site monitor port client ACCUMULO_MONITOR ALLOCATED_PORT ACCUMULO MONITOR ALLOCATED PORT site accumulo site monitor port log site accumulo site monitor port log site accumulo site trace port client site accumulo site trace port client site accumulo site trace token properti password site accumulo site trace token properti password secret secret site accumulo site trace user site accumulo site trace user root root site accumulo site tserver cach data size site accumulo site tserver cach data size site accumulo site tserver cach index size site accumulo site tserver cach index size site accumulo site tserver memori map max site accumulo site tserver memori map max site accumulo site tserver port client site accumulo site tserver port client site accumulo site tserver sort buffer size site accumulo site tserver sort buffer size site accumulo site tserver walog max size site accumulo site tserver walog max size site global accumulo_instance_name site global accumulo_instance_name instancenam instancenam site global accumulo_root_password site global accumulo_root_password secret secret site global app_install_dir site global app_install_dir AGENT_WORK_ROOT app instal AGENT WORK ROOT app instal site global app_log_dir site global app_log_dir AGENT_LOG_ROOT app log AGENT LOG ROOT app log site global app_pid_dir site global app_pid_dir AGENT_WORK_ROOT app run AGENT WORK ROOT app run site global app_root site global app_root AGENT_WORK_ROOT app instal accumulo AGENT WORK ROOT app instal accumulo site global app_user site global app_user yarn yarn site global gc_heapsize site global gc_heapsize site global hadoop_conf_dir site global hadoop_conf_dir etc hadoop conf etc hadoop conf site global hadoop_prefix site global hadoop_prefix usr lib hadoop usr lib hadoop site global master_heapsize site global master_heapsize site global monitor_heapsize site global monitor_heapsize site global other_heapsize site global other_heapsize site global security_enabled site global security_enabled fals fals site global tserver_heapsize site global tserver_heapsize site global user_group site global user_group hadoop hadoop site global zookeeper_home site global zookeeper_home usr lib zookeep usr lib zookeep href href http api view SLIDER version instanc SLIDER apptyp HBASE http api view SLIDER version instanc SLIDER apptyp HBASE id id HBASE HBASE instance_name instance_name SLIDER SLIDER typeComponents type compon id id HBASE_MASTER HBASE MASTER name name HBASE_MASTER HBASE MASTER categori categori MASTER MASTER displayName display name HBASE_MASTER HBASE MASTER prioriti prioriti instanceCount instanc count maxInstanceCount max instanc count yarnMemory yarn memori yarnCpuCores yarn cpu core id id HBASE_REGIONSERVER HBASE REGIONSERVER name name HBASE_REGIONSERVER HBASE REGIONSERVER categori categori SLAVE SLAVE displayName display name HBASE_REGIONSERVER HBASE REGIONSERVER prioriti prioriti instanceCount instanc count maxInstanceCount max instanc count yarnMemory yarn memori yarnCpuCores yarn cpu core id id HBASE_CLIENT HBASE CLIENT name name HBASE_CLIENT HBASE CLIENT categori categori CLIENT CLIENT displayName display name HBASE_CLIENT HBASE CLIENT prioriti prioriti instanceCount instanc count maxInstanceCount max instanc count yarnMemory yarn memori yarnCpuCores yarn cpu core typeDescription type descript apach apach HBase base hadoop databas distribut scalabl big data store store requir requir ensur parent dir path hbase site hbase rootdir hbase site hbase rootdir access app owner owner ensur ZK root hbase site zookeep znode parent hbase site zookeep znode parent uniqu app instanc instanc typeName type name HBASE HBASE typePackageFileName type packag file name hbase_v hbase_v zip zip typeVersion type version version version view_name view_name SLIDER SLIDER typeConfigs type config agent conf agent conf slider agent conf agent ini slider agent conf agent ini applic def applic def slider hbase_v zip slider hbase_v zip config_types config_types core site core site hdf site hdf site hbase site hbase site java_home java_home usr jdk jdk  usr jdk jdk  package_list package_list file hbase hadoop bin tar gz file hbase hadoop bin tar gz site core site fs defaultFS site core site fs default FS NN_URI NN URI site global app_install_dir site global app_install_dir AGENT_WORK_ROOT app instal AGENT WORK ROOT app instal site global app_log_dir site global app_log_dir AGENT_LOG_ROOT app log AGENT LOG ROOT app log site global app_pid_dir site global app_pid_dir AGENT_WORK_ROOT app run AGENT WORK ROOT app run site global app_root site global app_root AGENT_WORK_ROOT app instal hbase hadoop AGENT WORK ROOT app instal hbase hadoop site global app_user site global app_user yarn yarn site global ganglia_server_host site global ganglia_server_host NN_HOST NN HOST site global ganglia_server_id site global ganglia_server_id applic applic site global ganglia_server_port site global ganglia_server_port site global hbase_master_heapsize site global hbase_master_heapsize site global hbase_regionserver_heapsize site global hbase_regionserver_heapsize site global security_enabled site global security_enabled fals fals site global user_group site global user_group hadoop hadoop site hbase site hbase client keyvalu maxsiz site hbase site hbase client keyvalu maxsiz site hbase site hbase client scanner cach site hbase site hbase client scanner cach site hbase site hbase cluster distribut site hbase site hbase cluster distribut true true site hbase site hbase default version skip site hbase site hbase default version skip true true site hbase site hbase hregion majorcompact site hbase site hbase hregion majorcompact site hbase site hbase hregion max files site hbase site hbase hregion max files site hbase site hbase hregion memstor block multipli site hbase site hbase hregion memstor block multipli site hbase site hbase hregion memstor flush size site hbase site hbase hregion memstor flush size site hbase site hbase hregion memstor mslab enabl site hbase site hbase hregion memstor mslab enabl true true site hbase site hbase hstore blockingStoreFiles site hbase site hbase hstore block store file site hbase site hbase hstore compactionThreshold site hbase site hbase hstore compact threshold site hbase site hbase hstore flush retri number site hbase site hbase hstore flush retri number site hbase site hbase local dir site hbase site hbase local dir hbase tmp dir local hbase tmp dir local site hbase site hbase master info port site hbase site hbase master info port HBASE_MASTER ALLOCATED_PORT HBASE MASTER ALLOCATED PORT site hbase site hbase regionserv global memstor lowerLimit site hbase site hbase regionserv global memstor lower limit site hbase site hbase regionserv global memstor upperLimit site hbase site hbase regionserv global memstor upper limit site hbase site hbase regionserv handler count site hbase site hbase regionserv handler count site hbase site hbase regionserv info port site hbase site hbase regionserv info port site hbase site hbase regionserv port site hbase site hbase regionserv port site hbase site hbase rootdir site hbase site hbase rootdir NN_URI app hbase data NN URI app hbase data site hbase site hbase secur authent site hbase site hbase secur authent simpl simpl site hbase site hbase secur author site hbase site hbase secur author fals fals site hbase site hbase stagingdir site hbase site hbase stagingdir NN_URI app hbase stage NN URI app hbase stage site hbase site hbase superus site hbase site hbase superus yarn yarn site hbase site hbase tmp dir site hbase site hbase tmp dir AGENT_WORK_ROOT work app tmp AGENT WORK ROOT work app tmp site hbase site hbase zookeep properti clientPort site hbase site hbase zookeep properti client port site hbase site hbase zookeep quorum site hbase site hbase zookeep quorum ZK_HOST ZK HOST site hbase site hbase zookeep useMulti site hbase site hbase zookeep use multi true true site hbase site hfile block cach size site hbase site hfile block cach size site hbase site zookeep session timeout site hbase site zookeep session timeout site hbase site zookeep znode parent site hbase site zookeep znode parent hbase unsecur hbase unsecur site hdf site df namenod http address site hdf site df namenod http address NN_HOST NN HOST site hdf site df namenod http address site hdf site df namenod http address NN_HOST NN HOST href href http api view SLIDER version instanc SLIDER apptyp STORM http api view SLIDER version instanc SLIDER apptyp STORM id id STORM STORM instance_name instance_name SLIDER SLIDER typeComponents type compon id id NIMBUS NIMBUS name name NIMBUS NIMBUS categori categori MASTER MASTER displayName display name NIMBUS NIMBUS prioriti prioriti instanceCount instanc count maxInstanceCount max instanc count yarnMemory yarn memori yarnCpuCores yarn cpu core id id STORM_REST_API STORM REST API name name STORM_REST_API STORM REST API categori categori MASTER MASTER displayName display name STORM_REST_API STORM REST API prioriti prioriti instanceCount instanc count maxInstanceCount max instanc count yarnMemory yarn memori yarnCpuCores yarn cpu core id id SUPERVISOR SUPERVISOR name name SUPERVISOR SUPERVISOR categori categori SLAVE SLAVE displayName display name SUPERVISOR SUPERVISOR prioriti prioriti instanceCount instanc count maxInstanceCount max instanc count yarnMemory yarn memori yarnCpuCores yarn cpu core id id STORM_UI_SERVER STORM UI SERVER name name STORM_UI_SERVER STORM UI SERVER categori categori MASTER MASTER displayName display name STORM_UI_SERVER STORM UI SERVER prioriti prioriti instanceCount instanc count maxInstanceCount max instanc count yarnMemory yarn memori yarnCpuCores yarn cpu core id id DRPC_SERVER DRPC SERVER name name DRPC_SERVER DRPC SERVER categori categori MASTER MASTER displayName display name DRPC_SERVER DRPC SERVER prioriti prioriti instanceCount instanc count maxInstanceCount max instanc count yarnMemory yarn memori yarnCpuCores yarn cpu core typeDescription type descript apach apach hadoop stream process framework framework typeName type name STORM STORM typePackageFileName type packag file name storm_v zip storm_v zip typeVersion type version version version view_name view_name SLIDER SLIDER typeConfigs type config agent conf agent conf slider agent conf agent ini slider agent conf agent ini applic def applic def slider storm_v zip slider storm_v zip config_types config_types storm site storm site java_home java_home usr jdk jdk  usr jdk jdk  package_list package_list file apach storm tar gz file apach storm tar gz site global app_root site global app_root AGENT_WORK_ROOT app instal apach storm AGENT WORK ROOT app instal apach storm site global app_user site global app_user yarn yarn site global ganglia_server_host site global ganglia_server_host NN_HOST NN HOST site global ganglia_server_id site global ganglia_server_id applic applic site global rest_api_admin_port site global rest_api_admin_port STORM_REST_API ALLOCATED_PORT STORM REST API ALLOCATED PORT site global rest_api_port site global rest_api_port STORM_REST_API ALLOCATED_PORT STORM REST API ALLOCATED PORT site global security_enabled site global security_enabled fals fals site global user_group site global user_group hadoop hadoop site storm site dev zookeep path site storm site dev zookeep path AGENT_WORK_ROOT app tmp dev storm zookeep AGENT WORK ROOT app tmp dev storm zookeep site storm site drpc childopt site storm site drpc childopt xmx xmx site storm site drpc invoc port site storm site drpc invoc port DRPC_SERVER ALLOCATED_PORT DRPC SERVER ALLOCATED PORT site storm site drpc port site storm site drpc port DRPC_SERVER ALLOCATED_PORT DRPC SERVER ALLOCATED PORT site storm site drpc queue size site storm site drpc queue size site storm site drpc request timeout sec site storm site drpc request timeout sec site storm site drpc worker thread site storm site drpc worker thread site storm site java librari path site storm site java librari path usr local lib opt local lib usr lib usr local lib opt local lib usr lib site storm site logview append name site storm site logview append name site storm site logview childopt site storm site logview childopt xmx xmx site storm site logview port site storm site logview port SUPERVISOR ALLOCATED_PORT SUPERVISOR ALLOCATED PORT site storm site nimbu childopt site storm site nimbu childopt xmx xmx djava secur auth login config etc storm storm_jaas conf djava secur auth login config etc storm storm_jaas conf javaag AGENT_WORK_ROOT app instal apach storm contrib storm jmxetric lib jmxetric jar host javaag AGENT WORK ROOT app instal apach storm contrib storm jmxetric lib jmxetric jar host port port wireformat true wireformat true mode multicast mode multicast config AGENT_WORK_ROOT app instal apach storm contrib storm jmxetric conf jmxetric conf xml config AGENT WORK ROOT app instal apach storm contrib storm jmxetric conf jmxetric conf xml process Nimbus_JVM process nimbu JVM site storm site nimbu cleanup inbox freq sec site storm site nimbu cleanup inbox freq sec site storm site nimbu file copi expir sec site storm site nimbu file copi expir sec site storm site nimbu host site storm site nimbu host NIMBUS_HOST NIMBUS HOST site storm site nimbu inbox jar expir sec site storm site nimbu inbox jar expir sec site storm site nimbu monitor freq sec site storm site nimbu monitor freq sec site storm site nimbu reassign site storm site nimbu reassign true true site storm site nimbu supervisor timeout sec site storm site nimbu supervisor timeout sec site storm site nimbu task launch sec site storm site nimbu task launch sec site storm site nimbu task timeout sec site storm site nimbu task timeout sec site storm site nimbu thrift max_buffer_size site storm site nimbu thrift max_buffer_size site storm site nimbu thrift port site storm site nimbu thrift port NIMBUS ALLOCATED_PORT NIMBUS ALLOCATED PORT site storm site nimbu topolog valid site storm site nimbu topolog valid backtyp storm nimbu DefaultTopologyValidator backtyp storm nimbu default topolog valid site storm site storm cluster mode site storm site storm cluster mode distribut distribut site storm site storm local dir site storm site storm local dir AGENT_WORK_ROOT app tmp storm AGENT WORK ROOT app tmp storm site storm site storm local mode zmq site storm site storm local mode zmq fals fals site storm site storm messag netti buffer_size site storm site storm messag netti buffer_size site storm site storm messag netti client_worker_threads site storm site storm messag netti client_worker_threads site storm site storm messag netti max_retries site storm site storm messag netti max_retries site storm site storm messag netti max_wait_ms site storm site storm messag netti max_wait_ms site storm site storm messag netti min_wait_ms site storm site storm messag netti min_wait_ms site storm site storm messag netti server_worker_threads site storm site storm messag netti server_worker_threads site storm site storm messag transport site storm site storm messag transport backtyp storm messag netti context backtyp storm messag netti context site storm site storm thrift transport site storm site storm thrift transport backtyp storm secur auth SimpleTransportPlugin backtyp storm secur auth simpl transport plugin site storm site storm zookeep connect timeout site storm site storm zookeep connect timeout site storm site storm zookeep port site storm site storm zookeep port site storm site storm zookeep retri interv site storm site storm zookeep retri interv site storm site storm zookeep retri intervalceil milli site storm site storm zookeep retri intervalceil milli site storm site storm zookeep retri time site storm site storm zookeep retri time site storm site storm zookeep root site storm site storm zookeep root storm storm site storm site storm zookeep server site storm site storm zookeep server ZK_HOST ZK HOST site storm site storm zookeep session timeout site storm site storm zookeep session timeout site storm site supervisor childopt site storm site supervisor childopt xmx xmx djava secur auth login config etc storm storm_jaas conf djava secur auth login config etc storm storm_jaas conf dcom sun manag jmxremot dcom sun manag jmxremot dcom sun manag jmxremot ssl fals dcom sun manag jmxremot ssl fals dcom sun manag jmxremot authent fals dcom sun manag jmxremot authent fals dcom sun manag jmxremot port SUPERVISOR ALLOCATED_PORT dcom sun manag jmxremot port SUPERVISOR ALLOCATED PORT javaag AGENT_WORK_ROOT app instal apach storm contrib storm jmxetric lib jmxetric jar host javaag AGENT WORK ROOT app instal apach storm contrib storm jmxetric lib jmxetric jar host port port wireformat true wireformat true mode multicast mode multicast config AGENT_WORK_ROOT app instal apach storm contrib storm jmxetric conf jmxetric conf xml config AGENT WORK ROOT app instal apach storm contrib storm jmxetric conf jmxetric conf xml process Supervisor_JVM process supervisor JVM site storm site supervisor enabl site storm site supervisor enabl true true site storm site supervisor heartbeat frequenc sec site storm site supervisor heartbeat frequenc sec site storm site supervisor monitor frequenc sec site storm site supervisor monitor frequenc sec site storm site supervisor slot port site storm site supervisor slot port SUPERVISOR ALLOCATED_PORT SUPERVISOR ALLOCATED PORT SUPERVISOR ALLOCATED_PORT SUPERVISOR ALLOCATED PORT site storm site supervisor worker start timeout sec site storm site supervisor worker start timeout sec site storm site supervisor worker timeout sec site storm site supervisor worker timeout sec site storm site task heartbeat frequenc sec site storm site task heartbeat frequenc sec site storm site task refresh poll sec site storm site task refresh poll sec site storm site topolog acker executor site storm site topolog acker executor null null site storm site topolog builtin metric bucket size sec site storm site topolog builtin metric bucket size sec site storm site topolog debug site storm site topolog debug fals fals site storm site topolog disruptor wait strategi site storm site topolog disruptor wait strategi com lmax disruptor BlockingWaitStrategy com lmax disruptor block wait strategi site storm site topolog enabl messag timeout site storm site topolog enabl messag timeout true true site storm site topolog error throttl interv sec site storm site topolog error throttl interv sec site storm site topolog executor receiv buffer size site storm site topolog executor receiv buffer size site storm site topolog executor send buffer size site storm site topolog executor send buffer size site storm site topolog fall back java serial site storm site topolog fall back java serial true true site storm site topolog kryo factori site storm site topolog kryo factori backtyp storm serial DefaultKryoFactory backtyp storm serial default kryo factori site storm site topolog max error report per interv site storm site topolog max error report per interv site storm site topolog max spout pend site storm site topolog max spout pend null null site storm site topolog max task parallel site storm site topolog max task parallel null null site storm site topolog messag timeout sec site storm site topolog messag timeout sec site storm site topolog optim site storm site topolog optim true true site storm site topolog receiv buffer size site storm site topolog receiv buffer size site storm site topolog skip miss kryo registr site storm site topolog skip miss kryo registr fals fals site storm site topolog sleep spout wait strategi time ms site storm site topolog sleep spout wait strategi time ms site storm site topolog spout wait strategi site storm site topolog spout wait strategi backtyp storm spout SleepSpoutWaitStrategy backtyp storm spout sleep spout wait strategi site storm site topolog state synchron timeout sec site storm site topolog state synchron timeout sec site storm site topolog stat sampl rate site storm site topolog stat sampl rate site storm site topolog tick tupl freq sec site storm site topolog tick tupl freq sec null null site storm site topolog transfer buffer size site storm site topolog transfer buffer size site storm site topolog trident batch emit interv milli site storm site topolog trident batch emit interv milli site storm site topolog tupl serial site storm site topolog tupl serial backtyp storm serial type ListDelegateSerializer backtyp storm serial type list deleg serial site storm site topolog worker childopt site storm site topolog worker childopt null null site storm site topolog worker share thread pool size site storm site topolog worker share thread pool size site storm site topolog worker site storm site topolog worker site storm site transact zookeep port site storm site transact zookeep port null null site storm site transact zookeep root site storm site transact zookeep root transact transact site storm site transact zookeep server site storm site transact zookeep server null null site storm site ui port site storm site ui port STORM_UI_SERVER ALLOCATED_PORT STORM UI SERVER ALLOCATED PORT site storm site worker childopt site storm site worker childopt xmx xmx javaag AGENT_WORK_ROOT app instal apach storm contrib storm jmxetric lib jmxetric jar host javaag AGENT WORK ROOT app instal apach storm contrib storm jmxetric lib jmxetric jar host port port wireformat true wireformat true mode multicast mode multicast config AGENT_WORK_ROOT app instal apach storm contrib storm jmxetric conf jmxetric conf xml config AGENT WORK ROOT app instal apach storm contrib storm jmxetric conf jmxetric conf xml process worker ID _JVM process worker ID  JVM site storm site worker heartbeat frequenc sec site storm site worker heartbeat frequenc sec site storm site zmq hwm site storm site zmq hwm site storm site zmq linger milli site storm site zmq linger milli site storm site zmq thread site storm site zmq thread,0,0,0,0,0,0,1 
5895,Dmitry Lysnichenko,null,0,Suppress any debug and info messages from package managers in setupAgent.py, suppress debug info messag packag manag setupAgent py setup agent py,During bootstrapping of agents  installation retrieve versions of available packages from system package manager. After some test was founded that in different situations package managers can produce specific info/debug output which can be reason of wrong parsing of output.Example:Zypper command:se2mon1400652583-9:/etc/zypp/repos.d # zypper search -s --match-exact ambari-agent Building repository 'Hortonworks Data Platform Utils Version - HDP-UTILS-1.1.0.16' cache &#91;done&#93;Building repository 'Hortonworks Data Platform Utils Version - HDP-UTILS-1.1.0.17' cache &#91;done&#93;Building repository 'Hosted (SLES_11)' cache &#91;done&#93;Building repository 'ambari-1.6.0 - Updates' cache &#91;done&#93;Building repository 'Ambari 1.x' cache &#91;done&#93;Building repository 'PostgreSQL and related packages (SLE_11_SP3)' cache &#91;done&#93;Loading repository data...Reading installed packages...S | Name | Type | Version | Arch | Repository -----------------------------------+---------------------- ambari-agent  package  1.6.0-46  x86_64  ambari-1.6.0 - Updates ambari-agent  package  1.2.0.1-1  x86_64  Ambari 1.xParsed as: Building repository 'ambari-1.6.0 We should suppress any debug/info output in setupAgent.py to avoid any unexpected situation., bootstrap agent instal retriev version avail packag system packag manag manag test found differ situat packag manag produc specif info debug info debug output reason wrong pars output exampl zypper output exampl zypper command se mon etc zypp repo command se mon etc zypp repo zypper search match exact match exact ambari agent ambari agent build repositori hortonwork hortonwork data platform util version HDP UTILS HDP UTILS cach done build done build repositori hortonwork hortonwork data platform util version HDP UTILS HDP UTILS cach done build done build repositori host host SLES SLES cach done build done build repositori ambari ambari updat updat cach done build done build repositori ambari ambari cach done build done build repositori PostgreSQL postgr SQL relat packag SLE _SP SLE  SP cach done load done load repositori data read data read instal packag packag name type version arch repositori ambari agent ambari agent packag   ambari ambari updat ambari agent ambari agent packag   ambari xParsed pars build repositori ambari ambari suppress debug info debug info output setupAgent py setup agent py avoid unexpect situat situat,0,0,0,0,0,0,0 
5922,Siddharth Wagle,ambari-server,0,Predicates don't work on fields with float values, predic work field float valu,API should be able to process filter with predicates(&lt; &gt; =) for fields with float values; For example field: metrics/load/load_one.Currently the Greater than predicate will fail for values in between 0.0 and 1.0, API abl process filter predic lt predic lt gt gt field float valu valu exampl field field metric load load_one current metric load load_one current greater predic fail valu,0,0,0,0,0,0,1 
5930,Jonathan Hurley,null,0,Some HBase properties are empty  but required to be filled, HBase base properti empti requir fill,This HBase properties are empty after install via blueprint: hbase.coprocessor.region.classes hbase.coprocessor.master.classesBut they required to be filled.After enabling security they became filled., HBase base properti empti instal via blueprint blueprint hbase coprocessor region class hbase coprocessor region class hbase coprocessor master classesBut hbase coprocessor master class requir fill fill enabl secur becam fill fill,0,0,0,0,0,0,0 
5932,Antonenko Alexander,ambari-web,0,Slider apps table does not remove entry when app is removed, slider app tabl not remov entri app remov,Lets say I have a running app. I freeze it and then destroy it. The app goes away from the /apps response. However the UI still continues to show it. I think the mapper is not removing deleted entries from the model.Mapper should remove entries not being sent by /apps., let say run app app freez destroy app goe away app respons respons howev UI still continu show think mapper not remov delet entri model mapper model mapper remov entri not sent app app,0,0,0,0,0,0,1 
5935,Myroslav Papirkovskyy,ambari-server,0,Maintenance state and status commands perf improvements., mainten state statu command perf improv improv,getEffectiveState should not fetch map of all hosts every time Status commands should not be sent until component is installed, getEffectiveState get effect state not fetch map host everi time statu command not sent compon instal,0,0,0,0,0,0,1 
5956,Vitaly Brodetskyi,ambari-agent,0,DB connection check error if jdk_name does not exist., DB connect check error jdk_name not exist exist,We can get such situation when user using custom java., get situat user use custom java java,0,0,0,0,0,0,1 
5957,Dmitry Lysnichenko,ambari-server,0,Bootstrap API call says bootstrap is running even though all agents have installed and registered, bootstrap API call say bootstrap run even though agent instal regist,UI keeps showing that the agents are being installed  because the bootstrap API GET call keeps returning that hostsStatus/status is RUNNINGI suspected time.sleep(1) instruction. If restart takes too long time  situation  when ambari-agent.log has not been created yet is possible. So  tail command returned not 0 retcode and exit from procedure. But in logs I cant see any non-zero retcodes. Thus  too short logs could be explaned by this issue., UI keep show agent instal bootstrap API GET call keep return hostsStatus statu host statu statu RUNNINGI suspect time sleep time sleep instruct instruct restart take long time situat ambari agent log ambari agent log not creat yet possibl possibl tail command return not retcod exit procedur procedur log cant see non zero non zero retcod retcod thu short log could explan issu issu,0,0,0,0,0,0,0 
5994,Andrii Babiichuk,ambari-web,0,Storm UI in Ambari quick link fails when Storm UI server is not co-hosted with nimbus host, storm UI ambari quick link fail storm UI server not co host co host nimbu host,quick link for Storm UI was linked with nimbus server. it should use Storm UI server host., quick link storm UI link nimbu server server use storm UI server host host,0,0,0,0,0,ambari-web/app/models/quick_links.js;ambari-web/app/views/common/quick_view_link_view.js;,1 
6003,Aleksandr Kovalenko,ambari-web,0,metrics hostname is not correct for storm, metric hostnam not correct storm,Some of the storm configs have extra 'localhost' appended to the host name.'nimbus.childopts' : '-Xmx1024m -Djava.security.auth.login.config=/etc/storm/conf/storm_jaas.conf -javaagent:/usr/lib/storm/contrib/storm-jmxetric/lib/jmxetric-1.0.4.jar=host=c6401.ambari.apache.orglocalhost port=8649 wireformat31x=true mode=multicast config=/usr/lib/storm/contrib/storm-jmxetric/conf/jmxetric-conf.xml process=Nimbus_JVM''supervisor.childopts' : '-Xmx256m -Djava.security.auth.login.config=/etc/storm/conf/storm_jaas.conf -Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.ssl=false -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.port=56431 -javaagent:/usr/lib/storm/contrib/storm-jmxetric/lib/jmxetric-1.0.4.jar=host=c6401.ambari.apache.orglocalhost port=8650 wireformat31x=true mode=multicast config=/usr/lib/storm/contrib/storm-jmxetric/conf/jmxetric-conf.xml process=Supervisor_JVM''worker.childopts' : '-Xmx768m -javaagent:/usr/lib/storm/contrib/storm-jmxetric/lib/jmxetric-1.0.4.jar=host=c6401.ambari.apache.orglocalhost port=8650 wireformat31x=true mode=multicast config=/usr/lib/storm/contrib/storm-jmxetric/conf/jmxetric-conf.xml process=Worker_%ID%_JVM', storm config extra localhost localhost append host name nimbu childopt name nimbu childopt xmx xmx djava secur auth login config etc storm conf storm_jaas conf djava secur auth login config etc storm conf storm_jaas conf javaag usr lib storm contrib storm jmxetric lib jmxetric jar host ambari apach orglocalhost javaag usr lib storm contrib storm jmxetric lib jmxetric jar host ambari apach orglocalhost port port wireformat true wireformat true mode multicast mode multicast config usr lib storm contrib storm jmxetric conf jmxetric conf xml config usr lib storm contrib storm jmxetric conf jmxetric conf xml process Nimbus_JVM supervisor childopt process nimbu JVM supervisor childopt xmx xmx djava secur auth login config etc storm conf storm_jaas conf djava secur auth login config etc storm conf storm_jaas conf dcom sun manag jmxremot dcom sun manag jmxremot dcom sun manag jmxremot ssl fals dcom sun manag jmxremot ssl fals dcom sun manag jmxremot authent fals dcom sun manag jmxremot authent fals dcom sun manag jmxremot port dcom sun manag jmxremot port javaag usr lib storm contrib storm jmxetric lib jmxetric jar host ambari apach orglocalhost javaag usr lib storm contrib storm jmxetric lib jmxetric jar host ambari apach orglocalhost port port wireformat true wireformat true mode multicast mode multicast config usr lib storm contrib storm jmxetric conf jmxetric conf xml config usr lib storm contrib storm jmxetric conf jmxetric conf xml process Supervisor_JVM worker childopt process supervisor JVM worker childopt xmx xmx javaag usr lib storm contrib storm jmxetric lib jmxetric jar host ambari apach orglocalhost javaag usr lib storm contrib storm jmxetric lib jmxetric jar host ambari apach orglocalhost port port wireformat true wireformat true mode multicast mode multicast config usr lib storm contrib storm jmxetric conf jmxetric conf xml config usr lib storm contrib storm jmxetric conf jmxetric conf xml process worker ID _JVM process worker ID  JVM,0,0,0,0,0,0,0 
6014,Jonathan Hurley,null,0,HDFS alert hangs for a long time after enabling Maintenance mode, HDFS alert hang long time enabl mainten mode,STR: Stop HDFS with started Nagios service. Turn on Maintenance mode for HDFS.Result: All alerts dissapear  except 'HDFS capacity utilization' - it hangs for a long time (in my case it was smthng about 10-11 minutes), STR STR stop HDFS start nagio servic servic turn mainten mode HDFS result HDFS result alert dissapear except HDFS HDFS capac util util hang long time case smthng minut minut,0,0,0,0,0,0,1 
6034,Antonenko Alexander,ambari-web,0,Services -> Configs page for Yarn  HIVE  MapReduce services is not displayed, servic config page yarn HIVE MapReduce map reduc servic not display,Config page for services that use App.YARNDefaultsProvider is not displayed.Following JS error thrown:Uncaught TypeError: Cannot call method 'forEach' of null yarn_defaults_provider.js:291, config page servic use app YARNDefaultsProvider app YARN default provid not display follow display follow JS error thrown uncaught thrown uncaught TypeError type error cannot call method forEach null yarn_defaults_provider js yarn_defaults_provider js,0,0,0,0,0,0,0 
6044,Vitaly Brodetskyi,ambari-agent,0,Issues with jdbc properties, issu jdbc properti,remove dots in --help params description and in warningscopy fails if jdbc selected by --jdbc-driver is already in resourceshide other points of ambari-server setup if jdbc options are passed and server is running, remov dot help param descript warningscopi fail jdbc select jdbc driver jdbc driver alreadi resourceshid point ambari server ambari server setup jdbc option pass server run,0,0,0,0,0,0,0 
6045,Andrii Tkach,ambari-web,0,Master components are missing, master compon miss,Master components info is missing in service summary., master compon info miss servic summari summari,0,0,0,0,0,ambari-web/app/mappers/service_metrics_mapper.js;,1 
6048,Dmitry Lysnichenko,ambari-agent,0,Ambari Agent script should check for running processes before starting, ambari agent script check run process start,PROBLEM: If the Ambari Agent installation fails for whatever reason then a process of ambari-agent is left running. This results in the ambari-agent status to show as it not running. If you then start another ambari-agent it dies because the port is already in use.If the script could check the PID file and check for a running process then it would resolve this issue.BUSINESS IMPACT: Not a huge business impact as the workaround is to kill the running ambari-agent processWorkaround: Kill running ambari-agent process before startingANALYSIS: I cannot reproduce this issue in house and the SE who raised it can not reproduce on demand., PROBLEM PROBLEM ambari agent instal fail whatev reason process ambari agent ambari agent left run run result ambari agent ambari agent statu show not run run start anoth ambari agent ambari agent die port alreadi use use script could check PID file check run process would resolv issu BUSINESS issu BUSINESS IMPACT IMPACT not huge busi impact workaround kill run ambari agent ambari agent processWorkaround process workaround kill run ambari agent ambari agent process startingANALYSIS start ANALYSIS cannot reproduc issu hous SE rais not reproduc demand demand,0,0,0,0,0,0,1 
6053,Andrii Tkach,ambari-web,0,Add Host wizard get stuck on Confirm Hosts step, add host wizard get stuck confirm host step,,,0,0,0,0,0,ambari-web/app/controllers/main/host/add_controller.js;ambari-web/app/controllers/wizard/step2_controller.js;ambari-web/app/controllers/wizard/step3_controller.js;ambari-web/app/views/main/host/add_view.js;,1 
6056,Jonathan Hurley,null,0,Agent Custom Command Output Coerces Integers to Floats, agent custom command output coerc integ float,When posting a command such as{ 'RequestInfo': { 'action': 'check_host'  'context': 'Check host'  'parameters': { 'check_execute_list': 'host_resolution_check'  'hosts': 'c6401.ambari.apache.org  c6402.ambari.apache.org  c6403.ambari.apache.org  foobar'  'threshold': '20' } }  'Requests/resource_filters': [ { 'hosts': 'c6401.ambari.apache.org c6402.ambari.apache.org' } ]The returned result from the custom action has some integer values coerced into floats: 'structured_out' : { 'host_resolution_check' : { 'exit_code' : '0'  'failed_count' : 0.0  'failures' : [ ]  'message' : 'All hosts resolved to an IP address.'  'success_count' : 4.0 }The structured_output written out to disk does NOT have the float values:{'host_resolution_check': {'failures': []  'message': 'All hosts resolved to an IP address.'  'failed_count': 0  'success_count': 4  'exit_code': '0'}} Therefore this is a problem with the framework and not the command., post command RequestInfo request info action action check_host check_host context context check check host host paramet paramet check_execute_list check_execute_list host_resolution_check host_resolution_check host host ambari apach org ambari apach org ambari apach org ambari apach org ambari apach org ambari apach org foobar foobar threshold threshold request resource_filters request resource_filters host host ambari apach org ambari apach org ambari apach org ambari apach org return result custom action integ valu coerc float float structured_out structured_out host_resolution_check host_resolution_check exit_code exit_code failed_count failed_count failur failur messag messag host resolv IP address address success_count success_count structured_output written disk NOT float valu host_resolution_check valu host_resolution_check failur failur messag messag host resolv IP address address failed_count failed_count success_count success_count exit_code exit_code therefor problem framework not command command,0,0,0,0,0,0,1 
6063,Dmytro Sen,ambari-server,0,'ambari-server start command' hangs if was executed via ssh command, ambari server ambari server start command command hang execut via ssh command,Problem:Ambari Server command 'ssh root@vmhost ambari-server start' hangs on message 'Ambari Server 'start' completed successfully.'. Same command executed successfully on the local console  as a result this behavior can be reproduced only via remote execution of commands.How to reproduce: Deploy server Stop server locally Start server from another host using ssh command, problem ambari problem ambari server command ssh root vmhost root vmhost ambari server ambari server start start hang messag ambari ambari server start start complet success success command execut success local consol result behavior reproduc via remot execut command command reproduc reproduc deploy server stop server local start server anoth host use ssh command,0,0,0,0,0,ambari-server/src/main/python/ambari-server.py;ambari-server/src/main/python/ambari_server/utils.py;ambari-server/src/test/python/TestAmbariServer.py;ambari-server/src/test/python/TestUtils.py;,1 
6080,Aleksandr Kovalenko,ambari-web,0,Hosts Components filter on Service summary page doesn't work, host compon filter servic summari page work,When user clicks on some component filter on Service summary page  it opens hosts page  but filter is not applied., user click compon filter servic summari page open host page filter not appli appli,0,0,0,0,0,0,1 
6087,Oleg Nechiporenko,ambari-web,0,Multiple ATS appear on YARN summary page, multipl ATS appear YARN summari page,STR1. Go to add Service Wizard.2. Select some new services and proceed to deploy.3. Close Wizard (Esc-button).4. Wait a little bit (maybe page-refresh needed).5. Go to YARN summary.6. New 'none' components will appear periodically.See screenshot., STR STR Go add servic wizard wizard select new servic proceed deploy deploy close wizard esc button esc button wait littl bit mayb page refresh page refresh need need Go YARN summari summari new none none compon appear period see period see screenshot screenshot,0,0,0,0,0,0,1 
6112,Andrii Tkach,ambari-web,0,Filter by alerts fails on Hosts table, filter alert fail host tabl,Steps to reproduce:1. Go to Hosts page2. Choose filter AlertsResult:Hosts are not filtered by alerts.The request with filter by alerts has incorrect url data., step reproduc reproduc Go host page page choos filter AlertsResult host alert result host not filter alert alert request filter alert incorrect url data data,0,0,0,0,0,ambari-web/app/controllers/global/update_controller.js;ambari-web/app/controllers/main/host.js;ambari-web/app/data/host/categories.js;,1 
6113,Vitaly Brodetskyi,ambari-agent,0,Nagios install fails on SLES due to php5-json not available, nagio instal fail SLES due php json php json not avail,Using SLES 11 SP3 quick-start image on EC2. Doesn't look like php5-json is available  but php53-json is available.WORKAROUND:I modified NAGIOS/metainfo.xml and this worked. &lt;package&gt; &lt;name&gt;php5*-json&lt;/name&gt; &lt;/package&gt;, use SLES SP SP quick start quick start imag EC EC look like php json php json avail php json php json avail WORKAROUND avail WORKAROUND modifi NAGIOS metainfo xml NAGIOS metainfo xml work work lt packag gt lt packag gt lt name gt php json lt name gt lt name gt php json lt name gt lt packag gt lt packag gt,0,0,0,0,0,0,1 
6123,Xi Wang,ambari-web,0,issues with dialog keypresses, issu dialog keypress,1) on 'manage config groups' pressing return does something even though return is not valid (i.e. can't save)2) Once you press return in #1  then you have to press esc twice to close the dialog3) once you open the nested dialog (to add a group)  esc closes the parent  then esc again  closes the nested dialog4) once you open the nested dialog  also notice it doesn't start focus on the name field  you have to click to get that focus., manag config group group press return someth even though return not valid save save press return press esc twice close dialog dialog open nest dialog add group group esc close parent esc close nest dialog dialog open nest dialog also notic start focu name field click get focu focu,0,0,0,0,0,0,0 
6137,Andrii Babiichuk,ambari-web,0,Bulk operations confirmation popup, bulk oper confirm popup,Hosts page  'Actions' menu (dropdown)Each action shows confirmation popup with list of affected hosts.For big cluster this may be 2000+ hosts.If there are more than 3 hosts  then show 'host1  host2  host3  and X more hosts show all', host page action action menu dropdown dropdown action show confirm popup list affect host host big cluster may host host host show host host host host host host host show,0,0,0,0,0,ambari-web/app/controllers/wizard/step8_controller.js;ambari-web/app/messages.js;ambari-web/app/styles/application.less;ambari-web/app/templates/main/host/bulk_operation_confirm_popup.hbs;ambari-web/app/views/main/host.js;ambari-web/test/controllers/wizard/step8_test.js;,0 
6140,Antonenko Alexander,ambari-web,0,Step3. Hosts checks requests, step step host check request,Proceed to step3  wait while registration is complete.Host checks requests are set every second.UI should set next request only when previous is completed., proce step step wait registr complet host complet host check request set everi second UI second UI set next request previou complet complet,0,0,0,0,0,0,0 
6146,Xi Wang,ambari-web,0,It's not possible to input 'Enter' on 'Target hosts' textarea on 2nd step of Installer wizard', not possibl input enter enter target target host host textarea nd step instal wizard wizard,It's not possible to input 'Enter' on 'Target hosts' textarea., not possibl input enter enter target target host host textarea textarea,0,0,0,0,0,0,0 
6147,Xi Wang,ambari-web,0,Ambari Dashboard page  click NameNode link returns wrong page, ambari dashboard page click NameNode name node link return wrong page,STR:1. go to dashboard page2. click NameNode link inside HDFS Links widget.instead of go to NameNode host detail page  it returns an empty page, STR STR go dashboard page page click NameNode name node link insid HDFS link widget instead widget instead go NameNode name node host detail page return empti page,0,0,0,0,0,0,0 
6155,Oleg Nechiporenko,ambari-web,0,JS error on POST config group request (step7 installer), JS error POST config group request step step instal instal,Go to installer step7Click override for some propertySelect 'New Config Group'Click 'OK'JS-error appears - 404 error. Missing clusterName in request URL., Go instal step click step click overrid propertySelect properti select new new config group click group click OK JS error OK JS error appear error error miss clusterName cluster name request URL URL,0,0,0,0,0,0,0 
6162,Oleg Nechiporenko,ambari-web,0,Behavior change: host filtering no longer handles startsWith matches, behavior chang chang host filter no longer handl startsWith start match,If I have a host that has IP 10.0.2.15  in Ambari 1.6.0 if I start to filter by IP (by typing 10.0....)  the hosts that match 'startsWith' stay displayed.In Ambari 1.6.1  now it only does exact match  so once I start typing  all hosts disappear until I finally type the whole thing in for exact match.Hosts/ip.matches(10), host IP ambari start filter IP type host match startsWith start stay display display ambari exact match start type host disappear final type whole thing exact match host ip match match host ip match,0,0,0,0,0,0,0 
6169,Jaimin D Jetly,ambari-web,0,Installer wizard: ambari web-client issues invalid requests after switching stacks, instal wizard wizard ambari web client web client issu invalid request switch stack,Steps To Reproduce Select 2.X stack and go ahead to 'Select Services' page Navigate back to 'Select Stack' page and select 1.x stack Go ahead to step-8 'Review' page. On clicking next  API call to create components for HDFS service fails with UI displaying an error message.Invalid Request: Unsupported or invalid component in stack  clusterName=cc  serviceName=HDFS  componentName=JOURNALNODE  stackInfo=HDP-1.3, step reproduc select stack go ahead select select servic servic page navig back select select stack stack page select stack Go ahead step step review review page page click next API call creat compon HDFS servic fail UI display error messag invalid messag invalid request request unsupport invalid compon stack clusterName cc cluster name cc serviceName HDFS servic name HDFS componentName JOURNALNODE compon name JOURNALNODE stackInfo HDP stack info HDP,0,0,0,0,0,0,0 
6184,Dmitry Lysnichenko,ambari-agent,0,Incorrect value for started_count of Datanode component, incorrect valu started_count datanod compon,STR:  Installed a 3-node cluster for HDP 1.3 stack HDFS+MapReduce+Nagios+Ganglia+zooKeeper installed with slave components installed on all 3 hosts. Enable security with no kerberos setup On expected failure of security wizard  Disable security. After successfully disabling security  Following API returns incorrect number for started_count of Datanode. It says 0 but Datanode is actually running on all hostshttp://server:8080/api/v1/clusters/c1/components/?ServiceComponentInfo/category.in(SLAVE CLIENT)&amp;fields=ServiceComponentInfo/service_name ServiceComponentInfo/installed_count ServiceComponentInfo/started_count ServiceComponentInfo/total_count&amp;minimal_response=trueReason:During wrong kerberos setup DN processes fail to start  but leave stale pid file owned by root. Next one DN start command starts DN process  but can not override pid file. So the server considers DN as stopped. If we start DN once more  commands fail soon after start (due to lock file at data dir owned by already running DN). Agent reports to server that DN is not running  so server displays a correct information from his point of view., STR STR instal node cluster HDP stack HDFS MapReduce nagio ganglia zooKeeper HDFS map reduc nagio ganglia zoo keeper instal slave compon instal host host enabl secur no kerbero setup expect failur secur wizard disabl secur secur success disabl secur follow API return incorrect number started_count datanod datanod say datanod actual run hostshttp server api cluster compon ServiceComponentInfo categori SLAVE hostshttp server api cluster compon servic compon info categori SLAVE CLIENT amp field ServiceComponentInfo service_name CLIENT amp field servic compon info service_name ServiceComponentInfo installed_count servic compon info installed_count ServiceComponentInfo started_count servic compon info started_count ServiceComponentInfo total_count amp minimal_response trueReason servic compon info total_count amp minimal_response true reason wrong kerbero setup DN process fail start leav stale pid file own root root next one DN start command start DN process not overrid pid file file server consid DN stop stop start DN command fail soon start due lock file data dir own alreadi run DN DN agent report server DN not run server display correct inform point view view,0,0,0,0,0,0,0 
6194,Xi Wang,ambari-web,0,Unsuitable height of dropdown menu on metrics page, unsuit height dropdown menu metric page,STR:Delete all widgets from dashboard.Go to Metrics-&gt;Add menu.Result: Appeared inappropriate dropdown: bad_metrics.png, STR delet STR delet widget dashboard Go dashboard Go metric gt add metric gt add menu result menu result appear inappropri dropdown dropdown bad_metrics png bad_metrics png,0,0,0,0,0,0,0 
6197,Jaimin D Jetly,ambari-web,0,Decommissioned running DataNode has 'delete' menu item in action pulldown, decommiss run DataNode data node delet delet menu item action pulldown,Delete operation is not allowed for a hostComponent if it is in STARTED state.Currently delete menu item is shown when a hostComponent is flagged decommissioned and in STARTED state. Performing delete operation in this condition returns API 500 server error. If the hostComponent is brought in INSTALLED state with the decommissioned flag and then delete operation is performed then it happens as expectedDelete menu item should be shown When hostComponent is in INSTALLED state and should be grayed when it is in STARTED state. ambari-web client should not consider decommission status of a hostComponent while validating the required condition to enable/disable 'delete' menu item., delet oper not allow hostComponent host compon STARTED state current state current delet menu item shown hostComponent host compon flag decommiss STARTED state state perform delet oper condit return API server error error hostComponent host compon brought INSTALLED state decommiss flag delet oper perform happen expectedDelete expect delet menu item shown hostComponent host compon INSTALLED state gray STARTED state state ambari web ambari web client not consid decommiss statu hostComponent host compon valid requir condit enabl disabl enabl disabl delet delet menu item item,0,0,0,0,0,0,0 
6199,Jaimin D Jetly,ambari-web,0,ListBoxes with hostnames on 'Select Hosts' page of 'Enable NameNode HA Wizard' do not work, ListBoxes list box hostnam select select host host page enabl enabl NameNode name node HA wizard wizard not work,On the second step of HA 'Enable NameNode HA Wizard' do not work listboxes with hostnames. Real additional components position does not depend from values in listboxes (see screenshots).It is possible to choose any host in any listbox  which is incorrect., second step HA enabl enabl NameNode name node HA wizard wizard not work listbox hostnam hostnam real addit compon posit not depend valu listbox see screenshot screenshot possibl choos host listbox incorrect incorrect,0,0,0,0,0,0,0 
6201,John Speidel,null,0,Fix sub-resource names in /stacks API, fix sub resourc sub resourc name stack API,The /stacks api uses sub-resource names such as stackServices and serviceComponents instead of services and components which are the names of the resources specified in the URL. These incorrect resource names would need to be used in any queries for stack resources.For example:To get stack service named HDFS the URL would be:api/v1/stacks/HDP/versions/2.1/services/HDFSBut  if we wanted to do a query of for HDFS services across all versions:api/v1/stacks/HDP/versions?stackServices/StackServices/service_name=HDFSInstead this should be:api/v1/stacks/HDP/versions?services/StackServices/service_name=HDFSFix all sub-resource names that are returned and fix sub-resource names used in queries and partial response., stack api use sub resourc sub resourc name stackServices stack servic serviceComponents servic compon instead servic compon name resourc specifi URL URL incorrect resourc name would need use queri stack resourc resourc exampl exampl get stack servic name HDFS URL would api stack HDP version servic HDFSBut api stack HDP version servic HDFS want queri HDFS servic across version api stack HDP version stackServices StackServices service_name HDFSInstead version api stack HDP version stack servic stack servic service_name HDFS instead api stack HDP version servic StackServices service_name HDFSFix api stack HDP version servic stack servic service_name HDFS fix sub resourc sub resourc name return fix sub resourc sub resourc name use queri partial respons respons,0,0,0,0,0,0,0 
6203,Andrii Tkach,ambari-web,0,Unable to assign host in HA wizard, unabl assign host HA wizard,STR:1. Open HA wizard2. Proceed to Select Host step3. Try to select host for any master componentResult:nothing changing  js error emerge., STR STR open HA wizard wizard proce select host step step tri select host master componentResult noth compon result noth chang js error emerg emerg,0,0,0,0,0,ambari-web/app/styles/application.less;ambari-web/app/templates/main/admin/highAvailability/step2.hbs;,0 
6206,Aleksandr Kovalenko,ambari-web,0,BGO popup: Incorrect number of tasks in category, BGO popup popup incorrect number task categori,Tasks with 'aborted' status are not included in any 'Aborted' category., task abort abort statu not includ abort abort categori categori,0,0,0,0,0,0,0 
6207,Antonenko Alexander,ambari-web,0,Installer Wizard Step 7-8: namenode_heapsize property incorrect value., instal wizard step namenode_heapsize properti incorrect valu valu,On the Step 7 namenode_heapsize value is empty and on deploy even if its value filled it saved as 'm' which cause error on NameNode startup.Part of object passed for configuration saving:namenode_heapsize: 'm'namenode_opt_maxnewsize: '200m'namenode_opt_newsize: '200m'nodemanager_heapsize: '1024', step namenode_heapsize valu empti deploy even valu fill save caus error NameNode name node startup part startup part object pass configur save namenode_heapsize save namenode_heapsize namenode_opt_maxnewsize namenode_opt_maxnewsize namenode_opt_newsize namenode_opt_newsize nodemanager_heapsize nodemanager_heapsize,0,0,0,0,0,0,0 
6208,Antonenko Alexander,ambari-web,0,Nagios 'Restart all components' button does not work, nagio restart restart compon compon button not work,On service page for Nagios  under 'Service actions' menu  'Restart all' operation does not work correctly. There is dialog window after pressing  but after confirmation there is not any activity. In API there is not any new request.Note: described situation relates only for Nagios. Other services make restart correctly (including generating new requests in API)., servic page nagio servic servic action action menu restart restart oper not work correctli correctli dialog window press confirm not activ activ API not new request note request note describ situat relat nagio nagio servic make restart correctli includ gener new request API API,0,0,0,0,0,0,0 
6215,Antonenko Alexander,ambari-web,0,Default add host sequence triggers many unseen before cluster-wide operations, default add host sequenc trigger mani unseen cluster wide cluster wide oper,I've added 1 host through the add host wizardon deploy step all hosts were present. and install operations were performed on all of them., ad host add host wizardon deploy step host present present instal oper perform,0,0,0,0,0,0,0 
6221,Myroslav Papirkovskyy,ambari-server,0,Ambari Server reset show wrong commands for DB manipulation, ambari server reset show wrong command DB manipul,When performing ambari-server reset with external DB  ambari-server does nothing but outputs commands for resetting it manually.But:1. Commands are wrong  at least on Suse:su -postgres --command=psql -f /var/lib/ambari-server/resources/Ambari-DDL-Postgres-DROP.sql -v username=''ambari'' -v password=''bigdata''su: invalid option -- 'o'Try 'su --help' for more information.2. This commands should take in account that external DB can be located on the another host.3. Maybe the best option would be to give user ability to reset automatically  for example via command line switch like ambari-server reset -a, perform ambari server ambari server reset extern DB ambari server ambari server noth output command reset manual manual command wrong least suse su suse su postgr command psql command psql var lib ambari server resourc ambari DDL postgr DROP sql var lib ambari server resourc ambari DDL postgr DROP sql usernam ambari usernam ambari password bigdata su password bigdata su invalid option tri tri su help help inform inform command take account extern DB locat anoth host host mayb best option would give user abil reset automat exampl via command line switch like ambari server ambari server reset,0,0,0,0,0,0,0 
6228,Xi Wang,ambari-web,0,host checks 'Show Report' link is missing from dialog, host check show show report report link miss dialog,On 'Confirm Hosts' step &gt; Hosts Check popup window  the 'Show Reports' link is missing even if the host check warnings existed.Reason:The newly added hosts checks (jdk  disk  repo and hostNameResolution) dont trigger the ''show reports' link to show up., confirm confirm host host step gt gt host check popup window show show report report link miss even host check warn exist reason exist reason newli ad host check jdk disk repo hostNameResolution host name resolut dont trigger show report report link show,0,0,0,0,0,0,0 
6234,Dmitry Lysnichenko,ambari-server,0,Security issue - private key password show in logs, secur issu privat key password show log,During generating private key and certificates using openssl password of key shown in logs:11:21:30 735 INFO [main] ShellCommandUtil:44 - Command openssl genrsa -des3 -passout pass:**** -out /var/lib/ambari-server/keys/ca.key 4096 was finished with exit code: 0 - the operation was completely successfully.11:21:30 750 INFO [main] ShellCommandUtil:44 - Command openssl req -passin pass:**** -new -key /var/lib/ambari-server/keys/ca.key -out /var/lib/ambari-server/keys/ca.csr -batch was finished with exit code: 0 - the operation was completely successfully.11:21:30 766 INFO [main] ShellCommandUtil:44 - Command open**** ca -create_serial -out /var/lib/ambari-server/keys/ca.crt -days 365 -keyfile /var/lib/ambari-server/keys/ca.key -key vgGAzzSaCPkI3F7UU7qZZY6CahDUTSnY7B9a8TH0YiGDB10LdJ -selfsign -extensions jdk7_ca -config /var/lib/ambari-server/keys/ca.config -batch -infiles /var/lib/ambari-server/keys/ca.csr was finished with exit code: 0 - the operation was completely successfully.11:21:30 773 INFO [main] ShellCommandUtil:44 - Command openssl pkcs12 -export -in /var/lib/ambari-server/keys/ca.crt -inkey /var/lib/ambari-server/keys/ca.key -certfile /var/lib/ambari-server/keys/ca.crt -out /var/lib/ambari-server/keys/keystore.p12 -password pass:**** -passin pass:**** see '-key vgGAzzSaCPkI3F7UU7qZZY6CahDUTSnY7B9a8TH0YiGDB10LdJ', gener privat key certif use openssl password key shown log log INFO main main ShellCommandUtil shell command util command openssl genrsa de de passout pass pass var lib ambari server key ca key var lib ambari server key ca key finish exit code code oper complet success success INFO main main ShellCommandUtil shell command util command openssl req passin pass pass new key var lib ambari server key ca key var lib ambari server key ca key var lib ambari server key ca csr var lib ambari server key ca csr batch finish exit code code oper complet success success INFO main main ShellCommandUtil shell command util command open open ca create_serial var lib ambari server key ca crt var lib ambari server key ca crt day keyfil var lib ambari server key ca key var lib ambari server key ca key key vgGAzzSaCPkI UU qZZY CahDUTSnY TH YiGDB LdJ vg azz Sa Pk UU ZZY cah DUT Sn TH Yi GDB Ld selfsign extens jdk _ca jdk _ca config var lib ambari server key ca config var lib ambari server key ca config batch infil var lib ambari server key ca csr var lib ambari server key ca csr finish exit code code oper complet success success INFO main main ShellCommandUtil shell command util command openssl pkc pkc export var lib ambari server key ca crt var lib ambari server key ca crt inkey var lib ambari server key ca key var lib ambari server key ca key certfil var lib ambari server key ca crt var lib ambari server key ca crt var lib ambari server key keystor var lib ambari server key keystor password pass pass passin pass pass see key vgGAzzSaCPkI UU qZZY CahDUTSnY TH YiGDB LdJ vg azz Sa Pk UU ZZY cah DUT Sn TH Yi GDB Ld,0,0,0,0,0,0,0 
6236,Oleg Nechiporenko,ambari-web,0,Hosts page: there is no indication that filtering/sorting/paging is happening or not (confusing), host page page no indic filter sort page filter sort page happen not confus confus,In 1.6.1  filtering/sorting/paging on the Hosts page has been converted from client-side to server-side in order to address scalability issues.As a result of that  the responsiveness of UI is dependent upon how quickly the server can respond to filtering/sorting/paging calls (and also depends on the network). While UI is waiting for the new table content to come from the server  there should be some indication that work is in progress. For example  we can put an overlay on the table with a spinner (gray out the table with a spinner on top - kind of like when switching filters on JIRA's Agile Board)., filter sort page filter sort page host page convert client side client side server side server side order address scalabl issu issu result respons UI depend upon quickli server respond filter sort page filter sort page call also depend network network UI wait new tabl content come server indic work progress progress exampl put overlay tabl spinner gray tabl spinner top kind like switch filter JIRA JIRA agil board board,0,0,0,0,0,0,0 
6244,Xi Wang,ambari-web,0,Restart icon is present after Service Actions->Restart all button click., restart icon present servic action restart action restart button click click,STR:Change property for some service (Hive as example)Save changesClick Service Actions-&gt;Restart all buttonActual result:Service Actions-&gt;Restart all button does not work (do nothing). Restart passed  but restart icon still present.Expected result:Service Actions-&gt;Restart all button works. Restart passed  restart icon is not present after action., STR chang STR chang properti servic hive hive exampl save exampl save changesClick chang click servic action gt restart action gt restart buttonActual button actual result servic result servic action gt restart action gt restart button not work noth noth restart pass restart icon still present expect present expect result servic result servic action gt restart action gt restart button work work restart pass restart icon not present action action,0,0,0,0,0,0,0 
6247,Antonenko Alexander,ambari-web,0,Add host stops all services, add host stop servic,STR Install cluster Add hostActual resultAfter adding host all components on all hosts are stoppedExpected resultAll components on all hosts are started, STR instal cluster add hostActual host actual resultAfter result ad host compon host stoppedExpected stop expect resultAll result compon host start,0,0,0,0,0,0,0 
6265,Xi Wang,ambari-web,0,Have spinners instead of charts at Dashboard and Service tabs on IE 11, spinner instead chart dashboard servic tab IE,STR:1) Deploy cluster with defualt settings.2) Navigate on Dashboard pageExpected result:All charts are present.Actual result:Have spinners instead some charts., STR STR deploy cluster defualt set set navig dashboard pageExpected page expect result result chart present actual present actual result result spinner instead chart chart,0,0,0,0,0,0,0 
6267,Andrii Tkach,ambari-web,0,Add Services fails with a server error under some conditions, add servic fail server error condit,Upon clicking on 'Deploy' from Review page in Add Services Wizard  sometimes the UI shows a server error saying 'Resource Already Exists'.It looks like the UI is trying to add client components on hosts that already have them.I've seen it for HDFS_CLIENT  MAPREDUCE2_CLIENT  etc.  when trying to add Oozie (for sure)  Storm (I think)  and possibly others., upon click deploy deploy review page add servic wizard sometim UI show server error say resourc resourc alreadi exist exist look like UI tri add client compon host alreadi seen HDFS_CLIENT HDFS CLIENT MAPREDUCE _CLIENT MAPREDUCE  CLIENT etc etc tri add oozi sure sure storm think think possibl other other,0,0,0,0,0,ambari-web/app/controllers/wizard/step8_controller.js;ambari-web/app/utils/ajax/ajax.js;,0 
6268,Antonenko Alexander,ambari-web,0,step 6 pagination is slow, step pagin slow,,,0,0,0,0,0,0,0 
6270,Andrew Onischuk,ambari-server; stacks,0,Repoinfo.xml should use family tag rather than type tag, repoinfo xml repoinfo xml use famili tag rather type tag,That is a bit confusing we should change that  since we changed the way itworks &lt;os type='redhat6'&gt;should be &lt;os family='redhat6'&gt;, bit confus chang sinc chang way itwork lt os lt os type redhat gt type redhat gt lt os lt os famili redhat gt famili redhat gt,0,0,0,0,0,0,0 
6273,Antonenko Alexander,ambari-web,0,Manage Config Groups: if Ganglia is not installed config group popup doesn't appear, manag config group group ganglia not instal config group popup appear,We take some data from Ganglia metrics for hosts and if Ganglia is not installed browser throw js error which blocks popup initializing., take data ganglia metric host ganglia not instal browser throw js error block popup initi initi,0,0,0,0,0,0,0 
6276,Andrii Babiichuk,ambari-web,0,Prompt to put Service in Maintenance Mode when doing Rolling Restart / Service Stop, prompt put servic mainten mode roll restart servic stop,When initiating Rolling Restart / Service Stop  they would like an option (via a checkbox  for example) to put the service in maintenance mode (if it is not already in MM) to avoid getting a lot of alerts., initi roll restart servic stop would like option via checkbox exampl exampl put servic mainten mode not alreadi MM MM avoid get lot alert alert,0,0,0,0,0,ambari-web/app/controllers/main/service/item.js;ambari-web/app/templates/common/confirmation_feedback.hbs;ambari-web/app/templates/common/rolling_restart_view.hbs;ambari-web/app/utils/ajax/ajax.js;ambari-web/app/utils/batch_scheduled_requests.js;ambari-web/app/views/common/modal_popup.js;ambari-web/app/views/common/rolling_restart_view.js;,0 
6292,Greg Hill,ambari-web,0,Python client caches curl flags between requests causing problems, python client cach curl flag request caus problem,Currently if you use the python client  if you issue a DELETE request followed by a GET request  that GET request becomes a DELETE request. You can imagine why that's undesirable.The problem is that we set the CUSTOMREQUEST field on the DELETE  but we don't unset it on the next GET. pycurl sees it still set and assumes we're still doing a DELETE., current use python client issu DELETE request follow GET request GET request becom DELETE request request imagin undesir undesir problem set CUSTOMREQUEST field DELETE unset next GET GET pycurl see still set assum still DELETE DELETE,0,0,0,0,0,0,0 
6295,Srimanth Gunturi,ambari-web,0,UI freezes for more than 2 seconds  every 15 seconds  on 2K-node cluster, UI freez second everi second node node cluster,It seems that we call App.componentConfigMapper every 15 seconds.This mapper takes more than 2 seconds to run. While the mapper is running  the entire UI is frozen., seem call app componentConfigMapper app compon config mapper everi second second mapper take second run run mapper run entir UI frozen frozen,0,0,0,0,0,0,0 
6298,Siddharth Wagle,ambari-server,0,Custom Command execution takes too long, custom command execut take long,It takes significant amount of time to populate clusterHostInfo for every Execution Cmd on a 2000 node cluster.org.apache.ambari.server.utils.StageUtils.getClusterHostInfo(Map  Cluster), take signific amount time popul clusterHostInfo cluster host info everi execut cmd node cluster org apach ambari server util StageUtils getClusterHostInfo map cluster org apach ambari server util stage util get cluster host info map cluster cluster,0,0,0,0,0,0,0 
6299,Siddharth Wagle,ambari-server,0,JMXPropertyProvider makes call to endpoint without checking support for properties, JMXPropertyProvider JMX properti provid make call endpoint without check support properti,Causes CPU usage go upto 1500 % and UI becomes unusable.1000's of Exception:00:01:50 666 ERROR [pool-1-thread-17] JMXPropertyProvider:539 - Caught exception getting JMX metrics : Connection refusedAll JMX endpoints called for any JMX metric., caus CPU usag go upto UI becom unus unus except except ERROR pool thread pool thread JMXPropertyProvider JMX properti provid caught except get JMX metric connect refusedAll refus JMX endpoint call JMX metric metric,0,0,0,0,0,0,0 
6311,Antonenko Alexander,ambari-web,0,Bulk Ops only targets a maximum of 'page size' hosts, bulk op target maximum page size size host,It seems that the max number of target hosts for a bulk operation is capped by the current 'page size' on the Hosts page.For example  on the 2K cluster with 2K DataNodes: Go to Hosts page Click on Actions. Either going to Filtered Hosts (2005) or All Hosts (2005)  select 'DataNodes &gt; Stop' A confirmation popup tells me that 50 DataNodes are about to be stopped. This should have been ~ 2000 DataNodes instead. 50 is the current page size on the Hosts page that I set.Another scenario: Set page size to 50. Select 100 hosts using 'check all'  'next page'  then 'check all' Go to 'Actions &gt; Selected Hosts &gt; DataNodes &gt; Stop'. Again  it tries to perform actions on only 50 DataNodes., seem max number target host bulk oper cap current page size size host page page exampl cluster DataNodes data node Go host page click action action either go filter host host select DataNodes data node gt gt stop stop confirm popup tell DataNodes data node stop stop DataNodes data node instead instead current page size host page set anoth set anoth scenario scenario set page size select host use check next page page check Go action action gt gt select host gt gt DataNodes data node gt gt stop stop tri perform action DataNodes data node,0,0,0,0,0,0,0 
6322,Srimanth Gunturi,ambari-web,0,Choosing bulk hosts to decommission on 120 node cluster on the hosts page just spins., choos bulk host decommiss node cluster host page spin spin,Steps to reproduce1. Filter by DataNodes2. Increase the page size to 503. Select all 50 and decommision datanodes.This ends up with a spinner .This might be a blocker. Attaching snapshot., step reproduc reproduc filter DataNodes data node increas page size select decommis datanod datanod end spinner might blocker blocker attach snapshot snapshot,0,0,0,0,0,0,0 
6327,Srimanth Gunturi,ambari-web,0,Rolling Restart: 'only start stale' checkbox not worked functionally, roll restart restart start stale stale checkbox not work function,Rolling restart page  there is a ' Only restart NodeManagers with stale configs' checkbox  nothing happened no matter if that one was checked or not. 1. On service(HDFS or YARN) actions &gt; restart all DN (NM). All DN(NM) will be restart no matter if the ' Only restart NodeManagers with stale configs' option checked., roll restart page restart NodeManagers node manag stale config config checkbox noth happen no matter one check not not servic HDFS servic HDFS YARN YARN action gt gt restart DN NM NM DN NM DN NM restart no matter restart NodeManagers node manag stale config config option check check,0,0,0,0,0,0,0 
6332,Andrii Babiichuk,ambari-web,0,Bulk Decommission: Background Operation Popup content looks broken, bulk decommiss decommiss background oper popup content look broken,header in task details popup looks broken when we run decommission for many Datanodes., header task detail popup look broken run decommiss mani datanod datanod,0,0,0,0,0,ambari-web/app/templates/wizard/step9/step9HostTasksLogPopup.hbs;ambari-web/app/styles/application.less;ambari-web/app/templates/common/host_progress_popup.hbs;,0 
6335,Andrii Tkach,ambari-web,0,Add service wizard removes any new property added to core-site and global after cluster installation, add servic wizard remov new properti ad core site core site global cluster instal,,,0,0,0,0,0,ambari-web/app/controllers/global/cluster_controller.js;ambari-web/app/controllers/wizard/step7_controller.js;ambari-web/app/controllers/wizard/step8_controller.js;ambari-web/app/utils/config.js;,0 
6337,Aleksandr Kovalenko,ambari-web,0,Hosts page. Incorrect total number of hosts after filtering by installed component, host page page incorrect total number host filter instal compon,STR1. Go to hosts page2. Filter by Components. Check DATANODE3. At Bottom right corner I see Show 10 | 1-10 of 10, STR STR Go host page page filter compon compon check DATANODE DATANODE bottom right corner see show,0,0,0,0,0,0,0 
6340,Aleksandr Kovalenko,ambari-web,0,filtering by selected hosts resets pagination, filter select host reset pagin,1. page size 102. select all 10 hosts on first page3. go to page 2  select 2 hosts (total 12 selection)4. click on '12 host selected' and it goes to page 1  1-10 of 12 hosts (correct)5. click to go to page 2 (to see the 2 hosts selected) but it resets to page 1  1-10 of 103, page size select host first page page go page select host total select select click host select select goe page host correct correct click go page see host select select reset page,0,0,0,0,0,0,0 
6349,Srimanth Gunturi,ambari-web,0,After changing property and clicking save button in MapReduce Config Page  no comfirmation popup, chang properti click save button MapReduce map reduc config page no comfirm popup,STR1. Go to MapReduce Config Page2. Change JobTracker new generation size with a new value3. Clike Save buttonResult no confirmation popup  and save button turns grey  when switching pages the save button in the warning popup is not working neither., STR STR Go MapReduce map reduc config page page chang JobTracker job tracker new gener size new valu valu clike save buttonResult button result no confirm popup save button turn grey switch page save button warn popup not work neither neither,0,0,0,0,0,0,0 
6350,Andrii Tkach,ambari-web,0,Unable to restart all host-components on 110 node cluster, unabl restart host compon host compon node cluster,On a 110 node cluster I went to the hosts page and went into All Hosts &gt; Hosts &gt; Restart All Components. Following that I got an error dialog (image attached) and the below exceptions in the log21:03:20 017 ERROR [qtp1391464722-1188] AmbariJpaLocalTxnInterceptor:114 - [DETAILED ERROR] Rollback reason:Local Exception Stack:Exception [EclipseLink-4002] (Eclipse Persistence Services - 2.4.0.v20120608-r11652): org.eclipse.persistence.exceptions.DatabaseExceptionInternal Exception: java.sql.BatchUpdateException: Batch entry 0 INSERT INTO requestoperationlevel (operation_level_id  cluster_name  host_component_name  host_name  level_name  request_id  service_name) VALUES (2  'Horton'  NULL  'horton-1.c.pramod-thangali.internal horton-10.c.pramod-thangali.internal horton-100.c.pramod-thangali.internal horton-101.c.pramod-thangali.internal horton-103.c.pramod-thangali.internal horton-104.c.pramod-thangali.internal horton-105.c.pramod-thangali.internal horton-106.c.pramod-thangali.internal horton-107.c.pramod-thangali.internal horton-108.c.pramod-thangali.internal horton-109.c.pramod-thangali.internal horton-11.c.pramod-thangali.internal horton-12.c.pramod-thangali.internal horton-13.c.pramod-thangali.internal horton-14.c.pramod-thangali.internal horton-15.c.pramod-thangali.internal horton-16.c.pramod-thangali.internal horton-17.c.pramod-thangali.internal horton-18.c.pramod-thangali.internal horton-19.c.pramod-thangali.internal horton-2.c.pramod-thangali.internal horton-20.c.pramod-thangali.internal horton-21.c.pramod-thangali.internal horton-22.c.pramod-thangali.internal horton-23.c.pramod-thangali.internal horton-24.c.pramod-thangali.internal horton-25.c.pramod-thangali.internal horton-26.c.pramod-thangali.internal horton-27.c.pramod-thangali.internal horton-28.c.pramod-thangali.internal horton-29.c.pramod-thangali.internal horton-3.c.pramod-thangali.internal horton-30.c.pramod-thangali.internal horton-31.c.pramod-thangali.internal horton-32.c.pramod-thangali.internal horton-33.c.pramod-thangali.internal horton-34.c.pramod-thangali.internal horton-35.c.pramod-thangali.internal horton-36.c.pramod-thangali.internal horton-37.c.pramod-thangali.internal horton-38.c.pramod-thangali.internal horton-39.c.pramod-thangali.internal horton-4.c.pramod-thangali.internal horton-40.c.pramod-thangali.internal horton-41.c.pramod-thangali.internal horton-42.c.pramod-thangali.internal horton-43.c.pramod-thangali.internal horton-44.c.pramod-thangali.internal horton-45.c.pramod-thangali.internal horton-46.c.pramod-thangali.internal horton-47.c.pramod-thangali.internal horton-48.c.pramod-thangali.internal horton-49.c.pramod-thangali.internal horton-5.c.pramod-thangali.internal horton-50.c.pramod-thangali.internal horton-51.c.pramod-thangali.internal horton-52.c.pramod-thangali.internal horton-53.c.pramod-thangali.internal horton-54.c.pramod-thangali.internal horton-55.c.pramod-thangali.internal horton-56.c.pramod-thangali.internal horton-57.c.pramod-thangali.internal horton-58.c.pramod-thangali.internal horton-59.c.pramod-thangali.internal horton-6.c.pramod-thangali.internal horton-60.c.pramod-thangali.internal horton-61.c.pramod-thangali.internal horton-62.c.pramod-thangali.internal horton-63.c.pramod-thangali.internal horton-64.c.pramod-thangali.internal horton-65.c.pramod-thangali.internal horton-66.c.pramod-thangali.internal horton-67.c.pramod-thangali.internal horton-68.c.pramod-thangali.internal horton-69.c.pramod-thangali.internal horton-7.c.pramod-thangali.internal horton-70.c.pramod-thangali.internal horton-71.c.pramod-thangali.internal horton-72.c.pramod-thangali.internal horton-73.c.pramod-thangali.internal horton-74.c.pramod-thangali.internal horton-75.c.pramod-thangali.internal horton-76.c.pramod-thangali.internal horton-77.c.pramod-thangali.internal horton-78.c.pramod-thangali.internal horton-79.c.pramod-thangali.internal horton-8.c.pramod-thangali.internal horton-80.c.pramod-thangali.internal horton-81.c.pramod-thangali.internal horton-82.c.pramod-thangali.internal horton-83.c.pramod-thangali.internal horton-84.c.pramod-thangali.internal horton-85.c.pramod-thangali.internal horton-86.c.pramod-thangali.internal horton-87.c.pramod-thangali.internal horton-88.c.pramod-thangali.internal horton-9.c.pramod-thangali.internal horton-90.c.pramod-thangali.internal horton-91.c.pramod-thangali.internal horton-92.c.pramod-thangali.internal horton-93.c.pramod-thangali.internal horton-94.c.pramod-thangali.internal horton-95.c.pramod-thangali.internal horton-96.c.pramod-thangali.internal horton-97.c.pramod-thangali.internal horton-98.c.pramod-thangali.internal horton-99.c.pramod-thangali.internal horton-master-1.c.pramod-thangali.internal horton-master-2.c.pramod-thangali.internal horton-master-3.c.pramod-thangali.internal'  'Host'  25  NULL) was aborted. Call getNextException to see the cause.Error Code: 0Call: INSERT INTO requestoperationlevel (operation_level_id  cluster_name  host_component_name  host_name  level_name  request_id  service_name) VALUES (?  ?  ?  ?  ?  ?  ?) bind =&gt; [7 parameters bound]Query: InsertObjectQuery(org.apache.ambari.server.orm.entities.RequestResourceFilterEntity@2c6ae575) at org.eclipse.persistence.exceptions.DatabaseException.sqlException(DatabaseException.java:333) at org.eclipse.persistence.internal.databaseaccess.DatabaseAccessor.processExceptionForCommError(DatabaseAccessor.java:1501) at org.eclipse.persistence.internal.databaseaccess.DatabaseAccessor.executeJDK12BatchStatement(DatabaseAccessor.java:875) at org.eclipse.persistence.internal.databaseaccess.ParameterizedSQLBatchWritingMechanism.executeBatchedStatements(ParameterizedSQLBatchWritingMechanism.java:145) at org.eclipse.persistence.internal.databaseaccess.ParameterizedSQLBatchWritingMechanism.appendCall(ParameterizedSQLBatchWritingMechanism.java:88) at org.eclipse.persistence.internal.databaseaccess.DatabaseAccessor.basicExecuteCall(DatabaseAccessor.java:571) at org.eclipse.persistence.internal.databaseaccess.DatabaseAccessor.executeCall(DatabaseAccessor.java:537) at org.eclipse.persistence.internal.sessions.AbstractSession.basicExecuteCall(AbstractSession.java:1800) at org.eclipse.persistence.sessions.server.ClientSession.executeCall(ClientSession.java:286) at org.eclipse.persistence.internal.queries.DatasourceCallQueryMechanism.executeCall(DatasourceCallQueryMechanism.java:207) at org.eclipse.persistence.internal.queries.DatasourceCallQueryMechanism.executeCall(DatasourceCallQueryMechanism.java:193) at org.eclipse.persistence.internal.queries.DatasourceCallQueryMechanism.insertObject(DatasourceCallQueryMechanism.java:342) at org.eclipse.persistence.internal.queries.StatementQueryMechanism.insertObject(StatementQueryMechanism.java:162) at org.eclipse.persistence.internal.queries.StatementQueryMechanism.insertObject(StatementQueryMechanism.java:177) at org.eclipse.persistence.internal.queries.DatabaseQueryMechanism.insertObjectForWrite(DatabaseQueryMechanism.java:471) at org.eclipse.persistence.queries.InsertObjectQuery.executeCommit(InsertObjectQuery.java:80) at org.eclipse.persistence.queries.InsertObjectQuery.executeCommitWithChangeSet(InsertObjectQuery.java:90) at org.eclipse.persistence.internal.queries.DatabaseQueryMechanism.executeWriteWithChangeSet(DatabaseQueryMechanism.java:286) at org.eclipse.persistence.queries.WriteObjectQuery.executeDatabaseQuery(WriteObjectQuery.java:58) at org.eclipse.persistence.queries.DatabaseQuery.execute(DatabaseQuery.java:852) at org.eclipse.persistence.queries.DatabaseQuery.executeInUnitOfWork(DatabaseQuery.java:751) at org.eclipse.persistence.queries.ObjectLevelModifyQuery.executeInUnitOfWorkObjectLevelModifyQuery(ObjectLevelModifyQuery.java:108) at org.eclipse.persistence.queries.ObjectLevelModifyQuery.executeInUnitOfWork(ObjectLevelModifyQuery.java:85) at org.eclipse.persistence.internal.sessions.UnitOfWorkImpl.internalExecuteQuery(UnitOfWorkImpl.java:2875) at org.eclipse.persistence.internal.sessions.AbstractSession.executeQuery(AbstractSession.java:1602) at org.eclipse.persistence.internal.sessions.AbstractSession.executeQuery(AbstractSession.java:1584) at org.eclipse.persistence.internal.sessions.AbstractSession.executeQuery(AbstractSession.java:1535) at org.eclipse.persistence.internal.sessions.CommitManager.commitNewObjectsForClassWithChangeSet(CommitManager.java:224) at org.eclipse.persistence.internal.sessions.CommitManager.commitAllObjectsForClassWithChangeSet(CommitManager.java:191) at org.eclipse.persistence.internal.sessions.CommitManager.commitAllObjectsWithChangeSet(CommitManager.java:136) at org.eclipse.persistence.internal.sessions.AbstractSession.writeAllObjectsWithChangeSet(AbstractSession.java:3914) at org.eclipse.persistence.internal.sessions.UnitOfWorkImpl.commitToDatabase(UnitOfWorkImpl.java:1419) at org.eclipse.persistence.internal.sessions.RepeatableWriteUnitOfWork.commitToDatabase(RepeatableWriteUnitOfWork.java:634) at org.eclipse.persistence.internal.sessions.UnitOfWorkImpl.commitToDatabaseWithChangeSet(UnitOfWorkImpl.java:1509) at org.eclipse.persistence.internal.sessions.RepeatableWriteUnitOfWork.commitRootUnitOfWork(RepeatableWriteUnitOfWork.java:266) at org.eclipse.persistence.internal.sessions.UnitOfWorkImpl.commitAndResume(UnitOfWorkImpl.java:1147) at org.eclipse.persistence.internal.jpa.transaction.EntityTransactionImpl.commitInternal(EntityTransactionImpl.java:84) at org.eclipse.persistence.internal.jpa.transaction.EntityTransactionImpl.commit(EntityTransactionImpl.java:63) at org.apache.ambari.server.orm.AmbariJpaLocalTxnInterceptor.invoke(AmbariJpaLocalTxnInterceptor.java:91) at com.google.inject.internal.InterceptorStackCallback$InterceptedMethodInvocation.proceed(InterceptorStackCallback.java:72) at com.google.inject.internal.InterceptorStackCallback.intercept(InterceptorStackCallback.java:52) at org.apache.ambari.server.actionmanager.ActionDBAccessorImpl$$EnhancerByGuice$$ddd0d231.persistActions(&lt;generated&gt;) at org.apache.ambari.server.actionmanager.ActionManager.sendActions(ActionManager.java:95) at org.apache.ambari.server.actionmanager.ActionManager.sendActions(ActionManager.java:84) at org.apache.ambari.server.controller.AmbariManagementControllerImpl.createAction(AmbariManagementControllerImpl.java:2583) at org.apache.ambari.server.controller.internal.RequestResourceProvider$1.invoke(RequestResourceProvider.java:124) at org.apache.ambari.server.controller.internal.RequestResourceProvider$1.invoke(RequestResourceProvider.java:121) at org.apache.ambari.server.controller.internal.AbstractResourceProvider.createResources(AbstractResourceProvider.java:237) at org.apache.ambari.server.controller.internal.RequestResourceProvider.createResources(RequestResourceProvider.java:121) at org.apache.ambari.server.controller.internal.ClusterControllerImpl.createResources(ClusterControllerImpl.java:274) at org.apache.ambari.server.api.services.persistence.PersistenceManagerImpl.create(PersistenceManagerImpl.java:75) at org.apache.ambari.server.api.handlers.CreateHandler.persist(CreateHandler.java:36) at org.apache.ambari.server.api.handlers.BaseManagementHandler.handleRequest(BaseManagementHandler.java:72) at org.apache.ambari.server.api.services.BaseRequest.process(BaseRequest.java:135) at org.apache.ambari.server.api.services.BaseService.handleRequest(BaseService.java:103) at org.apache.ambari.server.api.services.BaseService.handleRequest(BaseService.java:72) at org.apache.ambari.server.api.services.RequestService.createRequests(RequestService.java:119) at sun.reflect.GeneratedMethodAccessor113.invoke(Unknown Source), node cluster went host page went host gt gt host gt gt restart compon compon follow got error dialog imag attach attach except log log ERROR qtp qtp AmbariJpaLocalTxnInterceptor ambari jpa local txn interceptor DETAILED DETAILED ERROR ERROR rollback reason local reason local except stack except stack except EclipseLink eclips link eclips eclips persist servic org eclips persist except DatabaseExceptionInternal org eclips persist except databas except intern except except java sql BatchUpdateException java sql batch updat except batch entri INSERT requestoperationlevel operation_level_id cluster_name host_component_name host_name level_name request_id service_name service_name VALUES horton horton NULL horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton pramod thangali intern horton master pramod thangali intern horton master pramod thangali intern horton master pramod thangali intern horton master pramod thangali intern horton master pramod thangali intern horton master pramod thangali intern host host NULL NULL abort abort call getNextException get next except see caus error caus error code code call call INSERT requestoperationlevel operation_level_id cluster_name host_component_name host_name level_name request_id service_name service_name VALUES bind gt gt paramet bound queri bound queri InsertObjectQuery org apach ambari server orm entiti RequestResourceFilterEntity ae insert object queri org apach ambari server orm entiti request resourc filter entiti ae org eclips persist except DatabaseException sqlException DatabaseException java org eclips persist except databas except sql except databas except java org eclips persist intern databaseaccess DatabaseAccessor processExceptionForCommError DatabaseAccessor java org eclips persist intern databaseaccess databas accessor process except comm error databas accessor java org eclips persist intern databaseaccess DatabaseAccessor executeJDK BatchStatement DatabaseAccessor java org eclips persist intern databaseaccess databas accessor execut JDK batch statement databas accessor java org eclips persist intern databaseaccess ParameterizedSQLBatchWritingMechanism executeBatchedStatements ParameterizedSQLBatchWritingMechanism java org eclips persist intern databaseaccess parameter SQL batch write mechan execut batch statement parameter SQL batch write mechan java org eclips persist intern databaseaccess ParameterizedSQLBatchWritingMechanism appendCall ParameterizedSQLBatchWritingMechanism java org eclips persist intern databaseaccess parameter SQL batch write mechan append call parameter SQL batch write mechan java org eclips persist intern databaseaccess DatabaseAccessor basicExecuteCall DatabaseAccessor java org eclips persist intern databaseaccess databas accessor basic execut call databas accessor java org eclips persist intern databaseaccess DatabaseAccessor executeCall DatabaseAccessor java org eclips persist intern databaseaccess databas accessor execut call databas accessor java org eclips persist intern session AbstractSession basicExecuteCall AbstractSession java org eclips persist intern session abstract session basic execut call abstract session java org eclips persist session server ClientSession executeCall ClientSession java org eclips persist session server client session execut call client session java org eclips persist intern queri DatasourceCallQueryMechanism executeCall DatasourceCallQueryMechanism java org eclips persist intern queri datasourc call queri mechan execut call datasourc call queri mechan java org eclips persist intern queri DatasourceCallQueryMechanism executeCall DatasourceCallQueryMechanism java org eclips persist intern queri datasourc call queri mechan execut call datasourc call queri mechan java org eclips persist intern queri DatasourceCallQueryMechanism insertObject DatasourceCallQueryMechanism java org eclips persist intern queri datasourc call queri mechan insert object datasourc call queri mechan java org eclips persist intern queri StatementQueryMechanism insertObject StatementQueryMechanism java org eclips persist intern queri statement queri mechan insert object statement queri mechan java org eclips persist intern queri StatementQueryMechanism insertObject StatementQueryMechanism java org eclips persist intern queri statement queri mechan insert object statement queri mechan java org eclips persist intern queri DatabaseQueryMechanism insertObjectForWrite DatabaseQueryMechanism java org eclips persist intern queri databas queri mechan insert object write databas queri mechan java org eclips persist queri InsertObjectQuery executeCommit InsertObjectQuery java org eclips persist queri insert object queri execut commit insert object queri java org eclips persist queri InsertObjectQuery executeCommitWithChangeSet InsertObjectQuery java org eclips persist queri insert object queri execut commit chang set insert object queri java org eclips persist intern queri DatabaseQueryMechanism executeWriteWithChangeSet DatabaseQueryMechanism java org eclips persist intern queri databas queri mechan execut write chang set databas queri mechan java org eclips persist queri WriteObjectQuery executeDatabaseQuery WriteObjectQuery java org eclips persist queri write object queri execut databas queri write object queri java org eclips persist queri DatabaseQuery execut DatabaseQuery java org eclips persist queri databas queri execut databas queri java org eclips persist queri DatabaseQuery executeInUnitOfWork DatabaseQuery java org eclips persist queri databas queri execut unit work databas queri java org eclips persist queri ObjectLevelModifyQuery executeInUnitOfWorkObjectLevelModifyQuery ObjectLevelModifyQuery java org eclips persist queri object level modifi queri execut unit work object level modifi queri object level modifi queri java org eclips persist queri ObjectLevelModifyQuery executeInUnitOfWork ObjectLevelModifyQuery java org eclips persist queri object level modifi queri execut unit work object level modifi queri java org eclips persist intern session UnitOfWorkImpl internalExecuteQuery UnitOfWorkImpl java org eclips persist intern session unit work impl intern execut queri unit work impl java org eclips persist intern session AbstractSession executeQuery AbstractSession java org eclips persist intern session abstract session execut queri abstract session java org eclips persist intern session AbstractSession executeQuery AbstractSession java org eclips persist intern session abstract session execut queri abstract session java org eclips persist intern session AbstractSession executeQuery AbstractSession java org eclips persist intern session abstract session execut queri abstract session java org eclips persist intern session CommitManager commitNewObjectsForClassWithChangeSet CommitManager java org eclips persist intern session commit manag commit new object class chang set commit manag java org eclips persist intern session CommitManager commitAllObjectsForClassWithChangeSet CommitManager java org eclips persist intern session commit manag commit object class chang set commit manag java org eclips persist intern session CommitManager commitAllObjectsWithChangeSet CommitManager java org eclips persist intern session commit manag commit object chang set commit manag java org eclips persist intern session AbstractSession writeAllObjectsWithChangeSet AbstractSession java org eclips persist intern session abstract session write object chang set abstract session java org eclips persist intern session UnitOfWorkImpl commitToDatabase UnitOfWorkImpl java org eclips persist intern session unit work impl commit databas unit work impl java org eclips persist intern session RepeatableWriteUnitOfWork commitToDatabase RepeatableWriteUnitOfWork java org eclips persist intern session repeat write unit work commit databas repeat write unit work java org eclips persist intern session UnitOfWorkImpl commitToDatabaseWithChangeSet UnitOfWorkImpl java org eclips persist intern session unit work impl commit databas chang set unit work impl java org eclips persist intern session RepeatableWriteUnitOfWork commitRootUnitOfWork RepeatableWriteUnitOfWork java org eclips persist intern session repeat write unit work commit root unit work repeat write unit work java org eclips persist intern session UnitOfWorkImpl commitAndResume UnitOfWorkImpl java org eclips persist intern session unit work impl commit resum unit work impl java org eclips persist intern jpa transact EntityTransactionImpl commitInternal EntityTransactionImpl java org eclips persist intern jpa transact entiti transact impl commit intern entiti transact impl java org eclips persist intern jpa transact EntityTransactionImpl commit EntityTransactionImpl java org eclips persist intern jpa transact entiti transact impl commit entiti transact impl java org apach ambari server orm AmbariJpaLocalTxnInterceptor invok AmbariJpaLocalTxnInterceptor java org apach ambari server orm ambari jpa local txn interceptor invok ambari jpa local txn interceptor java com googl inject intern InterceptorStackCallback InterceptedMethodInvocation proceed InterceptorStackCallback java com googl inject intern interceptor stack callback intercept method invoc proceed interceptor stack callback java com googl inject intern InterceptorStackCallback intercept InterceptorStackCallback java com googl inject intern interceptor stack callback intercept interceptor stack callback java org apach ambari server actionmanag ActionDBAccessorImpl EnhancerByGuice ddd persistActions lt gener gt org apach ambari server actionmanag action DB accessor impl enhanc guic ddd persist action lt gener gt org apach ambari server actionmanag ActionManager sendActions ActionManager java org apach ambari server actionmanag action manag send action action manag java org apach ambari server actionmanag ActionManager sendActions ActionManager java org apach ambari server actionmanag action manag send action action manag java org apach ambari server control AmbariManagementControllerImpl createAction AmbariManagementControllerImpl java org apach ambari server control ambari manag control impl creat action ambari manag control impl java org apach ambari server control intern RequestResourceProvider invok RequestResourceProvider java org apach ambari server control intern request resourc provid invok request resourc provid java org apach ambari server control intern RequestResourceProvider invok RequestResourceProvider java org apach ambari server control intern request resourc provid invok request resourc provid java org apach ambari server control intern AbstractResourceProvider createResources AbstractResourceProvider java org apach ambari server control intern abstract resourc provid creat resourc abstract resourc provid java org apach ambari server control intern RequestResourceProvider createResources RequestResourceProvider java org apach ambari server control intern request resourc provid creat resourc request resourc provid java org apach ambari server control intern ClusterControllerImpl createResources ClusterControllerImpl java org apach ambari server control intern cluster control impl creat resourc cluster control impl java org apach ambari server api servic persist PersistenceManagerImpl creat PersistenceManagerImpl java org apach ambari server api servic persist persist manag impl creat persist manag impl java org apach ambari server api handler CreateHandler persist CreateHandler java org apach ambari server api handler creat handler persist creat handler java org apach ambari server api handler BaseManagementHandler handleRequest BaseManagementHandler java org apach ambari server api handler base manag handler handl request base manag handler java org apach ambari server api servic BaseRequest process BaseRequest java org apach ambari server api servic base request process base request java org apach ambari server api servic BaseService handleRequest BaseService java org apach ambari server api servic base servic handl request base servic java org apach ambari server api servic BaseService handleRequest BaseService java org apach ambari server api servic base servic handl request base servic java org apach ambari server api servic RequestService createRequests RequestService java org apach ambari server api servic request servic creat request request servic java sun reflect GeneratedMethodAccessor invok unknown sun reflect gener method accessor invok unknown sourc sourc,0,0,0,0,0,ambari-web/app/utils/batch_scheduled_requests.js;ambari-web/test/controllers/main/host_test.js;,0 
6359,Antonenko Alexander,ambari-web,0,Hosts page : mysterious 'selected hosts' keep coming back, host page mysteri select host host keep come back,See attached video.Somehow  there are always 10 hosts selected. After explicitly hitting 'clear selection'  page refresh somehow reverts back to 10 hosts being selected., see attach video somehow video somehow alway host select select explicitli hit clear select select page refresh somehow revert back host select select,0,0,0,0,0,0,0 
6369,Xi Wang,ambari-web,0,hostname wrapping with icon asterisks on assign slaves, hostnam wrap icon asterisk assign slave,see attached., see attach attach,0,0,0,0,0,0,0 
6376,Aleksandr Kovalenko,ambari-web,0,Excessive requests are sending on hosts page, excess request send host page,When we open hosts page  we can see  that we have excessive requests as spinner appears two times one after another., open host page see excess request spinner appear two time one anoth anoth,0,0,0,0,0,0,0 
6379,Andrii Tkach,ambari-web,0,In Host Detailed Page  decommissioned NM is labeled as STOPPED, host detail page decommiss NM label STOPPED,In Yarn Service page  NodeManagers Status: 3 active / 0 lost / 0 unhealthy / 0 rebooted / 1 decommissionedIn Host Detailed Page of that decommissioned NM  the state of the NM is labeled as 'stopped'  which is not consistent comparing to Service page.API call:'href' : 'http://172.18.145.115:8080/api/v1/clusters/cl1/hosts/us3mon1404188570-3.cs1cloud.internal/host_components/NODEMANAGER'  'HostRoles' : { 'cluster_name' : 'cl1'  'component_name' : 'NODEMANAGER'  'desired_admin_state' : 'DECOMMISSIONED'  'desired_stack_id' : 'HDP-2.1'  'desired_state' : 'STARTED'  'host_name' : 'us3mon1404188570-3.cs1cloud.internal'  'maintenance_state' : 'OFF'  'service_name' : 'YARN'  'stack_id' : 'HDP-2.1'  'stale_configs' : false  'state' : 'INSTALLED' As a result  user cannot start the NodeManger as it is considered to be decommissioned by ResourceManger., yarn servic page NodeManagers node manag statu statu activ lost unhealthi reboot decommissionedIn decommiss host detail page decommiss NM state NM label stop stop not consist compar servic page API page API call href call href http api cluster cl host us mon cs cloud intern host_components NODEMANAGER http api cluster cl host us mon cs cloud intern host_components NODEMANAGER HostRoles host role cluster_name cluster_name cl cl component_name component_name NODEMANAGER NODEMANAGER desired_admin_state desired_admin_state DECOMMISSIONED DECOMMISSIONED desired_stack_id desired_stack_id HDP HDP desired_state desired_state STARTED STARTED host_name host_name us mon cs cloud intern us mon cs cloud intern maintenance_state maintenance_state service_name service_name YARN YARN stack_id stack_id HDP HDP stale_configs stale_configs fals state state INSTALLED INSTALLED result user cannot start NodeManger node manger consid decommiss ResourceManger resourc manger,0,0,0,0,0,0,0 
6402,Oleg Nechiporenko,ambari-web,0,Many services failed to start when using custom user names and groups, mani servic fail start use custom user name group,On Customize services page set next values for users and groups:Name: ValueProxy group for Hive WebHCat Oozie and Falcon: custom-usersgrHDFS User: custom-hdfsMapReduce User: custom-mapredYARN User: custom-yarnHBase User: custom-hbaseHive User: custom-hiveHCat User: custom-hcatWebHCat User: custom-hcatOozie User: custom-oozieFalcon User: custom-falconStorm User: custom-stormZooKeeper User: custom-zookeeperGanglia User: custom-nobodyNagios User: custom-nagiosNagios Group: custom-nagiosgrSmoke Test User: ambari-qaTez User: custom-tezHadoop Group: custom-hadoopgrSkip group modifications during install: falseAfter deploy many services fail to start:MapReduce  Hbase  Hive  WebHcat  Falcon  OozieSame error for all:Call From ins1404365245-9.cs1cloud.internal/172.18.145.154 to localhost:8020 failed on connection exception: java.net.ConnectException: Connection refused; For more details see: http://wiki.apache.org/hadoop/ConnectionRefused, custom servic page set next valu user group name group name ValueProxy valu proxi group hive WebHCat web cat oozi falcon falcon custom usersgrHDFS custom usersgr HDFS user user custom hdfsMapReduce custom hdf map reduc user user custom mapredYARN custom mapr YARN user user custom yarnHBase custom yarn base user user custom hbaseHive custom hbase hive user user custom hiveHCat custom hive cat user user custom hcatWebHCat custom hcat web cat user user custom hcatOozie custom hcat oozi user user custom oozieFalcon custom oozi falcon user user custom falconStorm custom falcon storm user user custom stormZooKeeper custom storm zoo keeper user user custom zookeeperGanglia custom zookeep ganglia user user custom nobodyNagios custom nobodi nagio user user custom nagiosNagios custom nagio nagio group group custom nagiosgrSmoke custom nagiosgr smoke test user user ambari qaTez ambari qa tez user user custom tezHadoop custom tez hadoop group group custom hadoopgrSkip custom hadoopgr skip group modif instal instal falseAfter fals deploy mani servic fail start MapReduce start map reduc hbase hive WebHcat web hcat falcon OozieSame oozi error call call in cs cloud intern in cs cloud intern localhost localhost fail connect except except java net ConnectException java net connect except connect refus refus detail see see,0,0,0,0,0,0,0 
6405,Aleksandr Kovalenko,ambari-web,0,Move Wizard: get stuck if wizard is running second time for the same component without page refresh, move wizard wizard get stuck wizard run second time compon without page refresh,STR:1. Run Move Wizard for some master component.2. Do not click Complete button after all operation will be finished. Close wizard (confirm closing).3. Without page refresh open wizard for the same master component and try it to reassign to another host (ex. back to the previous host).Wizard will get stuck  as source host for master component will be calculated incorrectly.This issue is related to host components mapper. After first running of move wizard in the model there were 2 masters one with host before moving and the new one. Old host component was deleted on server but UI model still contains it. And it brakes algorithm of calculating source host on assign master step., STR STR run move wizard master compon compon not click complet button oper finish finish close wizard confirm close close without page refresh open wizard master compon tri reassign anoth host ex ex back previou host wizard host wizard get stuck sourc host master compon calcul incorrectli incorrectli issu relat host compon mapper mapper first run move wizard model master one host move new one one old host compon delet server UI model still contain brake algorithm calcul sourc host assign master step step,0,0,0,0,0,0,0 
6406,Andrii Tkach,ambari-web,0,Move Wizard: assign master step next button is not disabled  when host input has error, move wizard wizard assign master step next button not disabl host input error,When Move Wizard is running on cluster with a large number of hosts  assign master step has input to enter hostname instead of select dropdown. If this dropdown is empty  it shows an error. But if in the same time target host was selected correctly the next button is enabled., move wizard run cluster larg number host assign master step input enter hostnam instead select dropdown dropdown dropdown empti show error error time target host select correctli next button enabl enabl,0,0,0,0,0,ambari-web/app/controllers/main/service/reassign/step2_controller.js;ambari-web/app/controllers/wizard/step5_controller.js;,0 
6409,Alejandro Fernandez,infra,0,Postgres create script generates errors for clusterconfig, postgr creat script gener error clusterconfig,Manually running the postgres create sql script encountered errors.Errors: psql:Ambari-DDL-Postgres-CREATE.sql:22: ERROR: column 'config_attributes' specified more than once psql:Ambari-DDL-Postgres-CREATE.sql:103: ERROR: relation 'clusterconfig' does not exist psql:Ambari-DDL-Postgres-CREATE.sql:126: ERROR: relation 'clusterconfig' does not existRepro Steps:1. Spin up a CentOS 6.4 VM vagrant up c6401 vagrant ssh c6401 sudo su - wget http://public-repo-1.hortonworks.com/ambari/centos6/1.x/updates/1.6.0/ambari.repo cp ambari.repo /etc/yum.repos.d yum install ambari-server -y2. Setup a postgres database vi /etc/yum.repos.d/CentOS-Base.repo edit the &#91;base&#93; and &#91;updates&#93; sections by adding the following line without quotes  'exclude=postgresql*' yum localinstall http://yum.postgresql.org/9.3/redhat/rhel-6-x86_64/pgdg-centos93-9.3-1.noarch.rpm yum install postgresql-server cd /etc/yum.repos.d/ service postgresql initdb chkconfig postgresql on service postgresql start3. Run the script cp /vagrant/Ambari-DDL-Postgres-CREATE.sql /var/lib/ambari-server/resources/ (assuming you have the latest file from trunk) cp /var/lib/ambari-server/resources/Ambari-DDL-Postgres-CREATE.sql /var/lib/pgsql/ su - postgres psql Follow step #1 at http://docs.hortonworks.com/HDPDocuments/Ambari-1.6.0.0/bk_ambari_reference/content/nndb-using-ambari-postgresql.html where $AMBARIDATABASE is ambari  $AMBARIUSER is postgres  and $AMBARISCHEMA is ambari. /i Ambari-DDL-Postgres-CREATE.sql;Then verify the errors. When done  issue /q on the psql command line to exit., manual run postgr creat sql script encount error error error error psql ambari DDL postgr CREATE sql psql ambari DDL postgr CREATE sql ERROR ERROR column config_attributes config_attributes specifi psql ambari DDL postgr CREATE sql psql ambari DDL postgr CREATE sql ERROR ERROR relat clusterconfig clusterconfig not exist psql ambari DDL postgr CREATE sql psql ambari DDL postgr CREATE sql ERROR ERROR relat clusterconfig clusterconfig not existRepro exist repro step step spin CentOS cent OS VM vagrant vagrant ssh sudo su wget cp ambari repo ambari repo etc yum repo etc yum repo yum instal ambari server ambari server setup postgr databas vi etc yum repo CentOS base repo etc yum repo cent OS base repo edit base base updat updat section ad follow line without quot exclud postgresql exclud postgresql yum localinstal yum instal postgresql server postgresql server cd etc yum repo etc yum repo servic postgresql initdb chkconfig postgresql servic postgresql start start run script cp vagrant ambari DDL postgr CREATE sql vagrant ambari DDL postgr CREATE sql var lib ambari server resourc var lib ambari server resourc assum latest file trunk trunk cp var lib ambari server resourc ambari DDL postgr CREATE sql var lib ambari server resourc ambari DDL postgr CREATE sql var lib pgsql var lib pgsql su postgr psql follow step AMBARIDATABASE AMBARIDATABASE ambari AMBARIUSER AMBARIUSER postgr AMBARISCHEMA AMBARISCHEMA ambari ambari ambari DDL postgr CREATE sql ambari DDL postgr CREATE sql verifi error error done issu psql command line exit exit,0,0,0,0,0,0,0 
6418,Andrii Tkach,ambari-web,0,Config pages load slowly on 2k-node cluster for some services, config page load slowli node node cluster servic,On the 2k-node cluster  service config pages load slowly (though the load time has improved significantly from before).The load time depends on the service.Here are some sample load times:HDFS: 5sYARN: 17sMR2: 16sTEZ: 10sHBASE: 3sHIVE: 13sWEBHCAT: 3sFALCON: 3sSTORM: 17sOOZIE: 11sGANGLIA: 1sNAGIOS: 1sZOOKEEPER: 2sPIG: 2sSQOOP: n/a (no config page), node node cluster servic config page load slowli though load time improv significantli load time depend servic servic sampl load time HDFS time HDFS sYARN YARN sMR MR sTEZ TEZ sHBASE HBASE sHIVE HIVE sWEBHCAT WEBHCAT sFALCON FALCON sSTORM STORM sOOZIE OOZIE sGANGLIA GANGLIA sNAGIOS NAGIOS sZOOKEEPER ZOOKEEPER sPIG PIG sSQOOP SQOOP no config page page,0,0,0,0,0,ambari-web/app/controllers/main/service/info/configs.js;ambari-web/app/data/global_properties.js;ambari-web/app/utils/ajax/ajax.js;ambari-web/app/utils/configs/defaults_providers/defaultsProvider.js;ambari-web/app/utils/configs/defaults_providers/yarn_defaults_provider.js;,0 
6426,Alejandro Fernandez,site,0,Link to ExtJS license in 'Choose Services' page has moved, link ExtJS ext JS licens choos choos servic servic page move,Step 4 of the Ambari installer has a broken link.When 'Choosing Services'  the link for the 'ExtJS' library license under the 'Oozie' service has moved from http://www.sencha.com/products/extjs/license/It should be updated to the URL below since it covers that Ext JS is available under GPL v3 license:http://www.sencha.com/legal/open-source-faq/, step ambari instal broken link link choos choos servic servic link ExtJS ext JS librari licens oozi oozi servic move updat URL sinc cover ext JS avail GPL licens http www sencha com legal open sourc faq licens http www sencha com legal open sourc faq,0,0,0,0,0,0,0 
6439,Andrii Babiichuk,ambari-web,0,Filter state does not clear in Background Operation popup and causes a lot of confusion, filter state not clear background oper popup caus lot confus,In the Background Operations popup  the filter state persists at the Host and Task levels  even after closing the popup (the filter should be cleared once the user goes back up one level or closes the popup).This causes a lot of confusion because the user will expect these filters to be cleared but instead cannot see the hosts and tasks that they are expecting., background oper popup filter state persist host task level even close popup filter clear user goe back one level close popup popup caus lot confus user expect filter clear instead cannot see host task expect expect,0,0,0,0,0,ambari-web/app/utils/host_progress_popup.js;,0 
6440,Aleksandr Kovalenko,ambari-web,0,Unable to move NameNode, unabl move NameNode name node,STR: Enabled NNHA.Active NameNode is on suse1101 hostStandby NameNode is on suse1102 host Stopped SNN. Opened move NN wizardResult: Next button is active when I choose existing topology (suse1101 and suse1102)Next button is inactive when I choose custom topology (suse1103 and suse1101)UPD: Reproduced also on non-HA cluster., STR STR enabl NNHA activ NNHA activ NameNode name node suse suse hostStandby host standbi NameNode name node suse suse host stop SNN SNN open move NN wizardResult wizard result next button activ choos exist topolog suse suse suse next suse next button inact choos custom topolog suse suse suse UPD suse UPD reproduc also non HA non HA cluster cluster,0,0,0,0,0,0,0 
6442,Antonenko Alexander,ambari-web,0,JS error occurs periodically when Job Details page is opened, JS error occur period job detail page open,'Uncaught TypeError: Cannot read property 'properties' of undefined'at /ambari-web/app/views/common/quick_view_link_view.js:246, uncaught uncaught TypeError type error cannot read properti properti properti undefin undefin ambari web app view common quick_view_link_view js ambari web app view common quick_view_link_view js,0,0,0,0,0,0,0 
6471,Srimanth Gunturi,ambari-web,0,Add Services Wizard can corrupt config files unpredictably, add servic wizard corrupt config file unpredict,Testing using the 1.6.1 RC bits (branch-1.6.1  hash=ffb702b252a8b979529864ec5579465a122060b5) revealed that Add Services can corrupt config files in an unpredictable manner.We have seen: adding Pig resulted in core-site dropping all existing properties except for 'hadoop.proxyuser.falcon.hosts and hadoop.proxyuser.falcon.groups' add Storm resulted in core-site retaining all existing properties but dropping hadoop.proxyuser.* settings for all services except Falcon adding Storm dropped a number of existing properties in yarn-site (and NodeManagers can no longer restart after that)The bottomline here is that behavior seems pretty random (adding the same service on different clusters results in different behavior).Also  when adding a service  certain configs (like hdfs-site) were not cloned while most other configs (like yarn-site  mapred-site) get cloned even if no property changes are made regardless of which service is added.Update: changes to hdfs-site during Add Services Wizard never persists., test use RC bit branch branch hash ffb ec hash ffb ec reveal add servic corrupt config file unpredict manner manner seen seen ad pig result core site core site drop exist properti except hadoop proxyus falcon host hadoop proxyus falcon host hadoop proxyus falcon group hadoop proxyus falcon group add storm result core site core site retain exist properti drop hadoop proxyus hadoop proxyus set servic except falcon ad storm drop number exist properti yarn site yarn site NodeManagers node manag no longer restart bottomlin behavior seem pretti random ad servic differ cluster result differ behavior also behavior also ad servic certain config like hdf site hdf site not clone config like yarn site yarn site mapr site mapr site get clone even no properti chang made regardless servic ad updat ad updat chang hdf site hdf site add servic wizard never persist persist,0,0,0,0,0,0,0 
6477,Andrii Babiichuk,ambari-web,0,AddHost Wizard: error for existing host is not present, AddHost add host wizard wizard error exist host not present,STR: Click AddHost Type existing host Click 'Register and Confirm' buttonActual result: There present only message about 'SSH Private Key is required'Excpected Result: SHould be also present message like 'These hosts are already exists'.---------------------------------Note: the excpected message only present if we type/select ss key and will click 'Register and Confirm', STR STR click AddHost add host type exist host click regist regist confirm confirm buttonActual button actual result result present messag SSH SSH privat key requir excpect requir excpect result result hould also present messag like host alreadi exist note exist note excpect messag present type select type select ss key click regist regist confirm confirm,0,0,0,0,0,ambari-web/app/controllers/wizard/step2_controller.js;,0 
6483,Oleg Nechiporenko,ambari-web,0,JS errors on Jobs page if ATS is stopped, JS error job page ATS stop,If ATS stopped  Jobs page continuously produces following js errors:NetworkError: 400 Bad Request - http://172.18.145.185:8080/proxy?url=http://us1mon1402550931-re-5.cs1cloud.internal:8188/ws/v1/timeline/HIVE_QUERY_ID?fields=events primaryfilters otherinfo&amp;secondaryFilter=tez:true&amp;limit=11&amp;_=1402578530622'proxy?...8530622'NetworkError: 400 Bad Request - http://172.18.145.185:8080/proxy?url=http://us1mon1402550931-re-5.cs1cloud.internal:8188/ws/v1/timeline/HIVE_QUERY_ID?limit=1&amp;secondaryFilter=tez:true&amp;_=1402578531674'proxy?...8531674'NetworkError: 400 Bad Request - http://172.18.145.185:8080/proxy?url=http://us1mon1402550931-re-5.cs1cloud.internal:8188/ws/v1/timeline/HIVE_QUERY_ID?limit=1&amp;secondaryFilter=tez:true&amp;_=1402578537654', ATS stop job page continu produc follow js error NetworkError error network error bad request primaryfilt otherinfo amp secondaryFilter tez true amp limit amp  proxi NetworkError otherinfo amp secondari filter tez true amp limit amp  proxi network error bad request bad request,0,0,0,0,0,0,1 
6491,Antonenko Alexander,ambari-web,0,Default config group name contains 'undefined' instead of service name in Manage Config Groups popup, default config group name contain undefin undefin instead servic name manag config group popup,,,0,0,0,0,0,0,0 
6499,Oleg Nechiporenko,ambari-web,0,Unable to proceed from step 4 of installer if YARN-dependent services are selected but YARN isn't (HDP 2.0), unabl proceed step instal YARN depend YARN depend servic select YARN HDP HDP,STROn step 4 of Install Wizard  select any of the services dependent on YARN (Piq  Oozie  Hive) but don't select YARN itself. Press 'Next' button.Expected resultPopup with the info about YARN dependence appears.Actual resultNothing happens. JS error occurs:Uncaught TypeError: Cannot read property 'get' of undefinedatapp/controllers/wizard/step4_controller.js:180, STROn STR step instal wizard select servic depend YARN piq piq oozi hive hive select YARN press next next button expect button expect resultPopup result popup info YARN depend appear actual appear actual resultNothing result noth happen happen JS error occur uncaught occur uncaught TypeError type error cannot read properti get get undefinedatapp control wizard step _controller js undefinedatapp control wizard step _controller js,0,0,0,0,0,0,0 
6504,Aleksandr Kovalenko,ambari-web,0,Incorrect errors count for YARN on step 7 of Install Wizard (HDP 2.0), incorrect error count YARN step instal wizard HDP HDP,'Customize Services' step indicates that 8 YARN properties need revision but no one is highlighted as incorrect., custom custom servic servic step indic YARN properti need revis no one highlight incorrect incorrect,0,0,0,0,0,0,0 
6521,Xi Wang,ambari-web,0,Hostname case sensitivity, hostnam case sensit,Hostname CaSe SeNsiTiVity causes hostnames don't match error.'in the install wizard  the hostnames MUST be lower case in the user input  otherwise the 'hostnames don't match' during the install and it fails. Ambari should tolower() both hosts before comparing.'Effected Install/Add Host Wizard., hostnam CaSe Ca Se SeNsiTiVity Se nsi Ti viti caus hostnam match error error instal wizard hostnam MUST lower case user input otherwis hostnam match match instal fail fail ambari tolow tolow host compar effect compar effect instal add instal add host wizard wizard,0,0,0,0,0,0,0 
6525,Andrii Babiichuk,ambari-web,0,Unable to install cluster after coming back to step 1 and selecting different stack version, unabl instal cluster come back step select differ stack version,STRProceed to step 7 of Install Wizard. Return to step 1 and choose a different stack version. Go forward.ResultUnable to proceed from step 3. JS error occurs:Uncaught Error: &lt;DS.StateManager:ember26192&gt; could not respond to event didChangeData in state rootState.loaded.updated.uncommitted.WorkaroundTo log out and log in again before perforfing installation with different stack version., STRProceed STR proce step instal wizard wizard return step choos differ stack version version Go forward ResultUnable forward result unabl proceed step JS error occur uncaught occur uncaught error error lt DS StateManager ember gt lt DS state manag ember gt could not respond event didChangeData chang data state rootState load updat uncommit WorkaroundTo root state load updat uncommit workaround log log perforf instal differ stack version version,0,0,0,0,0,ambari-web/app/controllers/wizard/step7_controller.js;ambari-web/app/mappers/stack_service_mapper.js;,0 
6539,Oleg Nechiporenko,ambari-web,0,Create main page with table of jobs, creat main page tabl job,,,0,0,0,0,0,0,1 
6558,Xi Wang,ambari-web,0,FE allows add host on host that is in UNKNOWN state (agent was stopped), FE allow add host host UNKNOWN state agent stop stop,added a host to a cluster (manually installed and started an agent)http://c6403.ambari.apache.org:8080/api/v1/hosts/c6401.ambari.apache.org{ 'href' : 'http://c6403.ambari.apache.org:8080/api/v1/hosts/c6401.ambari.apache.org'  'Hosts' : { 'host_health_report' : ''  'host_name' : 'c6401.ambari.apache.org'  'host_state' : 'HEALTHY'  'host_status' : 'HEALTHY' }}After the agent is stopped for the host{ 'href' : 'http://c6403.ambari.apache.org:8080/api/v1/hosts/c6401.ambari.apache.org'  'Hosts' : { 'host_health_report' : ''  'host_name' : 'c6401.ambari.apache.org'  'host_state' : 'HEARTBEAT_LOST'  'host_status' : 'UNKNOWN' }}At this point I can perform AddHost and start the wizard. But AddHost will eventually fail - although now I see it just waiting.We need some form of error indication when host is not lost., ad host cluster manual instal start agent http ambari apach org api host ambari apach org agent http ambari apach org api host ambari apach org href href http ambari apach org api host ambari apach org http ambari apach org api host ambari apach org host host host_health_report host_health_report host_name host_name ambari apach org ambari apach org host_state host_state HEALTHY HEALTHY host_status host_status HEALTHY HEALTHY agent stop host host href href http ambari apach org api host ambari apach org http ambari apach org api host ambari apach org host host host_health_report host_health_report host_name host_name ambari apach org ambari apach org host_state host_state HEARTBEAT_LOST HEARTBEAT LOST host_status host_status UNKNOWN UNKNOWN point perform AddHost add host start wizard wizard AddHost add host eventu fail although see wait wait need form error indic host not lost lost,0,0,0,0,0,0,0 
6568,Jaimin D Jetly,ambari-web,0,Service pluggability: New added services in the stack has Add Property link in log-4j and env categories, servic pluggabl pluggabl new ad servic stack add properti link log log env categori,,,0,0,0,0,0,0,1 
6570,Oleg Nechiporenko,ambari-web,0,Fast user can skip 'Customize Services' step (add service wizard) while configs are not loaded, fast user skip custom custom servic servic step add servic wizard wizard config not load,STR Install cluster Go to Add Service Wizard Proceed to step 'Customize services' While configs are loading click 'Next'.If user tried to install services with configs that should be provided manually using UI (like Nagios)  he will get JS-error on next step., STR instal cluster Go add servic wizard proce step custom custom servic servic config load click next next user tri instal servic config provid manual use UI like nagio nagio get JS error JS error next step step,0,0,0,0,0,0,0 
6571,Oleg Nechiporenko,ambari-web,0,'all/none' links affect already installed services on 'Select Services' step, none none link affect alreadi instal servic select select servic servic step,,,0,0,0,0,0,0,0 
6575,Antonenko Alexander,ambari-web,0,Linked Ganglia charts from Host Details page don't show any graphs (except on NameNode host), link ganglia chart host detail page show graph except NameNode name node host host,The UI links to Ganglia Web to display the graphs for a specific host as http://&lt;ganglia-host&gt;/ganglia/mobile_helper.php?show_host_metrics=1&amp;h=&lt;target-fqdn&gt;&amp;c=HDPNameNode&amp;r=hour&amp;cs=&amp;ce=Note that c=HDPNameNode is static.I believe this worked before as the NameNode gmond was repeated on all the hosts (we should not have and this has been fixed but now it's causing this issue).For this ticket  let's change the call the UI makes from 'HDPNameNode' to 'HDPSlaves' and verify that host-level Ganglia links work for all hosts on a multi-node cluster (including hosts with clients only)., UI link ganglia web display graph specif host HDPNameNode HDP name node static static believ work NameNode name node gmond repeat host not fix caus issu issu ticket let let chang call UI make HDPNameNode HDP name node HDPSlaves HDP slave verifi host level host level ganglia link work host multi node multi node cluster includ host client,0,0,0,0,0,0,1 
6585,Alejandro Fernandez,site,0,Deleted hosts come back to life after ambari-server restart, delet host come back life ambari server ambari server restart,When attempting to delete a host through the UI  and then re-add it  the re-add operation fails because a record already exists in the clusterhostmapping table.This can be reproduced as follows (host names will change of course) 1. Create a cluster and add a host so that it is populated in the clusterhostmapping table.2. Make sure the agent is running.3. On the server  run ambari-server restart  and immediately run the following repeatedly in another terminal window before the restart finishes  curl --write-out %{http_code} --show-error -u admin:admin -H 'X-Requested-By:1' -i -X DELETE http://c6404.ambari.apache.org:8080/api/v1/clusters/dev/hosts/c6407.ambari.apache.orgHTTP/1.1 200 OKSet-Cookie: AMBARISESSIONID=z91px2l41uc6dwjv52zl2mcu;Path=/Expires: Thu  01 Jan 1970 00:00:00 GMTContent-Type: text/plainContent-Length: 0Server: Jetty(7.6.7.v20120910)4. Quickly verify that the host name is removed from the clusterhostmapping table.5. On the agent  run ambari-agent restart  and repeatedly requery the clusterhostmapping table  until the record is reinserted (should take no more than 30 seconds to appear).6. Run the curl command to attempt to re-add the host  and receive the error message curl --write-out %{http_code} --show-error -u admin:admin -H 'X-Requested-By:1' -i POST http://c6404.ambari.apache.org:8080/api/v1/clusters/dev/hosts/c6407.ambari.apache.orgHTTP/1.1 500 Exception [EclipseLink-4002] (Eclipse Persistence Services - 2.4.0.v20120608-r11652): org.eclipse.persistence.exceptions.DatabaseException Internal Exception: java.sql.BatchUpdateException: Batch entry 0 INSERT INTO ClusterHostMapping (cluster_id  host_name) VALUES (2  'c6407.ambari.apache.org') was aborted. Call getNextException to see the cause. Error Code: 0 Call: INSERT INTO ClusterHostMapping (cluster_id  host_name) VALUES (?  ?) bind =&gt; [2 parameters bound]Set-Cookie: AMBARISESSIONID=1je1wahcml82f11gjrserxgdyl;Path=/Content-Type: text/plain;charset=ISO-8859-1Content-Length: 530Server: Jetty(7.6.7.v20120910){ 'status': 500  'message': 'Exception [EclipseLink-4002] (Eclipse Persistence Services - 2.4.0.v20120608-r11652): org.eclipse.persistence.exceptions.DatabaseException/nInternal Exception: java.sql.BatchUpdateException: Batch entry 0 INSERT INTO ClusterHostMapping (cluster_id  host_name) VALUES (2  /u0027c6407.ambari.apache.org/u0027) was aborted. Call getNextException to see the cause./nError Code: 0/nCall: INSERT INTO ClusterHostMapping (cluster_id  host_name) VALUES (?  ?)/n/tbind /u003d/u003e [2 parameters bound]'At this point  here is the state of the tables.select * from clusterhostmapping where host_name = 'c6407.ambari.apache.org'; cluster_id | host_name------------+------------------------- 2 | c6407.ambari.apache.orgselect * from hoststate where host_name = 'c6407.ambari.apache.org'; agent_version | available_mem | current_state | health_status | host_name | time_in_state | maintenance_state---------------------+---------------+---------------+----------------------------------------------+-------------------------+---------------+------------------- {'version':'1.6.0'} | 250232 | INIT | {'healthStatus':'HEALTHY' 'healthReport':''} | c6407.ambari.apache.org | 1405718796141 | {'2':'ON'}I then deleted both records  restarted the server  and was then able to add the host successfully.This is a bug in the persistence layer., attempt delet host UI add add add add oper fail record alreadi exist clusterhostmap tabl tabl reproduc follow host name chang cours cours creat cluster add host popul clusterhostmap tabl tabl make sure agent run run server run ambari server ambari server restart immedi run follow repeatedli anoth termin window restart finish curl write write http_code http_code show error show error admin admin admin admin request request DELETE OKSet cooki OK set cooki AMBARISESSIONID px uc dwjv zl mcu path expir AMBARISESSIONID px uc dwjv zl mcu path expir thu jan GMTContent type GMT content type text plainContent length text plain content length server server jetti jetti quickli verifi host name remov clusterhostmap tabl tabl agent run ambari agent ambari agent restart repeatedli requeri clusterhostmap tabl record reinsert take no second appear appear run curl command attempt add add host receiv error messag curl write write http_code http_code show error show error admin admin admin admin request request POST except EclipseLink eclips link eclips eclips persist servic org eclips persist except DatabaseException org eclips persist except databas except intern except except java sql BatchUpdateException java sql batch updat except batch entri INSERT ClusterHostMapping cluster host map cluster_id host_name host_name VALUES ambari apach org ambari apach org abort abort call getNextException get next except see caus caus error code code call call INSERT ClusterHostMapping cluster host map cluster_id host_name host_name VALUES bind gt gt paramet bound set cooki bound set cooki AMBARISESSIONID je wahcml gjrserxgdyl path content type AMBARISESSIONID je wahcml gjrserxgdyl path content type text plain charset ISO content length text plain charset ISO content length server server jetti jetti statu statu messag messag except except EclipseLink eclips link eclips eclips persist servic org eclips persist except DatabaseException nInternal org eclips persist except databas except intern except except java sql BatchUpdateException java sql batch updat except batch entri INSERT ClusterHostMapping cluster host map cluster_id host_name host_name VALUES ambari apach org ambari apach org abort abort call getNextException get next except see caus nError caus error code code nCall call INSERT ClusterHostMapping cluster host map cluster_id host_name host_name VALUES tbind tbind paramet bound bound point state tabl select tabl select clusterhostmap host_name ambari apach org ambari apach org cluster_id host_name host_name ambari apach orgselect ambari apach orgselect hoststat host_name ambari apach org ambari apach org agent_version available_mem current_state health_status host_name time_in_state maintenance_state maintenance_state version version INIT healthStatus HEALTHY health statu HEALTHY healthReport health report ambari apach org ambari apach org delet record restart server abl add host success success bug persist layer layer,0,0,0,0,0,0,1 
6587,Siddharth Wagle,ambari-server,0,Views: exception on server restart after creating view instance, view view except server restart creat view instanc,1) installed the files view (built from source)2) I created an instance of the viewPOSThttp://c6401.ambari.apache.org:8080/api/v1/views/FILES/versions/0.1.0/instances/MyFiles[ {'ViewInstanceInfo' : { 'properties' : { 'dataworker.defaultFs' : 'webhdfs://c6401.ambari.apache.org:50070'  'dataworker.username' : 'ambari-qa' } }} ]3) I restart ambari-server and get this exception  so ambari-server can't start up. If I delete the view jar and restart  then I can get ambari-server to start.00:41:59 433 INFO [main] Server:266 - jetty-7.6.7.v2012091000:41:59 914 WARN [main] WebAppContext:489 - Failed startup of context o.e.j.w.WebAppContext{/views/FILES/0.1.0/MyFiles file:/var/lib/ambari-server/resources/views/work/FILES%7B0.1.0%7D/} /var/lib/ambari-server/resources/views/work/FILES{0.1.0}java.util.zip.ZipException: invalid entry size (expected 12027 but got 11985 bytes) at java.util.zip.ZipInputStream.readEnd(ZipInputStream.java:403) at java.util.zip.ZipInputStream.read(ZipInputStream.java:195), instal file view built sourc sourc creat instanc viewPOSThttp ambari apach org api view FILES version instanc MyFiles view POS thttp ambari apach org api view FILES version instanc file ViewInstanceInfo view instanc info properti properti datawork defaultFs datawork default Fs webhdf ambari apach org webhdf ambari apach org datawork usernam datawork usernam ambari qa ambari qa restart ambari server ambari server get except ambari server ambari server start delet view jar restart get ambari server ambari server start start INFO main main server server jetti jetti WARN main main WebAppContext web app context fail startup context WebAppContext view FILES MyFiles web app context view FILES file file var lib ambari server resourc view work FILES file var lib ambari server resourc view work FILES var lib ambari server resourc view work FILES java util zip ZipException var lib ambari server resourc view work FILES java util zip zip except invalid entri size expect got byte byte java util zip ZipInputStream readEnd ZipInputStream java java util zip zip input stream read end zip input stream java java util zip ZipInputStream read ZipInputStream java java util zip zip input stream read zip input stream java,0,0,0,0,0,0,1 
6589,Jaimin D Jetly,ambari-web,0,Management Console: UI Layout  Basic Routing and Create User Management Page (with mock data), manag consol consol UI layout basic rout creat user manag page mock data data,,,0,0,0,0,0,0,1 
6603,Srimanth Gunturi,ambari-web,0,Install wizard should have ability to load default 'final' configs  and save them, instal wizard abil load default final final config save,In Ambari if a stack service has configs with final=true  then during install wizard these configs should have the final-checkbox checked. Also  if the user changes these checkboxes  the values should be stored in the properties_attributes of configs when Deploy is hit., ambari stack servic config final true final true instal wizard config final checkbox final checkbox check check also user chang checkbox valu store properties_attributes config deploy hit hit,0,0,0,0,0,0,0 
6609,Dmytro Sen,ambari-server,0,Ambari-DDL-Postgres-CREATE.sql fix for CLUSTER.OPERATE, ambari DDL postgr CREATE sql ambari DDL postgr CREATE sql fix CLUSTER OPERATE CLUSTER OPERATE,,,0,0,0,0,0,ambari-server/src/main/resources/Ambari-DDL-Postgres-CREATE.sql;,0 
6622,Srimanth Gunturi,ambari-server,0,BlueprintResourceProviderTest fails on exception message assertion, BlueprintResourceProviderTest blueprint resourc provid test fail except messag assert,testDecidePopulationStrategy_unsupportedSchema(org.apache.ambari.server.controller.internal.BlueprintResourceProviderTest) Time elapsed: 0.02 sec &lt;&lt;&lt; FAILURE!java.lang.AssertionError:Expected: (exception with message a string containing 'Configuration definition schema is not supported' and an instance of java.lang.IllegalArgumentException) got: &lt;java.lang.IllegalArgumentException: 'Configuration format provided in Blueprint is not supported'&gt;, testDecidePopulationStrategy_unsupportedSchema org apach ambari server control intern BlueprintResourceProviderTest test decid popul Strategy_unsupported schema org apach ambari server control intern blueprint resourc provid test time elaps elaps sec lt lt lt lt lt lt FAILURE java lang AssertionError expect FAILURE java lang assert error expect except messag string contain configur configur definit schema not support support instanc java lang IllegalArgumentException java lang illeg argument except got got lt java lang IllegalArgumentException lt java lang illeg argument except configur configur format provid blueprint not support gt support gt,0,0,0,0,0,0,0 
6623,Alejandro Fernandez,test,0,Fix unit tests that are broken after AMBARI-6533, fix unit test broken AMBARI AMBARI,Unit tests are broken after commit f3aab68ec417d8e2c39c216962e1e1d47d56d401The root cause is the properties in InMemoryDefaultTestModule.java., unit test broken commit aab ec aab ec root caus properti InMemoryDefaultTestModule java memori default test modul java,0,0,0,0,0,0,0 
6626,Jaimin D Jetly,ambari-web; site,0,HDP-1.3 stack shows HUE in select services page, HDP HDP stack show HUE select servic page,HUE is defined in HDP-1.3.2 stack with configuration sites but there is no agent scripts defining configure/stop/start/status functions for the service.HUE is not supported to work with Ambari. In that case we should not expose HUE via stack definition API as supported service of HDP-1.x stack., HUE defin HDP HDP stack configur site no agent script defin configur stop start statu configur stop start statu function servic HUE servic HUE not support work ambari ambari case not expos HUE via stack definit API support servic HDP HDP stack stack,0,0,0,0,0,0,0 
6628,Srimanth Gunturi,ambari-server,0,Cannot start ambari-server due to empty metainfo table, cannot start ambari server ambari server due empti metainfo tabl,Trying to deploy latest trunk build ambari-server-1.7.0-70 and hit the following when running ambari-server startambari-server.log01:30:53 074 INFO [main] AmbariServer:157 - ********* Meta Info initialized **********01:30:53 086 INFO [main] ClustersImpl:103 - Initializing the ClustersImpl01:30:53 679 INFO [main] AmbariManagementControllerImpl:230 - Initializing the AmbariManagementControllerImpl01:30:53 894 INFO [main] AmbariServer:487 - Checking DB store version01:30:53 894 WARN [main] AmbariServer:502 - Current database store version is not compatible with current server version  serverVersion=null  schemaVersion=null01:30:53 895 ERROR [main] AmbariServer:592 - Failed to run the Ambari Serverorg.apache.ambari.server.AmbariException: Current database store version is not compatible with current server version  serverVersion=null  schemaVersion=null at org.apache.ambari.server.controller.AmbariServer.checkDBVersion(AmbariServer.java:503) at org.apache.ambari.server.controller.AmbariServer.run(AmbariServer.java:164) at org.apache.ambari.server.controller.AmbariServer.main(AmbariServer.java:589)The metainfo table is empty with no values indicating version of Ambari installed., tri deploy latest trunk build ambari server ambari server hit follow run ambari server ambari server startambari server log startambari server log INFO main main AmbariServer ambari server meta info initi INFO main main ClustersImpl cluster impl initi ClustersImpl cluster impl INFO main main AmbariManagementControllerImpl ambari manag control impl initi AmbariManagementControllerImpl ambari manag control impl INFO main main AmbariServer ambari server check DB store version version WARN main main AmbariServer ambari server current databas store version not compat current server version serverVersion null server version null schemaVersion null schema version null ERROR main main AmbariServer ambari server fail run ambari serverorg apach ambari server AmbariException serverorg apach ambari server ambari except current databas store version not compat current server version serverVersion null server version null schemaVersion null schema version null org apach ambari server control AmbariServer checkDBVersion AmbariServer java org apach ambari server control ambari server check DB version ambari server java org apach ambari server control AmbariServer run AmbariServer java org apach ambari server control ambari server run ambari server java org apach ambari server control AmbariServer main AmbariServer java org apach ambari server control ambari server main ambari server java metainfo tabl empti no valu indic version ambari instal instal,0,0,0,0,0,0,0 
6630,Jaimin D Jetly,ambari-web,0,Add Service wizard: Retry installation functionality does not work, add servic wizard wizard retri instal function not work,API triggered on clicking Retry button results in failure with 400 status code, API trigger click retri button result failur statu code,0,0,0,0,0,0,0 
6638,Andrii Tkach,ambari-web,0,Config categories aren't displayed on 'Configure Services' step of Secrity Wizard, config categori display configur configur servic servic step secriti wizard,See the screenshot attached.JS error Uncaught TypeError: Cannot read property 'filterProperty' of undefined at ambari-web/app/views/common/configs/services_config.js:338, see screenshot attach JS attach JS error uncaught TypeError type error cannot read properti filterProperty filter properti undefin ambari web app view common config services_config js ambari web app view common config services_config js,0,0,0,0,0,ambari-web/app/controllers/main/admin/security/add/step2.js;ambari-web/app/views/common/configs/services_config.js;,1 
6640,Andrii Babiichuk,ambari-web,0,Memory leaks during tabs switching on 'Customize Services' page, memori leak tab switch custom custom servic servic page,Steps:Go to 'Customize services page'.Switch to other tab many a time (50 switches = about 100MB).Result: firefox browser gets 1.2 GB in memory., step Go step Go custom custom servic page switch page switch tab mani time switch MB result MB result firefox browser get GB memori memori,0,0,0,0,0,ambari-web/app/templates/common/configs/service_config.hbs;ambari-web/app/templates/common/configs/service_config_category.hbs;ambari-web/app/templates/common/configs/service_config_wizard.hbs;ambari-web/app/templates/common/configs/services_config.hbs;ambari-web/app/views/common/configs/services_config.js;ambari-web/test/views/common/configs/services_config_test.js;,1 
6664,Vitaly Brodetskyi,ambari-agent,0,Oozie service can not be started on Ambari server with external Postgres, oozi servic not start ambari server extern postgr,STR: Install single node cluster with Postgres 9 server as Ambari and Oozie DB (Stack - 2.0). Postgres server should be on dedicated host; Start all services.Actual result: Oozie server will not start.Error message for Oozie:2014-07-23 08:42:57 947 - Error while executing command 'start':Traceback (most recent call last): File '/usr/lib/python2.6/site-packages/resource_management/libraries/script/script.py'  line 111  in execute method(env) File '/var/lib/ambari-agent/cache/stacks/HDP/2.0.6/services/OOZIE/package/scripts/oozie_server.py'  line 43  in start oozie_service(action='start') File '/var/lib/ambari-agent/cache/stacks/HDP/2.0.6/services/OOZIE/package/scripts/oozie_service.py'  line 43  in oozie_service Execute( db_connection_check_command  tries=5  try_sleep=10) File '/usr/lib/python2.6/site-packages/resource_management/core/base.py'  line 148  in __init__ self.env.run() File '/usr/lib/python2.6/site-packages/resource_management/core/environment.py'  line 149  in run self.run_action(resource  action) File '/usr/lib/python2.6/site-packages/resource_management/core/environment.py'  line 115  in run_action provider_action() File '/usr/lib/python2.6/site-packages/resource_management/core/providers/system.py'  line 239  in action_run raise exFail: Execution of '/usr/jdk64/jdk1.7.0_45/bin/java -cp /usr/lib/ambari-agent/DBConnectionVerification.jar:/usr/lib/oozie/libserver/postgresql-9.0-801.jdbc4.jar org.apache.ambari.server.DBConnectionVerification jdbc:postgresql://&lt;host&gt;:5432/ooziedb oozieuser [PROTECTED] org.postgresql.Driver' returned 1. ERROR: Unable to connect to the DB. Please check DB connection properties.java.lang.ClassNotFoundException: org.postgresql.Driver, STR STR instal singl node cluster postgr server ambari oozi DB stack stack postgr server dedic host host start servic actual servic actual result result oozi server not start error start error messag oozi oozi error execut command start traceback start traceback recent call last last file usr lib python site packag resource_management librari script script py usr lib python site packag resource_management librari script script py line execut method env method env file var lib ambari agent cach stack HDP servic OOZIE packag script oozie_server py var lib ambari agent cach stack HDP servic OOZIE packag script oozie_server py line start oozie_service action start oozie_service action start file var lib ambari agent cach stack HDP servic OOZIE packag script oozie_service py var lib ambari agent cach stack HDP servic OOZIE packag script oozie_service py line oozie_service execut execut db_connection_check_command tri tri try_sleep try_sleep file usr lib python site packag resource_management core base py usr lib python site packag resource_management core base py line init self env run self env run file usr lib python site packag resource_management core environ py usr lib python site packag resource_management core environ py line run self run_action resourc self run_action resourc action action file usr lib python site packag resource_management core environ py usr lib python site packag resource_management core environ py line run_action provider_action provider_action file usr lib python site packag resource_management core provid system py usr lib python site packag resource_management core provid system py line action_run rais exFail ex fail execut usr jdk jdk  bin java usr jdk jdk  bin java cp usr lib ambari agent DBConnectionVerification jar usr lib oozi libserv postgresql jdbc jar usr lib ambari agent DB connect verif jar usr lib oozi libserv postgresql jdbc jar org apach ambari server DBConnectionVerification org apach ambari server DB connect verif jdbc postgresql lt host gt ooziedb jdbc postgresql lt host gt ooziedb oozieus PROTECTED PROTECTED org postgresql driver org postgresql driver return ERROR ERROR unabl connect DB DB pleas check DB connect properti java lang ClassNotFoundException properti java lang class not found except org postgresql driver org postgresql driver,0,0,0,0,0,0,1 
6667,Jonathan Hurley,null,0,Unit test failures on jenkins for Ambari 1.7.0 related to alerts., unit test failur jenkin ambari relat alert alert,Tests run locally and pass 100% consistently.These test results are fishy; they randomly fail on different OS deployments. Even the simple logic ones fail. There are only 5 alert targets ever created  yet there are 9 returned sometimes. I'm wondering if this is because we tried to load some data in the @BeforeClass instead of @Before - maybe there's a weird Guice/JUnit race condition going on.I can't say I can fix this with confidence since I can't reproduce it. I'm going to move some things to @Before and hope it helps.java.lang.AssertionError: expected:&lt;5&gt; but was:&lt;9&gt; at org.junit.Assert.fail(Assert.java:93) at org.junit.Assert.failNotEquals(Assert.java:647) at org.junit.Assert.assertEquals(Assert.java:128) at org.junit.Assert.assertEquals(Assert.java:472) at org.junit.Assert.assertEquals(Assert.java:456) at org.apache.ambari.server.orm.dao.AlertDispatchDAOTest.testFindAllTargets(AlertDispatchDAOTest.java:117), test run local pass consist consist test result fishi fishi randomli fail differ OS deploy deploy even simpl logic one fail fail alert target ever creat yet return sometim sometim wonder tri load data BeforeClass class instead mayb weird guic JUnit guic unit race condit go say fix confid sinc reproduc go move thing hope help java lang AssertionError help java lang assert error expect lt gt expect lt gt lt gt lt gt org junit assert fail assert java org junit assert fail assert java org junit assert failNotEquals assert java org junit assert fail not equal assert java org junit assert assertEquals assert java org junit assert assert equal assert java org junit assert assertEquals assert java org junit assert assert equal assert java org junit assert assertEquals assert java org junit assert assert equal assert java org apach ambari server orm dao AlertDispatchDAOTest testFindAllTargets AlertDispatchDAOTest java org apach ambari server orm dao alert dispatch DAO test test find target alert dispatch DAO test java,0,0,0,0,0,0,1 
6672,Vitaly Brodetskyi,ambari-agent,0,Oozie fails for stack 2.0 and 2.1, oozi fail stack,,,0,0,0,0,0,0,1 
6716,Antonenko Alexander,ambari-web,0,'Refresh configs' action doesn't work for Flume, refresh refresh config config action work flume,STR: Deployed cluster with Flume  without Flume Agents. Added Flume agent on each host. Configured 7 agents  assigned to different hosts. Changed config of one Flume agent. Clicked 'Refresh configs' action.Result: Nothing happened., STR STR deploy cluster flume without flume agent agent ad flume agent host host configur agent assign differ host host chang config one flume agent agent click refresh refresh config config action result action result noth happen happen,0,0,0,0,0,0,0 
6721,Yusaku Sako,ambari-web,0,Capacity Scheduler config cannot be saved, capac schedul config cannot save,STR: Go to YARN &gt; Config Under 'Scheduler' section  modify 'Capacity Scheduler' configs. Hit Save. The page reloads. The modifications are reverted back., STR STR Go YARN gt gt config schedul schedul section modifi capac capac schedul schedul config config hit save save page reload reload modif revert back back,0,0,0,0,0,0,0 
6729,Aleksandr Kovalenko,ambari-web,0,RM HA wizard is experimental but shouldn't be, RM HA wizard experiment,Installed 1.7.0 build and RM HA is not available unless I go enable #experimental.Should not be experimental. RM HA is available with HDP 2.1+ Stack (but not with HDP 2.0.* stack)., instal build RM HA not avail unless go enabl experiment experiment not experiment experiment RM HA avail HDP stack not HDP stack stack,0,0,0,0,0,0,1 
6735,Aleksandr Kovalenko,ambari-web,0,Once RM HA is config'd  none of the RM summary info or RM dashboard widgets show data, RM HA config config none RM summari info RM dashboard widget show data,Configure RM HA. None of the summary info shows in Services &gt; YARN &gt; Summary All of the RM Dashboard widgets show N/A, configur RM HA HA none summari info show servic gt gt YARN gt gt summari RM dashboard widget show,0,0,0,0,0,0,0 
6741,Andrii Babiichuk,ambari-web,0,On HDFS config page edit boxes with memory size values have incorrect behavior., HDFS config page edit box memori size valu incorrect behavior behavior,Go to HDFS config page.Change Name Node java heap size.Save configs.'Successful' message appears  but on config page edit boxes have wrong values.After clicking 'OK' fields get right value again.Same issue reproduced on Nano but it looks like there it fails to save configs., Go HDFS config page chang page chang name node java heap size save size save config success config success messag appear config page edit box wrong valu valu click OK OK field get right valu issu reproduc nano look like fail save config config,0,0,0,0,0,ambari-web/app/controllers/main/service/info/configs.js;ambari-web/test/controllers/main/service/info/config_test.js;,1 
6744,Aleksandr Kovalenko,ambari-web,0,'Select Host' page on Resource Manager HA Enabling wizard does not save selected values after next/back steps, select select host host page resourc manag HA enabl wizard not save select valu next back next back step,STR:1) Deploy cluster2) Go to Enable Resourse Manager Enable HA wizard3) Go to 'Select Host' page4) Select some different from default value in combobox 'Additional Resourse manager'5) Click 'Next' and go to 'Review' page6) Click 'Back' and again go to 'Select Host' page.Actual result: value in 'Additional Resourse Manager' is default againExpected result: value in 'Additional Resourse Manager' is the same with choosen previously., STR STR deploy cluster cluster Go enabl resours manag enabl HA wizard wizard Go select select host host page page select differ default valu combobox addit addit resours manag manag click next next go review review page page click back back go select select host host page actual page actual result result valu addit addit resours manag manag default againExpected expect result result valu addit addit resours manag manag choosen previous previous,0,0,0,0,0,0,1 
6749,Jonathan Hurley,null,0,Flume service should be in STARTED state when no agents configured, flume servic STARTED state no agent configur,When installing Flume service by default if we dont configure any agents  we end up with Flume being the only service shown in a red STOPPED state. For the case where there are no agents  this should be set to STARTED., instal flume servic default dont configur agent end flume servic shown red STOPPED state state case no agent set STARTED STARTED,0,0,0,0,0,ambari-server/src/main/resources/stacks/HDP/2.0.6/services/FLUME/package/scripts/flume_handler.py;ambari-server/src/test/python/stacks/2.0.6/FLUME/test_flume.py;,1 
6754,Aleksandr Kovalenko,ambari-web,0,Resource Manager HA: after enabling RM HA  UI does not display standby and active Resource Managers on Summary tab, resourc manag HA HA enabl RM HA UI not display standbi activ resourc manag summari tab,STR:1) Deploy 3-node cluster2) Enable RM HA3) Go to YARN Service page  Summary tabResult: There are not Resource Managers on Summary tab4) Select config tab and after that return back to Summary tabResult: Summary tab is as expected, STR STR deploy node cluster cluster enabl RM HA HA Go YARN servic page summari tabResult tab result not resourc manag summari tab tab select config tab return back summari tabResult tab result summari tab expect,0,0,0,0,0,0,1 
6769,Andrii Babiichuk,ambari-web,0,Add security configs on Add service wizard, add secur config add servic wizard,add service wizard doesn't add secure cinfigs, add servic wizard add secur cinfig,0,0,0,0,0,ambari-web/app/controllers/global/cluster_controller.js;ambari-web/app/controllers/main/admin/highAvailability_controller.js;ambari-web/app/controllers/main/admin/security/add/step4.js;ambari-web/app/controllers/main/host/details.js;ambari-web/app/controllers/main/service/item.js;ambari-web/app/controllers/wizard/step7_controller.js;ambari-web/app/controllers/wizard/step8_controller.js;ambari-web/app/mixins.js;ambari-web/app/mixins/wizard/addSecurityConfigs.js;ambari-web/app/views/main/admin/highAvailability_view.js;ambari-web/test/controllers/main/admin/security/add/step4_test.js;ambari-web/test/controllers/wizard/step8_test.js;ambari-web/test/mixins/wizard/addSeccurityConfigs_test.js;ambari-web/app/templates/main/admin/highAvailability.hbs;,1 
6782,Jaimin D Jetly,ambari-web,0,Wizard: Adding Master component does not create and install the master host component, wizard wizard ad master compon not creat instal master host compon,STR: On 3-node cluster  Go to Assign Masters page. Add another HBase Master. (Note: HBase Master and ZK server are only addable components.) Go forward to the review page. Review page will show correct information that 2 HBase master are selected for installation Eventually on deploying the cluster installation  HBase Master is only created and installed on the host that was a default selection on Assign Master page, STR STR node cluster Go assign master page page add anoth HBase base master master note note HBase base master ZK server addabl compon compon Go forward review page page review page show correct inform HBase base master select instal eventu deploy cluster instal HBase base master creat instal host default select assign master page,0,0,0,0,0,0,0 
6787,Xi Wang,ambari-web,0,Cleanup of Cluster > Admin tab, cleanup cluster admin tab,1. Remove 'Users' and 'Access' category from 'Admin' tab on the main menu.2. Rename 'Clusters' --&gt; 'Repositories'3. Rename 'misc' --&gt; 'Service Accounts', remov user user access access categori admin admin tab main menu menu renam cluster cluster gt gt repositori repositori renam misc misc gt gt servic servic account account,0,0,0,0,0,0,1 
6788,Aleksandr Kovalenko,ambari-web,0,Ambari installation webhcat templeton.hive.properties set thrift host name to be localhost, ambari instal webhcat templeton hive properti templeton hive properti set thrift host name localhost,PROBLEM:default installation of Ambari sets webhcat-site.xmltempleton.hive.properties=hive.metastore.local=false  hive.metastore.uris=thrift://localhost:9933  hive.metastore.sasl.enabled=falsethe proper value should be the FQDN of the thrift host name  plus hive.metastore.execute.setugi=truefor example:hive.metastore.local=false  hive.metastore.uris=thrift://this.fqdn.com:9933  hive.metastore.sasl.enabled=false hive.metastore.execute.setugi=true, PROBLEM default PROBLEM default instal ambari set webhcat site xmltempleton hive properti hive metastor local fals webhcat site xmltempleton hive properti hive metastor local fals hive metastor uri thrift localhost hive metastor uri thrift localhost hive metastor sasl enabl falseth hive metastor sasl enabl falseth proper valu FQDN thrift host name plu hive metastor execut setugi truefor hive metastor execut setugi truefor exampl hive metastor local fals exampl hive metastor local fals hive metastor uri thrift fqdn com hive metastor uri thrift fqdn com hive metastor sasl enabl fals hive metastor sasl enabl fals hive metastor execut setugi true hive metastor execut setugi true,0,0,0,0,0,0,0 
6793,Aleksandr Kovalenko,ambari-web,0,Need ResourceManager UI Quicklinks for active / standby, need ResourceManager resourc manag UI quicklink activ standbi,Similar to NN HA., similar NN HA HA,0,0,0,0,0,0,0 
